 a novel hybrid approach of rough set and neural network for extract classification knowledge. 
induction of classification rule base on rough set and neural network have be an active research area in the field of machine learning due to their strength of hand imprecise and nonlinear problem. 
however from previous literature rough set be only a pre processing tool to eliminate redundant datum and neural network act as a classifier to output classification. 
since neural network operate in black box fashion and lack explanation facility for result knowledge it be often difficult to extract rule from a train neural network. 
in this paper from a new prospective a novel hybrid approach base on rough set and neural network have be propose. 
our hybrid approach consist of three phrase firstly use rough set to reduce redundant attribute from a decision table and then a neural network be train to delete noisy attribute and record in the table. 
finally classification rule be generate from the reduce decision table by variable precision rough set model. 
the new approach have be apply to two artificial dataset and two real world dataset. 
the empirical result show that the propose approach be more effective than some available hybrid approach in generate classification knowledge. 
population forecasting model base on wavelet least square support vector machine. 
a new population forecasting model base on wavelet least square support vector machine wls svm be propose in this paper. 
support vector machine svm be a new kind of neural network base on statistical learning theory which be a powerful tool to deal with problem such as small sample nonlinearity high dimension and local minima. 
ls svm be a refined svm which use equality instead of inequality constraint of standard svm to simplify calculation of parameter of svm. 
wavelet kernel function be use to construct wls svm in this paper. 
because this kind of kernel function can simulate almost any function in square integral space it enhance the generalization ability of the svm. 
base on wavelet kernel function wls svm regression model be propose. 
then the wls svm regression model deduce a new population forecasting method. 
experiment on predication of population of china show the propose method have high precision than classical neural network such as radial basis function rbf neural network. 
a parallel independent component implement base on learn update with form of matrix transformation. 
pvm parallel virtual machine library be a tool which use process large amount of datum set. 
this paper want to achieve a high performance solution that exploit pvm library and parallel computer to solve ica independent component analysis problem. 
the paper present parallel power ica implementation to decomposition datum set. 
power iteration pi be an algorithm for independent component analysis which have some desire feature. 
it have high performance and data capacity than current sequential implementation. 
this paper we show the power iteration algorithm which learn updating be in the form of matrix transformation. 
from power iteration algorithm we develop parallel power iteration algorithm and implement parallel component decomposition solution. 
at last experimental result analysis and future plan be present. 
research on rheological property of magnetorheological fluid. 
the magnetorheological mr fluid be a new functional material. 
it be colloidal solution that solid grain be spread around fluid equably. 
it have be use in many region for good controllable feature and mechanical feature. 
as for advanced optical manufacturing technology magnetorheological finishing mrf be decide by the rheological property of mr fluid to a great extent. 
take into account the need of mrf the component of mr fluid be choose the evaluate system of rheological property of mr fluid be establish. 
the effect on mr fluid by component scale be research by experiment on measurement equipment. 
from that the theological property that magnetorheological fluid in the presence of an apply magnetic field and in the different shear strain rate be obtain. 
meanwhile the effect on mrf be research by experiment on the mrf prototype machine e tool. 
the influence to surface quality be analyze. 
the result show that the relationship among the rheological property and the component scale of mr fluid and apply effect can be establish by the theoretically analyze and experiment research. 
the result provide the basis for mr fluid engineering development and engineering application. 
on the stability and bias variance analysis of kernel matrix learning. 
stability and bias variance analysis be two powerful tool to understand learn algorithm well. 
we use these tool to analyze learn the kernel matrix lkm algorithm. 
the motivation come from i lkm work in the transductive setting where both training and test datum point be to be give apriori. 
hence it be worth know the stability of lkm under small variation in the datum set and ii it have be argue that lkm overfit the give datum set. 
in particular we be interested in answer the follow question a be lkm a stable algorithm b do they overfit c what be the bias behavior with different optimal kernel. 
our experimental result show that lkm do not overfit the give datum set. 
the stability analysis reveal that lkm be unstable algorithm. 
the transformation between fuzzy cognitive map and a class of simplified dynamical cognitive network. 
cognitive map cm fuzzy cognitive map fcm and dynamical cognitive network dcn be three relate tool for model human being s cognition and facilitate machine inference accordingly. 
a main desirable feature of fcm be that it be easy to use for modeling and visualize human knowledge. 
different model in the cm family have different capability in capture human knowledge. 
however a recent theoretical result show that a cm can be transform into a fcm and vice versa. 
this paper report that a class of simplified dcn can also be transform into fcm. 
foreign exchange trading with support vector machines. 
this paper analyze and examine the general ability of support vector machine svm model to correctly predict and trade daily eur exchange rate direction. 
seven model with vary kernel function be consider. 
each svm model be benchmarke against traditional forecasting technique in order to ascertain its potential value as out of sample forecasting and quantitative trading tool. 
it be find that hyperbolic svm perform well in term of forecasting accuracy and trading result via a simulated strategy. 
this support the idea that svm be promise learning system for cope with nonlinear classification task in the field of financial time series application. 
automatic morphological query expansion use analogy base machine learning. 
information retrieval system irs usually suffer from a low ability to recognize a same idea that be express in different form. 
a way of improve these system be to take into account morphological variant. 
we propose here a simple yet effective method to recognize these variant that be far use so as to enrich query. 
in comparison with already publish method our system do not need any external resource or a priori knowledge and thus support many language. 
this new approach be evaluate against several collection six different language and be compare to exist tool such as a stemmer and a lemmatizer. 
report result show a significant and systematic improvement of the whole irs efficiency both in term of precision and recall for every language. 
numerical optimization of an industrial multi step stamping process by use the design of experiment method. 
the deep drawing process consist in realize part with complex shape like different kind of box cup etc from a metal sheet. 
these part be obtain through one or several stamping step. 
the tool setup motion of the stamping process be difficult to obtain. 
it require practice and special knowledge on the process. 
the design be long and difficult to optimize. 
it be expensive in machine tool operation because it need many trial and modification on the tool before obtain the right shape and the good working of the tool. 
the main reason of these difficulty come from the strain heterogeneity the spring back after the tool remove and the decrease of thickness. 
there be many influent parameter for this kind of process. 
they modify directly the shape of the part. 
these parameter can be list in three different category firstly the parameter link to the tool geometry like the die enter radius the punch diameter and the clearance between die and punch. 
secondly the parameter link to the manufacturing condition like the stamp speed the lubricant and the blank holder force. 
and thirdly the parameter link to the flank geometry. 
this paper propose a systematic method of stamp progression optimization illustrate on an industrial five part make from five form step. 
by use empirical rule and industrial knowledge the number of step the nominal dimension and process condition be define. 
from this initial tool definition the numerical simulation by the finite element method of the stamp step be carry out use abaqus software. 
then the parameter of each stage which have an influence on the shape of the final stamped part have to be select. 
a range of variation around their nominal value be define. 
experimental design be use to test the influence of these parameter in the numerical simulation. 
this allow to establish a mathematical model between the geometrical variation on the part and select influent parameter. 
with this model an optimization of these parameter can be realize to find their good value. 
machine strategy choice performance viewer. 
nowadays high speed machining hsm machine tool combine productivity and part quality. 
so mould and die maker invest in hsm. 
die and mould feature be more and more complex shape. 
thus it be difficult to choose the good machining strategy accord to part shape. 
geometrical analysis of machine feature be not sufficient to make an optimal choice. 
some research show that security technical functional and economical constrain must be take into account to elaborate a machining strategy. 
during complex shape machining production system limit induce feed rate decrease thus loss of productivity in some part area. 
in this paper we propose to analyse these area by estimate tool path quality. 
first we perform experiment on hsm machine tool to determine trajectory impact on machine tool behaviour. 
then we extract critical criterion and establish model of performance loss. 
our work be focus on machine tool kinematical performance and numerical controller unit calculation capacity. 
we implement these model on esprito(r cam software. 
during machine trajectory creation critical part area can be visualize and analyze. 
parameter such as segment or be length nature of discontinuity encounter be use to analyse critical part area. 
accord to this visualization process development engineer should validate or modify the trajectory. 
identification of cut relation in high speed mill. 
the knowledge of the cut force and their evolution along time be very interesting for the optimisation and the monitoring of the machining process. 
the prediction of the time evolution of the cut force could allow optimize tool geometry or well adapt the cut condition and the machine tool to the considered machining operation in order to minimize the level of cut force. 
it could also be helpful to optimize tool trajectory in cam software for example. 
the objective of this study be to improve the qualification procedure of a tool for mill a give material consider first the local geometry of the cutting edge and go back then to the global geometry of the consider tool or tool family. 
this methodology can be adapt for all global shape of tool even in the case of complex geometry. 
only the local definition of the cutting edge must be constant so that the methodology could be applicate to several tool of the family. 
this study have also be possible thank to the use of a dynamometer with accelerometric compensation allow to obtain good quality signal even at high frequency of tool rotation. 
cross lingual document clustering. 
the ever increase number of web accessible document be available in language other than english. 
the management of these heterogeneous document collection have pose a challenge. 
this paper propose a novel model call a domain alignment translation model to conduct cross lingual document clustering. 
while most exist cross lingual document cluster method make use of an expensive machine translation system to fill the gap between two language our model aim to effectively handle the cross lingual document cluster by learn a cross lingual domain alignment model and a domain specific term translation model in a collaborative way. 
experimental result show our method c tls without any resource other than a bilingual dictionary can achieve comparable performance to the direct machine translation method via a machine translation system google language tool. 
also our method be more efficient. 
incremental learning and its application to bush condition monitoring. 
the problem of fault diagnosis of electrical machine have be an ongoing research in power system. 
many machine learning tool have be apply to this problem use static machine learning structure such as neural network support vector machine that be unable to accommodate new information as it become available into their exist model. 
this paper present a new method to bush fault condition monitoring use fuzzy artmap(fam. 
fam be introduce for bush condition monitoring because it have the ability to incrementally learn information as it become available. 
an ensemble of classifier be use to improve the classification accuracy of the system. 
the testing result show that fam ensemble give an accuracy of 98.5. 
furthermore the result show that fuzzy artmap can update its knowledge in an incremental fashion without forget previously learn information. 
a neural fuzzy pattern recognition algorithm base cut tool condition monitoring procedure. 
an intelligent tool wear monitor system for metal cutting process will be introduce in this paper. 
the system be equip with four kind of sensor signal transforming and collect apparatus and a micro computer. 
a knowledge base intelligent pattern recognition algorithm have be develop. 
the fuzzy drive neural network can carry out the integration and fusion of multi sensor information. 
the weighted approach degree can measure the difference of signal feature accurately and anns successfully recognize the tool wear state. 
the algorithm have strong learning and noise suppression ability. 
this lead to successful tool wear classification under a range of machining condition. 
an expert system for fault diagnosis repair and maintenance of electrical machine. 
this paper present an original software tool base on a model of expert system that have be develop to satisfy the requirement of fault diagnosis repair and maintenance of electrical machine in industrial educational or other application. 
this software comprise an sql server database and provide different user level simple user power user and administrator. 
by the introduction of suitable weighting factor concern the priority of knowledge base question an artificial intelligence approach be achieve. 
a simple user friendly and flexible interface be use while low hardware requirement be need. 
this software provide efficient monitoring of the operational condition of electrical machine reduce time and cost of repair and improve maintenance procedure. 
resample approach for anomalous change detection. 
we investigate the problem of identify pixel in pair of co registered image that correspond to real change on the ground. 
change that be due to environmental difference illumination atmospheric distortion etc or sensor difference focus contrast etc will be widespread throughout the image and the aim be to avoid these change in favor of change that occur in only one or a few pixel. 
formal outlier detection scheme such as the one class support vector machine can identify rare occurrence but will be confound by pixel that be c equally rare in both image they may be anomalous but they be not change. 
we describe a resample scheme we have develop that formally address both of these issue and reduce the problem to a binary classification a problem for which a large variety of machine learning tool have be develop. 
in principle the effect of misregistration will manifest themselves as pervasive change and our method will be robust against they but in practice misregistration remain a serious issue. 
machine center efficiency optimization use artificial intelligence. 
this paper present machine parameter optimization base on usage of artificial intelligence. 
to increase efficiency and productivity of machine tool optimal cutting parameter have to be obtain in order to find optimal cut parameter genetic algorithm ga be use as optimal solution finder. 
ga be optimization algorithm base on artificial intelligence. 
optimization have to yield minimum machining time and minimum production cost while consider technological and material constrain. 
artificial intelligence in definition of material enter datum that determine quality finish after awj cutting process. 
tolerance of set awj cut parameter on each material have big influence on quality finish and all characteristic of material kefr after cut process. 
there be direct relation between specie of workpiece material and final result obtain after awj cutting. 
thus there be a need to have a tool for right material setting choose optimal cut parameter and find relation between each variable of cut process. 
use of information technology especially machine learning method should be the right way. 
from all method the receptive field weighted regression rfwr can be use as a function approximator for different mapping task like learn the value function for reinforcement learning. 
after learn process we can do several operation with obtain datum base like a choosing of cut condition for new or incomplete deffine material or find relation between each property of awj process. 
design of an expert information system for decision making in the textile industry. 
the overarch goal of this study be to create an expert information system for decision making in the textile industry. 
base on knowledge engineering. 
knowledge of the design of a new product knowledge of the current manufacturing process knowledge of how the machinery currently operate knowledge of the machinery s flexibility knowledge of machine time with this expert system prototype we can provide a useful information tool for the designer who want to introduce new product or make change to its current configuration. 
it can help he make decision in this design task and will provide he at all time information on the repercussion his design modification will have on his production system. 
surface quality in the electric discharge machining process. 
the unconventional manufacturing method technology mainly electric discharge machining have be perform for over 20 year within the faculty for machine building from technical university of cluj napoca. 
lately the research have be extend also on the last generation of machine that be receive within international research program. 
concern the electric discharge machining method it be very important to record the variation of the parameter depend on the material and on the depth of the work piece. 
it must be mention that for a well planning of electric discharge machining technology be necessary a very good knowledge of the work parameter. 
the article present some result about the roughness variation depend on the depth of the work piece speed of cutting and material. 
fuzzy control of feed drive in end milling process. 
this paper discuss the application of fuzzy adaptive control strategy to the problem of cut force control in high speed end mill operation. 
the research be concern with integrate adaptive control with a standard computer numerical controller cnc for optimize a metal cutting process. 
it be design to adaptively maximize the feedrate subject to allowable cut force on the tool which be very beneficial for a time consume complex shape machining. 
the purpose be to present a reliable robust neural controller aim at adaptively adjust feed rate to prevent excessive tool wear tool breakage and maintain a high chip removal rate. 
numerous simulation and experiment be conduct to confirm the efficiency of this architecture. 
application of dynamic model and an sv machine to inflation modelling. 
base on work we investigate the quantifying of statistical structural model parameter of inflation in slovak economic. 
dynamic and svm s supper vector machine modelling approach be use for automate specification of a functional form of the model in datum mining system. 
base on dynamic modelling we provide the fit of the inflation model over the period 1993 2003 in the slovak republic and use they as a tool to compare their forecasting ability with those obtain use svm s method. 
some methodological contribution be make to dynamic and svm s modelling approach in economic and to their use in data mining system. 
the study discuss analytically and numerically demonstrate the quality and interpretability of the obtain result. 
the svm s methodology be extend to predict the time series model. 
use machine learning techniques to analyze and support mediation of student e discussion. 
student be start to use networked visual argumentation tool to discuss debate and argue with one another about topic present by a teacher. 
however this development give rise to an emergent issue for teacher how do they support student during these e discussion the argunaut system aim to provide the teacher or moderator with tool that will facilitate effective moderation of several simultaneous e discussion. 
awareness indicators provide as part of a moderator s user interface help monitor the progress of discussion on several dimension e.g. critical reasoning. 
in this paper we discuss preliminary step take in use machine learn technique to support the awareness indicators. 
focus on individual contribution single object contain textual content contribute in the visual workspace by student and sequence of two link contribution two object the connection between they and the student textual contribution we have run a series of machine learn experiment in an attempt to train classifier to recognize important student action such as use critical reasoning and raise and answer question. 
the initial result present in this paper be encouraging but we be only at the beginning of our analysis. 
predict students performance with simstudent learn cognitive skills from observation. 
simstudent be a machine learn agent that learn cognitive skill by demonstration. 
simstudent be originally build as a building block for cognitive tutor authoring tools to help an author build a cognitive model without significant programming. 
in this paper we evaluate a second use of simstudent viz student modeling for intelligent tutoring systems. 
the basic idea be to have simstudent observe human student solve problem. 
it then create a cognitive model that can replicate the student performance. 
if the model be accurate it would predict the human student performance on novel problem. 
an evaluation study show that when train on 15 problem simstudent accurately predict the human student correct behavior on the novel problem more than 80 of the time. 
however the current implementation of simstudent do not accurately predict when the human student make error. 
machine learn technique for decision support in anesthesia. 
the grow availability of measurement device in the operating room enable the collection of a huge amount of datum about the state of the patient and the doctor practice during a surgical operation. 
this paper explore the possibility of generating from these datum decision support rule in order to support the daily anesthesia procedure. 
in particular we focus on machine learn technique to design a decision support tool. 
the preliminary test in a simulation setting be promise and show the role of computational intelligence technique in extract useful information for anesthesiologist. 
content collection for the labelling of health relate web content. 
as the number of health relate web site in various language increase so do the need for control mechanism that give the user adequate guarantee on whether the web resource they be visit meet a minimum level of quality standard. 
base upon state of the art technology in the area of semantic web content analysis and quality labelling the medieq project integrate exist technology and test they in a novel application the automation of the labelling process in health relate web content. 
medieq provide tool that crawl the web to locate unlabelled health web resource to label they accord to pre defined labelling criterion as well as to monitor they. 
this paper focus on content collection and discuss our experiment in the english language. 
on the combination of dissimilarity for gene expression data analysis. 
dna microarray technology allow we to monitor the expression level of thousand of gene simultaneously. 
this technique have become a relevant tool to identify different type of cancer. 
several machine learning technique such as the support vector machines svm have be propose to this aim. 
however common svm algorithm be base on euclidean distance which do not reflect accurately the proximity among the sample profile. 
the svm have be extend to work with non euclidean dissimilarity. 
however no dissimilarity can be consider superior to the other because each one reflect different feature of the datum. 
in this paper we propose to combine several support vector machines that be base on different dissimilarity to improve the performance of classifier base on a single measure. 
the experimental result suggest that our method reduce the misclassification error of classifier base on a single dissimilarity and a widely use combination strategy such as bagging. 
bayesian belief network for astronomical object recognition and classification in cti ii. 
the university of new mexico unm be currently design and build the cce transit instrument ii cti ii mcgraw et al. 
2006 a 1.8 m transit survey telescope. 
the stationary cti ii use the time delay and integrate readout mode with a mosaic of ccd to generate over 100 gigapixel per night which be require to be analyze within a day of observation. 
we be attempt to develop robust machine learning technique that use multiple scientific and engineering datum stream to classify object within an image frame and the image frame itself. 
we propose the use of bayesian belief net as both classifier and as tool to integrate and explore the datum stream. 
this initial report explore the use of bayesian network as source noise separator. 
instantiation of parameterized data structure for model base testing. 
model base testing be bind by essence to use the enumerate data structure of the system under test sut. 
on the other hand formal modeling often involve the use of parameterized data structure in order to be more general such a model should be sufficient to test many implementation variant and to abstract irrelevant detail. 
consequently the validation engineer be soon or later require to instantiate these parameter. 
at the current time this instantiation activity be a matter of experience and knowledge of the sur. 
this work investigate how to rationalize the instantiation of the model parameter. 
it be obvious that a poor instantiation may badly influence the quality of the result test. 
however recent result in instantiation base theorem proving and their application to software verification show that it be often possible to guess the small most general datum enumeration. 
we first provide a formal characterization of what a most general instantiation be in the framework of functional testing. 
then we propose an approach to automate the instantiation of the model parameter which leave the specifi and the validation engineer free to use the desire level of abstraction during the model design process without have to satisfy any finiteness requirement. 
we investigate case where delay the instantiation be not a problem. 
this work be illustrate by a realistic running example. 
it be present in the framework of the bz testing tools methodology which use a b abstract machine for model base testing and target many implementation language. 
a generic flash base animation engine for prob. 
write a formal specification for real life industrial problem be a difficult and error prone task even for expert in formal method. 
in the process of specify a formal model for later refinement and implementation it be crucial to get approval and feedback from domain expert to avoid the cost of change a specification at a late point of the development. 
but understand formal model write in a specification language like b require mathematical knowledge a domain expert might not have. 
in this paper we present a new tool to visualize b machines use the prob animator and macromedia flash. 
our tool offer an easy way for specifier to build a domain specific visualization that can be use by domain expert to check whether a b specification correspond to their expectation. 
from maxent to machine learning and back. 
to jaynes in his original paper maxent be a method of reasoning which ensure that no unconscious arbitrary assumption have be introduce while fifty year later the maxent conference home page suggest that the method be not yet fully available to the statistic community at large. 
in fact it be possible to see that generalize maxent problem often in disguise do play a significant role in machine learning and statistic. 
deviation from the classic form of the problem be typically use to incorporate some form of prior knowledge. 
sometimes that knowledge would be difficult or impossible to represent with only linear constraint or an initial guess for the density. 
to clarify these connection a good place to start be the classic maxent problem. 
this can then be generalize until the problem encompass a large class of problem study by the machine learn community. 
relaxed constraint generalization of shannon boltzmann gibbs sbg entropy and a few tool from convex analysis make the task relatively straightforward. 
in the example discuss the original maxent problem remains embed as a special case provide a trail back to the original maxent problem will highlight the potential for cross fertilization between the two field. 
an empirical comparison of dimensionality reduction method for classify gene and protein expression dataset. 
the recent explosion in availability of gene and protein expression datum for cancer detection have necessitate the development of sophisticated machine learning tool for high dimensional datum analysis. 
previous attempt at gene expression analysis have typically use a linear dimensionality reduction method such as principal components analysis pca. 
linear dimensionality reduction method do not however account for the inherent nonlinearity within the datum. 
the motivation behind this work be to demonstrate that nonlinear dimensionality reduction method be more adept at capture the nonlinearity within the datum compare to linear method and hence would result in well classification and potentially aid in the visualization and identification of new datum class. 
consequently in this paper we empirically compare the performance of three commonly use linear versus three nonlinear dimensionality reduction technique from the perspective of a distinguish object belong to cancer and non cancer class and b new class discovery in high dimensional gene and protein expression study for different type of cancer. 
quantitative evaluation use a support vector machine and a decision tree classifier reveal statistically significant improvement in classification accuracy by use nonlinear dimensionality reduction method compare to linear method. 
infer biological network with output kernel tree. 
background elucidate biological network between protein appear nowadays as one of the most important challenge in system biology. 
computational approach to this problem be important to complement high throughput technology and to help biologist in design new experiment. 
in this work we focus on the completion of a biological network from various source of experimental datum. 
result we propose a new machine learning approach for the supervised inference of biological network which be base on a kernelization of the output space of regression tree. 
it inherit several feature of tree base algorithm such as interpretability robustness to irrelevant variable and input scalability. 
we apply this method to the inference of two kind of network in the yeast s. 
cerevisiae a protein protein interaction network and an enzyme network. 
in both case we obtain result competitive with exist approach. 
we also show that our method provide relevant insight on input datum regard their potential relationship with the existence of interaction. 
furthermore we confirm the biological validity of our prediction in the context of an analysis of gene expression data. 
conclusion output kernel tree base method provide an efficient tool for the inference of biological network from experimental datum. 
their simplicity and interpretability should make they of great value for biologist. 
analysis of nanopore detector measurement use machine learning method with application to single molecule kinetic analysis. 
background a nanopore detector have a nanometer scale trans membrane channel across which a potential difference be establish result in an ionic current through the channel in the pa na range. 
a distinctive channel current blockade signal be create as individually capture dna molecule interact with the channel and modulate the channel s ionic current. 
the nanopore detector be sensitive enough that nearly identical dna molecule can be classify with very high accuracy use machine learning technique such as hidden markov models hmm and support vector machines svm. 
result a non standard implementation of an hmm emission inversion be use for improved classification. 
additional feature be consider for the feature vector employ by the svm for classification as well the addition of a single feature represent spike density be show to notably improve classification result. 
another much large feature set expansion be study 2500 additional feature instead of one derive from include all the hmm s transition probability. 
the expand feature can introduce redundant noisy information as well as diagnostic information into the current feature set and thus degrade classification performance. 
a hybrid adaptive boosting approach be use for feature selection to alleviate this problem. 
conclusion the method show here for more informed feature extraction improve both classification and provide biologist and chemist with tool for obtain a well understanding of the kinetic property of molecule of interest. 
svm  fold a tool for discriminative multi  class protein fold and superfamily recognition. 
background predict a protein s structural class from its amino acid sequence be a fundamental problem in computational biology. 
much recent work have focus on develop new representation for protein sequence call string kernel for use with support vector machine svm classifier. 
however while some of these approach exhibit state of the art performance at the binary protein classification problem discriminate between a particular protein class and all other class few of these study have address the real problem of multi class superfamily or fold recognition. 
moreover there be only limited software tool and system for svm base protein classification available to the bioinformatics community. 
result we present a new multi class svm base protein fold and superfamily recognition system and web server call svm fold which can be find at http://svm fold.c2b2.columbia.edu. 
our system use an efficient implementation of a state of the art string kernel for sequence profile call the profile kernel where the underlying feature representation be a histogram of inexact match k mer frequency. 
we also employ a novel machine learn approach to solve the difficult multi class problem of classify a sequence of amino acid into one of many know protein structural class. 
binary one vs the rest svm classifier that be train to recognize individual structural class yield prediction score that be not comparable so that standard one vs all classification fail to perform well. 
moreover svm for class at different level of the protein structural hierarchy may make useful prediction but one vs all do not try to combine these multiple prediction. 
to deal with these problem our method learn relative weight between one vs the rest classifier and encode information about the protein structural hierarchy for multi class prediction. 
in large scale benchmark result base on the scop database our code weighting approach significantly improve on the standard one vs all method for both the superfamily and fold prediction in the remote homology setting and on the fold recognition problem. 
moreover our code weight learn algorithm strongly outperform near neighbor method base on psi blast in term of prediction accuracy on every structure classification problem we consider. 
conclusion by combine state of the art svm kernel method with a novel multi class algorithm the svm fold system deliver efficient and accurate protein fold and superfamily recognition. 
control of complex machine for meta learning in computational intelligence. 
recent year have reveal grow need for efficient meta learn. 
for much long time it have be know that there be no single adaptive algorithm eligible to provide satisfactory i.e. 
close to optimal solution for every kind of problem however compute power facilitate practical application of more and more sophisticated learning strategy and more and more thorough search in the space of candidate model. 
because test all possible model be not and will never be feasible we need intelligent tool to combine human expert knowledge the knowledge extract by mean of computational intelligence and different search strategy to disclose the nature of a problem and provide attractive model. 
we present some technique we have successfully use in our meta learn approach describe the crucial idea of our general architecture for meta learning and show some example. 
heat flow simulation for dry machining of power train casting. 
dry machining of power train component eg. 
cylinder block head be very challenging. 
high heat input due to the lack of coolant can result in an inhomogeneous temperature distribution lead to omni directional distortion. 
this distortion can be calculate use fem simulation. 
it require however a detailed knowledge about the heat input of each operation. 
so far this can only be determine by extensive experiment. 
the aim of this paper be to present a model describe the heat input as a function of cut parameter and tool geometry. 
base on this model the heat input can be calculate. 
this allow the simulation and optimization of the operation sequence. 
universal manufacturing platform for cnc machining. 
today cnc technology be a major contributor to the production capacity of industrial company. 
the current nc standard only allow rudimentary low bandwidth information transfer between various resource. 
a complex network of post processor be therefore need for the basic functionality of cad cam cnc system. 
in this paper the author investigate and design a universal platform for support cnc manufacturing. 
the platform shift the necessary knowledge transformation from the vendor specific software domain to the conceptual model space. 
this will eliminate the requirement for postprocessor. 
consequently resource will be interchangeable and interoperable add to the strategic agility of the manufacturing network. 
a scientific foundation of collaborative engineering. 
collaborative engineering be the practical application of collaboration science to the engineering domain. 
in today s highly connect technology drive economy the production industry must rely on the good practice of collaborative engineering to stay competitive when designing manufacturing and operate complex machine process and system on a global scale. 
despite its importance collaborative engineering be currently more of a practiced art than a scientific discipline. 
a well understanding of how engineer should collaborate with all stakeholder to accomplish complex task that fulfill our increase social responsibility be a grand challenge. 
however because we currently lack well define science of human collaboration we must first establish a scientific foundation of collaborative engineering to develop this emerge field into a rigorous discipline. 
this paper report on the cirp community s collective effort to establish such a scientific foundation accord to the observation hypothesis theory development pathway. 
our objective be to spearhead the rigorous development of this new human center engineering discipline so that useful knowledge can be generate to educate student and practical guideline can be develop to enable engineer to become more productive collaboration leader in the new global production industry. 
tool wear monitoring and failure prediction base on hybrid. 
a method of pattern recognition of tool wear base on discrete hidden markov models dhmm be propose to monitor tool wear and to predict tool failure. 
at the first fft feature be extract from the vibration signal and cut force in cut process then fft vector be presorte and code into code book of integer number by som and these code book be introduce to dhmm for machine learning to build up three hmm for different tool wear stage. 
and then pattern of hmm be recognise by use maximum probability. 
finally the result of tool wear recognition and failure prediction experiment be present and show that the methodproposed be effective. 
xml document mining use contextual self organize map for structure. 
xml be become increasingly popular as a language for represent many type of electronic document. 
the consequence of the strict structural document description via xml be that a relatively new task in mining document base on structural and/or content information have emerge. 
in this paper we investigate one the suitability of new unsupervised machine learning method for the cluster task of xml document and two the importance of contextual information for the same task. 
these task be part of an international competition on xml clustering and categorization inex 2006. 
it will be show that the propose approach provide a suitable tool for the clustering of structured datum as they yield the good result in the international inex 2006 competition on clustering of xml datum. 
a valuation technology for product development option use an executable meta model language. 
mistake or foresight in the early phase of product development tend to be amplify over the course of a project. 
therefore have a rigorous approach and support tool to identify and filter a development portfolio at the early stage can be highly rewarding. 
this paper present an executable specification language object process network opn that can be use by system designer to formally represent the development option space and automate certain model refinement activity at early phase of product development. 
specifically an opn specification model can automatically enumerate a set of alternative development portfolio. 
opn also provide an algebraic mechanism to handle the knowledge incompleteness problem at vary phase of planning so that uncertain property of different portfolio can be represent and analyze under algebraic principle. 
in addition it have a recursively define model transformation operator that can iteratively refine the specification model to simplify or enhance the detail of the machine generate alternative. 
a list of successful application case be present. 
the collaborative digital process methodology achieve the half lead time of new car development. 
in brazil the industry of agricultural machine and implement represent a a japanese automotive manufacturer finally achieve the less than one year lead time for product development of its new automotive that be release in 2005. 
note a new automotive release from nissan motor co. ltd. 
in january 2005 be throw into the market after 10 and a half month of product development period which be the first achievement all over the world. 
one that mean super shorten process reduce the lead time of new automotive development to the half which have need more than 20 month. 
the japanese automotive industry have achieve the less than one year period of super shorten process come from five lot process in 1980 s through shorten process in 1990 s as a result of its continuous efforts.(fig. 
one one have bring up the methodology call digital collaboration process methodology from the countermeasure which have contribute these 20 year process innovation. 
a machine learning base reliability assessment model for critical software system. 
service orient architecture soa technique be be increasingly use for develop critical application especially network centric system. 
while the soa paradigm provide flexibility and agility to well respond to change business requirement the task of assess the reliability of soa base system be challenge especially for composite service. 
however derive high confidence reliability estimate for mission critical system can require huge cost and time. 
this paper present a reliability assessment and prediction model for soa base system. 
the service be assume to be realize with reuse and logical composition of component. 
the model use ai reasoning technique on dynamically collect failure datum of each service and its component as one of the evidence together with result from random testing. 
memory base reasoning technique and bayesian belief network be use as reasoning tool to guide the prediction analysis. 
the least test and high usage input subdomain be identify and necessary remedial action be take depend on the predict result from the propose model. 
the model be illustrate use a simulated case study base on a real time dataset from the nasa soft ware repository. 
challenge in select cots component guideline. 
reuse of cots commercial off the shelf component be a new development approach in software engineering. 
developer get benefit from cots base development cbd environment to select suitable component adopt and integrate into the system that to achieve well software more quickly and low cost. 
but the current environment didn t support the typical of cbd process in all process. 
some environment be support in some step or focus on how to develop the component and component interoperability that allow in the same environment. 
in this paper we propose a new environment tool call cs cots be consist of one sophisticate machine learning tool for generate rule in selection and integration. 
two guideline for select method category. 
three predict a success rate to integrate method fit into system. 
neural gas cluster for dissimilarity datum with continuous prototype. 
prototype base neural clustering or datum mining method such as the self organize map or neural gas constitute intuitive and powerful machine learning tool for a variety of application area. 
however the classical method be restrict to datum embed in a real vector space and have only limit applicability to noneuclidean datum as occur in for example biomedical or symbolic field. 
recently extension of unsupervised neural prototype base cluster to dissimilarity datum datum characterize in term of a dissimilarity matrix only have be propose substitute the mean by the so call generalize median. 
thereby the location of prototype be choose within the discrete input space which constitute a severe limitation in particular for sparse data set since the prototype flexibility be restrict. 
here we present a generalization of median neural gas such that prototype can be interpret as mixture of discrete input location. 
we derive a batch optimization scheme base on a correspond cost function. 
build a large scale commonsense knowledge base by convert an exist one in a different language. 
this paper describe our effort to build a large scale commonsense knowledge base in korean by convert a pre exist one in english call conceptnet. 
the english commonsense knowledge base be essentially a huge net consist of concept and relation. 
triplet in the form of concept relation concept in the net be extract from english sentence collect from volunteer through a web site who be interested in enter commonsense knowledge. 
our effort be an attempt to obtain its korean version by utilize a variety of language resource and tool. 
we not only employ a morphological analyzer and exist commercial machine translation software but also develop our own special purpose translation and out of vocabulary handling method. 
in order to handle ambiguity we also devise a noisy concept filter and concept generalization method. 
out of the 2.4 million assertion triplet of concept relation concept in the english conceptnet we generate about 200,000 korean assertion so far. 
base on our manual judgment of a five sample the accuracy be 84.4. 
chronic hepatitis and cirrhosis classification use snp datum decision tree and decision rule. 
a machine learning technique decision tree be use to predict the susceptibility to two liver disease chronic hepatitis and cirrhosis from single nucleotide polymorphism(snp datum. 
also it be use to identify a set of snp relevant to those disease. 
the experimental result show that a decision tree be able to distinguish chronic hepatitis from normal with accuracy of 69.59 and cirrhosis from normal with accuracy of 76.72 and the c4.5 decision rule be with accuracy of 69.59 for chronic hepatitis and 79.31 for cirrhosis. 
the experimental result show that decision tree be a potential tool to predict the susceptibility to chronic hepatitis and cirrhosis from snp datum. 
support vector machine their use in geotechnical engineering as illustrate use seismic liquefaction datum. 
empirical model base on know or measure sample datum be often use to develop solution to problem in which the underlying first principle be not well define and it be not possible to define a concise relationship between the variable or the problem be too complicated to be describe mathematically. 
increasingly various modern learning algorithm such as neural network be be consider to develop model that essentially map a dependency between the input and output from know datum pattern. 
this study look at a fairly new pattern recognition tool know as support vector machine svm that can be use for solve classification type problem. 
there be two main idea underlie the svm for discriminant type problem. 
the first be an optimum linear separate hyperplane decision surface that separate the datum pattern. 
the second main idea be the use of kernel function dot product of two vector to apply mapping to the original nonlinear datum pattern such that the datum become linearly separable in a high dimensional feature space. 
an overview of the svm be first present follow by an illustration of its use to assess seismic liquefaction datum. 
the svm model be train and test on a relatively large datum set comprise 226 field record of liquefaction performance and cone penetration test measurement. 
the overall classification success rate for the entire datum set be 98. 
c 2007 elsevier ltd. 
all right reserve. 
knowledge discovery in database induction graph and cellular automaton. 
in this article we present the general architecture of a cellular machine which make it possible to reduce the size of induction graph and to optimize automatically the generation of symbolic rule. 
our objective be to propose a tool for detect and eliminate non relevant variable from the database. 
the goal after acquisition by machine learn from a set of datum be to reduce the complexity of storage thus to decrease the computing time. 
the objective of this work be to experiment a cellular machine for system of inference contain rule. 
our system rely upon the graph generate by the sipina method. 
after an introduction aim at position our contribution within the area of machine learning we briefly present the sipina method for automatic retrieval of knowledge start from datum. 
we then describe our cellular system and the phase of knowledge post processing in particular the validation and the use of extract knowledge. 
the presentation of our system be mostly do through an example take from medical diagnosis. 
a case study of algorithm for morphosyntactic tagging of polish language. 
the paper present in evaluation of several part of speech tagger represent main tagging algorithm apply to corpus of frequency dictionary of the contemporary polish language. 
we report our result consider two tag scheme ipi pan positional tagset and its simplified version. 
tagging accuracy be calculate for different training set and take into account many subcategorie accuracy on know and unknown token word segment sentence etc the comparison of result with other inflecting and analytic language be do. 
performance aspect time demand of used tagging tool be also discuss. 
improve robustness of image quality measurement with degradation classification and machine learning. 
image quality metric can be classify as generic or degradation specific. 
degradation specific measure perform poorly under mismatched condition. 
generic measure on the other hand may compromise quality measurement accuracy while gain robustness to variation in distortion condition. 
to improve the accuracy robustness tradeoff we employ support vector degradation classification and machine learning tool to judiciously combine generic and degradation specific measure. 
to test our algorithm composite quality metric be optimize for five different distortion class. 
experiment result show that the propose algorithm achieve improved performance and robustness relative to two benchmark generic quality metric. 
how to compare different loss function and their risk. 
many learning problem be describe by a risk functional which in turn be define by a loss function and a straightforward and widely know approach to learn such problem be to minimize a modify empirical version of this risk functional. 
however in many case this approach suffer from substantial problem such as computational requirement in classification or robustness concern in regression. 
in order to resolve these issue many successful learning algorithm try to minimize a modify empirical risk of a surrogate loss function instead. 
of course such a surrogate loss must be reasonably relate to the original loss function since otherwise this approach can not work well. 
for classification good surrogate loss function have be recently identify and the relationship between the excess classification risk and the excess risk of these surrogate loss function have be exactly describe. 
however beyond the classification problem little be know on good surrogate loss function up to now. 
in this work we establish a general theory that provide powerful tool for compare excess risk of different loss function. 
we then apply this theory to several learning problem include cost sensitive classification regression density estimation and density level detection. 
cooperative decision making with scheduler agent. 
in this study an agent base collaborative scheduling system be represent as a model of scheduling among shop. 
agent base system describe the behavior of distribute decision maker agent in manufacturing system. 
agent in the system be production planning agent and shop floor agent. 
shop floor agents be semi autonomous agent so that the degree of autonomy be determine by the production planning agent. 
the distributed system form heterogeneous unit be design by hybrid control architecture. 
the study focus on construct an agent base collaborative scheduling system that be capable of conduct scheduling negotiation among shop floor agent. 
the design system be capable of scheduling by consider heterogeneous objective of the shop floor agent within a collaborative manufacturing environment. 
negotiation be co operative not competitive. 
shop floor agents generate collaboratively their schedule. 
the schedule for the good interest of the system as a whole be select by the production planning agent. 
structure base drug design for hiv protease from molecular modeling to cheminformatic. 
significant progress over the past decade in virtual representation of molecule and their physicochemical property have produce new drug from virtual screening of the structure of single protein molecule by conventional modeling method. 
the development of clinical antiviral drug from structural datum for hiv protease have be a major success in structure base drug design. 
technique for virtual screening involve the ranking of the affinity of potential ligand for the target site on a protein. 
two main alternative have be develop modeling of the target protein with a series of relate ligand molecule and dock molecule from a database to the target protein site. 
the computational speed and prediction accuracy will depend on the representation of the molecular structure and chemistry the search or simulation algorithm and the scoring function to rank the ligand. 
moreover the general challenge in modem computational drug design arise from the profusion of datum include whole genome of dna protein structure chemical library affinity and pharmacological datum. 
therefore software tool be be develop to manage and integrate diverse datum and extract and visualize meaningful relationship. 
current area of research include the development of searchable chemical database which require new algorithm to represent molecule and search for structurally or chemically similar molecule and the incorporation of machine learning technique for datum mining to improve the accuracy of prediction. 
example will be present for the virtual screening of drug that target hiv protease. 
digital enterprise technology study of the saarinen arch. 
for their studio project while learn det undergraduate and graduate student model the st. 
louis arch use the exact mathematical relationship of eero saarinen. 
they use that digital model to do finite element stress analysis for stress deflection and vibration. 
they investigate the challenge construction methodology use in build the arch. 
they confirm saarinen s uniform stress assumption use compute power that he never dream of they check out what be need in the way of hydraulic force and piston travel to expand the two leg for keystone placement. 
they conceive and analyze different tool path strategy for the possible three  and five axis cutting of exact physical model of that arch geometry. 
most recently use delmia to electronically model not only the tool path but also the machine tool operation and plant layout itself precise 1/1000 sized model of the arch be be cut and cast in aluminium and other material. 
this paper be a follow up of the paper submit at the 2004 det in seattle entitle catia studies of the st. 
louis arch by oit students. 
as a final step the study be focus on a physical model to be produce with the assistance of freightliner llc a daimlerchrysler company and the precision casiparts corporation. 
the long term institutional objective for the overall project be not just to have course in det but also to position det centrally within the undergraduate and graduate manufacturing and mechanical curricula and finally to use it to its full power and functionality. 
process analysis and flexible transfer line configuration. 
the offer of the good machine tool configuration for specific customer s need be a decisive factor to compele in the machine tool sector. 
normally the offer be define by the manufacturer mostly on the basis of his own experience and require a considerable effort in term of tune and money while it lead to actual selling in a small percentage of the case. 
also the knowledge relate to the activity of offer preparation be not well formalized and this put the company in a weak position in the case of retirement or job change of the expert. 
to address these problem this paper present a method for process analysis and transfer line configuration. 
result of the application of the method to a real case be report. 
computer aid lumbar support design and application. 
support property in the lumbar area have be identify as a major factor for the comfort impression on automotive seat. 
however the relationship of human body characteristic to specific property of seat be not clear. 
ongoing research at l&p automotive group analyze seat dimension and human body characteristic in order to evaluate the man machine interface of the seat human. 
computer tool employ be 3d measure system pressure mapping and subjective comfort assessment. 
specific measurement routine have be develop to allow for correlation of human dimension and seat characteristic. 
use computer support method for measuring datum collection and datum processing in combination with engineering knowledge and knowledge about other soft fact comfort assessment process can be develop and effectively use in order to obtain well mean more comfortable product. 
a standard computable clinical trial protocol the role of the bridg model. 
today s clinical trial process be inefficiently mire in excessive documentation and unnecessary human intervention. 
the protocol lie at the heart of these operation make it a prime candidate for the benefit afford by computer processing. 
with a vision to develop a standard machine readable protocol the protocol representation pr group a team within the clinical data interchange standards consortium cdisc identify a set of element common to regulate clinical research protocol. 
these element be be incorporate into the biomedical research integrated domain group bridg model an information model of biomedical research initiate by cdisc and collaboratively developed and maintain by cdisc health level seven hl7 the national cancer institute nci the food and drug administration fda and other stakeholder. 
the pr group plan to use bridg as a pathway to develop a standard structure protocol representation so that protocol information can be repurpose across multiple clinical research document database and system from study start up through reporting and regulatory submission. 
the bridg model provide a mean of knowledge acquisition a tool for communication a focus for collaboration a starting point for application development a mean to standard development and harmonization and an informatic research platform to support clinical research. 
artificial intelligence technique apply to the evaluation of the research and technology development project and programme. 
the paper present the specific way in which indicator and artificial intelligence method and tool can be use for the evaluation of research project and programme. 
the author s research purpose be to improve the programme ex post evaluation and ex ante impact assessment think the development of a improved set of strong integrate research performance indicator structure accord to the result chain and comprehensively describe use a standard indicator template the development of datum set and database for project and programme evaluation and finally the development of project and programme evaluation technique base on database and machine learning technology. 
use these method a new and well understanding of the scientific technological human resource structuring economic social environmental etc impact of national and european research programme be possible. 
the research be finance by the minister of education and research idei programme. 
modeling of human physiological parameter in an e laboratory by som neural network. 
an approach of interpret some bioinformatics datum use self organize map som type neural network be describe. 
the way be propose construct intelligent program tool of embed agent to collect ecg and eeg datum for academic usage in a virtual e laboratory. 
a som base diagnostic algorithm be propose interpret datum from medical database donate by university of california machine learning page host etc. 
by apply som for eeg datum of colorado state university method recognize some unified mental task perform by different subject be propose. 
it be also show that knowledge discover by som datum interpretation can be involve in a process of e tutoring of student and learner of bioinformatic. 
keyword ambient intelligence embedded agents machine learning self organize map. 
ill. 
nine bibl. 
19 in english summary in english russian and lithuanian. 
multi scale modeling of surface topography in single point diamond turning. 
a multi scale model be propose to explain the effect of material induce vibration and the quantitative relation between cut force and the surface quality from dislocation grain orientation cut tool machine tool use in the simulation of the nano 3d surface topology in single point diamond turning. 
the model base simulation system compose of several model element which include a microplasticity model a dynamic model and an enhanced surface topography model. 
the multi scale model bring together knowledge from various discipline to link up physical phenomenon occur at different length scale to explain successfully the surface generation in single point diamond turning of crystalline material and offer a new direction of research in ultra precision machining. 
a study on friction stir process of magnesium alloy az31 sheet. 
friction stir process fsp be important for enhance mechanical property of metal sheet such as the tensile strength the elongation etc. 
the stress distribution of the tool pin be affect by the thermo mechanical characteristic of the workpiece in fsp. 
recently magnesium alloy az31 be widely use in machine industry due to the light weight material property. 
in this paper a thermo mechanical model for fsp use three dimensional fem analysis be propose for explore temperature distribution strain distribution and stress distribution of the workpiece. 
the heat generate from the plastic deformation and the friction between the head tool and workpiece be consider as the heat source in the simulation of the fsp process. 
a commercial finite element code deform 3d be use to carry out the simulation of the plastic deformation of az31 sheet during the fsp. 
the analytical result of temperature strain and stress distribution of the workpiece and head tool can provide useful knowledge for tool pin design in fsp. 
effectiveness of q learning as a tool for calibrate agent base supply network model. 
this paper examine effectiveness of q learning as a tool for specify agent attribute and behaviour in agent base supply network model. 
agent base modelling abm have be increasingly employ to study supply chain and supply network problem. 
a challenging task in build agent base supply network model be to properly specify agent attribute and behaviour. 
machine learning technique such as q learning can be a useful tool for this purpose. 
q learning be a reinforcement learning technique that have be show to be an effective adaptation and search mechanism in distribute setting. 
in this study q learning be employ by supply network agent to search for optimal value for a parameter in their operating policy simultaneously and independently. 
method be design to identify the optimal parameter value against which effectiveness of the learning be evaluate. 
robustness of the learning s effectiveness be also examine through consideration of different model setting and scenario. 
result show that q learning be very effective in find the optimal parameter value in all model setting and scenario consider. 
experience understanding performance in a commercial scale out environment. 
cluster of loosely connect machine be become an important model for commercial computing. 
the cost performance ratio make these scale out solution an attractive platform for a class of computational need. 
the work we describe in this paper focus on understand performance when use a scale out environment to run commercial workload. 
we describe the novel scale out environment we configure and the workload we run on it. 
we explain the unique performance challenge face in such an environment and the tool we apply and improve for this environment to address the challenge. 
we present datum from the tool that prove useful in optimize performance on our system. 
we discuss the lesson we learn apply and modify exist tool to a commercial scale out environment and offer insight into make future performance tool effective in this environment. 
enhance the assessment environment within a learning management systems. 
there be many open source or proprietary assessment tool on the market. 
these tool be embed in learning management systems lms and have as goal evaluation of learner. 
a problem that currently appear be that assessment tool be not always fair or accurate in classify student accord with accumulate knowledge. 
we propose a software module call quality module qm that may run along with an assessment tool within an lms. 
the qm perform offline analysis and obtain knowledge regard the classification capability of the assessment tool. 
the qm also obtain knowledge for course manager regard the course difficulty such that course material and quiz may be alter in order to obtain a more accurate assessment tool and thus well classification among learner. 
understand signal sequences with machine learning. 
protein translocation the transport of newly synthesize protein out of the cell be a fundamental mechanism of life. 
we be interested in understand how cell recognize the protein that be to be export and how the necessary information be encode in the so call signal sequences. 
in this paper we address these problem by build a physico chemical model of signal sequence recognition use experimental datum. 
this model be build use decision tree. 
in a first phase the classifier be build from a set of feature derive from the current knowledge about signal sequence. 
it be then expand by feature generation with genetic algorithm. 
the result predictor be efficient achieve an accuracy of more than 99 with our wild type protein set. 
furthermore the generate feature can give we a biological insight about the export mechanism. 
our tool be freely available through a web interface. 
design and algorithms realization of rough set simulation tool box. 
the basic conception and trait of datum analysis system base on rough set(rs method be briefly describe. 
two important concept of indiscernibility relation and relative positive region be mainly focus on. 
by use the dependant degree of knowledge the algorithm of rs datum analysis system be submit. 
by compare the number of reduce attribute the result of minimal attribute reduction be select. 
program realization of many algorithm of solve relative core upper(lower approximation equivalence relation relatively significant degree relatively attribute reduction relatively value reduction minimal decision rule be obtain. 
the matlab program of above field be give. 
matlab simulation tool box be design. 
by impose graphical user interface gui method the favorable man machine alternation system main interface be devise. 
gui programming method be particularly introduce by use a button example. 
a data classifier base on topsis method. 
as a multiple criterion decision make mcmd technique the technique for order preference by similarity to ideal solution(topsis traditionally have be apply in multiple criterion decision analysis. 
base on d.wu s datum mining model the topsis model present in this paper have improve from two aspect. 
firstly it extent to deal with both crisp and fuzzy datum secondly in order to really follow automatic machine learn principle to the large extent the weight must be immune to the subjective element and the datum noise. 
here the weight be obtain from datum set base on support vector regression(svr which be a more robust and efficient datum regression method than the traditional datum regression method. 
thus the propose model can provide additional efficient tool for comparative analysis of datum set. 
we apply it in supply chain complexity evaluation and simulation be use to validate the propose model. 
a parallel algorithm to construct concept lattice. 
concept lattice be an efficient tool for datum analysis and knowledge discovery and have be use in many field such as data mining machine learning and information search. 
with volume of datum grow increasingly it s important to design the algorithm which be more efficient. 
therefore a parallel algorithm of pstcl parallel sub top concept lattice be develop in this paper. 
the analysis and experiment show that the time performance of pstcl have be improve significantly over godin algorithm. 
in addition the space performance be well than the algorithm use under the single computer environment. 
research on similarity measure between vague set. 
many ai researcher have intensively investigate fuzzy knowledge acquisition. 
it be consider as a key problem in the field of expert system decision analysis machine learning ect. 
we notice that the vague set theory introduce by gau and buehrer have be conceive as a new efficient tool to deal with ambiguous datum and it have be apply successfully in different field. 
a vague set as a generalization of the concept of fuzzy set be a set of decision object each of which have a grade of membership whose value be a continuous subinterval of. 
it be characterize by a truth membership function and a false  membership function. 
in this paper we analyze the similarity measure between vague set give in literature. 
the concept of similarity degree be give. 
then we revise they and propose a new kind of similarity measure. 
the new measure be more rational thus provide a more useful way to measure the degree of similarity between vague set. 
nonlinear integration of spatial and temporal forecasting by support vector machines. 
spatio temporal datum mining be the extraction of unknown and implicit knowledge structure spatio temporal relationship or pattern not explicitly store in spatio temporal database. 
as one of datum mining technique forecasting be widely use to predict the unknown future base upon the pattern hide in the current and past datum. 
in order to achieve spatio temporal forecasting some mature analysis tool time series and spatial statistic be extend to the spatial dimension and the temporal dimension respectively or they be combine linearly as spatio temporal integration. 
however such linear combination of spatial and temporal dimension be just a simplification of complicated spatio temporal association exist in complex geographical phenomena. 
in this study the support vector machines be introduce to construct nonlinear combination function relate to the spatial and temporal dimension for integrate spatio temporal forecasting. 
the propose method have be test by forecast the annual average temperature of meteorological station in p r china. 
the forecasting result show that nonlinearly integrate spatio temporal forecasting model via support vector machines obtain well forecasting accuracy than those obtain by linear combination and other conventional method. 
comparison of datum mining and neural network method on aero engine vibration fault diagnosis. 
data mining and artificial neural network ann have be extensively apply on machinery fault diagnosis. 
aero engine as one kind of rotate machine with complex structure and high rotate speed have complicate vibration fault. 
ann be a good tool for aero engine fault diagnosis since they have strong ability to learn complex nonlinear function. 
data mining have advantage of discover knowledge from mountain of datum provide a simple way to interpret complex decision problem and automatically extract diagnostic rule to replace the expert s advice. 
this paper present application of the two method on aero engine vibration fault diagnosis and then make a comparison between they. 
from the study of this paper both the two method be effective on aero engine vibration fault diagnosis while each of they have its individual quality. 
review on application of datum mining in product design and manufacturing. 
implementation of data mining technology in some area such as banking finance marketing insurance health care etc. 
have give very good result. 
however application of datum mining in product design and manufacturing be not as broad as expect and many challenge be still ahead. 
this work analyze the reason for the limitation of data mining application in manufacture industry and focus on review the state of the art of the application of datum mining in product design and manufacturing. 
some point of view be also discuss and finally this paper be conclude. 
data mining neural net tree problem two and three of genetic analysis workshop 15. 
genome wide association study use thousand to hundred of thousand of single nucleotide polymorphism snp marker and region wide association study use a dense panel of snp be already in use to identify disease susceptibility gene and to predict disease risk in individual. 
because these task become increasingly important three different datum set be provide for the genetic analysis workshop 15 thus allow examination of various novel and exist datum mining method for both classification and identification of disease susceptibility gene gene by gene or gene by environment interaction. 
the approach most often apply in this presentation group be random forest because of its simplicity elegance and robustness. 
it be use for prediction and for screen for interesting snp in a first step. 
the logistic tree with unbiased selection approach appear to be an interesting alternative to efficiently select interesting snp. 
machine learning specifically ensemble method might be useful as pre screen tool for large scale association study because they can be less prone to overfitte can be less computer processor time intensive can easily include pair wise and high order interaction compare with standard statistical approach and can also have a high capability for classification. 
however improve implementation that be able to deal with hundred of thousand of snp at a time be require. 
the lefe algorithm embrace the complexity of gene expression in the interpretation of microarray datum. 
interpretation of microarray datum remain a challenge and most method fail to consider the complex nonlinear regulation of gene expression. 
to address that limitation we introduce learner of functional enrichment lefe a statistical machine learning algorithm base on random forest and demonstrate it on several diverse dataset smoker never smoker breast cancer classification and cancer drug sensitivity. 
we also compare it with previously publish algorithm include gene set enrichment analysis. 
lefe regularly identify statistically significant functional theme consistent with know biology. 
detect design flaw in uml state chart for embed software. 
embed system be use in various critical device and correct functioning of these device be crucial. 
for non trivial device exhaustive testing be costly time consume and probably impossible. 
a complementary approach be to perform static model check to verify certain design correctness property. 
though static model checking technique be widely use for hardware circuit verification the goal of model checking software system remain elusive. 
however embed system fall in the category of concurrent reactive system and can be express through communicate state machine. 
behavior of concurrent reactive system be more similar to hardware than general software. 
so far this similarity have not be exploit sufficiently. 
ibm r)(1 rational r rose r realtime rosert be widely use for design concurrent reactive system and support uml state charts. 
ibm rulebase be an effective tool for hardware model checking. 
in this paper we describe our experiment of use rulebase for static model check rosert model. 
our tool automatically convert rosert model to the input for rulebase allow user to specify constraint graphically use a variation of sequence diagram and present model checking result counterexamples as sequence diagram consist of state and event in the original uml model. 
the model checking step be seamlessly integrate with rosert. 
prior knowledge of model checking or formal method be not expect and familiarity of uml sequence diagram be exploit to make temporal constraint specification and counterexample presentation more accessible. 
this approach bring the benefit of model check to embed system developer with little cost of learning. 
interactive visual decision tree classification. 
datum mining dm modeling be a process of transform information enfold in a dataset into a form amenable to human cognition. 
most current dm tool only support automatic modeling during which use have little interaction with compute machine other than assign some parameter value at the beginning of the process. 
arbitrary selection of parameter value however can lead to an unproductive modeling process. 
automatic modeling also downplay the key role play by human in current knowledge discovery system. 
classification be the process of find model that distinguish datum class in order to predict the class of object whose class label be unknown. 
decision tree be one of the most widely use classification tool. 
a novel interactive visual decision tree ivdt classification process have be propose in this research it aim to facilitate decision tree classification process regard enhance user understanding and improve the effectiveness of the process by combine the flexibility creativity and general knowledge of human with the enormous storage capacity and computational power of computer. 
an ivdt for categorical input attribute have be develop and experiment on twenty subject to test three hypothesis regard its potential advantage. 
the experimental result suggest that compare to the automatic modeling process as typically apply in current decision tree modeling tool ivdt process can improve the effectiveness of modeling in term of produce tree with relatively high classification accuracy and small size enhance user understanding of the algorithm and give they great satisfaction with the task. 
decentralize information aggregation and central control in networked production environment. 
in production today s machine become increasingly intelligent. 
the use of embed cpu have become obligatory whereas more and more machine be equip with high level computer. 
this way production machine be enable not only to be drive via remote control but to deliver detailed status information and sensory output. 
to date most of this generate information be waste in the archive of the machine only read in case of up come machine failure. 
new approach like decentralize peer to peer production network promise new possibility to exploit this information and take a step beyond manufacturing execution systems mes. 
production cockpits be able to assemble collect datum filter on several layer and to decide which datum be important enough to be present to the user. 
development of an approach for optimize the accuracy of classify claim narrative use a machine learn tool textminer. 
this paper demonstrate a successful application of a fuzzy bayes machine learn tool for classify large amount of narrative text involve the use of roc curve to identify optimum prediction threshold value at which to filter prediction for manual review. 
different threshold be use for different category to optimize result and effectively minimize resource necessary for manual coding of a large number of claim narrative randomly extract from a large u.s. 
insurer. 
the result indicate that utilize a computer approach with strategic assignment of manual narrative filter out approximately 15 of the narrative for manual review and result in a final accuracy at the two digit classification level of 81. 
a bayesian methodology for semi automate task analysis. 
this research propose a new task analysis methodology that combine the fuzzy bayesian model with classic task analysis method to develop a semi automate task analysis tool to well help traditional task analyst identify subtask. 
we hypothesize that this approach could help task analyst identify activity unit perform by the call center agent. 
the term activity unit in our study represent the subtask the agent perform during a remote troubleshooting process. 
we also investigate whether this tool could help predict the activity unit as well. 
an effort intensive field base datum collection for the call center s naturalistic decision make s environment be accomplish. 
a human expert and an additional 18 purdue student participate in the validation of the assign subtask. 
the machine learn tool s performance be then examine. 
the preliminary result support our hypothesis that the fuzzy bayesian base tool be able to learn and predict subtask category from the agent customer narrative telephone conversation. 
exposure of hand arm vibration by hand guide woodworking machine. 
in the woodworke industry various hand guide machine be be use. 
accord to 2002/44 eg protect worker from the risk arise from vibration a work protection regulation for noise and vibration be publish in germany on the 6(th of march 2007. 
concern the hand arm vibration the risk can be assess by measure the frequency weight acceleration value determine on the three orthogonal axis of the room. 
the risk can also be assess by use the manufacturer s information about vibration. 
measurement at workplace be very complex and often disturb the working process. 
that be why the manufacturer s information about vibration be of special interest. 
however these datum be often measure accord to standard which describe the emission of vibration from the machine in only one normally the strong direction. 
especially the risk belong to neurological disturbance and vascular disease can be estimate only in a limited way by this kind of procedure. 
for the enterprise in the woodworke industry a detailed assessment of risk be not possible. 
the aim of the present investigation be to offer a way of how risk assessment can be do systematically at workplace and in the laboratory. 
accord din en iso 5349 the daily exposure to hand arm vibration can be calculate by formula one where the knowledge of the exposure time and the vibration value be necessary. 
in a preliminary talk between the institution for statutory accident insurance and prevention in the woodworke industry holz bg the bgia institute for occupational safety and health and the bgag institute work and health both institution of the german social accident insurance machine be select which be know to have an obvious vibrational effect on the worker. 
subsequently these machine be be investigate in various research trial in member enterprise of the holz bg. 
it be try to measure pneumatic and electrical machine from each type of machine in a comparable capability. 
table one show the most important result of these investigation. 
in the next step further investigation in the laboratory be plan for these machine which show the high value of vibration. 
these machine be random orbital sander hand hold router reciprocating see jigsaw reciprocating see sword saw orbital sander and additionally an electrical planer in chapter four the result of the laboratory measurement be illustrate. 
these measurement take into consideration the influence of the person who use the machine of new and use machine of the tool which be use of the setting of the machine like the rpm of the hardness of the wood the result show in the majority of case a good accordance of the vibration value that be find in the manufacturer s information independent from the person who use the machine. 
however in some case especially in the case of jigsaw and the orbital sander the exposure to vibration depend very strongly on the condition of use or show a clear difference between the measure result and the manufacturer s information. 
the present investigation make possible a detailed risk assessment for new and use hand guide machine in the woodworke industry in the woodworking industry various hand guide machine be be use. 
accord to 2002/44 eg protect worker from the risk arise from vibration a work protection regulation for noise and vibration be publish in germany on the 6(th of march 2007. 
concern the hand arm vibration the risk can be assess by measure the frequency weight acceleration value determine on the three orthogonal axis of the room. 
the risk can also be assess by use the manufacturer s information about vibration. 
measurement at workplace be very complex and often disturb the working process. 
that be why the manufacturer s information about vibration be of special interest. 
experimental result for the validation of dynamic finite element model. 
little be know about the load and stress of the musculoskeletal system this hold especially for the scope of the lumbar spine which be in particular interest for occupational medicine and social economic. 
reliable datum on stress derive from measurement of intradiscal pressure and from implant equip with sensor. 
those measurement provide datum for investigate structure. 
yet it be indistinct how implant influence the native force flow. 
finite element fe model of the anatomy of the lumbar spine which be embed into whole body model deliver powerful tool for evaluate vibration stress of the lumbar spine for a sit person in a construction machine. 
the quality of this assessment depend mainly on the knowledge of the structural material parameter. 
a multitude of material parameter can be determine post mortem with in vitro experiment. 
extensive study exist for the stress strain behaviour of functional spine unit. 
predominantly these study be execute without axial preload and concentrate mostly on extensional and flexional movement as it be present when bend backward and forward. 
dynamical load in the frequency range around 10 hz in axial and frontal or lateral shear direction be much more relevant with regard to whole body vibration. 
base on relaxation measurement a dynamic stiffening of spinal segment be calculate in this range of frequency. 
aim of this study be to determine the dynamic stiffening of non degenerated functional spine unit within a frequency and load range relevant to occupational medicine such to provide datum to validate dynamic fe model. 
anthropometrical datum of 30 young donor 33 six year be collect post mortem. 
functional spinal unit l4 l5 be harvest and deep frozen afterwards. 
ct scan of the deep frozen functional spine unit be make to enable numerical reconstruction of the vertebrae and to identify characteristic such as the height of intervertebral disc. 
after thaw functional spine unit be prepare and test dynamically one 12 hz with a biaxial hydraulic material testing machine in axial compression and anterior posterior as well as lateral shear. 
besides deformation and force the intradiscal pressure be measure. 
all measurement be perform in a physiological saline solution at 37 degree c. 
valuable datum be acquire due to the homogeneous young collective of donor and the high amount of specimen. 
standard error of all measurement be at three 5. 
the result show a distinct dependency of the total stiffness and the frequency. 
at a frequency of 12 hz the stiffness be eight 20 high than at one hz. 
as a result of the nonlinear material behaviour the axial preload as well as the load amplitude have a substantial contribution to the total stiffness. 
in order to investigate the influence of whole body vibration with numerical model dynamic measurement should be use in addition to quasistatic measurement to validate the structure. 
grow cell structures gcs a constructive learn neural network for tool wear estimation application. 
tool wear be one of the major factor that affect the automation of machine operation. 
there be a need to reliably detect the condition of the tool because it affect the product quality increase machine downtime and sometimes affect the machine tool and the personnel. 
tool condition monitoring tcm be important in the successful automation of manufacturing process. 
in this paper a new constructive learning algorithm propose by fritzke namely grow cell structures gcs be be use for tool wear estimation in face mill operation thereby monitor the condition of the tool. 
gcs generate compact network architecture in less training time and perform well on new untrained datum establish its feasibility in tool wear estimation application. 
the performance of this network have be compare with that of another constructive learn algorithm base neural network namely the resource allocation network ran. 
gcs have be find to be effective and efficient for tool wear estimation. 
an approach to cartographic object extraction from high resolution satellite imagery. 
of all task in photogrammetry the extraction of cartographic feature be the most time consume. 
since the introduction of digital photogrammetry much attention therefore have be pay to the development of tool for a more efficient acquisition of cartographic feature. 
fully automatic acquisition of feature like road and building however appear to be very difficult and may even be impossible. 
the extraction of cartographic feature from digital satellite imagery require interpretation of this imagery. 
the knowledge one need about the topographic object and their appearance in satellite image in order to recognize these object and extract the relevant object outline be difficult to model and to implement in computer algorithm. 
this paper introduce support vector machine svm base method of road extraction from high resolution remote sense image. 
in this approach road extraction be peforme in two step. 
hi the first step svm be employ to classify the image into two category road and non road. 
in the second step shape descriptor be use to extract road from other spectrally similar object. 
result show the validity of the approach. 
current status and future trend of nanoscale technology and its impact on modern computing biology medicine and agricultural biotechnology. 
nanoscale technology have go from be just an ambitious concept to be a rapidly advance area of interdisciplinary science with immense practical importance. 
feymnan s vision on nanoscience provide great impetus to the development of nanophysic nanochemistry nanoelectronic and nanotechnology in general. 
high resolution microscopic device such as scan tunneling microscope transmission electron microscope and atomic force microscope etc. 
in mid 1980s allow researcher to see individual atom on surface and arrange they at will. 
the author nanobiologist computer scientist biotechnologist and material scientist will attempt to provide a review of the state of the art in the field of nanoscale technology and its impact on various field of research like computation basic biology medicine and agricultural biotechnology. 
imprint of memory mechanism in living system operate at different level e.g. 
biochemical immunological and neuronal have provide input to design and fabricate bio inspired nanoelectronic device suitable for various application. 
several example of such nanoseale technology base framework and device will be present in the scenario of their potential role in the development of future nanoscale technology. 
nanoscale technology might finally revolutionize computational intelligence and thinking. 
the power and limit of compute process govern the intelligence knowledge acquisition and thinking process of human and machine. 
present computational method and model provide we courage to study the problem but these tool be not yet sufficient to answer the follow riddle of machine intelligence  what can computer do well than human what can human do well than computer and the most important one  what be computable the author will try to present evidence that will show bio inspire nanoscale technology might gain the power in help we to go deeply into these challenge of research in future. 
use decision tree learn to predict workflow activity time consumption. 
activity time consumption knowledge be essential to successful scheduling in workflow application. 
however the uncertainty of activity execution duration in workflow application make it a non trivial task for scheduler to appropriately organize the ongoing process. 
in this paper we present a k level prediction approach intend to help workflow scheduler to anticipate activity time consumption. 
this approach first define k level as a global measure of time. 
then it apply a decision tree learn algorithm to the workflow event log to learn various kind of activity execution characteristic. 
when a new process be initiate the classifier produce by the decision tree learning technique take prior activity execution information as input and suggest a level as the prediction of posterior activity s time consumption. 
in the experiment on three vehicle manufacturing enterprise 896 activity be investigate and we separately achieve and average prediction accuracy of 80.27 70.93 and 61.14 with k 10. 
we also apply our approach on great value of k however the result be less positive. 
we describe our approach and report on the result of our experiment. 
development of hsk tooling expert system in high speed machining. 
the analysis design and development of hsk tooling expert system be an important process of expert knowledge manage system in the paper. 
for a give application environment the entity model and datum model of the system be analyze and abstract through investigation and research. 
then an expert system be set up which be able to reflect the relationship between information in realistic world to fulfill datum requirement and cut requirement with the support of a certain database manage library system. 
therefore a hsk tooling expert system should possess advantage as datum structurize high independence of datum and application program datum sharing and reduce datum redundancy to the least limit. 
fpga base accelerator design for rankboost in web search engine. 
search relevance be a key measurement for the usefulness of search engine. 
shift of search relevance among search engine can easily change a search company s market cap by ten of billion of dollar. 
with the ever increase scale of the web machine learning technology have become important tool to improve search relevance rank. 
rankboost be a promising algorithm in this area but it be not widely use due to its long training time. 
to reduce the computation time for rankboost we design a fpga base accelerator system. 
the accelerator plug into a commodity pc increase the training speed on msn search engine datum by two order of magnitude compare to the original software implementation on a server. 
the propose accelerator have be successfully use by researcher in the search relevance rank. 
a fuzzy slide mode control base on model reference adaptive control for permanent magnet synchronous linear motor. 
in order to meet the demand of high acceleration high deceleration and high precision motion control system the direct drive linear motor as the prime motion actuator be widely use in modern motion control system such as machine tool range from mass transportation to factory automation etc. 
among these application permanent magnet synchronous linear motor pmslm owe to their simple structure easy of manufacture and simple control be more frequently use. 
the advantage of use pmslm be that it can provide high performance motion with reduce mechanical component but unlike conventional ball crew drive the pmslm system eliminate the mechanical coupling rotary to linear translator and reduction gear. 
therefore any change or disturbance in the load will be directly reflect back to the motor and control system which will cause large deterioration in motion control. 
in this paper the model of pmslm be establish firstly secondly a fuzzy slide mode control base on model reference adaptive control mrac for permanent magnet synchronous linear motor pmslm system which combine the merit of mrac the stide mode control and the fuzzy inference mechanism be propose. 
in order to reduce the complex identification of mrac the slide mode control smc be employ in the controller design which make the response of the pmslm system can strictly track the reference mode and be less sensitive to external load disturbance and the system uncertaintie. 
the introduction of fuzzy control effectively minimize the chattering of smc. 
at last the result of simulation use propose method be illustrate which illuminate the propose method have good track characteristic and strong robustness for external load disturbance and the system uncertainty. 
nonlinear programming in approximate dynamic programming bang bang solution stock management and unsmooth penalty. 
many stochastic dynamic programming task in continuous action space be tackle through discretization. 
we here avoid discretization then approximate dynamic programming adp involve i many learning task perform here by support vector machines for bellman function regression ii many non linear optimization task for action selection for which we compare many algorithm. 
we include discretization of the domain as particular non linear programming tool in our experiment so that by the way we compare optimization approach and discretization method. 
we conclude that robustness be strongly require in the non linear optimization in adp and experimental result show that i discretization be sometimes inefficient but some specific discretization be very efficient for bang bang problem ii simple evolutionary tool outperform quasi random in a stable manner iii gradient base technique be much less stable iv for most high dimensional less unsmooth problem covariance matrix adaptation be first rank. 
active learning in regression with application to stochastic dynamic programming. 
we study active learning as a derandomized form of sample. 
we show that full derandomization be not suitable in a robust framework propose partially derandomize sampling and develop new active learning method i in which expert knowledge be easy to integrate ii with a parameter for the exploration exploitation dilemma iii less randomized than the full random sampling yet also not deterministic. 
experiment be perform in the case of regression for value function learning on a continuous domain. 
our main result be i efficient partially derandomize point set ii moderate derandomization theorem iii experimental evidence of the importance of the frontier iv a new regression specific user friendly sample tool less robust than blind sampler but that sometimes work very efficiently in large dimension. 
all experiment can be reproduce by download the source code and run the provide command line. 
virtual security teach technique teach ia method use vmware team. 
teach security technique and method today require that the instructor know the student to a depth of trust and integrity that be often impractical in a university set. 
merely impart instruction and hand on how to information can sometimes put the instructor and potentially the educational institution at risk as these tool and technique for testing security be only a step remove from the method and mean of effect security breach or cause incident. 
the need for training must therefore be balance with the responsibility to provide an isolated and restrained environment in which to present material and hone new skill or to use the vernacular skilz. 
as a means of solve this virtual machines vm and virtual network environment or team architecture offer a solution to these issue. 
they also provide from an educational context a set of know problem and finding with which the student can study and develop the tool technique and knowledge to be an effective information assurance professional. 
this paper present a series of architecture and scenario propose to effect such a learning environment that retain the viability of a real network environment while provide an isolated and restrict learn area. 
this can be achieve through a series of scenario and vm team member scenario player in a virtual machine base learn environment. 
this approach allow a number of benefit isolation of the learn environment restrict potential issue do attack signature detection to a secure space provide limit on tool and technique usage and impact limit and mitigate risk and liability issue for the educational institution the vm environment also offer a unique opportunity to provide completely know interaction between the student and the learn environment the software and the underlying virtual hardware. 
a detailed set of propose scenario and a learn environment architecture include toolset and target of evaluation toe system be propose. 
the applicability of the vm team system approach be discuss through a suite of scenario design to illustrate attack causation monitoring and detection. 
predict building contamination use machine learning. 
potential event involve biological or chemical contamination of building be of major concern in the area of homeland security. 
tool be need to provide rapid onsite prediction of contaminant level give only approximate measurement in limited location throughout a building. 
in principal such tool could use calculation base on physical process model to provide accurate prediction. 
in practice however physical process model be too complex and computationally costly to be use in a real time scenario. 
in this paper we investigate the feasibility of use machine learning to provide easily compute but approximate model that would be applicable in the field. 
we develop a machine learning method base on support vector machine regression and classification. 
we apply our method to problem of estimate contamination level and contaminant source location. 
alignment of multiple protein with an ensemble of hide markov model. 
the alignment of multiple protein sequence be a problem of fundamental importance in bioinformatic. 
in general the optimal alignment can be obtain through the optimization of an objective function. 
however such an optimization task be often computationally intractible most of the exist alignment tool thus use statistical or machine learning base method to avoid direct optimization. 
in this paper we develop a new method that can progressively construct and update a set of alignment by add sequence in certain order to each of the exist alignment. 
in particular each of the exist alignment be model with a profile hide markov model hmm and an add sequence be align to each of these profile hmm. 
the profile hmm in the set be then update base on the alignment with lead alignment score. 
we perform experiment on balibase benchmark to compare the performance of this new approach with that of other alignment tool. 
our experiment show that by introduce an integer parameter that control the number of profile hmm in the set we be able to efficiently explore the alignment space and significantly improve the alignment accuracy on sequence with low similarity. 
a fast learning algorithm for one class support vector machine. 
support vector machine svm be a powerful tool to solve classification problem this paper propose a fast sequential minimal optimization smo algorithm for train one class support vector regression ocsvm firstly give a analytical solution to the size two quadratic programming qp problem then propose a new heuristic method to select the working set which lead to algorithm s fast convergence. 
the simulation result indicate that the propose smo algorithm can reduce the training time of ocsvm and the performance of propose smo algorithm be well than that of original smo algorithm. 
face recognition base on curveface. 
a new method call curveface be firstly present for face recognition which be base on curvelet transform. 
curvelet be the late multiscale geometric analysis tool. 
contrast to wavelet transform curvelet transform directly take edge as the basic representation element and be anisotropic with strong direction. 
it be a multiresolution band pass and directional function analysis method which be useful to represent the image edge and the curve singularity in image ignore efficiently. 
it yield a more sparse representation of the image than wavelet and ridgelet lran fortn. 
in ace recognition the curvelet coefficient can betler represent the mainfeature of theface. 
the support vector machine svm can then be use to classifi the image. 
svm be base on the statistical learning theory and be especially validfor small sample set and can get high recognition rate. 
multi class svm be employ in this paper. 
the simulation show that the propose method be well than wavelet base method. 
study of model cluster and its application to ensemble learning. 
cluster technique be an important tool for datum analysis and have a promising prospect in data mining pattern recognition etc. 
usually object in cluster analysis be of vector which consist of some feature. 
they may be represent as point in euclidean space. 
however in some task object in cluster analysis may be some abstract model other than datum point for example neural network decision tree support vector machine etc. 
by define the extended distance in real task there be some different definition form about distance cluster method be study for the abstract data object. 
framework of cluster algorithm for object of model be present as its application a method for improve diversity of ensemble learning with neural network be investigate. 
the relation between the number of cluster in cluster analysis the size of ensemble learning and performance of ensemble learning be study by experiment. 
semantic model base heterogeneous database integration platform. 
enterprise need integrate all relevant heterogeneous database in semantic level to react to requirement of their customer collaborate with partner identify and exploit new business opportunity quickly and effectively. 
in this context a semantic model base integration platform be develop to cover the whole integration process. 
the platform include three module correspond to different integration stage one metadata abstraction module be use to get available metadata for attribute correspondence identification. 
two semantic matching module be apply to analyze the metadata and find attribute in different database that represent the same real world concept. 
three user checking module adopt semantic model construction principle to describe the matching result as a draft semantic model and provide user edit tool to check and improve the draft model. 
this document describe the architecture of our platform walk through its most important two feature machine learning technology base attribute matching and semantic model construction principle. 
cooperation in the prey predator problem with learn classifier system. 
this paper deal with learn cooperation in a group of predator chase a prey. 
a learn predator have no knowledge about the environmental information. 
it only know that it should adapt its action to other predator expectation. 
the learn classifier system be a very interesting tool for the machine learn technique. 
indeed it help a learn agent to evaluate its action and to take right action correspond to situation in order to have a well cooperation with other agent. 
the result show how the learning be construct in such collective task. 
extract actionable knowledge from decision tree. 
most datum mining algorithm and tool stop at discover customer model produce distribution information on customer profile. 
such technique when apply to industrial problem such as customer relationship management crm be useful in point out customer who be likely attritor and customer who be loyal but they require human expert to postprocess the discover knowledge manually. 
most of the postprocesse technique have be limit to produce visualization result and interestingness ranking but they do not directly suggest action that would lead to an increase in the objective function such as profit. 
in this paper we present novel algorithm that suggest action to change customer from an undesired status such as attritor to a desire one such as loyal while maximize an objective function the expect net profit. 
these algorithm can discover cost effective action to transform customer from undesirable class to desirable one. 
the approach we take integrate datum mining and decision make tightly by formulate the decision make problem directly on top of the datum mining result in a postprocesse step. 
to improve the effectiveness of the approach we also present an ensemble of decision tree which be show to be more robust when the training datum change. 
empirical test be conduct on both a realistic insurance application domain and uci benchmark datum. 
bayesian neural network for internet traffic classification. 
internet traffic identification be an important tool for network management. 
it allow operator to well predict future traffic matrix and demand security personnel to detect anomalous behavior and researcher to develop more realistic traffic model. 
we present here a traffic classifier that can achieve a high accuracy across a range of application type without any source or destination host address or port information. 
we use supervised machine learning base on a bayesian train neural network. 
though our technique use training datum with category derive from packet content training and testing be do use feature derive from packet stream consist of one or more packet header. 
by provide classification without access to the content of packet our technique offer wide application than method that require full packet payload for classification. 
this be a powerful advantage use sample of classified traffic to permit the categorization of traffic base only upon commonly available information. 
learning unlearning eo for mine high resolution image. 
the last two decade show an important development of satellite imagery with past and present satellite acquire enormous volume of datum. 
meanwhile the quality of the acquire image increase permit the recording of high resolution image 0.6 divide by 2.5 meter pixel in multispectral band. 
thus both the data volume and the information detail increase dramatically. 
consequently new method and tool to access and interpret earth observation eo image be need. 
the present paper present a semantic search engine for high resolution hr eo image base on a hierarchical information model of satellite image content. 
to face the potentially ambiguo meaning of image structure depend on their contextual understanding the search engine use bayesian inference to learn category and a support vector machine svm classifier to assign semantic. 
the category be group and memorise the semantic of image structure facilitate their recognition in various context. 
also the generation of category help learn from a small training datum set i.e. 
image example thus the method be useful for the exploitation of very large datum volume. 
the concept have enhance infer power therefore optimise the human machine communication hmc which be enhance with learn unlearning function. 
non linear approach for the classification of facial expression at vary degree of intensity. 
the research discuss in this paper document a comparative analysis of two nonlinear dimensionality reduction technique for the classification of facial expression at vary degree of intensity. 
these nonlinear dimensionality reduction technique be kernel principal component analysis kpca and locally linear embedding lle. 
the approach present in this paper employ psychological tool computer vision technique and machine learning algorithm. 
in this paper we concentrate on compare the performance of these two technique when combine with support vector machines svm at the task of classify facial expression across the full expression intensity range from near neutral to extreme facial expression. 
receiver operate characteristic roc curve analysis be employ as a means of comprehensively compare the result of these technique. 
use digital pen to program welding task. 
purpose interaction with robot system for the specification of manufacture task need to be simple since the paper target the widespread use of robot in small and medium enterprise sme. 
in the good case exist practice from manual work could be use to ensure current employee a smooth introduction to robot technology as a natural part of their work. 
the aim of the paper be to simplify the robot program task by allow the user to simply make technical drawing on a sheet of paper. 
craftsman use paper and raw sketch for several situation to share idea to get a well perspective of the problem or to remember the customer situation. 
currently these sketch have to be either interpret by the worker when produce the final product by hand or transfer into cad file use an appropriate software tool. 
the former mean that no automation be include the latter mean extra work and considerable experience in use the cad tool. 
design methodology approach the approach be to use a digital pen and paper both base on the anoto technology as input device for sme robotic task thereby create simple and more user friendly alternative for the programming parameterization and command action. 
to this end the basic technology have be investigate and fully work prototype have be develop to explore the possibility in the context of typical sme application. 
base on the encouraging experimental result it be believe that drawing on digital paper will among other mean of human robot interaction play an important role in manufacture sme in the future. 
consequently a fully work test case welding example be present and explain allow a complete demonstration of all the develop feature. 
findings this paper explore the utilization of digital pen for the task of program industrial robot manipulator the possibility of obtain robot program from technical drawing on a sheet of paper. 
a practical implementation be present to demonstrate how to use digital pen and cad application to program industrial robot. 
the result clearly show that the digital pen base on anoto technology integrate with cad interface and code generation interface be very useful and powerful for the plan task. 
the next step will be to adopt a software infrastructure and develop the necessary service to allow system integrator to consider this type of device as an advanced user friendly robot program method. 
originality value this be the first time that digital pen have be use to program robot manipulator. 
predict shaft proximity probe track runout on api motor and generator. 
eddy current proximity probe be use extensively for monitor shaft vibration of large motor and generator especially those manufacture to american petroleum institute specification. 
it be important to minimize proximity probe track runout which be also know as slow roll runout so as to minimize the measurement error when monitor and diagnose vibration. 
customer specification strive to reduce the slow roll runout in order to improve the reliability of the vibration signal the slow roll runout specification be recognize as one of the more difficult requirement to meet on a consistent basis. 
if the runout specification be not meet during final test of a machine it can cause critical delay in delivery and impact project completion. 
manufacturer be develop strategy to provide motor and generator with the low possible runout consistently and on time. 
this paper describe a factory measurement method use during the manufacturing process that be able to discriminate the four major component of runout journal surface out of roundness proximity probe track out of roundness lack of concentricity of the two surface and electrical runout. 
with accurate knowledge of each of the component of slow roll runout manufacturer have the ability to control and improve they. 
with today s aggressive project timeline on time delivery be vital. 
diagnose issue early in the manufacturing process allow step to be take to mitigate problem before machine assembly. 
this minimize the likelihood of have to disassemble the machine to correct excessive runout and avoid the associated schedule delay. 
this be essential for critical machine and especially those that be schedule drive. 
result from this in process measurement method be also compare with final test stand result. 
machine learn to analyze migration parameter in parallel genetic algorithm. 
parallel genetic algorithm pga be a powerful tool to deal with complex optimization problem. 
nevertheless the task of select its parameter accurately be an optimization problem by itself. 
any additional help or hint to adjust the configuration parameter will lead both towards a more efficient pga application and to a well comprehension on how these parameter affect optimization behavior and performance. 
this contribution offer an analysis on certain pga parameter such as migration frequency topology connectivity and number of island. 
the study have be carry out on an intensive set of experiment that collect pga performance on several representative problem. 
the result have be analyze use machine learn method to identify behavioral pattern that be label as good pga configuration. 
this study be a first step to generalize relevant pattern from the problem analyze that identify well configuration in pga. 
a combination of tool method for learn interpretable fuzzy rule base classifier from support vector machine. 
a new approach be propose for the data base identification of transparent fuzzy rule base classifier. 
it be observe that fuzzy rule base classifier work in a similar manner as kernel function base support vector machine svm since both model the input space by nonlinearly map into a feature space where the decision can be easily make. 
accordingly train svm can be use for the construction of fuzzy rule base classifier. 
however the transformed svm do riot automatically result in an interpretable fuzzy model because the svm result in a complex rule base where the number of rule be approximately 40 60 of the number of the training datum. 
hence reduction of the svm initialize classifier be an essential task. 
for this purpose a three step reduction algorithm be develop base on the combination of previously publish model reduction technique. 
in the first step the identification of the svm be follow by the application of the reduced set method to decrease the number of kernel function. 
the reduced svm be then transform into a fuzzy rule base classifier. 
the interpretability of a fuzzy model highly depend on the distribution of the membership function. 
hence the second reduction step be achieve by merge similar fuzzy set base on a similarity measure. 
finally in the third step an orthogonal least square method be use to reduce the number of rule and re estimate the consequent parameter of the fuzzy rule base classifier. 
the propose approach be apply for the wiscon sin breast cancer iris and wine classification problem to compare its performance to other method. 
a concept for ubiquitous robotic in industrial environment. 
in this paper a concept for industrial ubiquitous robotic be present. 
the concept combine two different approach to manage agile adaptable production firstly the human operator be strongly in the production loop and secondly the robot workcell will be more autonomous and smart to manage production. 
this kind of autonomous robot cell can be call production island. 
communication to the human operator work in this kind of smart industrial environment can be divide into two level body area communication and operator infrastructure communication include device machine and infra. 
body area communication can be supportive in two direction datum be record by mean of measure physical action such as hand movement body gesture or supportive when it will provide information to user such as guide or manual for operation. 
body area communication can be carry out use short range communication technology such as nfc near field communication which be rfid type of communication. 
in the operator infrastructure communication wlan or bluetooth  communication can be use. 
beyond the current human machine interaction hmi system the present system concept be design to fulfill the requirement for hybrid knowledge intensive manufacturing in the future where human and robot operate in close co operation. 
a knowledge base manufacturing and cost evaluation system for product design re design. 
various research study have conclude that most new design project be actually re design activity. 
this re design may be for improvement or for reprovision of exist product. 
most research effort for provide computer tool for support conceptual or early design mainly concentrate on the design of new product. 
in practice manufacturing plan generate when an order be place may quickly become out date as the manufacturing environment and constraint often change. 
it be therefore equally important to regenerate manufacturing plan and re evaluate design every time a product be change redesign or reorder. 
this project focus on manufacturability analysis and provide re design support for conceptual design of discrete single piece mechanical part with emphasis on machine process. 
this limitation of implement the prototype system for re design activity be not a system design or methodology restriction. 
the condition have be impose by the author as a prelude to validate the system and its result. 
a novel hybrid approach use a combination of sequential flowchart logic and an expert system have be develop which use a user define feature tree as the input for its analysis. 
the system allow the designer to estimate manufacturability accord to criterion of time and cost and also to explore different scenario of parametric variation in the design. 
a case study have be present to validate the system s practicality and usefulness. 
an intelligent process planning system for prismatic part use step feature. 
this paper present an intelligent process planning system use step feature st featcapp for prismatic part. 
the system map a step ap224 xml datum file without use a complex feature recognition process and produce the correspond machining operation to generate the process plan and correspond step nc in xml format. 
it carry out several stage of process planning such as operation selection tool selection machine parameter determination machine tool selection and setup planning. 
a hybrid approach of most recent technique neural network fuzzy logic and rule base of artificial intelligence be use as the inference engine of the develop system. 
an object orient approach be use in the definition and implementation of the system. 
an example part be test and the correspond process plan be present to demonstrate and verify the propose capp system. 
the paper thus suggest a new feature base intelligent capp system for avoid complex feature recognition and knowledge acquisition problem. 
a novel approach to dfm in toolmaking a case study. 
a novel approach to avoid the knowledge gap between design and production be present in this paper. 
the main idea be to build a system in the form of a computer program whose core be the manufacturing expert system to be use by the product designer. 
the system reveal critical feature of the design product from the manufacturing point of view and point they out to the product designer. 
the product designer can decide whether to change the critical part of the product or not. 
the system present in this paper be prepare for the toolmaking where a lot of relatively cheap product be make by one relatively expensive tool. 
since the shape of the cavity in the tool be the negative shape of the product small change in the product design can significantly reduce the manufacturing cost of the tool. 
manufacture knowledge sharing in plm a progression towards the use of heavy weight ontology. 
the drive to maximize the potential benefit of decision support system continue to increase as industry be continually drive by the competitive need of operate in dynamic global environment. 
the more extensive information support tool which be become available in the plm world appear to have great potential but require a substantial overhead in their configuration. 
however share information and knowledge in cross disciplinary team and across system and company boundary be not straightforward and there be a clear need for more effective framework for information and knowledge sharing if new product development process be to have effective ict support. 
this paper present a view of the current status of manufacture information share use light weight ontology and go on to discuss the potential for heavyweight ontological engineering approach such as the process specification language psl. 
it explain why such language be need and how they provide an important step towards process knowledge sharing. 
machine example be use to illustrate how psl provide a rigorous basis for process knowledge sharing and subsequently to illustrate the value of link foundation and domain ontology to provide a basis for multi context knowledge sharing. 
tool path modification for optimize pocket milling. 
many operation in cnc milling task be perform use pocket milling which have two main type of tool path trajectory contour parallel path and direction parallel path. 
hence there have be a lot of work on geometrically efficient algorithm to generate tool path. 
although the conventional tool path obtain from geometric information have be successful to make a desirable shape it seldom consider physical process concern like cut force and chatter. 
in order to cope with these problem an optimize tool path which maintain as constant mrr as possible in order to achieve constant cut force and to avoid chatter vibration at all time be introduce and the result be verify. 
additional tool path segment be append to the basic tool path obtain by geometric shape by use a pixel base simulation technique. 
the algorithm have be implement for two dimensional contiguous end mill operation and cut test be conduct by measure spindle current which reflect machining situation to verify the significance of the propose method. 
development of advanced cad cam system use function feature. 
three dimensional cad system contribute considerably to the detailed design process of product. 
they be also use to build three dimensional model require for subsequent step that follow such as analysis and manufacturing process which apply cae and cam system. 
the ability of three dimensional cad system to form model be increasingly enhance enable designer to build product shape easily without design expertise. 
during the detailed design process designer be require not only to define product shape precisely but also to assign attribute information such as dimensional tolerance geometrical tolerance roughness etc. 
which be essential for manufacturing process. 
at the same time in mold design characteristic of mold and possible deformation of the mold item have to be consider while determine mold shape. 
they for example include set the draft angle estimate solidification contraction during injection mold design and estimate the springback angle during press die design. 
such task require designer with advanced design skill and manufacturing knowledge in order to achieve appropriate design. 
this paper propose a method to automatically assign required attribute information such as accuracy information and machining attribute to a portion of a design product by assign a function feature to it. 
with this method deformation be also incorporate automatically with due consideration for manufacture. 
a basic system to perform the above be develop with fundamental algorithm and datum construction. 
the usefulness of this function feature be then confirm through simple experiment. 
this paper also describe the incorporation of the propose system in a cad system. 
morfessor and varikn machine learning tool for speech and language technology. 
this paper introduce two recent open source software package develop for unsupervised natural language modeling. 
ne morfessor program segment word automatically into morpheme like unit without any rule base morphological analyzer. 
the varikn toolkit train language model produce a compact set of high order n gram utilize state of art kneser ney smoothing. 
as an example this paper show how to construct a language model for speech recognition in multiple language utilize only a minimal amount of linguistic resource. 
morfessor and varikn also have other application in text understanding information retrieval and machine translation. 
unsupervised machine learning technique be particularly well suited for the development of system for less resource language because they do not depend on manually design morphological or syntactical analyzer or annotated datum. 
accelerate the annotation of lexical data for less resource language. 
the development of digital resource be an expensive and time consume endeavor especially in the case of less resource language. 
in this paper we describe a freely available open source system call turboannotate for bootstrappe linguistic datum for machine learn purpose or for manually create gold standard or other annotated list. 
a detailed description of the design and functionality of the tool be give focus on how the requirement of end user be be address through it. 
it be indicate that turboannotate do not only promise to help increase the accuracy of human annotator but also to save enormously on human effort in term of time. 
feed rate control of the wire edm process. 
wire electrical discharge machining wire edm be a process of metal cutting where a special travel wire be use as the cutting tool and metal cutting be achieve through spark erosion. 
since the introduction of cnc wire edm the technology of monitoring and control of machining process have be accelerate because of the need for improvement in machine efficiency wire breakage prevention and part quality. 
in order to guarantee the high accuracy of the machining process the spark erosion should occur with an as constant as possible gap width. 
only in the optimum state the high material removal rate can be realize. 
the quality of feed rate control determine the stability of the gap width the machining process. 
base on the characteristic of gap voltage waveform there be four major gap state classify as open circuit normal spark arc discharge and short circuit. 
to achieve the stability of the machining operation a control strategy be propose to optimize of the feed rate. 
the optimization of the feed rate control be an important factor for maintain the process stability while spark erosion machining. 
the parameter of the feed rate control be a part of process analysis and must satisfy the goal of feed rate control. 
in the present paper relevant process parameter be investigate and assess. 
the follow four process variable can be use for feed control gap voltage ignition delay time voltage breakdown high frequency part of the burn voltage. 
a new pulse discriminate and control system have be develop for process monitoring and control in wire edm. 
in this paper a wire edm pulse discriminate and control system be develop for the identification of gap state then use these relevant process parameter to control machine process and make the process stability. 
the develop pulse discriminating and control system can significantly reduce the arc discharge and short sparking frequency as well as achieve stable machining under the condition where the instability of machining operation be prone to occur. 
visualizing berkeley socket call in students programs. 
the berkeley sockets api be a library of function macro and datum structure enable a program to initiate and manage network communication between two or more process on the same machine or across a network of machine. 
the api be the main mechanism by which program communicate with the operate system s tcp ip stack and thereby with almost all internet service and program. 
socket programming open a new realm of development for computer science students as they be able to create program that can communicate via the internet. 
however while learn student frequently misuse the socket api or have difficulty understanding where run time and logic error in their code occur. 
student learn about socket be typically present with a series of static diagram in textbook that increase in complexity with each progression. 
these diagram may not allow the reader to easily comprehend the transition between each step nor understand which function in the api perform the event. 
space constraint in textbook often limit a sequence of diagram to two or three whereas over 10 call to the socket api be often necessary to initiate and undertake communi cation. 
surprisingly there be no effective tool or general technique for debug student socket program. 
in this paper we present a software solution to visualize the execution of student program interaction with the berkeley sockets api. 
the tool accept the source code of two or more network program and compile they in such a way that at run time their call to the socket api and related function be display together with an annotation of activity and error condition. 
the program be not simply a static simulator it provide a mean to visualize the network event in actual student develop program. 
comparison of long term numerical and experimental total knee replacement wear during simulated gait loading. 
pre clinical experimental wear testing of total knee replacement tkr component be an invaluable tool for evaluate new implant design and material. 
however wear testing can be a lengthy and expensive process and hence parametric study evaluate the effect of geometric loading or alignment perturbation may at time be cost prohibitive. 
the objective of this study be to develop an adaptive fe method capable of simulate wear of a polyethylene tibial insert and to compare predict kinematic weight loss due to wear and wear depth contour to result from a force control experimental knee simulator. 
finite element base computational wear prediction be perform to five million gait cycle use both force  and displacement control input. 
the displacement control input by accurately match the experimental tibiofemoral motion provide an evaluation of the simple wear theory. 
the force control input provide an evaluation of the overall numerical method by simultaneously predict both kinematic and wear. 
analysis of the predict wear convergence behavior indicate that 10 iteration each represent 500,000 gait cycle be require to achieve numerical accuracy. 
use a wear factor estimate from the literature the predict kinematic polyethylene wear contour and weight loss be in reasonable agreement with the experimental datum particularly for the stance phase of gait. 
although further development of the simplified wear theory be important the initial prediction be encouraging for future use in design phase implant evaluation. 
in contrast to the experimental testing which occur over approximately two month computational wear prediction require only two h. 
c 2006 elsevier ltd. 
all right reserve. 
contemporary qsar classifier compare. 
we present a comparative assessment of several state of the art machine learning tool for mining drug datum include support vector machine svm and the ensemble decision tree method boost bagging and random forest use eight datum set and two set of descriptor. 
we demonstrate by rigorous multiple comparison statistical test that these technique can provide consistent improvement in predictive performance over single decision tree. 
however within these method there be no clearly well perform algorithm. 
this motivate a more in depth investigation into the property of random forest. 
we identify a set of parameter for the random forest that provide optimal performance across all the study data set. 
additionally the tree ensemble structure of the forest may provide an interpretable model a considerable advantage over svm. 
we test this possibility and compare it with standard decision tree model. 
build a faceted classification for the humanity principle and procedure. 
purpose this paper aim to provide an overview of principle and procedure involve in create a faceted classification scheme for use in resource discovery in an online environment. 
design methodology approach facet analysis provide an established rigorous methodology for the conceptual organization of a subject field and the structuring of an associated classification or control vocabulary. 
this paper explain how that methodology be apply to the humanity in the fatks project where the objective be to explore the potential of facet analytical theory for create a control vocabulary for the humanity and to establish the requirement of a faceted classification appropriate to an online environment. 
a detailed faceted vocabulary be develop for two area of the humanity within a broad facet framework for the whole of knowledge. 
research issue include how to create a data model which make the faceted structure explicit and machine readable and provide to its further development and use. 
findings in order to support easy facet combination in indexing and facet search and browse on the interface faceted classification require a formalized datum structure and an appropriate tool for its management. 
the conceptual framework of a faceted system proper can be apply satisfactorily to humanity and fully integrate within a vocabulary management system. 
research limitation implication the procedure describe in this paper be concern only with the structuring of the classification and do not extend to indexing retrieval and application issue. 
practical implication many stakeholder in the domian of resource discovery consider develop their own classification system and support tool. 
the method describe in this paper may clarify the process of build a faceted classification and may provide some useful idea with respect to vocabulary maintenance tool. 
originality value as far as the author be aware there be no comparable research in this area. 
train artificial neural network for glaucoma diagnosis use visual field datum a comparison with conventional algorithm. 
purpose to evaluate and confirm the performance of an artificial neural network ann train to recognize glaucomaton visual field defect and compare its diagnostic accuracy with that of other algorithm propose for the detection of visual field loss. 
method sita standard 30 two visual field from 100 glaucoma patient and 116 healthy participant form the datum set. 
our ann be a previously describe fully train network use score pattern deviation probability map as input datum. 
its diagnostic accuracy be compare to that of the glaucoma hemifield test the pattern standard deviation index at the p five and one and also to a technique base on the recognize cluster of significantly depressed test point. 
result the include test have early to moderate visual field loss median md 6.16 db. 
ann achieve a sensitivity of 93 at a specificity level of 94 with an area under the receiver operate characteristic curve of 0.984. 
glaucoma hemifield test attain a sensitivity of 92 at 91 specificity. 
pattern standard deviation with a cut off level at p five have a sensitivity of 89 with a specificity of 93 whereas at p one the sensitivity and specificity be 72 and 97 respectively. 
the cluster algorithm yield a sensitivity of 95 and a specificity of 82. 
conclusion the high diagnostic performance of our ann base on refined input visual field datum be confirm in this independent sample. 
its diagnostic accuracy be slightly to considerably well than that of the compare algorithm. 
the result indicate the large potential for ann as an important clinical glaucoma diagnostic tool. 
tool planning for a light out machining system. 
the goal of most advanced manufacturing system be to continuously improve uptime while reduce the amount of direct supervision require for operation. 
however when there be randomness in system component this improvement can be difficult to attain. 
for instance when automate metal cut operation the randomness of tool life require ensure that there be sufficient cutting tool available on the machine to meet unsupervised production requirement and variation in tool life can make planning challenge. 
this paper focus on the problem of select the cut speed for process a set of part type by an unsupervised metal cut flexible machine in such a situation. 
the machine be set up to operate unsupervised for a specific know duration. 
the tool magazine of this machine be preloade with tool commensurate with the processing requirement. 
the lifetime of each tool be random with the coefficient of variation assume to be constant and a system for online monitoring of the tool condition be available. 
the objective in this situation be to ensure that disruption be minimize in other word that the machine operate while ensure some minimum probability of completion. 
this be refer to as the required service level. 
this paper present model for determine the optimal magazine loading and cut speed that will meet a required service level. 
solution obtain use commonly available nonlinear programming solver be include for illustration and difference when the tool life distribution be either normal or erlang be contrast. 
c 2008 the society of manufacturing engineers. 
publish by elsevier ltd. 
all right reserve. 
on find the good parameter of fuzzy k mean for cluster microarray datum. 
cluster algorithm such as hierarchical clustering k mean and fuzzy k mean have become important tool for gene expression analysis of microarray datum. 
however the need of prior knowledge of the number of cluster k and the fuzziness parameter b limit the usage of fuzzy clustering. 
in this paper we use simulated anneal sa and fuzzy k mean cluster to determine the optimal parameter namely the number of cluster k and the fuzziness parameter b. 
to improve sa two method search with tabu list and shrink the scope of randomization be apply. 
our result show that a nearly optinial pair of k and b a near optimal value of k can be obtain without explore the entire search space. 
hybrid outcome prediction model for severe traumatic brain injury. 
numerous study address different method of head injury prognostication have be publish. 
unfortunately these study often incorporate different head injury prognostication model and study population thus make direct comparison difficult if not impossible. 
furthermore new artiricial intelligence tool such as machine learning method have evolve in the field of datum analysis alongside more traditional method of analysis. 
this study target the development of a set of integrated prognostication model combine different class of outcome and prognostic factor. 
methodology such as discriminant analysis logistic regression decision tree bayesian network and neural network be employ in the study. 
several prognostication model be develop use prospectively collect datum from 513 severe close head injure patient admit to the neurocritical unit at national neuroscience institute of singapore from april 1999 to february 2003. 
the correlation between prognostic factor at admission and outcome at six month follow injury be study. 
overritting error which may falsely distinguish different outcome be compare graphically. 
tenfold cross validation technique which reduce overfitte error be use to validate outcome prediction accuracy. 
the overall prediction accuracy achieve range from 49.79 to 81.49. 
consistently high outcome prediction accuracy be see with logistic regression and decision tree. 
combine both logistic regression and decision tree model a hybrid prediction model be then develop. 
this hybrid model would more accurately predict the six month post severe head injury outcome use baseline admission parameter. 
cognitive technical system what be the role of artificial intelligence. 
the newly establish cluster of excellence cotesys1 investigate the realization of cognitive capability such as perception learning reasoning planning and execution for technical system include humanoid robot flexible manufacturing system and autonomous vehicle. 
in this paper we describe cognitive technical system use a sensor equip kitchen with a robotic assistant as an example. 
we will particularly consider the role of artificial intelligence in the research enterprise. 
key research foci of artificial intelligence research in cotesys include o symbolic representation ground in perception and action o first order probabilistic representation of action object and situation o reasoning about object and situation in the context of everyday manipulation task and o the representation and revision of robot plan for everyday activity. 
improve the detection of unknown computer worm activity use active learning. 
detect unknown worm be a challenging task. 
extant solution such as anti virus tool rely mainly on prior explicit knowledge of specific worm signature. 
as a result after the appearance of a new worm on the web there be a significant delay until an update carry the worm s signature be distribute to anti virus tool. 
we propose an innovative technique for detect the presence of an unknown worm base on the computer operating system measurement. 
we monitor 323 computer feature and reduce they to 20 feature through feature selection. 
support vector machine be apply use three kernel function. 
in addition we use active learning as a selective sampling method to increase the performance of the classifier exceed above 90 mean accuracy and for specific unknown worm 94 accuracy. 
an application of machine learn method to pm10 level medium term prediction. 
the study describe in this paper analyze the urban and suburban air pollution principal cause and identify the good subset of feature meteorological datum and air pollutant concentration for each air pollutant in order to predict its medium term concentration in particular for the pm10. 
an information theoretic approach to feature selection have be apply in order to determine the good subset of feature by mean of a proper backward selection algorithm. 
the final aim of the research be the implementation of a prognostic tool able to reduce the risk for the air pollutant concentration to be above the alarm threshold fix by the law. 
the implementation of this tool will be carry out use machine learning method base on some of the most widespread statistical datum drive technique artificial neural networks ann and support vector machines svm. 
a comparison of two approach to classify with guarantee performance. 
the recently introduce transductive confidence machine approach and the roc isometric approach provide a framework to extend classifier such that their performance can be set by the user prior to classification. 
in this paper we use the k near neighbour classifier in order to provide an extensive empirical evaluation and comparison of the approach. 
from our result we may conclude that the approach be compete and promise generally applicable machine learning tool. 
browsing and visualization of semantic web content from web to the desktop. 
semantic web technology make the semantic of information explicit and thus machine processable. 
the primary aim of these technology be to fill the semantic gap by share and integrate knowledge. 
apart from the web the importance of these technology have be recognize in other area like digital library personal information management user modeling and personalization e learn and e government where they be use for explicit flexible and powerful knowledge representation and new knowledge generation. 
primarily design to be consume by computer the proliferation of ontology and semantic web content on the web as well as in other area have raise the need for direct human interaction in a simple manner. 
but the inherent limitation of rdf with respect to browse the different user requirement and the state of the current technology do not allow packaging all the require feature into a single universal browser. 
this paper report on the state of the art in browsing and visualization of datum express in rdf owl and topic map format the paper identify different user group of semantic web content and their browsing and visualization need and then evaluate state of the art tool base on those need. 
we believe that the effort of address the browse need be in the right direction and will help in the transition to the future web. 
dictionary writing system dws plus corpus query package cqp the case of tshwanelex. 
in this article the integrate corpus query functionality of the dictionary compilation software tshwanellex be analyse. 
attention be give to the handling of both raw corpus datum and annotate corpus datum. 
with regard to the latter it be show how with a minimum of human effort machine learning technique can be employ to obtain part of speech tag corpus that can be use for lexicographic purpose. 
all point be illustrate with datum draw from english and northern sotho. 
the tool and technique themselves however be language independent and as such the encouraging outcome of this study be far reach. 
an agent base approach to the multiple objective selection of reference vector. 
the paper propose an agent base approach to the multiple objective selection of reference vector from original dataset. 
effective and dependable selection procedure be of vital importance to machine learning and datum mining. 
the suggested approach be base on the multiple agent paradigm. 
the author propose use jabat middleware as a tool and the original instance reduction procedure as a method for select reference vector under multiple objective. 
the paper contain a brief introduction to the multiple objective optimization follow by the formulation of the multiple objective agent base reference vector selection optimization problem. 
further section of the paper provide detail on the propose algorithm generate a non dominated or pareto optimal set of reference vector set. 
to validate the approach the computational experiment have be plan and carry out. 
presentation and discussion of experiment result conclude the paper. 
affine feature extraction a generalization of the fukunaga koontz transformation. 
dimension reduction method be often apply in machine learning and datum mining problem. 
linear subspace method be the commonly use one such as principal component analysis pca fisher s linear discriminant analysis fda et al. 
in this paper we describe a novel feature extraction method for binary classification problem. 
instead of find linear subspace our method find lower dimensional affine subspace for data observation. 
our method can be understand as a generalization of the fukunaga koontz transformation. 
we show that the propose method have a closed form solution and thus can be solve very efficiently. 
also we investigate the information theoretical property of the new method and study the relationship of our method with other method. 
the experimental result show that our method as pca and fda can be use as another preliminary data explore tool to help solve machine learning and datum mining problem. 
surface roughness prediction use hybrid neural network. 
surface roughness be an important outcome in the machining process and it form a major part in the manufacture system. 
surface roughness depend on different machining parameter and its prediction and control be a challenge to the researcher. 
there be a need to predict surface roughness prior to machining to attain high productivity level. 
owe to advance in compute power there be an increase in the demand for the use of intelligent technique. 
recent research be direct towards hybridization of intelligent technique to make the good out of each technique. 
this article propose the development of a novel hybrid neural network nn train with genetic algorithm ga and particle swarm optimization pso for the prediction of surface roughness. 
the propose hybrid neural network be find to be competent in term of computational speed and efficiency over the neural network model. 
analysis of modular fixture design. 
a fixture be essential equipment to firmly fix the part at the good position in the workspace of the machine tool. 
the design of the fixture play an important part to obtain a machined part of good quality. 
we already formalize knowledge on the fixturing so as to be able to manage they throughout process planning design. 
now we be interested in the design of the fixture so as to pass from the fixturing model to the technological solution which will be use on the machine tool. 
this paper deal with the problem of modular fixture design with a technological point of view. 
the choice and the placement of element be carry out in take account of all the constraint quality accessibility and mechanical behaviour of the system part fixture cut tool during the machining. 
tool vibration detection with eddy current sensor in machining process and computation of stability lobe use fuzzy classifier. 
today the knowledge of a process be very important for engineer to find optimal combination of control parameter warrant productivity quality and function without defect and failure. 
in our laboratory we carry out research in the field of high speed machining with modelling simulation and experimental approach. 
the aim of our investigation be to develop a software allow the cutting condition optimisation to limit the number of predictive test and the process monitor to prevent any trouble during machine operation. 
this software be base on model and experimental datum set which constitute the knowledge of the process. 
in this paper we deal with the problem of vibration occur during a machining operation. 
these vibration may cause some failure and defect to the process like workpiece surface alteration and rapid tool wear. 
to measure on line the tool micro movement we equip a lathe with a specific instrumentation use eddy current sensor. 
obtain signal be correlate with surface finish and a signal processing algorithm be use to determine if a test be stable or unstable. 
then a fuzzy classification method be propose to classify the test in a space define by the width of cut and the cut speed. 
finally it be show that the fuzzy classification take into account of the measurement incertitude to compute the stability limit or stability lobe of the process. 
c 2005 elsevier ltd. 
all right reserve. 
bayesian networks for multivariate data analysis and prognostic modelling in cardiac surgery. 
prognostic model be tool to predict the outcome of disease and disease treatment. 
these model be traditionally build with supervised machine learning technique and consider prognosis as a static one shot activity. 
this paper present a new type of prognostic model that build on the bayesian network methodology that implement a dynamic process orient view on prognosis. 
in contrast to traditional prognostic model prognostic bayesian network explicate the scenario that lead to disease outcome and can be use to update prediction whet new information become available. 
a recursive datum analysis strategy for induce prognostic bayesian network from medical datum be present and apply to datum from the field of cardiac surgery. 
the result model outperform a model that be construct with off the shelf bayesian network learn software and have similar performance as class probability tree. 
text categorization model for identify unproven cancer treatments on the web. 
the nature of the internet as a non peer review and largely unregulated publication medium have allow wide spread promotion of inaccurate and unproven medical claim in unprecedented scale. 
patient with condition that be not currently fully treatable be particularly susceptible to unproven and dangerous promise about miracle treatment. 
in extreme case fatal adverse outcome have be document most commonly the cost be financial psychological and delay application of imperfect but prove scientific modality. 
to help protect patient who may be desperately ill and thus prone to exploitation we explore the use of machine learn technique to identify web page that make unproven claim. 
this feasibility study show that the result model can identify web page that make unproven claim in a fully automatic manner and substantially well than previous web tool and state of the art search engine technology. 
a frame of knowledge base consulting system for sulfide ore spontaneous combustion forecast. 
this paper describe a frame of knowledge base consulting system use for the assessment and forecast of spontaneous combustion of sulfide ore in underground mine. 
the system be base on a large number of laboratorial and field research result in this area for more than a decade. 
the system be compose of control centre inference machine interpreter knowledge basis knowledge acquisition and input and output. 
section. 
the knowledge basis. 
contain several important knowledge sub basis such as sulfide ore property mining factor geological information fire mechanism. 
fire case and fire control measure. 
these knowledge basis be manufacture with the assistance of the fault tree analysis technique. 
in conjunction with the risk assessment and the fire pre estimation mathematical model the system be able to define self heating potential suggest recommendation and strategy and output other recommendation and s strategy against the spontaneous combustion of sulfide ore and output other relevant conclusion. 
besides the system be capable of access the database and perform datum retrieval and update operation. 
with the help of this system mine engineer can select correct mining method and adopt a series of effective measure quickly and conveniently to void spontaneous combustion risk of sulfide ore. 
on a rough set base tool for generate rule from datum with categorical and numerical value. 
rough set theory have mainly be apply to datum with categorical value. 
in order to handle datum with numerical value we have define numerical pattern with two symbol and and have propose more flexible rough set base rule generation. 
the concept of coarse and fine for rule be explicitly define accord to numerical pattern. 
this paper focus on the rough set base method for rule generation which be enhance by numerical pattern and refer to the tool program. 
tool program be apply to datum in uci machine learning repository and some useful rule be obtain. 
a multivariate neuro fuzzy system for foreign currency risk management decision make. 
currency risk management decision involve decide on when how much and what hedge instrument i.e. currency future or option should be use to hedge its risk exposure with the base currency. 
intuitively the accuracy in forecast the direction and magnitude of future exchange rate movement be central to currency risk management decision making process. 
this research investigate the predictive performance of a hybrid multivariate model use multiple macroeconomic and microstructure of foreign exchange market variable. 
conceptually the propose system combine and exploit the merit of adaptive learn artificial neural network ann and intuitive reasoning fuzzy logic inference tool. 
an ann be employ to forecast a foreign exchange rate movement which be follow by the intuitive reasoning of multi period foreign currency return use multi value fuzzy logic for foreign currency risk management decision making. 
empirical test with statistical and machine learning criterion reveal plausible performance of its predictive capability. 
c 2006 elsevier b.v. 
all right reserve. 
classification of fmri independent component use ic fingerprint and support vector machine classifier. 
we present a general method for the classification of independent component ic extract from functional mri fmri datum set. 
the method consist of two step. 
in the first step each fmri ic be associate with an ic fingerprint a representation of the component in a multidimensional space of parameter. 
these parameter be post hoc estimate of global property of the ic and be largely independent of a specific experimental design and stimulus timing. 
in the second step a machine learn algorithm automatically separate the ic fingerprint into six general class after preliminary training perform on a small subset of expert label component. 
we illustrate this approach in a multisubject fmri study employ visual structure from motion stimulus encode face and control random shape. 
we show that one ic fingerprint be a valuable tool for the inspection characterization and selection of fmri ic and two automatic classification of fmri ic in new subject present a high correspondence with those obtain by expert visual inspection of the component. 
importantly our classification procedure highlight several neuro physiologically interesting process. 
the most intriguing of which be reflect with high intra  and inter subject reproducibility in one ic exhibit a transiently task relate activation in the face region of the primary sensorimotor cortex. 
this suggest that in addition to or as part of the mirror system somatotopic region of the sensorimotor cortex be involve in disambiguate the perception of a move body part. 
finally we show that the same classification algorithm can be successfully apply without re training to fmri collect use acquisition parameter stimulation modality and time considerably different from those use for training. 
c 2006 elsevier inc. 
all right reserve. 
fuzzy relational classification combine pairwise decomposition techniques with fuzzy preference modeling. 
this paper introduce a new approach to classification which combine pairwise decomposition technique from machine learning with hem and tool front fuzzy preference model. 
the approach call fuzzy relational classification effectively reduce the problem of classification to a problem of decision making base on a fuzzy preference relation. 
it will he show that by decompose such a relation into a strict preference an indifference and an incomparability relation it become possible to quantify different type of uncertainty in classification and thereby u support more sophisticated classification and postprocesse strategy. 
more complete gene silence by few sirnas transparent optimize design and biophysical signature. 
highly accurate knockdown functional analysis base on rna interference rnai require the possible most complete hydrolysis of the target mrna while avoid the degradation of untargete gene off target effect. 
this in turn require significant improvement to target selection for two reason. 
first the average silence activity of randomly select sirnas be as low as 62. 
second apply more than five different sirnas may lead to saturation of the rna induce silence complex risc and to the degradation of untargete gene. 
therefore select a small number of highly active sirnas be critical for maximize knockdown and minimize off target effect. 
to satisfy these need a publicly available and transparent machine learning tool be present that rank all possible sirnas for each target gene. 
support vector machine svm with polynomial kernel and constrain optimization model select and utilize the most predictive effective combination from 572 sequence thermodynamic accessibility and self hairpin feature over 2200 publish sirnas. 
this tool reach an accuracy of 92.3 in cross validation experiment. 
we fully present the underlying biophysical signature that involve free energy accessibility and dinucleotide characteristic. 
we show that while complete silencing be possible at certain structured target site accessibility information improve the prediction of the 90 active sirna target site. 
fast sirna activity prediction can be perform on our web server at http://optirna.unl.edu/.. 
an svm base approach for the analysis of mammography image. 
mammography be among the most popular imaging technique use in the diagnosis of breast cancer. 
nevertheless distinguish between healthy and ill image be hard even for an experienced radiologist because a single image usually include several region of interest roi. 
the hardness of this classification problem along with the substantial amount of datum gather from patient medical history motivate the use of a machine learning approach as part of a cad computer aided detection tool aim to assist radiologist in the characterization of mammography image. 
specifically our approach involve i the roi extraction ii the feature vector extraction iii the support vector machine svm classification of roi and iv the characterization of the whole image. 
we evaluate the performance of our approach in term of the svm s training and testing error and in term of roi specificity sensitivity. 
the result show a relation between the number of feature use and the svm s performance. 
fe thermal modelling of machine with ball end mill. 
in this paper a numerical model base on the finite element method be present to predict tool chip and workpiece temperature field in end mill operation use abaqus code. 
the model be fit to experimental datum from a study of a double tooth hall end mill. 
the collect chip present a good information resource that allow the evaluation of the model chip geometry and its contact length with tool cutting face within a micrographic exam. 
in order to set up the boundary condition we need in addition to the tool and workpiece convective coefficient value and the chip tool interface friction law the knowledge of thermal load in the first shear zone. 
that s why a mechanistic cutting force model be develop and adjust from experimental result to calculate the heat energy in each contact point between tool and workpiece. 
the predict temperature field and the heat flux generate by the fem model be in agreement with the heat balance in an end milling process. 
x ray 3d computed tomography of large object investigation of an ancient globe create by vincenzo coronelli. 
x ray cone beam computed tomography be a powerful tool for the non destructive investigation of the inner structure of work of art. 
with regard to cultural heritage conservation different kind of object have to be inspect in order to acquire significant information such as the manufacturing technique or the presence of defect and damage. 
the knowledge of these feature be very useful for determine adequate maintenance and restoration procedure. 
the use of medical ct scanner give good result only when the investigate object have size and density similar to those of the human body however this requirement be not always fulfil in cultural heritage diagnostic. 
for this reason a system for digital radiography and computed tomography of large object especially work of art have be recently develop by researcher of he physics department of the university of bologna. 
the design of the system be very different from any commercial available ct machine. 
the system consist of a 200 kvp x ray source a detector and a motorized mechanical structure for move the detector and the object in order to collect the required number of radiographic projection. 
the detector be make up of a 450x450 mm(2 structure csi(tl scintillating screen optically couple to a ccd camera. 
in this paper we will present the result of the tomographic investigation recently perform on an ancient globe create by the famous cosmographer cartographer and encyclopedist vincenzo coronelli. 
lens production enhancement by adoption of artificial influence function and a knowledge base system in a magnet orheological finishing process. 
high quality optical lense be usually finish by magnetorheological finishing mrf. 
in this process an abrasive fluid with the ability to stiffen in a magnetic field be use as the polish tool in a computer control machine tool. 
although the machine be automate it be necessary for a skilled operator to set the machine and make judgment with regard to its operation. 
an investigation have be under way to examine the detailed operation of the mrf process and the information that be necessary to establish good practice. 
this have result in the incorporation of a knowledge base system kbs into the machine control regime and a methodology for the creation of artificial polishing tool characteristic the machine influence function. 
the incorporation of the these element have be instrumental in the operation of an enhance mrf machine. 
this have be subject to extensive test procedure and it have be demonstrate that the production process may be enhance significantly and consistently. 
batch production time may be significantly reduce a figure in excess of a 50 reduction be meet consistently during prolonged operation. 
furthermore the incorporation of the kbs be instrumental in increase the automation of the mrf process reduce the level of manual input necessary to manage machine operation. 
gene expression analysis of leukemia sample use visual interpretation of small ensemble a case study. 
many advanced machine learning and statistical method have recently be employ in classification of gene expression measurement. 
although many of these method can achieve high accuracy they generally lack comprehensibility of the classification process. 
in this paper a new method for interpretation of small ensemble of classifier be use on gene expression datum from real world dataset. 
it be show that interactive interpretation system that be develop for classical machine learning problem also give a great range of possibility for the scientist in the bioinformatics field. 
therefore we choose a gene expression dataset discriminate three type of leukemia as a testbed for the propose visual interpretation of small ensembles vise tool. 
our result show that use the accuracy of ensemble and add comprehensibility gain not only accurate but also result that can possibly represent new knowledge on specific gene function. 
a user programmable link between datum preparation and mask manufacturing equipment. 
in order to fully exploit the design knowledge during the operation of mask manufacturing equipment as well as to enable the efficient feedback of manufacture information upstream into the design chain close communication link between the data processing domain and the machine be necessary. 
with shrink design rule and modeling technology require to drive simulation and correction the amount and variety of measurement for example be steadily grow. 
this require a flexible and automate setup of parameter and location information and their communication with the machine. 
the paper will describe a programming interface base on the tcl tk language that contain a set of frequently reoccurre function for data extraction and search site characterization site filtering and coordinate transfer. 
it enable the free programming of the link adapt to the flow and the machine need. 
the interface lower the effort to connect to new tool with specific measurement capability and it reduce the setup and measurement time. 
the interface be capable of handle all common mask writer format and their jobdeck as well as oasis and gdsii datum. 
the application of this interface be demonstrate for the carl zeiss aims tm system. 
some effect of a human resource strategy on total productive manufacturing tpm improvement. 
total productive manufacturing tpm also address plan maintenance as well as autonomous maintenance that determine the maintenance requirement of machine in their operate context. 
this paper focus on the effect of an integrate human resource strategy on total productive manufacturing tpm and assess how the combination of the two can increase a firm s productivity. 
some result of a south african manufacturing case study company in a unique environment be present. 
the main conclusion reach in this paper be that when innovative human resource practice be apply properly they will promote total machine system efficiency and hence increase the productivity of the company. 
as result tpm that do not normally focus on hr be take to a high level whereby the additional human factor be take into consideration. 
it suggest that operator should be nurture and be well train as part of the tpm focus because they be the one who be operate those machine with intimate knowledge. 
the limited research present here as part of a doctoral thesis highlight some element of human resource practice that can be apply to enable operator to be efficient and productive as part of the tpm machine system. 
practical private computation of vector addition base function. 
in this paper we explore private computation build on vector addition which be a surprisingly general tool for implement many useful analysis on user provide datum. 
example include both linear and non linear algorithm such as singular value decomposition svd regression analysis of variance anova and several machine learning algorithm base on expectation maximization em. 
the non linear algorithm aggregate user datum only in certain step such as conjugate gradient which be linear in per user datum. 
we introduce a new and highly efficient vss verifiable secret sharing protocol in a special but widely applicable model that allow secret share arithmetic operation in such aggregation step to be do over small field e.g. 
32 or 64 bit so that private arithmetic operation have the same cost as normal arithmetic. 
verification of user datum be require to prevent a malicious user from bias the computation. 
we provide a random projection method for verification that use a linear number of inexpensive small field operation and only a logarithmic number of large field 1024 bit or more cryptographic operation. 
our implementation show that the approach can achieve order of magnitude reduction in run time over standard technique from hour to second for large scale problem e.g. 
at the scale where the number of value per user be 10(6. 
a novel integrate web base learn system for electrical machine education. 
this study introduce a novel web base learn tool for electrical machine education. 
the tool develop consist of the real time experiment remotely accessible via internet in addition to thereotical presentation with animation and simulation on mathematical model of the electrical machine. 
the system be base on server client architecture. 
all operation step be execute by the server. 
so client do not need any additional software rather than internet connection and an internet browser. 
a dc motor course be give as an example to illustrate the novel tool develop. 
the remotely locate user can learn the therotical information about the dc motor by mean of use interactive web page. 
all thereotical presentation support with favorable animation to facilitate the understanding. 
also user can use the simulation model over the web to observe the motor s dynamic behaviour under the different parameter. 
moreover they can remotely access a dc motor experimental set via internet to perform real time experiment such as speed control and generator operation of dc motor. 
during the conducting real time experiment over the web the experimental set can be monitor with a webcam. 
experimental result show that the integrate web base learning system develop be user friendly and can be use for electrical machine education successfully. 
active a tool for build intelligent user interface. 
computer have become affordable small omnipresent and be often connect to the internet. 
however despite the availability of such rich environment user interface have not be adapt to fully leverage its potential. 
to help with complex task a new type of software be need to provide more user centric system that act as intelligent assistant able to interact naturally with human user and with the information environment. 
build an intelligent assistant be a difficult task that require expertise in many field range from artificial intelligence to core software and hardware engineering. 
we believe that provide a unified tool and methodology to create intelligent software will bring many benefit to this area of research. 
our solution the active framework combine an innovative production rule engine with community of service to model and implement intelligent assistant. 
in the medical field our approach be use to build an operating room assistant. 
use natural modality such as speech recognition and hand gesture it enable surgeon to interact with computer base equipment of the operating room as if they be active member of the team. 
in a broad context active aim to ease the development of intelligent software by make required technology more accessible. 
an asml model for an intelligent vehicle control system. 
an abstract state machine asm be a mathematical model of the system s evolve runtime state. 
asm can be use to faithfully capture the abstract structure and step wise behaviour of any discrete system. 
an easy way to understand asm be to see they as define a succession of state that may follow an initial state. 
we present a machine executable model for an intelligent vehicle control system implement in the specification language asml. 
executable specification be description of how software component work. 
asml be capable of describe the evolve state of asynchronous concurrent system such as agent base system. 
the mathematical background for the intelligent control of vehicle be represent by the stochastic automata. 
a stochastic automaton can perform a finite number of action in a random environment. 
when a specific action be perform the environment respond by produce an environment output that be stochastically relate to the action. 
this response may be favourable or unfavourable. 
the propose model be verify through simulation in specexplorer tool from microsoft research. 
intelligent adaptive control of machining process base on hybrid recurrent neural network. 
aim at the feasibility of intelligent adaptive control for a machining process a new network architecture call a hybrid recurrent neural network hrnn be first present base on the diagonal recurrent neural network drnn. 
consider the uncertain information in the machining process a generalize entropy square error gese criterion be then propose. 
the learn algorithm of the hrnn and the mathematic model of the machine tool for experiment be also explain. 
finally the hrnn be apply to the constant force control of the machining process. 
simulated result verify the effectiveness of the propose control scheme. 
and the experimental result also confirm the applicability of the describe controller in practice. 
gain knowledge exchange and analysis for meta learn. 
build accurate and reliable complex machine be not trivial but necessary in most real life problem. 
typical ensemble be often unsatisfactory. 
meta learn technique can be much more powerful in compose optimal or close to optimal solution to give task. 
efficient meta learning be possible only within a versatile and flexible datum mining framework provide uniform procedure for deal with different kind of method and tool for thorough analysis of learn process and their result. 
we propose a methodology for information exchange between machine of different abstraction level. 
inter machine communication be base on uniform representation of gain knowledge. 
implement in a general datum mining framework it provide tool for sophisticated analysis of adaptive process of heterogeneous machine. 
the result meta knowledge be a brilliant information source for further meta learning. 
a fault diagnosis strategy use local model fault intensity and boundary model base on sdg and data drive approach. 
in this study at first a hybrid local fault diagnostic model base on the sign digraph sdg which be a kind of model base approach and a statistical learning model support vector machine svm would be propose. 
and then the fault intensity model and the fault boundary model be construct for various fault intensity. 
key aspect be the issue of resolve signature result from the same fault but with differ intensity and make the decision tool to decide which a fault occur. 
apply support vector machine for crm problem. 
data mining in the crm aim at learn available knowledge from the customer relationship by machine learning or statistical method to instruct the strategic behavior so that obtain the most profit. 
in recent year support vector machine svm have be propose as a power tool in machine lean and datum mining. 
this paper apply the svm to resolve the practical crm problem in a company. 
the final result report the good general performance of svm for crm problem. 
fldf base decision tree use extended datum expression. 
we introduce a classification algorithm which can be apply to a problem with a data set include a miss variable. 
in this algorithm we use datum expansion treat it with a weight value and the probability technique. 
it be apply to extend a classifier which be consider the optimal projection plane base on fisher s formula. 
for do this we will derive equation from the procedure to be apply to the data expansion. 
the result be compare to that of different measurement by choose one variable in the datum set and then modify the rate of miss and non missing value in this select variable. 
the result of a data set with non missing variable compare with that of c4.5 which be know as a knowledge acquisition tool in machine learning. 
study of cluster algorithm base on model datum. 
cluster technique be a key tool in data mining and pattern recognition. 
usually object for some traditional clustering algorithm be express in the form of vector which consist of some component to be describe as feature. 
however object in real task may be some model which be cluster other than datum point for example neural network decision tree support vector machine etc. 
this paper study the cluster algorithm base on model datum. 
by define the extended measure clustering method be study for the abstract data object. 
framework of cluster algorithm for model be present. 
to validate the effectiveness of model cluster algorithm we choose the hierarchical model cluster algorithm in the experiment. 
model in cluster algorithm be bp(back propagation neural network and learning method be bp algorithm. 
measure be choose as both same fault measure and double fault measure for pairwise of model. 
distance between cluster be the single link and the complete link respectively. 
by this way we may obtain part of neural network model which be from each cluster and improve diversity of neural network model. 
then part of model be ensemble. 
moreover we also study the relation between the number of cluster in cluster analysis the size of ensemble learning and performance of ensemble learning by experiment. 
experimental result show that performance of ensemble learning by choose part of model use clustering of model be improve. 
build a machining knowledge base for intelligent machine tool. 
intelligent machine respond to external environment on the basis of decision that be make by sense the change in the environment and analyze the obtain information. 
this study focus on the construction of a knowledge base which enable decision make with that information. 
approximately 70 of all error that occur in machine tool be cause by thermal error. 
in order to proactively deal with these error a system which measure the temperature of each part and predict and compensate the displacement of each spindle have be develop. 
the system be build in an open type controller to enable machine tool to measure temperature change and compensate the displacement. 
the construction of a machining knowledge base be important for the implementation of intelligent machine tool and be expect to be applicable to the network base intelligent machine tool which look set to appear soon or later. 
calculation and prediction of energy consumption in discrete manufacture base on knowledge id j 009. 
there be great potentiality of energy saving in discrete manufacture however related research be weak in this area. 
the result of calculation and prediction of energy consumption could be use to aid process planning evaluation and workshop scheduling and it be the basis for fine energy management. 
three part be discuss for energy consumption in this paper. 
firstly ontology be use to make the calculation of energy consumption explicitly and it could make concept of energy management sharable. 
first order logic be use in common sense question reasoning and calculation of energy consumption. 
secondly cbr technology be use to predict energy consumption. 
in view of the characteristic of energy consumption in discrete manufacture the idea of hierarchical case base reasoning technology be adopt. 
there be different indexing strategy from product to part indexing base on machining tool be adopt at last. 
ultimately in the layer of machine operation neural networks be use in datum mining to predict energy consumption correspond to a set of operating parameter. 
micro electrochemical machining of aluminum. 
bang olufsen and dtu have be work in a joint research project with the manufacture of micro cavity in aluminum. 
the overall objective be to establish a technology platform for bring a conceptual prototype to industrial production. 
electrochemical machining be one of the process consider for industrial application. 
the activity comprise basic understanding of the electrochemical machining of aluminum include development of a test set up manufacturing experiment and process optimization. 
theoretical and experimental investigation be carry out in order to broaden the knowledge about process capability for production of micro cavity with a diameter of less than 100 mu m.. 
dynamic behaviour simulation of electromagnetic actuator use a new method base on co energy map. 
analytical complexity of an electromagnetic actuator grow with its geometrical complexity and control strategy. 
thus dynamic simulation normally make by finite element analysis fea software demand for high computation capability. 
this paper propose a new method for dynamic behaviour simulation that use finite element method fem software only at its early stage to obtain the co energy map for device concern static position for different excitation current. 
from the knowledge of co energy map inductance and force map be derive. 
the main contribution of this paper be the new propose model that allow the knowledge of dynamic behaviour of electromagnetic actuator. 
the propose method have be apply successfully to a choose case study simulation model and result be here present and compare with the one obtain from the fem tool analysis. 
the small computation effort demand require by the propose analysis method make possible that complex control methodology can be develop and test. 
a support vector machine model for the situation awareness system. 
situation awareness sa be to describe the challenge face by we when interact with control system or work environment through technological interface. 
this paper first give a mathematical description for sa. 
it then classify all the possibility of sa function into classification and regression problem which can be readily resolve by some machine learning tool. 
base on the result this paper construct a support vector machine model to deal with the two type of issue of sa. 
research on semantic attribute base partner selection in virtual manufacturing enterprise. 
selection of correct partner be one of the most crucial factor in organize virtual enterprise. 
current approach of partner selection do not consider the semantic feature in build a virtual enterprise. 
in this paper we describe a system that can select partner effectively through semantic attribute with naive bayesian algorithm. 
we show that semantic feature can be successfully extract by apply naive bayesian technology and build a knowledge base of potential partner in manufacture enterprise. 
an example of machine tool industry be use to describe the approach. 
adaptive control mill robot for orthopedic surgery. 
adaptive control of the machining process in orthopedic surgery will increase not only productivity but also the safety issue of tool usage. 
the author have develop a technology for an adaptive control system. 
the system have two mode the predictive mode and the adaptive mode. 
the predictive mode be use to shorten the air cutting time. 
in the adaptive mode the system monitor the cut force and the cut temperature and control the feed override accord to the difference between the real and the desire cut force. 
the software be implement on the robot controller and its effectiveness be evaluate with a urethane bone. 
dynamic guidance with pseudoadmittance virtual fixture. 
human machine collaborative systems hmcs have be develop to enhance sensation and suppress extraneous motion or force during surgical task require precise motion. 
however to date such system have enforce constraint on the position or path of a tool but have not consider the dynamic of motion. 
also the focus have be on the effect of guidance of motion during a task rather than on the learning of motion skill through repetition. 
we present a pseudo admittance framework for hmcs design to guide the user s velocity in such task. 
two different fixture design approach be analyze implement and compare. 
three test be then conduct show the fixture promise for both guide and learn motion with dynamic. 
learn to select state machine use expert advice on an autonomous robot. 
hierarchical state machine have prove to be a powerful tool for control autonomous robot due to their flexibility and modularity. 
for most real robot implementation however it be often the case that the control hierarchy be hand code. 
as a result the development process be often time intensive and error prone. 
in this paper we explore the use of an expert learn approach base on auer and colleague exp3 to help overcome some of these limitation. 
in particular we develop a modify learning algorithm which we call rexp3 that exploit the structure provide by a control hierarchary by treat each state machine as an expert. 
our experiment validate the performance of rexp3 on a real robot perform a task and demonstrate that rexp3 be able to quickly learn to select the good state machine expert to execute. 
through our investigation in these environment we identify a need for fast learning recovery when the relative performance of expert reorder such as in response to a discrete environment change. 
we introduce a modify learning rule to improve the recovery rate in these situation and demonstrate through simulation experiment that rexp3 perform as well or well than exp3 under such condition. 
assist minimally invasive surgery through exterior orientation to enhance perception. 
a diversity of action perception application rely on 2d information to perform 3d task. 
minimally invasive surgery mis be one of these application. 
it require a high degree of sensory motor skill to overcome the disengagement between action and perception cause by the physical separation of the surgeon with the operative site. 
the integration of body movement with visual information serve to assist the surgeon provide a sense of position. 
our purpose in this paper be to present the exterior orientation as a tool in assist intervention locate the instrument with respect to the surgeon. 
an enhanced perception be obtain by augment the 2d information impose position and orientation datum through a human machine interface. 
apply motion analysis in a sequence of image and have knowledge of the 3d transformation implement to the instrument we show it be possible to estimate its orientation with only two different rotation and also its position in the case its length information be supply. 
data mining application on customer service decision support and machine fault diagnosis. 
in traditional customer service support of a manufacturing environment a customer service database usually store two type of service information one unstructured customer service report record machine problem and its remedial action and two structure datum on sale employee and customer for day to day management operation. 
this paper investigate how to apply datum mining technique to extract knowledge from the database to support two kind of customer service activity decision support and machine fault diagnosis. 
a datum mining process base on the datum mining tool dbminer be investigate to provide structure management datum for decision support. 
in addition a data mining technique that integrate neural network case base reasoning and rule base reasoning be propose it would search the unstructured customer service record for machine fault diagnosis. 
the propose technique have be implement to support intelligent fault diagnosis over the world wide web. 
modeling and simulation of hard disk dive final assembly use a hdd template. 
a hdd template be design and develop for modeling and simulation for final assembly of hard disk drive hdd manufacturing use arena. 
the design hdd template be a high flexibility and good performance at an internal supply chain level and self development and improve the system performance significantly. 
it be develop the intelligent base dynamic machine knowledge which can capture dynamic base activity with fuzzy system. 
the study show how modeling and simulation tool can be use and integrate to implement highly automate system for industrial process and deal with flexible product. 
in such context we design and develop a prototype for the final assembly of hard disk drive with dynamic and static behavior. 
virtual training centre for cnc a sample virtual training environment. 
it be a fact that virtual training have be a scope of interest for vocational training for a very long time. 
however it need more time to be more common in all specific training field. 
this paper present the development of a virtual training centre vtc to promote and reinforce vocational training in computer numerical control cnc machine. 
virtual training centre for cnc be a multilateral ldv project and of high importance in term of virtual teaching and learn in vocational education and training. 
this virtual training environment be base on a common curriculum develop by the project partner. 
since it be an interactive training tool accessibility be the most important advantage over other training tool in vet. 
the development of an agent base distribute surface machining system. 
this paper focus on the development of an agent base intelligent distribute surface machining system structure through traditional manufacturing engineering activity analysis and systematic software engineering method. 
the advantage of a distribute system structure include ease of manipulation high expandability flexibility and the achievement towards the goal of networked manufacture. 
the propose system have present the feasibility in apply software agent base technology in construct a distribute freeform surface machining environment. 
several agent have be develop in the propose system one preliminary evaluation agent two sophisticated evaluation agent and three post processor agent. 
preliminary evaluation agent be in evaluation on the surface machining base on surface curvature. 
sophisticated evaluation agent could be access if the surface could not be machine by three axis mill machine base on the calculation result from preliminary evaluation this agent can suggest either four or five axis machine that could be apply for the surface mill operation base on visibility cone. 
post processor agent take care of generation of the nc code for mill operation. 
this agent can also convert five axis nc code among different five axis mill machine when the machine s mechanism could be define. 
these agent communicate via pre defined performative underlie knowledge query and manipulation language kqml for the surface machining capability. 
the develop system have then be successfully implement in form a distribute shoe surface machine system. 
this mean agent technology be very promising in enhance the communication of a distribute system to be able to communicate with high level knowledge rather than only in remote function call through platform independent network architecture. 
relevance vector machine regression apply to structural health monitoring. 
a recently develop bayesian learning methodology the relevance vector machine rvm can identify a regression model base on give training datum with the advantage of sparseness i.e. 
utilize only a small number of relevant basis expansion term by automatically prune other and automatic regularization of ill condition problem. 
in training of the rvm the probability distribution over the unknown regression model parameter be update base on give training datum by use bayes theorem with a special prior probability distribution call the automatic relevance determination prior. 
rvm use the same kernel basis expansion as in the popular machine learning methodology the support vector machine svm. 
however svm give only a single estimate while rvm give probabilistic prediction and it usually do so with a drastically small number of basis term than occur in the correspond svm for the same regression problem. 
a preliminary investigation of the applicability of rvm regression to structural health monitoring be make. 
rvm be use to learn a probabilistic relationship between the structural feature vector such as change in mode shape and natural frequency and correspond damage index vector describe the damage state of the structure. 
a two step approach to shm be investigate in which one train rvm be use to detect the location of any damage from dynamic datum and another train rvm be then use to estimate the damage severity at each location. 
the mathematical procedure for rvm and the result for illustrative example be present. 
these preliminary result suggest that rvm be worthy of further investigation as a data processing tool for structural health monitoring. 
an operator theoretic framework for analysis of large scale quadratic programming. 
one of the fundamental problem in the area of large scale constrain optimization problem be the study of the locality feature of spatially distribute optimization problem which can motivate the development of fast and well condition distribute algorithm. 
we study the spatial locality feature of large scale possibly infinite dimensional quadratic programming qp problem with linear inequality constraint. 
example of such problem include recede horizon control of spatially distribute linear system with input and state constraint optimal estimation of a parameter base on datum collect in a sensor network manifold learning of a large set of datum in machine learning etc. 
we propose a new approach for analysis of large scale qp problem by blend tool from duality theory with operator theory. 
the class of spatially decay matrix be introduce to capture coupling between optimization variable in the cost function and constraint. 
we show that the optimal solution of a large scale convex qp be piece wise affine  represent as convolution sum. 
more importantly we prove that the kernel of each convolution sum decay in the spatial domain at a rate proportional to the inverse of the correspond coupling function of the optimization problem. 
simulation result be provide to verify our theoretical result. 
gene expression profiling and machine learning to understand and predict primary graft dysfunction. 
lung transplantation be the treatment of choice for end stage pulmonary disease. 
a limited donor supply have result in 4000 patient on the waiting list. 
currently 10 20 of donor organ be deem suitable under the selection criterion of which 15 25 fail due to primary graft dysfunction pgd. 
in this study we attempt to further our understanding of pgd by observe the change in gene expression across donor lung that develop pgd versus those that do not. 
our second goal be to use a machine learn tool support vector machine svm to distinguish unsuitable donor lung from suitable donor lung base on the gene expression datum. 
classification result for distinguish suitable and unsuitable lung for transplantation use a svm be promise. 
this be the first such attempt to use human lung use for transplantation and combine the identification of a molecular signature for pgd with machine learning method for donor lung prediction. 
hybrid multi agent system for cooperative dynamic scheduling through meta heuristic. 
this paper describe a hybrid multi agent scheduling system that assume the existence of several agents which be decision make entity distribute inside the manufacturing system. 
to solve the scheduling problem machine agents and task agents must interact and cooperate with other agent in order to obtain optimal or near optimal global performance trough meta heuristic. 
the idea be that from local autonomous and often conflict agent s objective a global solution emerge from a community of machine agent solve locally their schedule while cooperate with other machine agent. 
agent have to manage their internal behavior and their relationship with other agent via cooperative negotiation in accordance with business policy define by the user manager. 
information leak detection in financial e mall use mail pattern analysis under partial information. 
with the advent of e mail sensitive information leakage have become a daunting problem in today s world. 
quite often the mail volume from a company be huge make manual monitor impossible. 
automatic screening mostly rely on the idea of content scan but sometimes the information be so sensitive that even scan the mail by a third party may not be permit. 
detection under such restriction become difficult. 
also mail originate from specific organization be often restrict in their subject and content suggest that powerful generic technique like content scan may not be need. 
we propose that selection of proper input variable relevant to the domain could help in such case a simple straightforward learning scheme can then detect information leak efficiently use only mail pattern analysis. 
we use our technique on real life mail from financial institution. 
by choose the input variable judiciously we be able to learn the mail pattern quite well and detect violation efficiently. 
the preliminary result be encourage with an accuracy close to 92. 
this technique be now be implement in a real life commercial tool. 
endmill condition monitoring and failure forecasting method for curvilinear cut of non constant radii. 
in this paper an endmill condition monitoring technique be present for curvilinear cutting. 
this algorithm operate without the need for prior knowledge of cut condition tool type cut curvature cut direction or directional rate of change. 
this technique be base on an autoregressive type monitoring algorithm which be use to track the tool s condition use a tri axial accelerometer. 
accelerometer signal be monitor due to the sensor relatively low cost and since use of the sensor do not limit the machining envelope. 
to demonstrate repeatability eight life test be conduct. 
the technique discuss herein successfully prognosis impend fracture or meltdown due to wear in all case provide sufficient time to remove the tool before failure be realize. 
furthermore the algorithm produce similar trend capable of forecasting failure regardless of tool type and cut geometry. 
success be see in all case without require algorithm modification or any prior information regard the tool or cut condition. 
quality and inspection of machine operation review of condition monitoring and cmm inspection technique 2000 to present. 
in order to consistently produce quality part aspect of the manufacturing process must be carefully monitor control and measure. 
the method and technique by which to accomplish these task have be the focus of numerous study in recent year. 
with the rapid advance in compute technology the complexity and overhead that can be feasibly incorporate in any develop technique have dramatically improve. 
thus technique that would have be impractical for implementation just a few year ago can now be realistically apply. 
this rapid growth have result in a wealth of new capability for improve part and process quality and reliability. 
in this paper overviews of recent advance that apply to machining be present. 
moreover due to the relative significance of two particular machining aspect this review focus specifically on research publication pertain to use tool condition monitoring and coordinate measurement machine to improve the machining process. 
tool condition have a direct effect on part quality and be discuss first. 
the application of tool condition monitoring as it apply to turn drilling milling and grind be present. 
the subsequent section provide recommendation for future research opportunity. 
the ensue section focus on the use of coordinate measure machine in conjunction with machining and be subdivide with respect to integration with machining tool inspection planning and efficiency advanced controller feedback machine error compensation and on line tool calibration in that specific order and conclude with recommendation regard where future need remain. 
model heat transfer effect during free form fabrication multi dimensional effect. 
laser powder deposition lpd for additive fabrication be a relatively new technology that be currently be qualified for use in the manufacturing industry. 
although this technology have significant advantage over conventional manufacturing process such as the reduce need for post production part machining the result component material property strength ductility etc be affect by process operating parameter such as laser power head manipulator speed and powder flow rate. 
set point for these parameter be often base upon trial and error with process control require the oversight of a system operator. 
additionally thermal stress that build up in the part and the substrate can lead to warping and separation of the part from the substrate. 
although this latter effect have be investigate no robust process control have be identify that will solve the problem. 
therefore to assure component part quality and to minimize residual stress and attendant deformation an intelligent laser deposition path planning control algorithm need to be develop. 
such control require knowledge of the part thermal history. 
the process however be not amenable to direct experimental measurement which have lead to the need to develop accurate and reliable thermal model. 
preliminary multi dimensional result from one such model discuss herein show the need for process control and how such a model be central to develop an intelligent laser powder deposition path planning strategy. 
opto acoustical flame monitoring of ccgt search for hum precursor. 
modem gas turbine be prone to trigger and sustain pressure oscillation induce by heat release in their combustor these oscillation call hum can cause severe damage on the machine structure or on a less detrimental level can limit gas turbine performance from load point of view or no emission increase their concentration in flue gas. 
thermoacoustic oscillation problem although deeply investigate during the last 15 year be far from be solve so that both theoretical and experimental approach be be use in order to improve basic knowledge of this phenomenon. 
with this aim an optoelectronic detector base system have be develop to be instal on a 270mw gas turbine to detect radiative energy release fluctuation due to thermoacoustic oscillation. 
this optoelectronic device have be use in combination with standard piezoelectric sensor with the target to get a well insight of the humming phenomenon. 
a datum analysis method base on well establish datum processing technique have be apply to datum gather from the field. 
the ensemble of datum processing technique seem to offer a method to evaluate the actual risk of thermoacoustic instability. 
this be the very first application of the propose tool and a long way have to be run before it be assess as a prognostic device. 
nevertheless in the h.o. 
of the author this first application encourage the continuation of develop the tool extend the base of monitor plant. 
chronic hepatitis classification use snp datum and datum mining technique. 
the machine learning technique svm decision tree and decision rule be use to predict the susceptibility to the liver disease chronic hepatitis from single nucleotide polymorphism(snp datum. 
also they be use to identify a set of snp relevant to the disease. 
in addition we apply backtrack technique to couple of feature selection algorithm forward selection and backward elimination and show that this technique be beneficial to find the well solution by experiment. 
the experimental result show that decision rule be able to distinguish chronic hepatitis from normal with the maximum accuracy of 73.20 whereas svm be with 67.53 and decision tree be with 72.68. 
it be also show that decision tree and decision rule be potential tool to predict the susceptibility to chronic hepatitis from snp datum. 
computer aid diagnosis of cross institutional mammogram use support vector machine with feature elimination. 
in the analysis of digital or digitize mammographic image a requirement be to learn to separate benign calcification from malignant one. 
such an activity could form part of a computer aid diagnosis cad tool. 
we present a cad study of calcification lesion to demonstrate that cad of same institutional mammogram provide significantly high accuracy compare to that of cross institutional mammogram. 
moreover use only a subset of the widely use six bi rads feature together with patient age and subtlety value describe each calcification lesion be show to increase the accuracy of cad. 
learn to decode instantaneous cognitive state from brain image. 
the study of human brain function have dramatically increase greatly due to the advent of functional magnetic resonance imaging fmri. 
recently it have be note that the use of machine learn classifier for decode cognitive state directly from fmri datum be a powerful technique that enable researcher to make prediction about the mental state of a subject. 
in this paper we explore some of the fundamental question fmri decode raise by apply and compare different machine learning technique and feature selection method to the problem of classify the instantaneous cognitive state of a person base on fmri datum. 
in particular we present successful case study of induce classifier which accurately discriminate between cognitive state produce by different stimulus. 
we show how classifier can be use as confirmatory tool allow the testing of compete hypothesis about the structure in the datum and show that it be possible to train successful classifier without prior anatomical knowledge and use only a very small number of feature. 
ai approach for cut tool diagnosis in machining process. 
monitoring of cut tool system be very important in machine tool and manufacturing equipment due to the impact they have in quality product and economy production. 
the cut tool condition can be determine by direct or indirect sense method. 
indirect method be the only practical approach that offer well result by exploit datum sensor fusion technique which help to make a more robust and stable diagnosis. 
different successful approach from the artificial intelligence ai community be review. 
a discussion of the implementation and evaluation of two ai technique be do. 
hidden markov model hmm base and bayesian networks base into an industrial machining center be test. 
excellent result demonstrate that hmm base approach have a potential industrial application. 
hyperplane algorithm first step of the pair plane classification procedure. 
the objective of supervised learning be to estimate unknown base on label training sample. 
if the unknown to be estimate be categorical or discrete the problem be one of classification. 
algorithms for supervised learning be useful tool in many area of agriculture medicine and engineering include prediction of malignant cancer document analysis and speech recognition. 
in general support vector machine algorithm have be successful in classification problem but they have high computational complexity. 
in this paper we present the hyperplane algorithm. 
it and two other relate algorithm form an ensemble classifier for supervised classification. 
the hyperplane algorithm be reminiscent of a support vector machine but be low in computational complexity. 
it also have several other advantage compare to support vector machines. 
result for five real life dataset result be show. 
correct your text with google. 
with the increase amount of text file that be produce nowadays spell checker have become essential tool for everyday task of million of end user. 
among the year several tool have be design that show decent performance. 
of course grammatical checker may improve correction of text nevertheless this require large resource. 
we think that basic spell checking may be improve a step towards use the web as a corpus and take into account the context of word that be identify as potential misspelling. 
we propose to use the google search engine and some machine learning technique in order to design a flexible and dynamic spell checker that may evolve among the time with new linguistic feature. 
a hybrid method for feature recognition in computer aid design model. 
automatic feature recognition afr technique apply to three dimensional 3d solid model be an important tool for achieve a true integration of computer aid design cad and computer aid manufacturing cam process. 
in particular afr system allow the identification in cad model of high level geometrical entity feature that be semantically significant for manufacture operation. 
however the recognition performance of most of the exist afr system be limit to the requirement of specific manufacturing application. 
this paper present a new hybrid method that facilitate the deployment of afr system in different application domain. 
in particular the method include two main processing stage learn and feature recognition. 
during the learning stage knowledge acquisition technique be apply for generate feature recognition rule and feature hint automatically from training datum. 
then these hint and rule basis be utilize in the feature recognition stage to analyse boundary representation b rep part model and identify their feature base internal structure. 
the propose afr method be implement within a prototype feature recognition system and its capability be verify on two benchmarke part. 
village aquaponic. 
over the year we have gather information about aquaponic from researcher hand on growing hobbyist aquaculturist commercial hydroponic grower and manufacturer of greenhouse. 
we put that knowledge together with properly manufacture component and come up with practical commercially viable food produce machine. 
when that food produce machine use fish waste to provide the nutrient for the plant it be generally call aquaponic. 
when an aquaponic system be use to provide nutrition in the form of fish and vegetable to people who live nearby we call it village aquaponics. 
we believe village aquaponics can be a viable mean of provide protein and vegetable to people in develop as well as develop nation. 
transient stability assessment of power system base on support vector machine. 
machine learning method be promise tool to transient stability assessment tsa of power system. 
support vector machine svm be use to assess the transient stability of power system after fault occur on transmission line. 
single machine attribute be study as input of the svm classifier. 
experimental result in ieee 50 generator test system show that attribute of single machine with small inertia coefficient be effective in tsa and the svm classifier with rbf kernel use these single machine attribute achieve satisfy classification accuracy. 
robotic programming for manufacture industry. 
programming robot to machine workpiece with complex geometry be a challenging and time consume job. 
this paper present an online programming by demonstration pbd method base on a force control platform. 
programming of complex 3d curve path without a cad model be achieve by two function namely lead through and path learning provide by the force controller. 
lead through which robot be compliant in select direction and stiff in the other direction make it very convenient to jog robot to desire target position. 
path learning which robot be compliant in normal to path direction to make the tool constantly contact with workpiece automate the entire programming process. 
use this pbd method the programming time for a complicated 3d curve path could be reduce from week to hour. 
feed rate self adaptive control and its application in nurbs curve interpolation. 
the feed rate control approach and interpolation arithmetic be crucial to high speed and high accuracy cnc machining. 
the acceleration deceleration acc dec control on servo motor be adopt to protect from lose step excess of stroke and impact on machine tool when nc machining. 
however a fix acc dec approach such as linear acc dec approach or exponent acc dec approach be carry out by cnc program in traditional cnc system which result in the weakness that it be difficult to meet the various demand of each situation and complex if change the acc dec performance greatly and append new acc dec control law. 
furthermore how to make the feed step meet the demand of both the acc dec control and profile precision be a key problem on complex profile part interpolation feed machining. 
aim at the demand of complex profile part high speed and high accuracy cnc machining the feed rate self adaptive control approach include acc dec self adaptive process and feed step control be develop to solve the above problem in the paper and its application in the nurbs curve direct interpolator be research in detail. 
the feed rate self adaptive control and nurbs curve interpolation arithmetic be program in c++ builder5. 
the interpolation example show that this approach can achieve high accuracy and smooth feed motion on the basis of meet the restriction of acc dec rule contouring error limitation and maximal centripetal acceleration. 
study on the framework of mas base rapid development platform for nc machining center. 
in the numerical control nc machine tools market always there be strong demand for short term design cycle and some special characteristic which customer want the machine tool to provide with. 
therefore design a rapid development platform which have a certain degree of intelligent ability to help the machine tool designer be meaningful. 
in this paper a multi agent system mas) based framework which be apply to the machining center mc be found and all agent who be assign different task and function be develop with java agent development framework jade in the host computer. 
by study conflict type and negotiation method agent interoperability in this collaborative system be analyze particularly. 
furthermore mechanism of knowledge representation kr be define in detail and a prototype case study be present to illustrate the application of this system. 
the approach mention above provide a solid foundation for the real actualization of intelligent aid design platform which will be a powerful tool for nc machining center rapid development. 
the paradigm of granular rough computing foundation and application. 
granular rough computing be a paradigm within rough computing which in turn can be set within the realm of cognitive informatics machine intelligence tool which emulate cognitive process in live organism its aim be to compute with granule of knowledge that be collective object form from individual object by mean of a similarity measure. 
in this work we apply the formalism for granule formation propose by we and study over last few year which be base on similarity measure call rough inclusions. 
a proper study of rough inclusion have be do within rough mereology a paradigm for approximate reasoning that be root in the theory of concept call mereology base on the notion of a part instead on the notion of an element like the naive concept theory. 
we give an outline of granulation theory base on rough inclusion then we discuss the most important consequence of similarity among object in a granule viz the hypothesis that granule represent new object which preserve the most important feature of object in a granule. 
this lead to the notion of a granular decision system obtain by mean of granulation from an original decision system. 
the hypothesis that granular decision system reflect property of original decision system to a satisfactory degree put forth by the author at 2005 and 2006 ieee grc conference have be test with very good result. 
we include here some result of those test. 
further result be include in the paper by polkowski and artiemjew in these proceedings. 
a knowledge representation tool base on concept algebra. 
a formal theory for abstract concept and knowledge manipulation be create by wang recently know as concept algebra. 
concept algebra be an abstract mathematical structure for the formal treatment of concept and their algebraic relation operation and associative rule for compose complex concept which provide a denotational mathernatic mean for knowledge system representation and manipulation. 
this paper present a method that show how the theory of concept algebra be implement and simulate use typical computer. 
a visualize knowledge representation tool for concept algebra be develop which enable machine learn concept and knowledge autonomously. 
nine form of concept association operation be implement in the tool to rigorously manipulate knowledge by concept network. 
the knowledge representation tool be capable to present concept and knowledge system in multiple way in order to visualize concept network by computer simulation. 
modeling of reinforcement in concrete beams use machine learning tools. 
the paper discuss the result obtain to predict reinforcement in singly reinforce beam use neural net nn support vector machines svm s and tree based models. 
major advantage of svm s over nn be of minimize a bound on the generalization error of model rather than minimize a bind on mean square error over the datum set as do in nn. 
tree based approach divide the problem into a small number of sub problem to reach at a conclusion. 
number of datum be create for different parameter of beam to calculate the reinforcement use limit state method for creation of model and validation. 
the result from this study suggest a remarkably good performance of tree base and svm s model. 
far this study find that these two technique work well and even well than neural network method. 
a comparison of predict value with actual value suggest a very good correlation coefficient with all four technique. 
a framework for ontology base manufacturing support system. 
conventionally design datum originally produce in the design department of a company be modify and/or change by the subsequent department such as production purchase quality control and marketing sale. 
each department extract or save its necessary information from the product information of a design stage then modify it so as to reflect the characteristic of the department. 
many design datum be prepare to produce a product but these datum include complicated relationship between part and process which be essential in the design of a production system. 
however exist commercial system do not sufficiently provide function such as the representation of the relationship and/or feature nor do they support the information require in the subsequent department. 
ontology be an information model technology that can be use for many purpose include enterprise integration database design information retrieval and interchange on the next generation web semantic web. 
this paper address a framework for ontology base manufacturing support system which model the relationship among design datum as well as the information in each department. 
meta datum implement through owl provide inference base query function enhance the efficiency and usability of the design datum. 
the framework be apply into ontology base capp computer aid process planning for nc machining process. 
a dynamic construction algorithm of incremental support vector machine. 
support vector machine(svm have become a popular tool for machine learning in recent year. 
for its outstanding power to summarize the data space in a concise way incremental svm framework be design to deal with large scale learning problem. 
the paper present a new dynamic construction algorithm of incremental svm learning. 
the cluster method be use to judge the relativity of new datum stream and history one and then multiple svm classifier be construct. 
the feature space be partition accord to the performance of each classifier and the statistical character on each region be count. 
the classifier that have the good performance on the region near the input sample be select as the final output. 
the experimental result confirm the feasibility and validity of the propose algorithm. 
svm for automatic speech recognition a survey. 
hidden markov models hmm be undoubtedly the most employ core technique for automatic speech recognition asr. 
nevertheless we be still far from achieve high performance asr system. 
some alternative approach most of they base on artificial neural networks anns be propose during the late eighty and early ninety. 
some of they tackle the asr problem use predictive anns while other propose hybrid hmm ann system. 
however despite some achievement nowadays the preponderance of markov models be a fact. 
during the last decade however a new tool appear in the field of machine learning that have prove to be able to cope with hard classification problem in several field of application the support vector machines svm. 
the svm be effective discriminative classifier with several outstanding characteristic namely their solution be that with maximum margin they be capable to deal with sample of a very high dimensionality and their convergence to the minimum of the associated cost function be guarantee. 
these characteristic have make svm very popular and successful. 
in this chapter we discuss their strength and weakness in the asr context and make a review of the current state of the art technique. 
we organize the contribution in two part isolate word recognition and continuous speech recognition. 
within the first part we review several technique to produce the fix dimension vector need for original svm. 
afterwards we explore more sophisticated technique base on the use of kernel capable to deal with sequence of different length. 
among they be the dtak kernel simple and effective which rescue an old technique of speech recognition dynamic time warping dtw. 
within the second part we describe some recent approach to tackle more complex task like connected digit recognition or continuous speech recognition use svm. 
finally we draw some conclusion and outline several ongoing line of research. 
towards automatic generation of conceptual interpretation of cluster. 
in this paper the methodology of conceptual characterization by embed conditioning ccec orient to the automatic generation of conceptual description of classification that can support later decision making be present as well as its application to the interpretation of previously identify class characterize the different situation on a wastewater treatment plant wwtp. 
the particularity of the method be that it provide an interpretation of a partition previously obtain on an ill structure domain start from a hierarchical clustering. 
the methodology use some statistical tool as the boxplot multiple introduce by tukey which in our context behave as a powerful tool for numeric variable together with some machine learning method to learn the structure of the datum this allow extract useful information use the concept of characterize variable for the automatic generation of a set of useful rule for later identification of class. 
in this paper the usefulness of ccec for build domain theory as model support later decision making be address. 
use a new alignment kernel function to identify secretory protein. 
as the knowledge of protein signal peptide can be use to reprogram cell in a desire way for gene therapy signal peptide have become a crucial tool for researcher to design new drug for target a particular organelle to correct a specific defect. 
to effectively use such a technique however we have to develop an automate method for fast and accurately predict signal peptide and their cleavage site particularly in the post genomic era when the number of protein sequence be be explosively increase. 
to realize this the first important thing be to discriminate secretory protein from non secretory protein. 
on the basis of the needleman wunsch algorithm we propose a new alignment kernel function. 
the novel approach can be effectively use to extract the statistical property of protein sequence for machine learning lead to a high prediction success rate. 
prediction of protein structure class with pseudo amino acid composition and fuzzy support vector machine network. 
it be a critical challenge to develop automate method for fast and accurately determine the structure of protein because of the increasingly widen gap between the number of sequence know protein and that of structure know protein in the post genomic age. 
the knowledge of protein structural class can provide useful information towards the determination of protein structure. 
thus it be highly desirable to develop computational method for identify the structural class of newly find protein base on their primary sequence. 
in this study accord to the concept of chou s pseudo amino acid composition pseaa eight pseaa vector be use to represent protein sample. 
each of the pseaa vector be a 40 d dimensional vector which be construct by the conventional amino acid composition aa and a series of sequence order correlation factor as original introduce by chou. 
the difference among the eight pseaa representation be that different physicochemical property be use to incorporate the sequence order effect for the protein sample. 
base on such a framework a dual layer fuzzy support vector machine fsvm network be propose to predict protein structural class. 
in the first layer of the fsvm network eight fsvm classifier train by different pseaa vector be establish. 
the 2(nd layer fsvm classifier be apply to reclassify the output of the first layer. 
the result thus obtain be quite promising indicate that the new method may become a useful tool for predict not only the structural classification of protein but also their other attribute. 
development of simplified evaluation method of iron boss in actual stator core of rotate machine. 
this paper deal with a simplified iron loss evaluation method for actual stator core of rotate machine. 
it be well known that the magnetic property deteriorate in construct core due to condition stress by rivet and weld in manufacturing process and punching and shear in cut process of the silicon steel sheet and so forth. 
as a result the iron loss increase in comparison with one of the ideal material assume in designing and the building factor become more than one. 
thus evaluation of core loss depend on stress become important to develop high efficiency motor and actuator. 
however at present the evaluation of core loss in actual laminated core of rotate machine have not yet examine fully. 
a difficultly exist in evaluation method of the field intensity and flux density distribution in actual complicated core structure. 
in this paper knowledge obtain in development of a simplified evaluation method of iron loss in actual stator core of rotate machine be present. 
automatic drilling process monitoring dpm for in situ characterization of weak rock mass strength with depth. 
this paper introduce a new in situ technique for characterize rock mass mechanical strength and the associated spatial distribution in the ground. 
the technique involve automatic drilling process monitor dpm. 
case example be give to show the original dpm datum and analyze result in a weather rock mass. 
the drilling machine in the example be pneumatic rotary percussive drilling machine with down the hole hammer. 
the dpm datum can directly show the in situ rock mass drilling resistance strength and their spatial distribution along the drillhole in the ground. 
the dpm be a simple reliable and practical tool for further the practice and knowledge of rock mechanic and engineering in the underground environment comprise weather soil and rock. 
find the reduct subject to preference order of attribute. 
in machine learning and knowledge discovery rough set theory be a useful tool to be employ as a preprocessing step for dimension reduction. 
however for a give system there may be more than one reduct to be select. 
different reduct will lead to discover knowledge which may be concise precise general understandable and practically useful in different level. 
it be a crucial issue to select the most suitable feature or property of the object in a dataset in the machine learning process. 
in this paper some external information be add to information system and may be simply regard as user preference on attribute. 
consequently it will guide the procedure of retrieve reduct which will give birth to the reduct subject to preference order of attribute. 
a weighted rough set approach for cost sensitive learning. 
in many real world application the cost of different error be often unequal. 
therefore the inclusion of cost into learning also name cost sensitive learning have be regard as one of the most relevant topic of future machine learn research. 
rough set theory be a powerful mathematic tool deal with inconsistent information for attribute dependence analysis knowledge reduction and decision rule extraction. 
however it be insensitive to the cost of misclassification due to the absence of a mechanism of consider the subjective knowledge. 
this paper discuss problem connect with introduce the subjective knowledge into rough set learning and propose a weighted rough set approach for cost sensitive learning. 
in this method weight be employ to represent the subjective knowledge of cost and a weighted information system be define firstly. 
with the introduction of weight weight attribute dependence analysis be carry out and an index of weighted approximate quality be give. 
furthermore weight attribute reduction algorithm and weight rule extraction algorithm be design to find the reduct and rule with the consideration of weight. 
base on the propose weight rough set a series of compare experimentation with several familiar general technique on cost sensitive learning be construct. 
the result show that the approach of weight rough set produce averagely the minimum misclassification cost and the low high cost error. 
manage uncertainty in schema matcher ensemble. 
schema matching be the task of match between concept describe the meaning of datum in various heterogeneous distribute data source. 
with many heuristic to choose from several tool have enable the use of schema matcher ensemble combine principle by which different schema matcher judge the similarity between concept. 
in this work we investigate mean of estimate the uncertainty involve in schema match and harness it to improve an ensemble outcome. 
we propose a model for schema matching base on simple probabilistic principle. 
we then propose the use of machine learning in determine the good mapping and discuss its pro and con. 
finally we provide a thorough empirical analysis use both real world and synthetic datum to test the propose technique. 
we conclude that the propose heuristic perform well give an accurate modeling of uncertainty in matcher decision making. 
squirrel an advanced semantic search and browse facility. 
search be see as a key application that can benefit from semantic technology with improvement to recall and precision over conventional information retrieval technique. 
this paper describe squirrel a search and browse toot that provide access to semantically annotate datum. 
squirrel provide combine keyword base and semantic searching. 
the intention be to provide a balance between the speed and ease of use of simple free text search and the power of semantic search. 
in addition the ontological approach provide the user with a much rich browse experience. 
squirrel build on and integrate a number of semantic technology component. 
these include machine learning and information extraction component which generate extract and manage semantic metadata contain within and about textual document at index time. 
a number of run time component have also be integrate to deliver an enhance user experience which go beyond merely present a list of document as a query response. 
the tool have be trialle and evaluate in two case study and we report early result from this exercise reveal promising result. 
field installation detail of a wireless shape acceleration array system for geotechnical application. 
the evaluation health monitoring and response prediction of soil and soil structure system during construction and due to extreme hazard condition be on the verge of a significant paradigm shift. 
new and less expensive sensing technology have enable the development of innovative instrumentation and advanced interactive modeling tool. 
these tool combine with recent advance in information technology include wireless sensor network datum mining visualization and system identification promise significant improvement in real time monitor during construction sensor assist design and early warning of impending failure. 
this paper present the newly develop wireless shape acceleration array wsaa sensor that measure multi dimensional acceleration and deformation profile and constitute a major step toward autonomous monitoring technology for soil and soil structure system. 
the wireless shape acceleration array wsaa sensor employ micro machine electromechanical sensor mems which have enable gravity base shape calculation along a sensorized substrate. 
the method be an extension of technology that use fiber optic orientation sense to calculate 3d polyline represent the shape of a sensor array. 
wsaa use mems accelerometer in a pre calibrate geometrically constrain array to provide long term stability previously unattainable with fiber optic method. 
this sensor array be capable of measure 2d soil acceleration and 3d permanent ground deformation to a depth of one hundred meter. 
each sensor array be connect to a wireless earth station to enable real time monitoring of a wide range of soil and soil structure system as well as remote sensor configuration. 
this paper present the evolving design of this new sensor array as well as lesson learn from two field installation of this sensor. 
soa and large scale and complex enterprise transformation. 
service orient architecture soa be an architectural approach to development that turn traditional technique upside down. 
soa encourage organization to think in term of actual business service and the associated datum rather than low level technology detail. 
instead of develop application from the ground up soa free organization to start with high level business definition for datum interface document and process. 
soa then map these high level service definition onto new or exist infrastructure regardless of the detail location or programming language in which the system be written(1,2 in this paper we share our practical experience regard application of soa to a very large and complex enterprise transformation. 
by transformation we mean modernization of legacy application operating system server component development of new application and business process automation with incremental deployment option use either a traditional distribute heterogeneous environment or a set of virtual machine deploy on a set of utility computing platform on demand computing. 
transform a large and complex enterprise require digital visibility into the holistic view of the enterprise. 
this holistic view be capture as a set of interrelated model. 
model be digital representation of the enterprise business architecture the associate technology architecture and their semantic dependency. 
model be store in a living and manageable repository with impact analysis capability to accommodate for soa modernization to be drive by the business need. 
we describe our 3d visible enterprise 3d ve)(3 modeling methodology as the analysis phase of our soa approach. 
we then describe how such analysis guide we through modernization style where each style prescribe the transformation of a legacy entity into its modernized form while follow our soa governance. 
in this approach the modernization requirement be map into the appropriate transformation style and finally to technical implementation. 
the mapping follow our soa governance a set of guideline regard transformation style selection and the soa design run time governance. 
relevant soa standard and product support modernization implementation be use to carry the implementation. 
in particular some aspect of modernization approach and unisys soa governance be describe as well. 
in this paper we try to describe three important area of our overall soa solution methodology namely the 3d ve modeling the architecture driven modernization and apply soa governance to the adm style. 
our plan be to publish subsequent paper each describe the detail of our soa solution methodology specifically the modeling phase the tool and method use to implement the apply adm style criterion select adm style the soa governance and the associate soa standard and product. 
the paper conclude with lesson learn through such a complex transformation especially the importance of the front end business process analysis lead we to identify the component or a subset of the enterprise computing environment for systematic and incremental soa transformation. 
finally we discuss some of the pro and con of the transformation apply soa. 
automatic process control in press shop. 
the manufacturing of automotive body component in press line be a sensitive process. 
the quality characteristic of body component vary. 
these fluctuation be root in the fact that the factor influence the component quality be vary fluctuation of batch regard material quality abrasion or heating of the tool during the production cycle. 
if a certain quality characteristic exceed a predefined range an intervention in the process be necessary. 
this intervention be base upon the subjective know how of the machine operator. 
objective information about the state of the process like tool temperature or the material quality of the semi finished product be not available. 
therefore a lack of knowledge emerge in the inter relation between the tuning parameter of the system press tool and the component quality during different stage of the process material quality temperature. 
in this paper a complete concept for an automatic process control in press shop be describe. 
the concept will be realize in a pilot plant for mass production in the press shop of audi ag. 
the mechanism of occurrence of quality defect be show in the paper as well as the essential factor influence the quality during the mass production of body component in the automotive industry and their variation. 
a sensor system for continuous measurement of influence variable during the mass production be present. 
the key element of the concept be the non destructive identification of material property for every single blank. 
by associate the sensor data with the respective quality a knowledge base process control can be realize. 
the purpose be to create a failure prediction algorithm and make optimal adjustment for each stroke of the moulding press respectively. 
the potential of exist actuator in modern press line as well as new tool integrate proposal for actuator be highlight. 
parallel evolution of game evaluation functions in ada. 
this be an ada experience report where we conclude that ada task and distribute processing facility make it a good research tool for experimentation with algorithm that might eventually need multiple processor. 
we implement a genetic algorithm in ada to create effective computer player for connect4. 
key to our success be employ ada tasking and alrm annex e distribute computing to harness a symmetric multiprocessor and a distribute machine with very few code change. 
easy extension of an original single task code to multi tasking and distribute variant even though extension be not plan in advance be essential to timely completion. 
use either the parallel or distribute implementation about 150 processor hour be sufficient to evolve player that neither the gnu four in a row expert player nor the author could defeat. 
this algorithm rely on human expertise to restrict the genetic search space. 
work be in progress on a new algorithm with near zero encode knowledge which will run on 220 distribute node within the same distribute computing framework. 
a machine learning approach to tcp throughput prediction. 
tcp throughput prediction be an important capability in wide area overlay and multi homed network where multiple path may exist between datum source and receiver. 
in this paper we describe a new lightweight method for tcp throughput prediction that can generate accurate forecast for a broad range of file size and path condition. 
our method be base on support vector regression modeling that use a combination of prior file transfer and measurement of simple path property. 
we calibrate and evaluate the capability of our throughput predictor in an extensive set of lab base experiment where ground truth can be establish for path property use highly accurate passive measurement. 
we report the performance for our method in the ideal case of use our passive path property measurement over a range of test configuration. 
our result show that for bulk transfer in heavy traffic tcp throughput be predict within 10 of the actual value 87 of the time represent nearly a three fold improvement in accuracy over prior history base method. 
in the same lab environment we assess our method use less accurate active probe measurement of path property and show that prediction can be make within 10 of the actual value nearly 50 of the time over a range of file size and traffic condition. 
this result represent approximately a 60 improvement over history base method with a much low impact on end to end path. 
finally we implement our predictor in a tool call pathperf and test it in experiment conduct on wide area path. 
the result demonstrate that pathperf predict tcp throughput accurately over a variety of path. 
mems design synthesis integrate case base reasoning and multi objective genetic algorithm. 
a case base reasoning c r knowledge base have be incorporate into a micro electro mechanical systems mems design tool that use a multi objective genetic algorithm moga to synthesize and optimize conceptual design. 
cbr utilize previously successful mems design and sub assembly as building block store in an indexed case library which serve as the knowledge base for the synthesis process. 
design in the case library be represent in a parameterized object orient format incorporate mems domain knowledge into the design synthesis loop as well as restriction for the genetic operation of mutation and crossover for moga optimization. 
reasoning tool locate case in the design library with solve problem similar to the current design problem and suggest promise conceptual design which have the potential to be start design population for a moga evolutionary optimization process to far generate more mems design concept. 
surface micro machine resonator be use as an example to introduce this integrate mems design synthesis process. 
the result of testing on resonator case study demonstrate how the combination of cbr and moga synthesis tool can help increase the number of optimal design concept present to mems designer. 
distribute integrated and collaborative research environment dicore an architectural design. 
in this paper we propose to develop a distribute integrated and collaborative research environment dicore that may enable a new generation of scientific discovery learn and innovation in all scientific area. 
dicore seamlessly integrate a set of carefully select high quality web base software tool with ajar style rich user interface. 
these tool collectively satisfy the daily research need of researcher. 
underneath dicore be a set of intelligent machine learning and datum mining algorithm that be design to serve researcher educator and student in different aspect such as recommend reading material base on researcher interest and suggest work research group. 
dicore be a potential enable research and educational environment that may satisfy our next generation collaborative research and educational need. 
a wide range of new collaborative research and educational project in all area of computing become possible under dicore. 
a computationally efficient supanova spline kernel base machine learn tool. 
many machine learning method just consider the quality of prediction result as their final purpose. 
to make the prediction process transparent reversible spline kernel base method be propose by gunn. 
however the original solution method term support vector parsimonious anova supanova be computationally very complex and demand. 
in this paper we propose a new heuristic to compute the optimal sparse vector in supanova that replace the original solver for the convex quadratic problem of very high dimensionality. 
the result system be much fast without the loss of precision as demonstrate in this paper on two benchmark the iris datum set and the boston housing market datum benchmark. 
evolutionary support vector regression machine. 
evolutionary support vector machine esvms be a novel technique that assimilate the learn engine of the state of the art support vector machine svm but evolve the coefficient of the decision function by mean of evolutionary algorithm eas. 
the new method have accomplish the purpose for which it have be initially develop that of a simple alternative to the canonical svm approach for solve the optimization component of training. 
esvm as svm be natural tool for primary application to classification. 
however since the latter have be furth on extend to also handle regression it be the scope of this paper to present the corresponding evolutionary paradigm. 
in particular we consider the hybridization with the classical epsilon support vector regression epsilon svr introduce by vapnik and the subsequent evolution of the coefficient of the regression hyperplane. 
epsilon evolutionary support regression epsilon esvr be validate on the boston housing benchmark problem and the obtain result demonstrate the promise of esvm also as concern regression. 
a machine learning base approach for estimate available bandwidth. 
in this paper we propose a machine learning base approach for estimate available bandwidth. 
we evaluate the approach via simulation use two probe model a packet train probe model and a pathchirp like probe model. 
the simulation result show that the former can not yield accurate estimate in our system however use the pathchirp like probe model the propose approach can estimate the available bandwidth with moderate traffic overhead more accurately than two widely use tool pathchirp and spruce. 
moreover we propose a normalization method that improve our approach s ability to estimate available bandwidth even if there be no sample with similar property to the measured path in the training dataset. 
the effectiveness and simplicity of this novel approach make it a promising scheme that go a long way toward achieve accurate estimation of available bandwidth on internet path. 
transformation base tectogrammatical dependency analysis of english. 
we present experiment with automatic annotation of english text take from the penn treebank at the dependency base tectogrammatical layer as it be define in the prague dependency treebank. 
the propose analyzer which be base on machine learn technique outperform a tool base on hand write rule which be use for partial tectogrammatical annotation of english now in the most important characteristic of tectogrammatical annotation. 
moreover both tool be combine and their combination give the good result. 
estimate monthly production of oil well. 
this paper describe result concern the capability of supervised machine learn technique to predict production potential for a single formation prior to drilling over a 16,000 square mile area of se new mexico. 
in this paper a neural network be use to predict production potential for a single formation of se new mexico region. 
the process involve gather datum for use as potential input collect production datum at know well select optimal input develop and test various network architecture make prediction analyze and apply the result. 
this predict production be far refine by exclude production at location where the woodford shale be not present. 
result be evaluate by inspect a map of predict production and perform statistical testing include a correlation of predict and actual production which produce a correlation coefficient of 0.79. 
the result be then use by the devonian fee tool an expert system design to reduce exploration risk. 
traceable measurement for beam propagation ratio m two. 
this paper report an investigation into measurement technique and infrastructure suitable for underpin traceable calibration of device for beam propagation parameter measurement. 
the accurate knowledge of the m two parameter be require for a diverse range of application include semiconductor manufacture process control laser machining thin film transistor tft fundamental research into frequency doubling and the production and characterisation of optical component. 
characterisation of the size and position of the beam waist be essential for the correct hazard classification of extended source laser system use the iec 60825 series of standard. 
a system for measure beam propagation factor measurement have be develop at npl base on the methodology outline in the iso 11146 series of standard. 
this methodology use spatial intensity profile measurement of the beam at define point along the direction of propagation of the beam through a beam waist produce by a convex lens. 
the beam width obtain use a ccd and a converging second moment method be fit to a hyperbolic propagation envelope and the beam propagation coefficient be obtain from this shape. 
the traceability of this method have be provide by use graticule calibrate against length standard and carefully measure ccd camera parameter. 
select datum for fast support vector machine training. 
in recent year support vector machine svm have become a popular tool for pattern recognition and machine learning. 
train a svm involve solve a constrain quadratic programming problem which require large memory and enormous amount of training time for large scale problem. 
in contrast the svm decision function be fully determine by a small subset of the training datum call support vector. 
therefore it be desirable to remove from the training set datum that be irrelevant to the final decision function. 
in this work we propose two new method that select a subset of datum for svm training. 
use real world dataset we compare the effectiveness of the propose datum selection strategy in term of their ability to reduce the training set size while maintain the generalization performance of the result svm classifier. 
our experimental result show that a significant amount of training datum can be remove by our propose method without degrade the performance of the result svm classifier. 
bold symbol base machine learning approach for supervised segmentation of follicular lymphoma images</bold. 
yinphoina be a broad term encompass a variety of cancer of the lymphatic system. 
lymphoma be differentiate 133 the type of cell that multiplie and how the cancer present itself. 
it be very important to get an exact diagnosis regard lymphoma and to determine the treatment that will be most effective for the patient s condition. 
our work be focus oil the identification of lymphoma by find follicle in microscopy image provide by the laboratory of pathology in the university hospital of tenerife spain. 
roughly we can divide our work in two stage in the first stage we do image pre processing and feature extraction and in the second stage we use different rough set approach for pixel classification. 
these result be compare to decision tree result we obtain early. 
symbolic machine learning approach be often neglect when look for image analysis tool. 
the result we get be very promising and show that symbolic approach call be successful in image analysis application. 
eyepatch prototyping camera base interaction through example. 
camera be a useful source of input for many interactive application but computer vision programming be difficult and require specialized knowledge that be out of reach for many hci practitioner. 
in an effort to learn what make a useful computer vision design tool we create eyepatch a tool for design camera base interaction and evaluate the eyepatch prototype through deployment to student in an hci course. 
this paper describe the lesson we learn about make computer vision more accessible while retain enough power and flexibility to be useful in a wide variety of interaction scenario. 
evaluate a simulated student use real student datum for training and testing. 
simstudent be a machine learn agent that learn cognitive skill by demonstration. 
it be originally develop as a building block of the cognitive tutor authoring tools ctat so that the author do not have to build a cognitive model by hand but instead simply demonstrate solution for simstudent to automatically generate a cognitive model. 
the simstudent technology could then be use to model human student performance as well. 
to evaluate the applicability of simstudent as a tool for model real student we apply simstudent to a genuine learning log gather from classroom experiment with the algebra i cognitive tutor. 
such datum can be see as the human student demonstration of how to solve problem. 
the result from an empirical study show that simstudent can indeed model human student performance. 
after training on 20 problem solve by a group of human student a cognitive model generate by simstudent explain 82 of the problem solve step perform correctly by another group of human student. 
femarepviz automatic extraction and geo temporal visualization of fema national situation updates. 
an architecture for visualize information extract from text document be propose. 
in conformance with this architecture a toolkit femarepviz have be implement to extract and visualize temporal geospatial and summarize information from fema national update reports. 
preliminary test have show satisfactory accuracy for femarepviz. 
a central component of the architecture be an entity extractor that extract name entity like person name location name temporal reference etc. 
femarepviz be base on factxtractor an entity extractor that. 
work on text document. 
the information extract use factxtractor be process use geotagger a geographical name disambiguation tool base on a novel clustering base disambiguation algorithm. 
to extract relationship among entity we propose a machine learning base algorithm that use a novel strip dependency tree kernel. 
we illustrate and evaluate the usefulness of our system on the fema national situation updates. 
daily report be fetch by femarepviz from the fema website segment into coherent section and each section be classify into one of several know incident type. 
we use conceptvista google maps and google earth to visualize the event extract from the text report and allow the user to interactively filter the topic location and time period of interest to create a visual analytic toolkit that be useful for rapid analysis of event report in a large set of text document. 
analysis guide visual exploration of multivariate datum. 
visualization system traditionally focus on graphical representation of information. 
they tend not to provide integrate analytical service that could aid user in tackle complex knowledge discovery task. 
user exploration in such environment be usually impede due to several problem one valuable information be hard to discover when too much datum be visualize on the screen two user have to manage and organize their discovery off line because no systematic discovery management mechanism exist three their discovery base on visual exploration alone may lack accuracy four and they have no convenient access to the important knowledge learn by other user. 
to tackle these problem it have be recognize that analytical tool must be introduce into visualization system. 
in this paper we present a novel analysis guide exploration system call the nugget management system nms. 
it leverage the collaborative effort of human comprehensibility and machine computation to facilitate user visual exploration process. 
specifically nms first extract the valuable information nuggets hide in dataset base on the interest of user. 
give that similar nugget may be re discover by different user nms consolidate the nugget candidate set by cluster base on their semantic similarity. 
to solve the problem of inaccurate discovery localize datum mining technique be apply to refine the nugget to well represent the capture pattern in dataset. 
lastly the result well organize nugget pool be use to guide user exploration. 
to evaluate the effectiveness of nms we integrate nms into xmd vtool a freeware multivariate visualization system. 
user study be perform to compare the user efficiency and accuracy in finish task on real dataset with and without the help of nms. 
our user study confirm the effectiveness of nms. 
sunfall a collaborative visual analytic system for astrophysic. 
computational and experimental science produce and collect everlarger and complex dataset often in large scale multi institution project. 
the inability to gain insight into complex scientific phenomenon use current software tool be a bottleneck face you all endeavor of science. 
in this paper we introduce sunfall a collaborative visual analytic system develop for the nearby supernova factory an international astrophysic experiment and the large data volume supernova search currently in operation. 
sunfall utilize novel interactive visualization and analysis technique to facilitate deep scientific insight into complex noisy high dimensional high volume time critical datum. 
the system combine novel image processing algorithm statistical analysis and machine team with highly interactive visual interface to enable collaborative user drive scientific exploration of supemova image and spectral datum. 
sunfall be currently in operation at the nearby supernova factory it be the first visual analytic system in production use at a major astrophysic project. 
cibyl an environment for language diversity on mobile device. 
with an estimate installation base of around one billion unit the java j2me platform be one of the large development target available. 
for mobile device j2me be often the only available environment. 
for the very large body of software write in c other language this mean difficult and costly porting to another language to support j2me device. 
this paper present the cibyl programming environment which allow exist code write in c and other language support by gcc to be recompile into java bytecode and run with close to native java performance on j2me device. 
cibyl translate compile mips binary into java bytecode. 
in contrast to other approach cibyl support the full c language be base on unmodified standard tool and do not rely on source code conversion. 
to achieve good performance cibyl employ extension to the mips architecture to support low overhead call to native java functionality and use knowledge of the mips abi to avoid compute unused value and transfer unnecessary register. 
an evaluation on multiple virtual machine show that cibyl achieve performance similar to native java with result range from a slowdown of around to a speedup of over nine depend on the jvm and the benchmark. 
a new support tool for machine learning and pattern recognition use tracking and motion segmentation. 
a new support tool use object tracking and motion base segmentation be develop for machine learning and pattern recognition. 
in the learning step an object of interest be track while learn be perform from segmented frame. 
in the recognition step target be track until favorable condition allow identification. 
this tool be use in the context of the aqu@theque project which include an automatic fish recognition system. 
tracking be a difficult task especially in case of real world image. 
particle filter method incorporate motion base segmentation measurement in importance sample step improve performance. 
enhance computer graphic through machine learning a survey. 
machine learning have experience explosive growth in the last few decade achieve sufficient maturity to provide effective tool for sundry scientific and engineering field. 
machine learning provide a firm theoretical foundation upon which to build technique that leverage exist datum to extract interesting information or to synthesize more datum. 
in this paper we survey the use of machine learning method and concept in recent computer graphic technique. 
many graphic technique be data drive however few graphic paper explicitly leverage the machine learn literature to underpin validate and develop their propose method. 
this survey provide novel insight by cast many exist computer graphic technique into a common learning framework. 
this not only illuminate how these technique be relate but also reveal possible way in which they may be improve. 
we also use our analysis to propose several direction for future work. 
interior permanent magnet synchronous motor ipmsm adaptive genetic parameter estimation. 
interior permanent magnet synchronous motors ipmsms be receive increase attention for high performance drive application because of their high power density high efficiency and flux weakening capability. 
however their high efficiency characteristic be influence by apply control strategy. 
thus much effort have be direct towards the efficiency optimization of the ipmsm by minimize motor copper loss this loss be influence by machine parameter. 
thus online estimation of these parameter be essential. 
on the other hand genetic algorithm ga be a tool for optimization and can be use for solve some problem that can be formulate in those form that this algorithm can handle it. 
in this paper we formulate nonlinear state equation of this motor in such form that we can use ga for estimate the unknown parameter. 
simulation result show that the estimate parameter converge to correct value after several iteration. 
use ontology with semantic web service to support modeling in system biology. 
model in system biology be concern with use experimental information and mathematical method to build quantitative model at different biological scale. 
this require interoperation among various knowledge source and service such as biological database mathematical equation datum analysis tool and so on. 
semantic web services provide an infrastructure that allow a consistent representation of these knowledge source as web base information unit and enable discovery composition and execution of these unit by associate machine processable semantic description with they. 
in this paper we show a method of use ontology alongside a semantic web service infrastructure to provide a knowledge standardisation framework in order to support modeling in system biology. 
we demonstrate how ontology be use to control the transformation of biological database and datum analysis method into web services and how ontology base web service description owl s be use to enable the composition between these service. 
aisle through the category forest utilise the wikipedia category system for corpus building in machine learning. 
the word wide web be a continuous challenge to machine learning. 
establish approach have to be enhance and new method be develop in order to tackle the problem of find and organise relevant information. 
it have often be motivate that semantic classification of input document help solve this task. 
but while approach of supervised text categorisation perform quite well on genre find in write text newly evolve genre on the web be much more demanding. 
in order to successfully develop approach to web mining respective corpus be need. 
however the composition of genre  or domain specific web corpora be still an unsolved problem. 
it be time consume to build large corpus of good quality because web page typically lack reliable meta information. 
wikipedia along with similar approach of collaborative text production offer a way out of this dilemma. 
we examine how social tagging as support by the mediawiki software can be utilise as a source of corpus building. 
far we describe a representation format for social ontology and present the wikipedia category explorer a tool which support categorical view to browse through the wikipedia and to construct domain specific corpus for machine learning. 
tool to foster semantic base collaboration a knowledge management approach base on a semantic wiki and personal ontology. 
increase mobility and team distribution may hinder collaboration in organization by hamper spontaneous communication in workplace. 
tool be require to be integrate and not intrusive with respect to user activity in order to provide effective support to worker for the development of joint project. 
in this paper we present the enhancement of a knowledge base collaborative system by mean of a semantic wiki which be a wiki exploit ontologic to create machine processable annotation of document. 
moreover we present a simple tool to edit personal ontology that can be share with other team or organization member. 
bayesian network for engineering design decision support. 
a method for machine learn a bayesian belief network bbn and associate dynamic decision support tool be present. 
this support tool have be tailor for the early engineering design stage where the nature of the design problem be ill structure and have traditionally rely on the designer s tacit domain expertise. 
the bbn enable a designer to interactively explore the design space. 
the bbn be efficiently induce from a database of prior design exemplar use a novel information content metric to greedily construct the causal graph structure. 
the method be illustrate use a conceptual car design domain. 
use self organize map to explore pattern in specie richness and protection. 
the combination of specie distribution with abiotic and landscape variable use geographic information systems can prioritize area for biodiversity protection by identify area of high richness although the number of variable and complexity of the relationship between they can prove difficult for traditional statistical method. 
the use of these method which commonly assume linearity and low correlation between independent variable can obscure even strong relationship and pattern. 
self organize map som be a heuristic statistical tool base on machine learning method that can be use to explore pattern in large complex dataset for linear and nonlinear pattern. 
here we use som to visualize broad pattern in specie richness by taxonomic group bird mammal reptile and amphibian and 78 habitat landscape and environmental variable use datum from the gap analysis project for west virginia usa. 
soil and habitat variable demonstrate clear relationship with specie richness area with high specie richness occur in area with high soil richness. 
landscape metric be less important although habitat diversity and evenness index be positively relate to specie richness in some taxonomic group. 
current coverage of protect area e.g. national forests and state park appear to be insufficient to cover most of the area of high specie richness especially for reptile many of the polygon with the high richness be not cover by these area. 
the identification of polygon with high richness and low protection can be use to focus conservation effort in those area. 
constraint base approach to investigate the process flexibility of food processing equipment. 
over the last decade the uk food processing industry have become increase competitive. 
this lead the sector to maintain high number of product variation. 
although some of these product be stable over long period other be short lived or seasonal. 
the ability to handle both the complexity of process and large variation in product format create extreme difficulty in ensure that the exist manufacturing handling and packaging equipment have the process flexibility to cope. 
this paper present an approach for investigate the performance envelope of machine utilize a constraint modelling environment. 
the approach aim to provide the engineer with enhanced understanding of the range of functionality of a give machine and provide the possibility of redesign to process variant product. 
c 2006 elsevier ltd. 
all right reserve. 
a knowledge discovery method to predict the economical sustainability of a company. 
in this study we be build a prototype of a machine learn system use an inductive supervised approach to predict the logistical performance of a company. 
focus lie on the learning phase the handling of different type of datum the creation of new concept in order to provide well measurable information. 
in this system numeric financial datum be combine with categorical datum create symbolic datum distinguish the phase of model generation from example and the phase of model classification and interpretation. 
the system have be implement in vector space. 
our datum be benchmarke survey on concurrent engineering ce measure the usage of in total 302 good practice in belgian manufacturing company. 
the general purpose for implement a good practice be the statement that the company will improve its product processing and that in this way the company will establish its economical existence on the market. 
our model process a limited number of predefined step generate value factor for the 302 good practice. 
the good practice be group into 30 subject the value factor combine in linear combination. 
these value factor and their linear combination be then subject to pattern interpretation relate ce performance to the past financial state of the company and also to the economical well doing of the company in the long term we also refer to the sustainability of the company in the market. 
web base machine translation as a tool for promote electronic literacy and language awareness. 
this article address a pervasive problem of concern to teacher of many foreign language the use of web base machine translation wbmt by student who do not understand the complexity of this relatively new tool. 
although networked technology have greatly increase access to many language and communication tool wbmt be still ineffective for translate text into another language especially when the user of the software be not able to make grammaticality and acceptability judgment in the target language. 
this article explain some specific limitation of wbmt with example from french and provide a pedagogical plan for teacher to present this tool to student in order to promote language awareness and electronic literacy which could help reduce the widespread misuse of this tool by student. 
spatio temporal processing for multichannel biosensor use support vector machine. 
rapid response biosensing system be necessary to counteract theat due to foreign and high consequence pathogen. 
a yes no multichannel biosensor be an important tool that enable simultaneous detection of different pathogen independent of their relative concentration level. 
this paper propose a novel multichannel biosense technique which combine multiclass support vector machine svm with multichannel immunosensor. 
the method combine spatial and temporal information generate by the multichannel immunosensor for rapid and reliable discrimination between pathogen of interest. 
this paper demonstrate that by include temporal and cross reactive spatial signature the accuracy of the system can be improve at low pathogen concentration level and for discrimination between closely relate strain of pathogen. 
compensation of systematic and biosensor fabrication error be achieve by the use of a supervised svm training which be also use in system calibration. 
experimental result with a prototype multichannel biosensor use for discriminate strain of e. coli k12 and o157 h7 and salmonella enterica serovar thompson show an accuracy of 98 for concentration level 10(0) 10(8 colony form unit per milliliter and total detection time of less than six min. 
machine assistance in collection building new tool research issue and reflection. 
digital tool making offer many challenge involve much trial and error. 
develop machine learning and assistance in automate and semi automate internet resource discovery metadata generation and rich text identification provide opportunity for great discovery innovation and the potential for transformation of the library community. 
the area of computer science involve as apply to the library application address be among that discipline s lead edge. 
make apply research practical and applicable through placement within library collection management system and service involve equal part computer scientist research librarian and legacy system archaeologist. 
still the early harvest be there for we now with a large harvest pende. 
data fountains and ivia the project discuss demonstrate this. 
clearly then the present would be a good time for the library community to more proactively and significantly engage with this technology and research to well plan for its impact to more proactively take up the challenge involve in its exploration and to well and more comprehensively guide effort in this new territory. 
the alternative to do this be that other will develop this territory for we do it not as well and sell it back to we at a premium. 
awareness of this technology and its current capability promise limitation and probable major impact need to be generalize throughout the library management metadata and system community. 
this article chart recent work promise avenue for new research and development and issue the library community need to understand. 
the efficacy of back propagation neural network with delta bar delta learn in predict the wear of carbide insert in face mill. 
face milling be a process predominantly affect by dynamic variation of cut force thermo mechanical shock and vibration lead to catastrophic tool failure along with gradual wear of the insert. 
keep in view the industrial importance of this process it be necessary to devise suitable method to predict in advance the onset of tool failure without grossly impair the machine set up and the job. 
hence the applicability of back propagation neural network with delta bar delta learning rule for fast convergence have be study with the above objective. 
the multi sensor base tool condition monitor strategy show that the learning rate adaptation scheme combine with the selection of suitable process parameter drastically reduce the training time of the artificial neural network without dispense with the prediction accuracy. 
an optimize contour parallel tool path for 2d milling with flat endmill. 
although the conventional contour parallel tool path obtain from geometric information have be successful in make desirable shape it seldom consider the physical process concern like cut force and chatter. 
in this paper an optimize contour parallel path which maintain constant mrr material removal rate at all time be introduce and the result be verify. 
the optimize tool path be base on a conventional contour parallel tool path. 
additional tool path segment be append to the basic tool path in order to achieve constant cut force and to avoid chatter vibration in the entire machining area. 
the algorithm have be implement for two dimensional contiguous end mill operation with flat end mill and cut test be conduct to verify the significance of the propose method. 
intelligent evolutionary design a new approach to optimize complex engineering system and its application to design heat exchanger. 
a new method for optimize complex engineering design be present that be base on the learnable evolution model lem a recently develop form of non darwinian evolutionary computation. 
unlike conventional darwinian type method that execute an unguided evolutionary process the propose method call lemd guide the evolutionary design process use a combination of two method one involve computational intelligence and the other involve encode expert knowledge. 
specifically lemd integrate two mode of operation learning mode and probing mode. 
learning mode apply a machine learn program to create new design through hypothesis generation and instantiation whereas probing mode create they by apply expert  suggest design modification operator tailor to the specific design problem. 
the lemd method have be use to implement two initial system ished i and iscodi specialize for the optimization of evaporator and condenser in cool system respectively. 
the design produce by these system match or exceed in performance the good design develop by human expert. 
these promising result and the generality of the present method suggest that lemd offer a powerful new tool for optimize complex engineering system. 
c 2006 wiley periodicals inc.. 
industrial development in the inland region of china a case study of the motorcycle industry. 
although the inland region of china have generally be leave behind in economic development compare with the coastal region. 
the motorcycle industry in chongqing have record remarkable growth due to the meteoric rise of private enterprise over the last decade. 
base on panel datum of enterprise. 
we attempt to identify the factor behind the dynamic development of this industry. 
we conclude that the success of the motorcycle industry in chongqing be attributable to a combination of positive feature from the wenzhou model in the 1990 in which industrial development be base on clustering of private enterprise and the sunan model in the 1980s. 
in which industrial development be base on the effective use of human resource recruit from exist state own enterprise soe. 
learn by collective enterprise from soe in chongqing couple with the growth of the private enterprise sector foster cluster base industrial development. 
advanced human machine system for intelligent manufacturing some issue in employ ontology for natural language processing. 
the use of ontology have gain more and more interest above all for the knowledge management the exchange of professional know how as report in various previous paper. 
under the pressure of a turbulent international market situation enterprise stress the importance of innovation in manufacturing area. 
for instance due to the drastic grow automation degree of manufacturing system an intuitive interaction form be require which enable the shop floor personnel an active participation to the production without specific technical background as well as to capture and retrieve systematically knowledge content arise from the interaction process. 
the follow contribution take this topic into consideration and propose an innovative ontology  base approach call ontological filter system ofs base on method and procedure to formalize natural language content in a systematic way. 
by mean of a so call ontological network on generic term form use in the human machine interaction hmi via natural language could be lead back to a set of pre define term. 
thus the on consist on the one hand of a large number of generic natural language term and on the other hand of a set of so call key term. 
the generic term be define classify in semantic category and chain together per semantic relation for a specific use in a particular domain of discourse. 
the key term be use to build information on machine level and therefore have a formal definition. 
through additional syntax role and application specific semantic constrain a systematic access and processing of natural language instruction be accomplish computationally. 
the propose concept have be set up and test within an experimental testbe. 
the obtain result show a high system performance and encourage the research team to invest further effort in order to validate the system operational performance towards its industrial use at shop floor level. 
application of support vector machine in the prediction of mechanical property of steel material. 
the investigation of the influence of important parameter include steel chemical composition and hot rolling parameter on the mechanical property of steel be a key for the system that be use to predict mechanical property. 
to improve the prediction accuracy support vector machine be use to predict the mechanical property of hot roll plain carbon steel q235b. 
support vector machine be a novel machine learning method which be a powerful tool use to solve the problem characterize by small sample non linearity and high dimension with a good generalization performance. 
on the basis of the datum collect from the supervisor of hot roll process the support vector regression algorithm be use to build prediction model and the off line simulation indicate that predict and measure result be in good agreement. 
thermal error modeling of a machining center use grey system theory and adaptive network base fuzzy inference system. 
thermal effect on machine tool be a well recognize problem in an environment of increase demand for product quality. 
the performance of a thermal error compensation system typically depend on the accuracy and robustness of the thermal error model. 
this work present a novel thermal error model utilize two mathematic scheme the grey system theory and the adaptive network base fuzzy inference system anfis. 
first the measure temperature and deformation result be analyze via the grey system theory to obtain the influence rank of temperature ascent on thermal drift of spindle. 
then use the highly rank temperature ascent as input for the anfis and train these datum by the hybrid learning rule a thermal compensation model be construct. 
the grey system theory effectively reduce the number of temperature sensor need on a machine structure for prediction and the anfis have the advantage of good accuracy and robustness. 
for test the performance of propose anfis model a real cut operation test be conduct. 
comparison result demonstrate that the modeling scheme of the anfis couple with the grey system theory have good predictive ability. 
research on auto reasoning process planning use a knowledge base semantic net. 
a process planning model pp model be propose to convert the geometric feature into manufacture machining operation and sequence the machining operation of the part in a feasible and effective order. 
the process planning model pp model construct a feature framework that make a mapping from geometric feature into machine operation. 
a semantic net name the precedence relations net be establish to reflect the precedence relationship among the machining operation. 
the vector and the matrix be employ to construct a mathematical sequencing model. 
a part be decompose into several basic geometrical unit namely u one u two u n. 
for each unit u i two vector name f i and p i represent the feature and machine operation of u i. 
finally a matrix name pp be use to memorize the process plan and a matrix po perform object represent the object of machine operation. 
c 2006 elsevier b.v. 
all right reserve. 
statistical strategy for avoid false discovery in metabolomic and related experiment. 
many metabolomic and other high content or high throughput experiment be set up such that the primary aim be the discovery of biomarker metabolite that can discriminate with a certain level of certainty between nominally match case and control sample. 
however it be unfortunately very easy to find marker that be apparently persuasive but that be in fact entirely spurious and there be well know example in the proteomic literature. 
the main type of danger be not entirely independent of each other but include bias inadequate sample size especially relative to the number of metabolite variable and to the required statistical power to prove that a biomarker be discriminant excessive false discovery rate due to multiple hypothesis testing inappropriate choice of particular numerical method and overfitte generally cause by the failure to perform adequate validation and cross validation. 
many study fail to take these into account and thereby fail to discover anything of true significance despite their claim. 
we summarise these problem and provide pointer to a substantial exist literature that should assist in the improved design and evaluation of metabolomic experiment thereby allow robust scientific conclusion to be draw from the available datum. 
we provide a list of some of the simple check that might improve one s confidence that a candidate biomarker be not simply a statistical artefact and suggest a series of preferred test and visualisation tool that can assist reader and author in assess paper. 
these tool can be apply to individual metabolite by use multiple univariate test perform in parallel across all metabolite peak. 
they may also be apply to the validation of multivariate model. 
we stress in particular that classical p value such as p 0.05 that be often use in biomedicine be far too optimistic when multiple test be do simultaneously as in metabolomic. 
ultimately it be desirable that all datum and metadata be available electronically as this allow the entire community to assess conclusion draw from they. 
these analysis apply to all high dimensional omic dataset. 
application of datum mining approach to drug delivery. 
computational approach play a key role in all area of the pharmaceutical industry from datum mining experimental and clinical datum capture to pharmacoeconomic and adverse event monitor. 
they will likely continue to be indispensable asset along with a grow library of software application. 
this be primarily due to the increasingly massive amount of biology chemistry and clinical datum which be now enter the public domain mainly as a result of nih and commercially fund project. 
we be therefore in need of new method for mine this mountain of datum in order to enable new hypothesis generation. 
the computational approach include but be not limited to database compilation quantitative structure activity relationship qsar pharmacophore network visualization model decision tree machine learning algorithm and multidimensional data visualization software that could be use to improve drug delivery after mine public and/or proprietary datum. 
we will discuss some area of unmet need in the area of datum mining for drug delivery that can be address with new software tool or database of relevance to future pharmaceutical project. 
c 2006 elsevier b.v. 
all right reserve. 
subsurface drainage practice from manual installation to large scale implementation. 
drainage of agricultural land be an instrument for production growth a safeguard for sustainable investment in irrigation and a tool for conservation of land resource. 
projection to meet the food and fibre need of the world during the next 25 year show that drainage of at least 10 15 million ha should be improve which will require an investment of eur 19 billion or about 750 eur million annually. 
it be expect that one third of this area will be provide with subsurface drainage system. 
subsurface drainage have be practice for thousand of year however the rapid introduction in europe and north america only start around 1940 when the prevail empirical knowledge of drainage and salinity control gain a solid theoretical foundation. 
since then the installation practice evolve from purely manual installation on individual farm plot to fully mechanized installation programme cover thousand of hectare. 
to make this rapid change possible practical tool for the implementation have to be develop start with the introduction of new type of installation equipment trencher and trenchless drainage machine. 
to optimize the use of these machine however a number of problem have to be solve. 
new material for drain pipe and envelope have to be develop to reduce the high transportation and installation cost of the traditional material and to improve quality of construction. 
next the traditional method of quality control prove to be inadequate because of the increase speed and method of mechanical installation. 
and last but not least staff have to be train in these modernise drainage machinery and installation technique as well as in the planning and organization of the implementation process. 
this paper discuss these development in installation technique equipment and material and the corresponding institutional change that be need to keep up with these change demand. 
these development be still go on to meet the specific need of installation in develop country under climatic physical and social condition that differ from the one for which they have be design. 
furthermore the specific need of drainage be also change particularly with regard to the quality of drainage water that require change in the drain system design and correspond installation practice. 
c 2006 elsevier b.v. 
all right reserve. 
predict the insurgence of human genetic disease associate to single point protein mutation with support vector machine and evolutionary information. 
motivation human single nucleotide polymorphism snp be the most frequent type of genetic variation in human population. 
one of the most important goal of snp project be to understand which human genotype variation be relate to mendelian and complex disease. 
great interest be focus on non synonymous code snp nssnps that be responsible of protein single point mutation. 
nssnps can be neutral or disease associate. 
it be know that the mutation of only one residue in a protein sequence can be relate to a number of pathological condition of dramatic social impact such as altzheimer s parkinson s and creutzfeldt jakob s disease. 
the quality and completeness of presently available snps database allow the application of machine learn technique to predict the insurgence of human disease due to single point protein mutation start from the protein sequence. 
result in this paper we develop a method base on support vector machine svm that start from the protein sequence information can predict whether a new phenotype derive from a nssnp can be relate to a genetic disease in human. 
use a dataset of 21185 single point mutation 61 of which be disease relate out of 3587 protein we show that our predictor can reach more than 74 accuracy in the specific task of predict whether a single point mutation can be disease related or not. 
our method although base on less information outperform other web available predictor implement different approach. 
availability a beta version of the web tool be available at http://gpcr.biocomp.unibo.it/cgi/predictors/phd snp/phd snp.cgi contact casadio@alma.unibo.it. 
bio inspire scheduling for dynamic job shop with flexible routing and sequence dependent setup. 
flexible routing require schedule to be responsive and robust. 
multi agent system have the potential to achieve robustness and provide a mean for real time planning and scheduling. 
the objective of this paper be to propose a multi agent scheduling system with a good solution quality and robustness. 
the propose multi agent approach be design for dynamic job shop with route flexibility and sequence dependent setup. 
a bio inspired strategy base on division of labour in insect society be present for coordination among agent. 
the strategy be accomplish use a computational model which be compose of response threshold response intention and machine centre reinforcement learning. 
the bio inspired scheduling be compare with an agent base approach and a dispatch rule base approach. 
the experiment be perform use simulation and statistical analysis. 
result show that the propose bio inspired scheduling model perform well than the other two method on all eight common scheduling metric. 
machine learn technique in disease forecasting a case study on rice blast prediction. 
background diverse modeling approach viz. 
neural network and multiple regression have be follow to date for disease prediction in plant population. 
however due to their inability to predict value of unknown datum point and long training time there be need for exploit new prediction software for well understanding of plant pathogen environment relationship. 
far there be no online tool available which can help the plant researcher or farmer in timely application of control measure. 
this paper introduce a new prediction approach base on support vector machine for develop weather base prediction model of plant disease. 
result six significant weather variable be select as predictor variable. 
two series of model cross location and cross year be develop and validate use a five fold cross validation procedure. 
for cross year model the conventional multiple regression reg approach achieve an average correlation coefficient r of 0.50 which increase to 0.60 and percent mean absolute error mae decrease from 65.42 to 52.24 when back propagation neural network bpnn be use. 
with generalize regression neural network grnn the r increase to 0.70 and mae also improve to 46.30 which far increase to r 0.77 and mae 36.66 when support vector machine svm base method be use. 
similarly cross location validation achieve r 0.48 0.56 and 0.66 use reg bpnn and grnn respectively with their corresponding mae as 77.54 66.11 and 58.26. 
the svm base method outperform all the three approach by far increase r to 0.74 with improvement in mae to 44.12. 
overall this svm base prediction approach will open new vista in the area of forecast plant disease of various crop. 
conclusion our case study demonstrate that svm be well than exist machine learning technique and conventional reg approach in forecast plant disease. 
in this direction we have also develop a svm base web server for rice blast prediction a first of its kind worldwide which can help the plant science community and farmer in their decision making process. 
the server be freely available at http://www.imtech.res.in/raghava/rbpred/.. 
tighten the net a review of current and next generation spam filter tool. 
this paper provide an overview of current and potential future spam filter approach. 
we examine the problem spam. 
introduce what spam be and how we can measure it. 
the paper primarily focus on automate non interactive filter with a broad review range from commercial implementation to idea confine to current research paper. 
both machine learning  and non machine learning base filter be review as potential solution and a taxonomy of know approach be present. 
while a range of different technique have and continue to be evaluate in academic research heuristic and bayesian filtering dominate commercial filter system therefore a case study of these technique be present to demonstrate and evaluate the effectiveness of these popular technique. 
c 2006 elsevier ltd. 
all right reserve. 
on the evolution of weld residual stress after mill and cut machining. 
residual stress develop during most manufacturing process involve material deformation heat treatment machining or processing operation that transform the shape or change the property of a material. 
they have a not negligible effect on the material strength especially on fatigue. 
for this reason it be important that some knowledge of the internal stress state can be deduce either from measurement or from model prediction. 
the object of this paper be forecast the modification and the evolution that a residual stress field originate by welding suffer after chip form machining such as mill and cut. 
numerical result have be critically compare to experimental measurement and show the potentiality but also the limitation of numerical technique. 
c 2006 elsevier ltd. 
all right reserve. 
visualise and assess the probable error from downscale ecological time series datum. 
collect natural datum at regular fine scale be an onerous and often costly procedure. 
however there be a basic need for fine scale datum when apply inductive method such as neural network or genetic algorithm for the development of ecological model. 
this paper will address the issue involve in interpolate datum for use in machine learning method by consider how to determine if a downscaling of the datum be valid. 
the approach be base on a multi scale estimate of error. 
the result function have similar property to a time series variogram however the comparison at different scale be base on the variance introduce by rescale from the original sequence. 
this approach have a number of property include the ability to detect frequency in the datum below the current sampling rate an estimate of the probable average error introduce when a sample variable be downscale and a method for visualise the sequence of a time series that be most susceptible to error due to sample. 
the describe approach be ideal for support the ongoing sampling of ecological datum and as a tool for assess the impact of use interpolate datum for build inductive model of ecological response. 
c 2006 elsevier b.v. 
all right reserve. 
inspection orient code service base on machine learning and semantic mining. 
hs code have be adopt by the majority of country as be the basis for import and export inspection and the generation of trade statistic. 
custom authority and international trader need a hs code query tool to make their processing efficient and automatic. 
since hs code be identify at five 7 level of classification then any intelligent code service will need to combine a knowledge database with the technique of datum mining machine learning and semantic reasoning. 
in this paper the author propose a comprehensive solution for such a code service. 
the architecture related technique technical solution and implementation consideration for the propose system have be provide. 
several of the propose function and implementation technique have be develop and deploy by the shanghai international airport entry exit inspection and quarantine bureau. 
the code service have be publish as a web service and have the potential to be widely use by authority and international trader around the world. 
the propose system may also be appropriate for other application that relate to code or classification process such as rfid base or product ontology base application. 
c 2006 elsevier ltd. 
all right reserve. 
data fusion and multicue datum match by diffusion map. 
data fusion and multicue datum matching be fundamental task of high dimensional datum analysis. 
in this paper we apply the recently introduce diffusion framework to address these task. 
our contribution be three fold first we present the laplace beltrami approach for compute density invariant embedding which be essential for integrate different source of datum. 
second we describe a refinement of the nystrom extension algorithm call geometric harmonic. 
we also explain how to use this tool for data assimilation. 
finally we introduce a multicue datum matching scheme base on nonlinear spectral graph alignment. 
the effectiveness of the present scheme be validate by apply it to the problem of lipreading and image sequence alignment. 
decision tree assist control islanding. 
control islanding refer to the control separation of an interconnect power system into electrically isolated region. 
the objective of this paper be to develop adaptive control islanding as a component of an emergency power system control strategy. 
there be two primary aspect of control islanding one where to island and two when to island assist by a decision tree dt approach this paper seek to address the when to island aspect. 
a decision tree base tool be propose to recognize condition exist in the system that warrant control islanding. 
a 29 generator 179 bus system be employ to demonstrate the tool. 
simulation datum be use to train dt and the online performance of dts be then evaluate as part of a control islanding strategy. 
use datum continualization and expansion to improve small datum set learning accuracy for early flexible manufacturing system fms scheduling. 
knowledge derive from limited datum gather in the early manufacturing stage be usually too fragile for a flexible manufacturing system fms. 
unfortunately production decision have to be make quickly in a competitive environment. 
in a previous study a strategy use continuous datum and domain external expansion method under a know data domain range be propose to solve the so call small datum set learning problem in fms. 
the present paper go far in seek a quantitative method to determine the range of domain external expansion under unknown domain bound. 
the research consider the data bias phenomenon that often occur in small data set and provide a method for its adjustment. 
beyond this the study also compare the learning result among three type of membership function bell trapezoid triangular for data fuzzification. 
the result show that the propose approach can advance the learning accuracy of a broad range of application. 
computerized modeling and simulation of spiral bevel and hypoid gear manufacture gleason face hobbing process. 
the gleason face bob process have be widely apply by the gear industry. 
but so far few paper have be find regard exact modeling and simulation of the tooth surface generation and tooth contact analysis tca of face hob spiral bevel and hypoid gear set. 
this paper present the generalize theory of the face hob generation method mathematic model of tooth surface generation and the simulation of meshing of face hob spiral bevel and hypoid gear. 
the face hob indexing motion be describe and visualize. 
a generalize description of the cut blade be introduce by consider four section of the blade edge geometry. 
a kinematical model be develop and analyze by break down the machine tool setting and the relative motion of the machine elemental unit and apply coordinate transformation of the elemental motion. 
the developed face hobbing generation model be directly relate to a physical bevel gear generator a generalized and enhance tca algorithm be propose. 
the face hobbing process have two category non generate formate((r and generate method apply to the tooth surface generation of the gear in both category the pinion be always finish with the generate method. 
the develop tooth surface generation model cover both category with left hand and right hand member. 
base upon the develop theory an advanced tooth surface generation and tca program be develop and integrate into gleason cage(tm for windows software. 
two numerical example be provide to illustrate the implementation of the develop mathematic model. 
knowledge evolutionary intelligent machine tool part one design of dialogue agent base on standard platform. 
in fms flexible manufacturing system and cim computer integrated manufacturing machine tool have be the target of integration in the last three decade. 
the conventional concept of integration be be change into the autonomous manufacturing device base on the knowledge evolution by apply advanced information technology in which an open architecture controller high speed network and internet technology be include. 
in the advanced environment the machine tool be not the target of integration anymore but have be the key subject of cooperation. 
in the near future machine tool will be more improved in the form of a knowledge evolutionary intelligent device. 
the final goal of this study be to develop an intelligent machine have knowledge evolution capability and a management system base on internet operability. 
the knowledge evolutionary intelligent machine tool be expect to gather knowledge autonomically by produce knowledge understand knowledge reason knowledge make a new decision dialogue with other machine etc. 
the concept of the knowledge evolutio nary intelligent machine be originate from the machine control be operate by human expert sense dialogue and decision. 
the structure of knowledge evolution in m2 m machine to machine and the scheme for a dialogue agent among agent base module such as a sensory agent a dialogue agent and an expert system decision support agent be present in this paper with intent to develop the knowledge evolutio nary machine tool. 
the dialogue agent function as an interface for inter machine cooperation. 
to design the dialogue agent module in an m2 m environment fipa foundation of intelligent physical agent standard platform and the ping agent base on fipa be analyze in this study. 
in addition the dialogue agent be design and apply to recommend cut condition and thermal error compensation in a tap machine. 
the knowledge evolutionary machine tool be expect easily implement on the basis of this study and show a good assistance to sensory and decision support agent. 
ontology base multi site software development methodology and tool. 
the disadvantage associate with remote communication rather than face to face communication be a key problem in the multi site distribute software development environment. 
awareness of what work have be do what task have be misunderstood what problem have be raise what issue have be clarify and understanding of why a team or a software engineer do not follow the project plan and how to carry out a discussion over a multi site distribute environment and to make a just in time decision be the challenge. 
different team might not be aware of what task be be carry out by other potentially lead to problem such as two group overlap in some work or other work not be perform due to misinterpretation of the task. 
wrong task may be carry out due to ignorance of who to contact to get the proper detail. 
if everyone work on a certain project be locate in the same area then situational awareness be relatively straightforward but the overhead in communication to get together to discuss the problem to raise issue to make decision and to find answer in a multi site distribute environment can become very large. 
consequently these problem cause project delay and anxiety among team and manager. 
ontology couple with a multi agent system allow great ease of communication by aggregate the agree knowledge about the project the domain knowledge the concept of software engineering into a share information resource platform and allow they to be share among the distribute team across the site and enable the intelligent agent to use the ontology to carry out initial communication and classification with developer when the problem be raise in the first instance. 
in this paper we present the key challenge in multi site software engineering and the ontology representation of commonly share conceptualisation in software development. 
we demonstrate the agent communication with developer in the form of man machine interaction and the great potential of such a system to be use in the future for software engineering in multi site environment. 
c 2006 elsevier b.v. 
all right reserve. 
fuzzy support vector machine for adaptive morse code recognition. 
morse code be now be harness for use in rehabilitation application of augmentative alternative communication and assistive technology facilitate mobility environmental control and adapt worksite access. 
in this paper morse code be select as a communication adaptive device for person who suffer from muscle atrophy cerebral palsy or other severe handicap. 
a stable typing rate be strictly require for morse code to be effective as a communication tool. 
therefore an adaptive automatic recognition method with a high recognition rate be need. 
the propose system use both fuzzy support vector machine and the variable degree variable step size least mean square algorithm to achieve these objective. 
we apply fuzzy membership to each point and provide different contribution to the decision learn function for support vector machine. 
statistical analysis demonstrate that the propose method elicit a high recognition rate than other algorithm in the literature. 
c 2006 ipem. 
publish by elsevier ltd. 
all right reserve. 
snp phage high throughput snp discovery pipeline. 
background single nucleotide polymorphism snps as define here be single base sequence change or short insertion deletion between or within individual of a give specie. 
as a result of their abundance and the availability of high throughput analysis technology snp marker have begin to replace other traditional marker such as restriction fragment length polymorphism rflps amplify fragment length polymorphism aflps and simple sequence repeat ssr or microsatellite marker for fine mapping and association study in several specie. 
for snp discovery from chromatogram data several bioinformatics program have to be combine to generate an analysis pipeline. 
result have to be store in a relational database to facilitate interrogation through query or to generate datum for further analysis such as determination of linkage disequilibrium and identification of common haplotype. 
although these task be routinely perform by several group an integrated open source snp discovery pipeline that can be easily adapt by new group interested in snp marker development be currently unavailable. 
result we develop snp phage snp discovery pipeline with additional feature for identification of common haplotype within a sequence tag site haplotype analysis and genbank dbsnp submission. 
this tool be apply for analyze sequence trace from diverse soybean genotype to discover over 10,000 snp. 
this package be develop on unix linux platform write in per1 and use a mysql database. 
script to generate a user friendly web interface be also provide with common query for preliminary datum analysis. 
a machine learning tool develop by this group for increase the efficiency of snp discovery be integrate as a part of this package as an optional feature. 
the snp phage package be be make available open source at http://bfgl.anri.barc.usda.gov/ml/snp phage/. 
conclusion snp phage provide a bioinformatics solution for high throughput snp discovery identification of common haplotype within an amplicon and genbank dbsnp submission. 
snp selection and visualization be aid through a user friendly web interface. 
this tool be useful for analyze sequence tag site stss of genomic sequence and this software can serve as a starting point for group interest in develop snp marker. 
extraction of classification rule characterize by ellipsoidal region use soft computing technique. 
this article present a soft computing base datum mining technique that address methodology aspect on extract classification rule characterize by ellipsoidal region in feature space. 
self organize mapping and statistical technique be employ to initialize the rule. 
a regularization model embed some information on recognition rate and generalization ability be present for refine the initial rule. 
rule optimization be implement for each individual rule use an evolutionary strategy. 
to generate rule for pattern with low probability of occurrence but considerable conceptual importance a multilayer structure of rule generation and use be propose. 
simulation result be carry out by three benchmark datum set and compare with other datum mining tool and classifier such as decision tree brainne building representations of artificial intelligence ai use neural networks support vector machine and neural network. 
our technique demonstrate its power and potential for real world application. 
hard turning of temper din 100cr6 steel with coated and no coated cbn insert. 
recent improvement in the machine tool technology specially the stiffness and positioning accuracy as well as the advent of the cubic boron nitride cbn ceramic cutting tool make the finish operation for machine harden steel part possible use tool with define cut geometry in substitution to the traditional grind operation. 
the advantage present by the hard turning be sufficiently attractive for many plant however these be still reluctant to adopt and substitute a well know and dominated process grind for other one not totally understand. 
aim to expand the knowledge of the processing effect of hard turning on the finishing of the machined workpiece as well as the effect on the tool wear life. 
series of experiment with seven different type of cbn insert have be carry out use insert with wiper geometry coat with tiain and tin as well as with no coated one. 
the cut parameter have be specify in such a form to cover the entire field recommend by tool supplier. 
the machined part be an axle of din 100cr6 steel temper to 62 hrc. 
all the machining operation be carry out at a mazak quick turn use an tool holder dclnr 164d with insert geometry iso cnga120408so1020 with edge with t preparation with 0.102 mm x 20 degree. 
the tool wear control be carry out use an optic microscope zollern saturn and a roughness profiler hommelwerk t8000. 
follow parameter be parameter be determine vbmax r a material removal rate and the tool life determine by the taylor s equation obtain for theoretically ideal cutting condition. 
preliminary analysis of the result compare with the literature indicate that they be significant. 
c 2006 elsevier b.v. 
all right reserve. 
computational prediction of the chromosome damage potential of chemical. 
we report on the generation of computer  base model for the prediction of the chromosome damage potential of chemical as assess in the in vitro chromosome aberration ca test. 
on the basis of publicly available ca test result of more than 650 chemical substance half of which be drug like compound we generate two different computational model. 
the first model be realize use the q sar tool mcase. 
result obtain with this model indicate a limited performance 53 for the assessment of a chromosome damaging potential sensitivity whereas ca  test negative compound be correctly predict with a specificity of 75. 
the low sensitivity of this model might be explain by the fact that the underlie 2d structural descriptor only describe part of the molecular mechanism lead to the induction of chromosome aberration that be direct drug dna interaction. 
the second model be construct with a more sophisticated machine learning approach and generate a classification model base on 14 molecular descriptor which be obtain after feature selection. 
the performance of this model be superior to the mcase model primarily because of an improved sensitivity suggest that the more complex molecular descriptor in combination with statistical learning approach be well suited to model the complex nature of mechanism lead to a positive effect in the ca  test. 
an analysis of misclassified pharmaceutical by this model show that a large part of the false negative predicted compound be uniquely positive in the ca  test but lack a genotoxic potential in other mutagenicity test of the regulatory testing battery suggest that biologically nonsignificant mechanism could be responsible for the observed positive ca  test result. 
since such mechanism be not amenable to modeling approach it be suggest that a positive prediction make by the model reflect a biologically significant genotoxic potential. 
an integration of the machine learn model as a screening tool in early discovery phase of drug development be propose. 
predict the survival or failure of click and mortar corporation a knowledge discovery approach. 
with the boom in e business several corporation have emerge in the late 1990 that have primarily conduct their business through the internet and the web. 
they have come to be know as the dotcom or click and mortar corporation. 
the success of these company have be short live. 
this research be an investigation of the burst of the dotcom bubble from a financial perspective. 
datum from the financial statement of several survive and fail dotcom company be use to compute financial ratio which be analyze use three classification technique discriminant analysis neural network and support vector machine to find out whether they can predict the financial fate of company. 
neural network perform the task well than other technique. 
use discriminant analysis and neural network the key financial ratio that play a major role in the process of prediction be identify. 
statistical test be conduct to validate the finding. 
c 2005 elsevier b.v. 
all right reserve. 
star predict recombination site from amino acid sequence. 
background design novel protein with site direct recombination have enormous prospect. 
by locate effective recombination site for swap sequence part the probability that hybrid sequence have the desire property be increase dramatically. 
the prohibitive requirement for apply current tool lead we to investigate machine learning to assist in find useful recombination site from amino acid sequence alone. 
result we present star site targeted amino acid recombination predictor which produce a score indicate the structural disruption cause by recombination for each position in an amino acid sequence. 
example prediction contrast with those of alternative tool illustrate star s utility to assist in determine useful recombination site. 
overall the correlation coefficient between the output of the experimentally validate protein design algorithm schema and the prediction of star be very high 0.89. 
conclusion star allow the user to explore useful recombination site in amino acid sequence with unknown structure and unknown evolutionary origin. 
the predictor service be available from http://pprowler.itee.uq.edu.au/star. 
a human assist knowledge extraction method for machine operation. 
this paper deal with a human assist knowledge extraction method to extract if.then. 
rule from a small set of machine datum. 
the present method utilize both probabilistic reasoning and fuzzy logical reasoning to benefit from the machining datum and from the judgment and preference of a machinist. 
use the extract rule one can determine the value of operational parameter feed cut velocity etc to ensure the desire machining performance keep surface roughness within the stipulated range e.g. moderate. 
apply the present method in a real life machining knowledge extraction situation and compare it with the inductive learning base knowledge extraction method i.e. id3 the usefulness of the method be demonstrate. 
as the concept of manufacture automation be shift toward how to support human by computer the present method provide some valuable hint to the developer of futuristic computer integrate manufacturing system. 
c 2006 elsevier ltd. 
all right reserve. 
predict protein structural class with pseudo amino acid composition and support vector machine fusion network. 
because a priori knowledge of a protein structural class can provide useful information about its overall structure the determination of protein structural class be a quite meaningful topic in protein science. 
however with the rapid increase in newly find protein sequence enter into databank it be both time consume and expensive to do so base solely on experimental technique. 
therefore it be vitally important to develop a computational method for predict the protein structural class quickly and accurately. 
to deal with the challenge this article present a dual layer support vector machine svm fusion network that be feature by use a different pseudo amino acid composition pseaa. 
the pseaa here contain much information that be relate to the sequence order of a protein and the distribution of the hydrophobic amino acid along its chain. 
as a showcase the rigorous jackknife cross validation test be perform on the two benchmark datum set construct by zhou. 
a significant enhancement in success rate be observe indicate that the current approach may serve as a powerful complementary tool to other exist method in this area. 
c 2006 elsevier inc. 
all right reserve. 
use active learning to annotate microscope image of parasite egg. 
microscopic analysis form an integral part of many scientific study. 
it be a task which require great expertise and care. 
however it can often be an extremely repetitive and labourious task. 
in some case many hundred of slide may need to be analyse a process that will require each slide to be meticulously examine. 
machine vision tool could be use to help assist in just such repetitive and tedious task. 
however many machine vision solution involve a lengthy datum acquisition phase and in many case result in system that be highly specialised and not easily adaptable. 
in this paper we describe a framework that apply flexible machine vision technique to microscope analysis and utilise active learning to help overcome the datum acquisition and adaptability problem. 
in particular we investigate the potential of various aspect of our propose framework on a particular real world microscopic task the recognition of parasite egg. 
a novel structure base encoding for machine learning apply to the inference of sh3 domain specificity. 
motivation unravel the rule underlie protein protein and protein ligand interaction be a crucial step in understand cell machinery. 
peptide recognition module prms be globular protein domain which focus their bind target on short protein sequence and play a key role in the frame of protein protein interaction. 
high throughput technique permit the whole proteome scan of each domain but they be characterize by a high incidence of false positive. 
in this context there be a press need for the development of in silico experiment to validate experimental result and of computational tool for the inference of domain peptide interaction. 
result we focus on the sh3 domain family and develop a machine learn approach for infer interaction specificity. 
sh3 domain be well study prms which typically bind proline rich short sequence characterize by the pxxp consensus. 
the bind information be know to be hold in the conformation of the domain surface and in the short sequence of the peptide. 
our method rely on interaction datum from high throughput technique and benefit from the integration of sequence and structure datum of the interact partner. 
here we propose a novel encoding technique aim at represent bind information on the basis of the domain peptide contact residue in complex of know structure. 
remarkably the new encoding require few variable to represent an interaction thus avoid the curse of dimension. 
our result display an accuracy 90 in detect new binder of know sh3 domain thus outperform neural model on standard binary encoding profile method and recent statistical predictor. 
the method moreover show a generalization capability infer specificity of unknown sh3 domain display some degree of similarity with the know datum. 
a virtual electrical drive control laboratory neuro fuzzy control of induction motor. 
neural and fuzzy course be widely offer at graduate and undergraduate level due to the successful application of neural and fuzzy control to nonlinear and unmodeled dynamic system include electrical drive however teach student a neurofuzzy control electrical drive in a laboratory environment be often difficult for school with limited access to expensive equipment facility. 
therefore computer simulation and dedicated software be need to assist the student in visualize the concept and to provide graphical feedback during the learning process. 
in this article an educational software be propose for the neuro fuzzy control of induction machine drive. 
the tool help student learn the application of neuro fuzzy control of electrical drive. 
the software have a flexible structure and graphical user interface. 
the neuro fuzzy architecture the motor and load parameter can be easily change in the developed software. 
neuro fuzzy control performance of induction motor can be monitor graphically for various control structure and current controller. 
c 2006 wiley periodicals inc.. 
machine learn in bioinformatics a brief survey and recommendation for practitioner. 
machine learning be use in a large number of bioinformatics application and study. 
the application of machine learning technique in other area such as pattern recognition have result in accumulate experience as to correct and principled approach for their use. 
the aim of this paper be to give an account of issue affect the application of machine learning tool focus primarily on general aspect of feature and model parameter selection rather than any single specific algorithm. 
these aspect be discuss in the context of publish bioinformatics study in lead journal over the last five year. 
we assess to what degree the experience gain by the pattern recognition research community pervade these bioinformatics study. 
we finally discuss various critical issue relate to bioinformatic datum set and make a number of recommendation on the proper use of machine learning technique for bioinformatics research base upon previously publish research on machine learning. 
c 2005 elsevier ltd. 
all right reserve. 
prediction of dose escalation for rheumatoid arthritis patient under infliximab treatment. 
rheumatoid arthritis ra be a chronic inflammatory joint disease that lead to irreversible joint destruction. 
to prevent this new biological therapy such as infliximab have be successfully develop. 
the present analysis be base on an expand access program in which 511 ra patient with chronic refractory disease be treat with infliximab. 
they receive a standard dose of three mg kg on week zero two six 14 and every eight week thereafter. 
on week 22 the treating rheumatologist evaluate the situation of every patient and decide whether the current dose should be increase or not. 
this decision can be consider as a measure of insufficient response. 
in the present analysis three machine learn classification technique the self organize map som multilayere perceptron mlp and support vector machine svm) are implement to model the decision to give a dose increase. 
their performance on increasingly multivariate real life datum will be study and compare to classical statistic linear discriminant analysis lda and logistic regression lr. 
result show that the som be an excellent tool for data visualization but not for classification. 
all the remain method show good classification performance if configure well. 
however as the number of feature increase the performance decrease. 
the svm suffer to a less degree from this curse of dimensionality. 
expectation maximization em come out as a good method to cope with missing value in such real life datum. 
c 2006 elsevier ltd. 
all right reserve. 
uncover the to do hide in your in box. 
in this paper we present scout an application that examine the machine generate message within the in box of an e mail application extract from these message information regard the task the recipient be ask to perform and display these message in a graphical interface where they be group by context. 
the tool be intend for business manager who receive daily a large number of machine generate message that require some action be take. 
scout use the ibm unstructured information management architecture uima framework to apply rule base reasoning for identification of task and it use contextual datum to customize the presentation of task information to the user. 
scout s open extensible architecture allow the use of alternate inference model such as machine learning algorithm as well as the integration of additional context source and client interface. 
scout be well receive by the participant in a small evaluation study. 
stream of variation sov) base measurement scheme analysis in multistation machining system. 
today machining system be complex multistation manufacturing system that involve a large number of machine operation and several locating datum change. 
dimensional error introduce at each machining operation get transform and cause the occurrence of new error as the workpiece propagate through the machining system. 
the appropriate choice of measurement in such a complex system be crucial for the subsequent successful identification of the root cause of machine error hide in dimensional measurement of the workpiece. 
in order to facilitate this measurement selection process method for quantitative characterization of measurement scheme must be develop. 
this problem of quantitative measurement characterization refer to as the measurement scheme analysis problem be deal with in this paper. 
the measurement scheme analysis be accomplish through characterization of the maximal. 
achievable accuracy of estimation of process level parameter base on the measurement in a give measurement scheme. 
the stream of variation methodology be employ to establish a connection between the process level parameter and measure product quality. 
both the bayesian and non bayesian assumption in the estimation be consider and several analytical property be derive. 
the property of the newly derive measurement scheme analysis method be demonstrate in measurement scheme characterization in the multistation machining system use for machining of an automotive cylinder head. 
analytical model for high performance mill. 
part i cut force structural deformation and tolerance integrity. 
milling be one of the most common manufacturing process in industry despite recent advance in machine technology productivity in milling be usually reduce due to the process limitation such as high cutting force and stability. 
if mill condition be not select properly the process may result in violation of machine limitation and part quality or reduce productivity. 
the usual practice in machine operation be to use experience base selection of cut parameter which may not yield optimum condition. 
in this two part paper mill force part and tool deflection form error and stability model be present. 
these method can be use to check the process constraint as well as optimal selection of the cut condition for high performance mill. 
the use of the model in optimize the process variable such as feed depth of cut and spindle speed be demonstrate by simulation and experiment. 
c 2005 elsevier ltd. 
all right reserve. 
active vibration control in palletised workholding system for mill. 
this paper present the development implementation and testing of an active control palletise workholding system for mill operation. 
the traditional approach to control vibration in a machining system be to develop control system for cut tool or machine spindle as in the case of mill machine. 
this work be a deviation from the traditional approach and target a workholding system for the control of unwanted vibration. 
palletise workholding system due to their compact design offer an opportunity to design active control system that be economical and easy to implement in the case of mill machine. 
the active control system develop here be base on an adaptive filter algorithm the filter x lms and employ piezo actuator for dynamic control force. 
the system have be test experimentally to demonstrate the reduction in dynamic force due to vibration. 
extensive testing have be carry out to validate the performance of the system in term of parameter of practical importance such as improvement in surface finish and increase in tool life. 
c 2005 elsevier ltd. 
all right reserve. 
manage semantic metadata for web grid service. 
web grid service metadata and semantic be becoming increase important for service sharing and effective reuse. 
in this paper we present a generic framework for engineering and managing service semantic metadata smd with the ultimate purpose of facilitate interoperability automation and knowledgeable reuse of service for problem solve. 
the framework address fundamental issue approach and tool for the whole lifecycle of smd management in other word those of acquiring modeling representing publishing and reuse service smd. 
it adopt ontology and the semantic web technology as the enable technology by which service metadata be semantically enrich and make interoperable understandable and accessible on the web grid for both human and machine. 
in particular mechanism be propose to make use of service smd for service discovery and composition. 
the paper also describe a service smd management system in the context of the uk e science project geodise. 
a suite of tool be develop which form the core of the smd management infrastructure. 
we demonstrate the add value of the use of smd through the integration of smd management with geodise application system. 
a review of wave rotor technology and its application. 
the objective of this paper be to provide a succinct review of past and current research in develop wave rotor technology. 
this technology have show unique capability to enhance the performance and operating characteristic of a variety of engine and machinery utilize thermodynamic cycle. 
although there have be a variety of application in the past this technology be not yet widely use and be barely know to engineer. 
here an attempt be make to summarize both the previously report work in the literature and ongoing effort around the world. 
the paper cover a wide range of wave rotor application include the early attempt to use wave rotor its successful commercialization as supercharger for car engine research on gas turbine topping and other development. 
the review also pay close attention to more recent effort utilization of such device in pressure gain combustor ultra micro gas turbine and water refrigeration system highlight possible further effort on this topic. 
observation and lesson learn from experimental study numerical simulation analytical approach and other design and analysis tool be present. 
a neural network base methodology for machine operation selection in computer aid process planning for rotationally symmetrical part. 
the relevant literature on machine operation selection in computer aid process planning capp by decision tree expert system and neural network have be review highlight their contribution and shortcoming. 
this paper aim at contribute to the applicability of back propagation neural network method for the selection of all possible operation for machine rotationally symmetrical component by prestructure the neural network with prior domain knowledge in the form of heuristic or thumb rule. 
it have be achieve by develop two form of representation for the input datum to the neural network. 
the external representation be use to enter the crisp value of the input decision variable namely the feature type and its attribute such as diameter or width tolerance and surface finish. 
the purpose of internal representation be to categorize the above crisp value into set which correspond to all the possible different range of the above input variable encounter in the antecedent if part of the thumb rule mention above. 
the input layer of the neural network have be design in such a way that one neuronal node be allocate for each of the feature type and the set of various feature attribute. 
in the output layer of the neural network one neuronal node be allocate to each of the various feasible machining operation sequence find in the consequent then part of the thumb rule. 
a systematic method for training of the neural network have be present with the above thumb rule use to serve as guideline for choose the input pattern of the training example. 
this method simplify the process of training reduce the time for preparation of training example and hence the time to develop the overall process planning system. 
it can far help ensure that the entire problem domain be represent in a well manner and improve the quality of response of the neural network. 
the example of an industrially relevant rotationally symmetrical workpiece have be analyze use the propose approach to demonstrate its potential for use in the real manufacturing environment. 
by this novel methodology workpiece of complex shape can be handle by invest a very limited amount of time hence make it attractive and cost effective for industrial application. 
mill of wood and wood base material with a computerized numerically control router v development of adaptive control grooving system correspond to progression of tool wear. 
a laser measure instrument be instal in a computerized numerically control cnc router and an automatic measurement system which be develop in a previous study be use to automatically measure the cutting edge profile of throw away type straight bit without stop the cnc router. 
in addition to the above mention system in this study an adaptive control program base on experimental datum be instal and an adaptive control grooving system that improve machining accuracy and control the burr formation correspond to the progression of tool wear under processing be develop. 
verification experiment of this system be carry out. 
the main result obtain be summarize as follow one the between process method be adopt for this system and three type of processing method type one two three which consist of a combination of an up mill surface and a down mill surface after processing be investigate two from the result of verification experiment type two and type three method show remarkable ability to improve the machining accuracy and control the burr formation and three it be find that the system employ adaptive control processing correspond to the progression of tool wear in grooving be very effective. 
cost curve an improved method for visualize classifier performance. 
this paper introduce cost curve a graphical technique for visualize the performance error rate or expect cost of two class classifier over the full range of possible class distribution and misclassification cost. 
cost curve be show to be superior to roc curve for visualize classifier performance for most purpose. 
this be because they visually support several crucial type of performance assessment that can not be do easily with roc curve such as show confidence interval on a classifier s performance and visualize the statistical significance of the difference in performance of two classifier. 
a software tool support all the cost curve analysis describe in this paper be available from the author. 
validation of predictive axis control structure within a virtual open architecture machine tool. 
this paper first present the elaboration of a virtual machine tool within an open architecture framework include cam computer aided manufacturing module such as trajectory generation and visualization facility. 
the propose advanced controller be then introduce within this simulator. 
base on predictive strategy it appear as an excellent control alternative couple to a simple design procedure and implementation facility. 
moreover the result controller structure under the polynomial rst form consider as a generic formalism for any siso single input single output numerical controller fulfill the requirement towards an open architecture framework. 
validation test be achieve within this virtual environment and compare to those obtain on a real machining center under its current control structure. 
kernel ridge regression for volume fraction prediction in electrical impedance tomography. 
we investigate use a kernel learning machine specifically kernel ridge regression krr to predict volume fraction in typical industrial electrical impedance tomography eit application. 
the curse of dimensionality associate with apply such method to physically capture eit training datum be overcome with a new training method involve sample of training datum during rapid random repositioning of a set of physical object in the measurement plane. 
we compare the performance to multi layer perceptron mlp neural network which appear to be the most common computational intelligence approach to the eit reconstruction problem. 
we use empirically train static situation so as to compare the result to previous research. 
dynamic situation be also investigate and krr be show to outperform mlp method in both case. 
furthermore krr be show to be a useful tool in eit for extract process information from industrial flow without first perform conventional image reconstruction. 
evolve neural network base on cellular automata for sensory motor controller. 
construct the controller of a mobile robot have several issue to be address how to automate behavior generation procedure how to insert available domain knowledge effectively and how to hybrid these method in an integrated manner. 
there have be extensive work to construct an optimal neural network for control a mobile robot by evolutionary approach such as genetic algorithm genetic programming and so on. 
however evolutionary approach have a difficulty to design the controller that conduct complex behavior. 
in order to overcome this shortcoming we propose an incremental evolution method for neural network base on cellular automata and a method of combine several evolved module by a rule base approach. 
the incremental evolution method evolve the neural network by start with simple environment and gradually make it more complex. 
the multi modules integration method can make complex behavior by combine several module evolve or program to do simple behavior. 
simulation result show the potential of the incremental evolution and multi module integration method as sophisticated technique to make the evolve neural network to do complex behavior. 
in this paper we attempt to investigate the applicability of cellular automata base neural network and propose sophisticated technique for the generation of high level behavior. 
c 2006 elsevier b.v. 
all right reserve. 
toxicogenomic strategy for predict drug toxicity. 
introduction the failure of pharmaceutical drug candidate due to toxicity especially hepatotoxicity be an important and continue problem for drug development. 
the current manuscript explore newtoxicogenomic approach to well understand the hepatotoxic potential of human pharmaceutical compound and to assess their toxicity early in the drug development process by mean of a toxicity screen. 
resource datum consist of two commercial knowledgebase that employ a hybrid experimental design in which human drug toxicity information be extract from the literature dichotomize and merge with rat base gene expression measure. 
one knowledgebase use gene expression from rat primary hepatocyte while the other employ whole rat. 
approximately 100 compound be use in each. 
method toxicity classification rule be build use a stochastic gradient boost machine learner with classification error estimate use a modify bootstrap estimate of true error. 
several type of cluster method be also apply some base on set of compound and other base on set of gene. 
result robust classification rule be construct for both in vitro hepatocyte and in vivo liver datum base on a high dose 24 hour design. 
there appear to be little overlap between the two classifier at least in term of their gene list. 
robust classifier could not be fit when early timepoint and/or low dose datum be include indicate that experimental design be important for these system. 
conclusion in light of these finding a work compound screen base on these toxicity classifier appear feasible with classifier operating characteristic use to tune a screen for a specific implementation. 
to ensure robust and optimal performance issue such as site variability of microarray and generalizability of finding should be address as indicate. 
prediction of cut force and temperature rise in the end mill operation. 
the cut force have a significant influence on the dimensional accuracy because of tool and workpiece deflection in mill. 
force modelling in metal cutting be important for a multitude of purpose include thermal analysis tool life estimation chatter prediction and tool condition monitoring. 
in this paper the dynamic cut force model for end milling be develop to predict the tangential cut force and the thrust force. 
the model prediction be validate with the experimental cut force during the machining of aisi 1020 steel use a three axis mill tool dynamometer. 
the tool chip interface temperature for different machining condition be determine use oxley s energy partition function and rapier s equation to study the thermal effect on the cut force. 
experiment have be conduct to validate the predict temperature use a k type thermocouple and an infrared pyrometer. 
the maximum temperature in the tool increase from 459 to 944 degree c as the cutting speed be increase from 20 to 200 m min when machine at a depth of cut of 2.5 mm. 
the surface plot have be draw use matlab to indicate the variation in the cut temperature in shear and friction zone with the cut parameter. 
knowledge of the force act on the cutter and tool chip interface temperature may help the operator to select suitable cut parameter in order to limit the tool chip interface temperature. 
lesson learn for build agile and flexible scheduling tool for turbulent environment in the extended enterprise. 
this paper present result of a 2.5 year multidisciplinary university industry collaborative effort investigate design of internet base scheduler for material optimisation and agile production in multi site enterprise in agile manufacturing is optimus a four nation collaborative project aim at improvement in turbulent manufacturing environment. 
the focus of this paper be specifically on the content of the work carry out along with the main benefit and result. 
key to achieve the goal be follow a complete project life cycle path from the initial stage where the industrial user requirement be identify and the system specification take place to the development and tuning of the final system. 
design choice for software must strike a balance between the user flexibility require and the represent environment constraint finite capacity scheduling which take production requirement from exist production planning system to schedule production resource like plant worker critical tool and machine. 
the system consist of a material optimiser work closely with the finite capacity scheduler and a dynamic scheduler provide automatic reaction to real time exception thus derive in solution of high performance. 
c 2006 publish by elsevier ltd.. 
intelligent automation system for predictive maintenance a case study. 
a case study be present where a predictive maintenance solution for non critical machinery such as elevator and machine tool be seek. 
both case be different. 
there be no experience in elevator monitoring and diagnosis and modeling have be perform use neural network. 
on the other hand machine tool be monitor through vibration system where some experience exist. 
in this case bayesian network be the paradigm of choice as it be also recommend to include some adaptation mechanism for the knowledge model in the network. 
the final system also include a sensor processing unit and a remote maintenance module system that provide an automate remote condition monitoring system for both application. 
result indicate the feasibility of partial solution in monitoring and diagnosis though future enhancement be need to compose a complete solution. 
this paper explain the characteristic of the bayesian network solution finally develop for high speed machine tool evaluate their strength and weakness and indicate the future enhancement. 
c 2006 elsevier ltd. 
all right reserve. 
optimization and analysis aid via data mining for simulated production system. 
the optimization of a production system consist of determine a value for certain parameter which influence system performance. 
however the majority of optimization method deliver a solution without any form of explanation and this be no long sufficient in a production context. 
decision maker would also like to have an analysis of their system and especially of the high performance behavior of those system. 
in order to avoid the black box effect of many optimization method and to produce knowledge on system behavior characterization of solution that perform well determination of critical parameter and analyze efficient solution the author propose a methodology which be base on the synergy between evolutionist optimization and an induction graph learning method. 
this approach be illustrate via the study of a simulated job shop compose of five workstation one entry station and one exit station the number of machine at each station the management method and the number of stock place in each station have to be optimize and analyze. 
c 2005 elsevier b.v. 
all right reserve. 
real time scheduling for holonic manufacturing system base on estimation of future status. 
this paper deal with a real time scheduling system of holonic manufacturing system hmss which be propose by an international cooperative research consortium call the hms consortium for autonomous distributed management and control of the manufacturing systems. 
the scheduling system generate real time suitable production schedule base on decision making by individual constituent name holon and their coordination. 
the objective of the present research be to improve the decision make process of the individual holon through the use of estimation process of the future status of the hms. 
procedure be develop and implement to the individual holon in order to estimate the future status of the hms by apply the simulation model of the hms. 
a neural network model be propose to represent and to simulate the decision make process of the individual holon. 
data mining manufacturing and service application. 
in this paper basic concept of machine learning and datum mining be introduce. 
machine learning algorithm extract knowledge from diverse datum basis that can be use to build decision make system. 
for example base on the operational engineering datum equipment fault can be detect the number of item to be order can be predict optimal control parameter can be determine. 
a framework for organize and apply knowledge for decision making in manufacturing and service application be present. 
the framework use decision make construct such decision table decision map and atlase. 
it offer a new data drive paradigm of importance to modern manufacturing and service organisation. 
example of datum mining application in industrial medical and pharmaceutical domain be present. 
it be envision that the data drive framework present in the paper will enhance these application. 
tsk type flc use a combine lr and ga surface roughness prediction in ultraprecision turning. 
due to non linearity of the cut parameter tool work combination and rigidity of machine tool it have be prove that a fuzzy logic concept give a well way to model a complex manufacturing process such as grind ultraprecision turning etc. 
in this paper an takagi sugeno kang tsk) type fuzzy logic controller flc be design to model the input output relationship of ultraprecision turning. 
the performance of an flc primarily depend on its knowledge base which consist of rule base and the membership function distribution fuzzy subset consider for the variable. 
in tsk type fuzzy system the output of a fuzzy rule be a linear combination of the input variable which be characterize by function coefficient and the variable s exponential parameter. 
in the present work two approach be consider to design the tsk type flc one be base on linear regression lr method with constant and same exponential parameter for all the rule and the other be base on lr with simultaneous optimization of exponential parameter use genetic algorithm ga. 
the result of the propose approach be compare with the empirical expression which be not accurate as well as real experimental datum to predict surface roughness in ultraprecision turning. 
c 2006 elsevier b.v. 
all right reserve. 
crnpre highly accurate prediction of one dimensional protein structure by large scale critical random network. 
background one dimensional protein structure such as secondary structure or contact number be useful for three dimensional structure prediction and helpful for intuitive understanding of the sequence structure relationship. 
accurate prediction method will serve as a basis for these and other purpose. 
result we implement a program crnpre which predict secondary structure contact number and residue wise contact order. 
this program be base on a novel machine learning scheme call critical random network. 
unlike most conventional one dimensional structure prediction method which be base on local window of an amino acid sequence crnpred take into account the whole sequence. 
crnpred achieve on average per chain q(3 81 for secondary structure prediction and correlation coefficient of 0.75 and 0.61 for contact number and residue wise contact order prediction respectively. 
conclusion crnpred will be a useful tool for computational as well as experimental biologist who need accurate one dimensional protein structure prediction. 
an improved approach for automatic process plan generation of complex boring. 
the research concern automate generation of process plan use knowledge formalization and capitalization. 
tool allow designer to deal with issue and specification of the machining domain be take into account. 
the main objective of the current work be to prevent designer from design solution that would be expensive and difficult to machine. 
among all available solution to achieve this goal two be distinguish the generative approach and the analogy approach. 
the generative approach be more adapt to generate the machining plan of part compose of numerous boring operation in interaction. 
however generative system have two major problem propose solution be often too numerous and be only geometrically but not technologically relevant. 
in order to overcome these drawback two new concept of feature and three control algorithm be develop. 
the paper present the two new feature the machining enabled geometrical feature megf and the machinable features mbf. 
this development be the result of the separation of the geometrical and the technological datum contain in one machining feature. 
the second objective of the paper be to improve the current process ascending generation pag system with control algorithm in order to limit the combinatorial explosion and disable the generation of unusable or not machinable solution. 
c 2006 elsevier b.v. 
all right reserve. 
diffusion map and coarse graining a unified framework for dimensionality reduction graph partition and datum set parameterization. 
we provide evidence that nonlinear dimensionality reduction clustering and datum set parameterization can be solve within one and the same framework. 
the main idea be to define a system of coordinate with an explicit metric that reflect the connectivity of a give datum set and that be robust to noise. 
our construction which be base on a markov random walk on the datum offer a general scheme of simultaneously reorganize and subsample graph and arbitrarily shape data set in high dimension use intrinsic geometry. 
we show that cluster in embed space be equivalent to compress operator. 
the objective of datum partition and clustering be to coarse grain the random walk on the datum while at the same time preserve a diffusion operator for the intrinsic geometry or connectivity of the datum set up to some accuracy. 
we show that the quantization distortion in diffusion space bound the error of compression of the operator thus give a rigorous justification fork mean cluster in diffusion space and a precise measure of the performance of general clustering algorithm. 
on the futuristic machine control in a step compliant manufacturing scenario. 
step nc iso 14649 provide a new data interface for computer numerical control cnc machine tool. 
however replace the current iso 6983 with step nc be not only a matter of change in nc programming language but it also have a far reach and profound effect on the future cnc and even on manufacture system. 
the cnc be destine to evolve from pure controller into integrate system with both decision making and control ability. 
in this paper strategy for implement the step compliant cnc system be discuss and a framework for the autonomous step nc controller be propose. 
the controller be organize into two agent the planning agent and the machine agent. 
this paper also provide a general discussion on issue about the part program interpretation the on line process planning. 
in order to support dynamic planning as well as meet the real time requirement in nc machining it be propose to solve the on line planning issue in two stage the shop floor planning and the real time planning. 
it be also propose to extend the feature base algorithm to the interpolation stage. 
a framework and datum processing for interface cnc with ap238. 
tomorrow s manufacturing workstation will be autonomous and intelligent with the ability to interpret geometric and manufacture knowledge and automatically to manufacture component. 
step nc be one of the building block that will support this endeavour for a new paradigm of the intelligent autonomous manufacturing. 
this paper outline a framework for a step nc controller which represent one of the building block for tomorrow s manufacturing workstation. 
the conceptual controller consist of an interpreting module interpreter a planning module planner a simulation module and a cnc kernel. 
the interpreter read an ap238 file and convert it into internal datum which the planner utilize to sequence the specific machining operation and process. 
the work illustrate the feasibility of the framework for interpret step nc information in an ap238 format and store the datum within a step compliant data structure for use in machine planning. 
the implementation tool and method for interpret the ap238 file be outline through an example part case study to demonstrate the step nc conversion process. 
lesson learn implement step nc ap 238. 
step nc ap 238 be an integrate version of the step nc iso 14649 standard that enable more datum share with the other step standard for cad cam and cae application. 
this paper describe how step nc ap 238 be be test for deployment in the united states of america. 
the test focus on show that step nc ap 238 allow multiple cam system to send five axis tool path datum to multiple cnc machine without any post process. 
the paper also describe the result of previous work perform on a feature base implementation of step nc and explain why us industry have have difficulty in adopt a feature base implementation as its initial deployment method. 
algorithms and an extended step nc compliant datum model for wire electro discharge machining base on 3d representation. 
the current paper describe the implementation of the wire electro discharge machining edm algorithm for the step nc project and some possible extension. 
wire edm use many work parameter parameter for spark generation speed of penetration etc the setting of which need expert system method. 
these expert system be a code form of the company knowledge and be base on their experience. 
the high information level provide by step nc allow the development of new algorithm to drive the wire. 
the current way of program the wire motion be to consider it as a mill tool for 2.5 axis machining operation the wire trajectory be compute use 2d planar curve offset and collision detection algorithm. 
the use of explicit rule surface allow real 3d offset and collision detection. 
the paper start by describe the datum model and architecture of the demonstration system which be develop during the project. 
this can be think of as a simplified process planning phase. 
the second part of the paper describe algorithm that have be implement in the step nc environment for prototype software run on the wire edm nc controller. 
the final part describe some open question that remain at the end of the project. 
facial expression classification use pca and hierarchical radial basis function network. 
intelligent human computer interaction hci integrate versatile tool such as perceptual recognition machine learning affective computing and emotion cognition to enhance the way human interact with computer. 
facial expression analysis be one of the essential medium of behavior interpretation and emotion modeling. 
in this paper we modify and develop a reconstruction method utilize principal component analysis pca to perform facial expression recognition. 
a framework of hierarchical radial basis function network hrbfn be far propose to classify facial expression base on local feature extraction by pca technique from lip and eye image. 
it decompose the acquire datum into a small set of characteristic feature. 
the objective of this research be to develop a more efficient approach to discriminate between seven prototypic facial expression such as neutral smile anger surprise fear disgust and sadness. 
a construetive procedure be detailed and the system performance be evaluate on a public database japanese females facial expression jaffe. 
we conclude that local image of lip and eye can be treat as cue for facial expression. 
as anticipate the experimental result demonstrate the potential capability of the propose approach. 
the evolution of the cerec system. 
background and overview. 
early in 1980 the author anticipate the attraction of restore posterior tooth with tooth color material. 
he conduct study and develop the clinical concept of bond ceramic inlay at the same time raise the issue of the fast fabrication of the ceramic restoration. 
the author develop plan for in office computer aid design computer aid manufacturing cad cam fabrication of ceramic restoration specifically to enable the dentist to complete one or multiple ceramic restoration chairside in a single appointment. 
the initial concept comprise a small mobile cad cam unit integrate a computer keyboard trackball foot pedal and optoelectronic mouth camera as input device a monitor and a machining compartment. 
cerec three sirona dental systems gmbh bensheim germany divide the system into an acquisition design unit and a separate machining unit. 
three dimensional software make the handling illustrative and easy both in the office and in the laboratory. 
conclusion. 
it appear that the cerec cad cam concept be become a significant part of dentistry. 
clinical implication. 
sound knowledge of adhesive bonding and diligent planning be essential for the successful integration of cad cam into clinical dental office. 
learn to classify document accord to genre. 
current document retrieval tool succeed in locate large number of document relevant to a give query. 
while search result may be relevant accord to the topic of the document it be more difficult to identify which of the relevant document be most suitable for a particular user. 
automatic genre analysis i.e. the ability to distinguish document accord to style would be a useful tool for identify document that be most suitable for a particular user. 
we investigate the use of machine learning for automatic genre classification. 
we introduce the idea of domain transfer genre classifier should be reusable across multiple topic which do not arise in standard text classification. 
we investigate different feature for build genre classifier and their ability to transfer across multiple topic domain. 
we also show how different feature set can be use in conjunction with each other to improve performance and reduce the number of document that need to be label. 
chatter prediction in end mill by fnn model with prune. 
this paper be concern with a study of chatter prediction in high speed end mill operation. 
chatter vibration occur in mechanical machining give rise to poor surface finish and dimensional inaccuracy in machine part reduction of tool life and even damage machine tool. 
various study of its prediction and avoidance have be carry out over the last several decade. 
the purpose of this study be to develop an expert system for predict chatter vibration in high speed end milling use wavelet transform and fuzzy neural network model with prune. 
the fnn model employ here use a pruning process which reduce a neural network to its most effective size. 
the amount of learn for convergence of a prune network be reduce in comparison with an initial network. 
the propose method be apply to a jig grind machine and the result demonstrate the effectiveness of the chatter prediction procedure. 
dna mechanic as a tool to probe helicase and translocase activity. 
helicase and translocase be protein that use the energy derive from atp hydrolysis to move along or pump nucleic acid substrate. 
single molecule manipulation have prove to be a powerful tool to investigate the mechanochemistry of these motor. 
here we first describe the basic mechanical property of dna unravel by single molecule manipulation technique. 
then we demonstrate how the knowledge of these property have be use to design single molecule assay to address the enzymatic mechanism of different translocase. 
we report on four single molecule manipulation system address the mechanism of different helicase use specifically design dna substrate uvrd enzyme activity detection on a stretched nick dna molecule hcv ns3 helicase unwind of a rna hairpin under tension the observation of recbcd helicase nuclease forward and backward motion and t7 gp4 helicase mediate opening of a synthetic dna replication fork. 
we then discuss experiment on two dsdna translocase the ruvab motor study on its natural substrate the holliday junction and the chromosome segregation motor ftsk show its unusual coupling to dna supercoiling. 
study on conventional cutting of intermetallic nickel and titanium aluminide. 
owe to the high percentage of covalent bond intermetallic nickel and titanium aluminide have specific physical and chemical characteristic that predestine they for component under high thermal and mechanical load. 
however the relatively low ductility and thermal conductivity at room temperature link to high tensile strength impede the machining with geometrically define cut edge in series production. 
the conventional machining process be characterize by microcrack formation at the component surface. 
one possible way be to warm up the intermetallic alloy locally above the quasi brittle ductile transition temperature by the interaction of the workpiece material and the tool. 
the subject of investigation be the influence of feed rate and cut speed on the tool face temperature and cut force as well as on the chip formation and fringe area formation during longitudinal cylindrical turning. 
the experiment be carry out with intermetallic nickel and titanium aluminide in an as cast and extrude state. 
the goal be to elaborate the technological basic knowledge for a damage minimized and productive machining of intermetallic aluminide with geometrically define cutting edge. 
ten common mistake in composite design and manufacture and how to avoid they. 
the design process for any composite involve both laminate and component design and must also include consideration of the manufacturing process and eventual environmental exposure. 
these step be all interdependent with composite and the most efficient design must involve true concurrent engineering. 
the requirement of concurrent design mean that someone from materials and processes manufacturing or manufacturing engineering on the design team be aware of some of the pitfall still inherent in composite design. 
too many time in spite of the most sophisticated computer routine and the most powerful fea analyse the design and manufacturing process develop problem because of some minor anomaly that could have be avoid with the right experience. 
the follow be tip glean from many source along with this author s own mistake. 
as far as can be ascertain the composite community be still make the same mistake that be prevalent when the advanced composite era start. 
the follow summarize several of the subject that the composite designer should be aware as a list title ten common mistake one inappropriate laminate configuration include appropriate area for and contrary to quasi isotropic laminate and balance and symmetry option two not prepare for outer surface damage to composite three ignore corrosion concerns four select a manufacturing method for the wrong reason five inattention to out of plane or unanticipated load six inattention to subsequent joining bonding requirement seven inattention to tooling requirement 8) not combine substructure nine not use appropriate design allowable or knockdown 10 inattention to cost consideration relate to tolerance production quantity joint machining surface finish and inspectability. 
integrated mechanistic and data drive modelling for multivariate analysis of signal pathway. 
mathematical model of highly interconnected and multivariate signal network provide useful tool to understand these complex system. 
however effective approach to extract multivariate regulation information from these model be still lack. 
in this study we propose a data drive modelling framework to analyse large scale multivariate dataset generate from mathematical model. 
we use an ordinary differential equation base model for the fas apoptotic pathway as an example. 
the first step in our approach be to cluster simulation output generate from model with varied protein initial concentration. 
subsequently decision tree analysis be apply in which we use protein concentration to predict the simulation outcome. 
our result suggest that no single subset of protein can determine the pathway behaviour. 
instead different subset of protein with different concentration range can be important. 
we also use the result decision tree to identify the minimal number of perturbation need to change pathway behaviour. 
in conclusion our framework provide a novel approach to understand the multivariate dependency among molecule in complex network and can potentially be use to identify combinatorial target for therapeutic intervention. 
predict eukaryotic protein subcellular location by fuse optimize evidence theoretic k nearest neighbor classifier. 
face the explosion of newly generate protein sequence in the post genomic era we be challenge to develop an automate method for fast and reliably annotate their subcellular location. 
knowledge of subcellular location of protein can provide useful hint for reveal their function and understand how they interact with each other in cellular networking. 
unfortunately it be both expensive and time consuming to determine the localization of an uncharacterized protein in a live cell purely base on experiment. 
to tackle the challenge a novel hybridization classifier be develop by fuse many basic individual classifier through a voting system. 
the engine of these basic classifier be operate by the oet knn optimize evidence theoretic k nearest neighbor rule. 
as a demonstration prediction be perform with the fusion classifier for protein among the follow 16 localization one cell wall two centriole three chloroplast four cyanelle five cytoplasm six cytoskeleton seven endoplasmic reticulum 8) extracell nine golgi apparatus 10 lysosome 11 mitochondria 12 nucleus 13 peroxisome 14 plasma membrane 15 plastid and 16 vacuole. 
to get rid of redundancy and homology bias none of the protein investigate here have g25 sequence identity to any other in a same subcellular location. 
the overall success rate thus obtain via the jack knife cross validation test and independent dataset test be 81.6 and 83.7 respectively which be 46 similar to 63 high than those perform by the other exist method on the same benchmark dataset. 
also it be clearly elucidated that the overwhelmingly high success rate obtain by the fusion classifier be by no mean a trivial utilization of the go annotation as prone to be misinterpret because there be a huge number of protein with give accession number and the correspond go number but their subcellular location be still unknown and that the percentage of protein with go annotation indicate their subcellular component be even less than the percentage of protein with know subcellular location annotation in the swiss  prot database. 
it be anticipate that the powerful fusion classifier may also become a very useful high throughput tool in characterize other attribute of protein accord to their sequence such as enzyme class membrane protein type and nuclear receptor subfamily among many other. 
a web server call euk  oet  ploc have be design at http:// 202.120.37.186/ bioinf/ euk  oet for public to predict subcellular location of eukaryotic protein by the fusion oet  knn classifier. 
intelligent prognostic tool and e maintenance. 
in today s global competitive marketplace there be intense pressure for manufacturing industry to continuously reduce and eliminate costly unscheduled downtime and unexpected breakdown. 
with the advent of internet and tether free technology company necessitate dramatic change in transform traditional fail and fix faf maintenance practice to a predict and prevent pap e maintenance methodology. 
e maintenance address the fundamental need of predictive intelligence tool to monitor the degradation rather than detect the fault in a networked environment and ultimately to optimize asset utilization in the facility. 
this paper introduce the emerge field of e maintenance and its critical element. 
furthermore performance assessment and prediction tool be introduce for continuous assessment and prediction of a particular product s performance ultimately enable proactive maintenance to prevent machine from breakdown. 
recent advance on intelligent prognostic technology and tool be discuss. 
several case study be introduce to validate these develop technology and tool. 
c 2006 elsevier b.v. 
all right reserve. 
an intelligent maintenance system for continuous cost base prioritisation of maintenance activity. 
a key aspect of competition in industrial maintenance be the trade off between cost and risk. 
decision making be dependent upon up to date information about distribute and disparate plant couple with knowledge of sensitive non technical issue. 
enable technology such as the internet be make stride in improve the quantity and quality of datum particularly by improve link with other information system. 
in maintenance the problem of disparate data source be important. 
it be very difficult to make optimal decision because the information be not easily obtain and merge. 
information about technical state or machine health cost of maintenance activity or loss of production and non technical risk factor such as customer information be require. 
even in the good information system these be not define in the same unit and be not present on a consistent time scale typically they be in different information system. 
some datum be continuously update condition datum but the critical risk information be typically draw from a historical survey fix in time. 
a particular problem for the user of condition base maintenance be the treatment of alarm. 
in principle only genuine problem be report but the technical risk of failure be not the full story. 
the decision maker will take into account cost criticality and other factor such as limited resource to prioritise the work. 
the work report here automatically prioritise job arise from condition base maintenance use a strategy call cost base criticality cbc which draw together three type of information. 
cbc weight each incident flag by condition monitor alarm with up to date cost information and risk factor allow an optimise prioritisation of maintenance activity. 
cbc do not attempt to change the strategic plan for maintenance activity it only address prioritisation. 
the strategy use a thin client architecture rather than a central database and be illustrate with example from food manufacturing. 
c 2006 elsevier b.v. 
all right reserve. 
process situation assessment from a fuzzy partition to a finite state machine. 
process situation assessment play a major role in supervision of complex system. 
the knowledge of the system behavior be relevant to support operator in their decision task. 
for complex industrial process such as chemical or petrochemical one most of supervision approach be base on datum acquisition technique and specifically on cluster method to cope with the difficulty of model the process. 
consequently the system behavior can be characterize by a state space partition. 
this way situation assessment be perform online through the tracking of the system evolution from one class to another. 
furthermore a finite state machine that be a support tool for process operator be elaborate to model the system behavior. 
this article present theoretical aspect accord to which the intuition that the trajectory observation of a dynamical system by a sequence of class to which the actual state belong give valuable information about the real behavior of the system be substantiate. 
thus practical aspect be develop on the state machine construction and illustrate by two simple application in the domain of chemical process. 
c 2006 elsevier ltd. 
all right reserve. 
a tool for generate and explain expressive music performance of monophonic jazz melody. 
in this paper we present a machine learn approach to model the knowledge apply by a musician when perform a score in order to produce an expressive performance of a piece. 
we describe a tool for both generate and explain expressive music performance of monophonic jazz melody. 
the tool consist of three component a a melodic transcription component which extract a set of acoustic feature from monophonic recording b a machine learning component which induce both an expressive transformation model and a set of expressive performance rule from the extract acoustic feature and c a melody synthesis component which generate expressive monophonic output midi or audio from inexpressive melody description use the induce expressive transformation model. 
we compare several machine learning technique we have explore for induce the expressive transformation model. 
mptp 0.2 design implementation and initial experiment. 
this paper describe the second version of the mizar problems for theorem proving mptp system and first experimental result obtain with it. 
the goal of the mptp project be to make the large formal mizar mathematical library mml available to current first order automate theorem prover atps and vice versa and to boost the development of domain base knowledge base and generally ai base atp method. 
this version of mptp switch to a generic extend tptp syntax that add term dependent sort and abstract fraenkel term to the tptp syntax. 
we describe these extension and explain how they be transform by mptp to standard tptp syntax use relativization of sort and deanonymization of abstract term. 
full mizar proof be now export and also encode in the extended tptp syntax allow a number of atp experiment. 
this cover for example consistent handling of proof local constant and proof local lemma and translating of a number of mizar proof construct into the tptp formalism. 
the proof use second order mizar scheme be now handle by the system too by remember and if necessary abstract from the proof context the first order instance that be actually use. 
these feature necessitate change in mizar in the mizar to tptp exporter and in the problem create tool. 
mizar have be reimplemente to produce and use natively a detailed xml format suitable for communication with other tool. 
the mizar to tptp exporter be now just a xslt stylesheet translate the xml tree to the tptp syntax. 
the problem creation and other mptp processing task be now implement in about 1,300 line of prolog. 
all these change have make mptp more generic more complete and more correct. 
the large remaining issue be the handling of the mizar arithmetical evaluation. 
we describe several initial atp experiment both on the easy and on the hard mml problem sometimes assist by machine learning. 
it be show that on the nonarithmetical problem countersatisfiability completion be no long detect by the atp system suggest that the mizar deconstruction do by mptp be in this case already complete. 
about every fifth nonarithmetical theorem be prove in a fully autonomous mode in which the premise be select by a machine learn system train on previous proof. 
in 329 of these case the newly discover proof be short than the mml original and therefore be likely to be use for mml refactoring. 
this situation suggest that even a simple inductive or deductive system train on formal mathematic can be sometimes smart than mml author and usable for general discovery in mathematic. 
a structure method for analyse product specification in product planning for machine tool. 
in the product planning procedure of a machine tool mature designer consider various kind of customer requirement while simultaneously conduct the necessary information processing so as to finally determine the most suitable product specification. 
in order to systematize this procedure it be necessary and indispensable to clarify the decision make process as well as knowledge of a mature designer in detail and to analyse design information use in the product planning. 
in this study to establish a product development methodology for machine tool characteristic of design information relate to the product specification have be analyse use a simple mathematical method. 
actual design information use in this analysis be obtain from focused interview and questionnaire investigation with mature designer within the lead machine tool manufacturer in japan. 
furthermore the validity and effectiveness of the propose method have be verify use the result of these investigation. 
improve glaucoma diagnosis by the combination of perimetry and hrt measurement. 
purpose the aim of this study be to determine whether the combination of morphologic datum of the optic nerve head and visual field vf datum would improve diagnosis of glaucoma on the basis of the measurement alone. 
patient and method eighty eight perimetric glaucomatous and 88 normal optic disc from the erlangen glaucoma registry be match for age. 
all normal and patient be examine in a standardized manner slitlamp biomicroscopy gonioscopy 24h applanation tonometry automate vf testing 15 degree optic disc stereographs and heidelberg retina tomograph hrt) scanne of the optic disc. 
the hrt variable be calculate in four optic disc sector. 
all variable be calculate with the software s standard reference plane. 
to gain the same allocation of sector as provide by the hrt software the vf response be average within four sector. 
classification result of these vf response be compare with the summarize result within four sector. 
six different combination of morphologic and vf datum be use to assess their suitability to diagnose the disease. 
hrt measurement and the standard output of the octopus hrt peri1 hrt measurement and the summarize sector and their standard deviation hrt peri2 hrt measurement standard output of the octopus and the summarize sector and their standard deviation hrt perii peri2 standard output of the octopus peri1 summarize sector of the octopus and their standard deviation peri2 and hrt measurement. 
to assess the diagnostic value of the different datum set machine learning classifier stabilize linear discriminant analysis classification tree bagging and double bagging be apply. 
result combination of morphologic and vf datum improve the automate classification rule. 
the accuracy to diagnose glaucoma just by vf and hrt index be maximize for double bagging use both diagnostic tool. 
an estimate misclassification probability of less than 0.07 could be achieve for the primary open angle glaucoma patient combine hrt and vf sector by double bagging. 
so high sensitivity be 95 and specificity 91 achieve by double bagging and combination of hrt peri1 and peri2. 
conclusion the combination of optic disc measurement and vf datum could not only improve glaucoma diagnosis in future but could also help to find an objective way to diagnose glaucomatous optic atrophy. 
the limitation of the topographic relationship between structure and function be the individual variability of the optic disc morphology and the subjective variability of vf testing. 
custom design haptic training for restore reach ability to individual with poststroke hemiparesis. 
we present an initial test of a technique for retrain reach skill in patient with poststroke hemiparesis in which error be temporarily magnify to encourage learning and compensation. 
individual with poststroke hemiparesis hold a horizontal plane robotic manipulandum that could exert a variety of force while record patient movement. 
we measure how well the patient recover movement straightness in a single visit to the laboratory similar to three h. 
follow training we return force to zero for an additional 50 movement to discern if aftereffect last. 
we find that all subject show immediate benefit from the training although three of the 10 subject do not retain these benefit for the remainder of the experiment. 
we discuss how these approach demonstrate great potential for rehabilitation tool that augment error to facilitate functional recovery. 
estimation of thermal deformation in machine tool use the hybrid autoregressive move average neural network model. 
a hybrid model which be compose of an autoregressive move average arma filter and a feedforward neural network fnn be propose to increase prediction accuracy and to reduce learning time for the estimation of thermal deformation in a machine tool. 
the arma filter be use to yield state variable which establish the relationship between the present and past state of thermal deformation for the reservation of the influence of past temperature and deformation. 
otherwise the quantity of fnn input be very vast because of the datum need for the non linear system. 
these state variable which be estimate by past measure temperature and past estimate deformation serve as input of the fnn. 
the algorithm of this hybrid model be present and verify by the experimental result also the prediction accuracy be compare with the arma and fnn independently for the same learning iteration. 
direct self tune model follow control with integral action for a variable frequency oil cool process. 
this paper present a direct self tune model follow control with integral action for a variable frequency oil cool process suitable for cool down high speed machine tool. 
the oil cool process be experimentally model as a first order system with a give time delay. 
base on this model a direct self tune model follow control with integral action be propose for achieve set point tracking and disturbance rejection. 
a real time adaptive predictive control algorithm be then present and implement utilize a standalone digital signal processor dsp. 
in comparison with the control method of tsai and huang the propose method provide a more practical and less computationally intensive approach for achieve the desire high precision set point tracking and disturbance rejection. 
experimental result show that the propose control method be capable of give a satisfactory set point tracking performance under set point change fix load and load change. 
prediction of rna bind site in protein from amino acid sequence. 
rna protein interaction be vitally important in a wide range of biological process include regulation of gene expression protein synthesis and replication and assembly of many virus. 
we have develop a computational tool for predict which amino acid of an rna bind protein participate in rna protein interaction use only the protein sequence as input. 
rnabindr be develop use machine learning on a validated nonredundant datum set of interface from know rna protein complex in the protein data bank. 
it generate a classifier that capture primary sequence signal sufficient for predict which amino acid in a give protein be locate in the rna protein interface. 
in leave one out cross validation experiment rnabindr identifie interface residue with 85 overall accuracy. 
it can be calibrate by the user to obtain either high specificity or high sensitivity for interface residue. 
rnabindr implement a naive bayes classifier perform as well as a more complex neural network classifier to our knowledge the only previously publish sequence base method for rna bind site prediction and offer the advantage of speed simplicity and interpretability of result. 
rnabindr prediction on the human telomerase protein htert be in good agreement with experimental datum. 
the availability of computational tool for predict which residue in an rna bind protein be likely to contact rna should facilitate design of experiment to directly test rna bind function and contribute to our understanding of the diversity mechanism and regulation of rna protein complex in biological system. 
rnabindr be available as a web tool from http://bindr.gdcb.iastate.edu. 
research of rapid and direct thick coating deposition by hybrid plasma laser. 
in this paper a new technology of direct and rapid thick coating fabrication with hybrid plasma laser deposition manufacturing pldm technology be advanced which be also suitable for functional prototyping and tooling application. 
it emphasize on the influence of laser to the microstructure of coating and physical property of surface layer. 
unlike the direct rapid plasma deposition manufacturing pdm in hybrid plasma laser deposition manufacturing the laser beam enter into plasma arc beam and focus on the molten pool as assist heat energy. 
a 280 w pulse nd yag yttrium aluminum garnet laser machine be use to inspect the effect. 
the experimental result show that the laser beam could improve the surface state the element distribution of coating deposit by pldm be even the physical property of surface coating fabricate with pldm be well than that deposit by pdm. 
c 2005 elsevier b.v. 
all right reserve. 
biocham an environment for model biological system and formalizing experimental knowledge. 
biocham the biochemical abstract machine be a software environment for model biochemical system. 
it be base on two aspect one the analysis and simulation of boolean kinetic and stochastic model and two the formalization of biological property in temporal logic. 
biocham provide tool and language for describe protein network with a simple and straightforward syntax and for integrate biological property into the model. 
it then become possible to analyze query verify and maintain the model with respect to those property. 
for kinetic model biocham can search for appropriate parameter value in order to reproduce a specific behavior observe in experiment and formalize in temporal logic. 
couple with other method such as bifurcation diagram this search assist the modeler biologist in the modeling process. 
a knowledge base engineering design tool for metal forging. 
this paper describe a knowledge base design tool enable the generation of hot forge die design from a component profile. 
the system integrate the hot forge die design process into a single framework and guide the user through the design process enable the generation of forgeable geometry from a component profile take into account machine material and forge company specific datum and design consideration. 
the product model manage all the routine engineering task. 
the role of the engineer who interact with the model be to provide the input specification such as component geometry material and production machine. 
c 2006 elsevier b.v. 
all right reserve. 
capability base emerge organization of autonomous agent for flexible production control. 
flexible structure in the manufacturing domain be of increase concern. 
nowadays distribute system for the coordination management and control of highly heterogeneous manufacturing structure be under research and development. 
however their flexibility be restrict by two main aspect on the one hand in the design step of the system designer be implement mostly static communication and reasoning skill for distribute software system. 
on the other hand knowledge on solution provide by machine tool be implement implicitly the software system represent a machine tool can only reason on capability for a solution with respect to the capability implement by the designer. 
in this paper we will propose an innovative approach to dynamic capability management enable software agent to reason on their capability and dynamically create capability as solution. 
c 2006 elsevier ltd. 
all right reserve. 
from graph to manifold laplacian the convergence rate. 
the convergence of the discrete graph laplacian to the continuous manifold laplacian in the limit of sample size n infinity while the kernel bandwidth epsilon zero be the justification for the success of laplacian base algorithm in machine learning such as dimensionality reduction semi supervised learning and spectral clustering. 
in this paper we improve the convergence rate of the variance term recently obtain by hein et al. 
from graph to manifold weak and strong pointwise consistency of graph laplacians in p. 
auer r. 
meir eds proc. 
18th conf. 
learning theory colt lecture notes comput. 
sci vol. 
3559 springer verlag berlin 2005 pp. 
470 485 improve the bias term error and find an optimal criterion to determine the parameter e give n. 
c 2006 elsevier inc. 
all right reserve. 
genetic attribute of cerebrospinal fluid derive hiv one env. 
hiv one often invade the cns during primary infection eventually result in neurological disorder in up to 50 of untreated patient. 
the cns be a distinct viral reservoir differ from peripheral tissue in immunological surveillance target cell characteristic and antiretroviral penetration. 
neurotropic hiv one likely develop distinct genotypic characteristic in response to this unique selective environment. 
we seek to catalogue the genetic feature of cns derive hiv one by analyse 456 clonal rna sequence of the c2 v3 env subregion generate from csf and plasma of 18 chronically infect individual. 
neuropsychological performance of all subject be evaluate and summarize as a global deficit score. 
a battery of phylogenetic statistical and machine learning tool be apply to these datum to identify genetic feature associate with hiv one neurotropism and neurovirulence. 
eleven of 18 individual exhibit significant viral compartmentalization between blood and csf p 0.01 slatkin maddison test. 
a csf specific genetic signature be identify comprise position nine 13 and 19 of the v3 loop. 
the residue at position five of the v3 loop be highly correlate with neurocognitive deficit p 0.0025 fisher s exact test. 
antibody mediate hiv one neutralize activity be significantly reduce in csf with respect to autologous blood plasma p 0.042 student s t test. 
accordingly csf derive sequence exhibit constrain diversity and contain few glycosylated and positively select site. 
our result suggest that there be several genetic feature that distinguish csf  and plasma derive hiv one population probably reflect alter cellular entry requirement and decrease immune pressure in the cns. 
furthermore neurological impairment may be influence by mutation within the viral v3 loop sequence. 
build an ontology of adverse drug reaction for automate signal generation in pharmacovigilance. 
automated signal generation in pharmacovigilance implement unsupervise statistical machine learning technique in order to discover unknown adverse drug reaction adr in spontaneous reporting system. 
the impact of the terminology use for code adr have not be address previously. 
the medical dictionary for regulatory activities meddra use worldwide in pharmacovigilance case do not provide formal definition of term. 
we have build an ontology of adr to describe semantic of meddra term. 
ontological subsumption and approximate matching inference allow a well grouping of medically relate condition. 
signal generation performance be significantly improve but time consumption relate to modelization remain very important. 
c 2005 elsevier ltd. 
all right reserve. 
spectral imaging perspective on cytomic. 
background cytomic involve the analysis of cellular morphology and molecular phenotype with reference to tissue architecture and to additional metadata. 
to this end a variety of image and nonimage technology need to be integrate. 
spectral imaging be propose as a tool that can simplify and enrich the extraction of morphological and molecular information. 
simple to use instrumentation be available that mount on standard microscope and can generate spectral image dataset with excellent spatial and spectral resolution these can be exploit by sophisticated analysis tool. 
method this report focus on brightfield microscopy base approach. 
cytological and histological sample be stain use nonspecific standard stain giemsa hematoxylin and eosin h&e or immunohistochemical ihc technique employ three chromogen plus a hematoxytin counterstain. 
the sample be image use the nuance tm system a commercially available liquid crystal tunable filter base multispectral imaging platform. 
the result datum set be analyze use spectral unmixing algorithm and/or learn by example classification tool. 
result spectral unmixing of giemsa stain guinea pig blood film readily classify the major blood element. 
machine learn classifier be also successful at the same task as well in distinguish normal from malignant region in a colon cancer example and in delineate region of inflammation in an h&e stain kidney sample. 
in an example of a multiplexed ich sample brown red and blue chromogen be isolate into separate image without crosstalk or interference from the also blue hematoxylin counterstain. 
conclusion cytomic require both accurate architectural segmentation as well as multiplexed molecular imaging to associate molecular phenotype with relevant cellular and tissue compartment. 
multispectral imaging can assist in both these task and convey new utility to brightfield base microscopy approach. 
c 2006 international society for analytical cytology. 
understand representational sensitivity in the iterated prisoner s dilemma with fingerprint. 
the iterated prisoner s dilemma be a widely use computational model. 
of cooperation and conflict. 
many study report emergent cooperation in population of agent train to play prisoner s dilemma with an evolutionary algorithm. 
this study vary the representation of the evolve agent result in level of emergent cooperation range from zero to over 90. 
the representation use in this study be directly encode finite state machine cellularly encode finite state machine feedforward neural network if skip action list parse tree store two type of boolean function lookup table boolean function stack and markov chain. 
an analytic tool for rapidly identify agent strategy and compare across representation call a fingerprint be use to compare the more complex representation. 
fingerprint provide functional signature of an agent s strategy in a manner that be independent of the agent s representation. 
this study demonstrate conclusively that choice of a representation dominate agent behavior in evolutionary prisoner s dilemma. 
this in turn suggest that any soft computing system intend to simulate behavior must be concern with the representation issue. 
an intelligent modeling system to improve the machining process quality in cnc machine tool use adaptive fuzzy petri net. 
the paper first present an and or net approach for planning of a computer numerical control cnc machining operation and then describe how an adaptive fuzzy petri net afpn can be use to model and control all activity and event within cnc machine tool. 
it also demonstrate how product quality specification such as surface roughness and machining process quality can be control by utilize afpn. 
the paper present an intelligent control architecture base on afpn with learn capability for model a cnc machining operation and control of machining process quality. 
in this paper it will be show that several idea and approach propose in the field of robotic assembly be applicable to the planning procedure modeling with minor modification. 
graph theory petri net and fuzzy logic be powerful tool which be employ in this research to model different feasible state for perform a process and to obtain the good process performance path use exertion of the process designer s criterion. 
a review on the integration of artificial intelligence into coastal modeling. 
with the development of compute technology mechanistic model be often employ to simulate process in coastal environment. 
however these predictive tool be inevitably highly specialize involve certain assumption and/or limitation and can be manipulate only by experienced engineer who have a thorough understanding of the underlie theory. 
this result in significant constraint on their manipulation as well as large gap in understanding and expectation between the developer and practitioner of a model. 
the recent advancement in artificial intelligence ai technology be make it possible to integrate machine learning capability into numerical modeling system in order to bridge the gap and lessen the demand on human expert. 
the objective of this paper be to review the state of the art in the integration of different ai technology into coastal modeling. 
the algorithm and method study include knowledge base system genetic algorithm artificial neural network and fuzzy inference system. 
more focus be give to knowledge base system which have apparent advantage over the other in allow more transparent transfer of knowledge in the use of model and in furnish the intelligent manipulation of calibration parameter. 
of course the other ai method also have their individual contribution towards accurate and reliable prediction of coastal process. 
the integrated model might be very powerful since the advantage of each technique can be combine. 
c 2005 elsevier ltd. 
all right reserve. 
fast sdp relaxation of graph cut clustering transduction and other combinatorial problem. 
the rise of convex programming have change the face of many research field in recent year machine learning be one of the one that benefit the most. 
a very recent developement the relaxation of combinatorial problem to semi definite program sdp have gain considerable attention over the last decade helmberg 2000 de bie and cristianini 2004a. 
although sdp problem can be solve in polynomial time for many relaxation the exponent in the polynomial complexity bound be too high for scale to large problem size. 
this have hamper their uptake as a powerful new tool in machine learning. 
in this paper we present a new and fast sdp relaxation of the normalize graph cut problem and investigate its usefulness in unsupervised and semi supervised learning. 
in particular this provide a convex algorithm for transduction as well as approach to cluster. 
we far propose a whole cascade of fast relaxation that all hold the middle between old spectral relaxation and the new sdp relaxation allow one to trade off computational cost versus relaxation accuracy. 
finally we discuss how the methodology develop in this paper can be apply to other combinatorial problem in machine learning and we treat the max cut problem as an example. 
a qcar approach to material modeling. 
little be know about the relationship between the function and structure of material. 
material solid with a function be complex entity and a well knowledge of the parameter that contribute to function be desirable. 
here we present modeling approach that correlate chemical composition with function of heterogeneous catalyst. 
the complete composition space of the mixed oxide of ni cr mn and of ni co mo mn 10 spacing have be measure for the oxidation of propene to acroleine. 
the datum have be collect visualize and model. 
different mathematical approach such as support vector machines multilevel b spline approximation and kriging have be apply to model this relationship. 
high throughput screen datum of ternary and quaternary composition spread be approximate to locate catalyst of high activity within the search space. 
for quaternary system slice plot offer a good tool for visualization of the result. 
use these approximation technique the composition of the most active catalyst can be predict. 
the study document that distinct relationship between chemical composition and catalytic function exist and can be describe by mathematical model. 
recent progress in the application of machine learning approach for predict protein functional class independent of sequence similarity. 
protein sequence contain clue to its function. 
functional prediction from sequence present a challenge particularly for protein that have low or no sequence similarity to protein of know function. 
recently machine learning method have be explore for predict functional class of protein from sequence derive property independent of sequence similarity which show promise potential for low  and non homologous protein. 
these method can thus be explore as potential tool to complement alignment  and clustering base method for predict protein function. 
this article review the strategy current progress and underlie difficulty in use machine learning method for predict the functional class of protein. 
the relevant software and web server be describe. 
the reported prediction performance in the application of these method be also present which need to be interpret with caution as they be dependent on such factor as dataset use and choice of parameter. 
learning base multi pass adaptive scheduling for a dynamic manufacturing cell environment. 
because the essential attribute be uncertain in a dynamic manufacturing cell environment to select a near optimal subset of manufacture attribute to enhance the generalization ability of knowledge basis remain a critical unresolved issue for classical artificial neural network base ann base multi pass adaptive scheduling mpas. 
to resolve this problem this study develop a hybrid genetic artificial neural network ga ann approach for ann base mpas system. 
the hybrid ga ann approach be use to evolve an optimal subset of system attribute from a large set of candidate manufacturing system attribute and simultaneously to determine configuration and learn parameter of the ann accord to various performance measure. 
in the ga ann base mpas approach for a give feature subset and the correspond topology and learn parameter of an ann decode by a ga an ann be apply to evaluate the fitness in the ga process and to generate the mpas knowledge base use for adaptive scheduling control mechanism. 
the result demonstrate that the propose ga ann base mpas approach have accord to various performance criterion a well system performance over a long period of time than those obtain with classical machine learning base mpas approach and the heuristic individual dispatching rule. 
c 2005 elsevier ltd. 
all right reserve. 
bootstrappe pronunciation model. 
bootstrapping technique can accelerate the development of language technology for resource scarce language. 
we define a framework for the analysis of a general bootstrappe process whereby a model be improve through a control series of increment at each stage use the previous model to generate the next. 
we apply this framework to the task of create pronunciation model for resource scarce language iteratively combine machine learning and human knowledge in a way that minimize the human intervention require during this process. 
we analyse the effectiveness of such an approach when develop a medium sized 5000 10 000 word pronunciation lexicon. 
we develop such an electronic pronunciation lexicon in afrikaans one of south africa s official language and provide initial result obtain for similar lexicon develop in zulu and sepedi two other south african language. 
we derive a mathematical model that can be use to predict the amount of time require for the development of a pronunciation lexicon of a give size demonstrate the various tool that can accelerate the bootstrappe process and evaluate the efficiency of these tool in practice. 
process strategy and analysis of roll in tube. 
a new method to manufacture composite workpiece be join of two part by rolling in a technique which have be develop at the department of machining technology isf and at the institute of forming technology and lightweight construction iul. 
in this article the technology be describe and different strategy to shorten the joining process without a decrease of the strength of the composite be present and compare. 
to improve the knowledge about the material flow the strain distribution in the contact zone have be analyse both experimentally and by mean of finite element analysis fea. 
in order to evaluate the strength of the composite an analysis of the pressout force and of the residual stress in the inner tube have be carry out also by mean of experiment and simulation. 
microforme current status and future demand. 
microforme technology be gain increase interest from the metal form community. 
this can be explain by the large number of new application and product deliver to market in the past yield small and small geometrical dimension of the final product and thus demand the small specimen to be manufacture in large quantity. 
up to now most of these part be be manufacture by machine technology well suited to the production of small series. 
the analysis of the current market situation show that the steadily increase trend towards the small product be continue in the future and thus require new manufacturing technology for large quantity production. 
form technology seem to be well suited due to its high production output and high accuracy. 
the aim of this paper be to give an overview of the current research activity relate to microforme technology show microforme technology capability and problem. 
the analysis of the current status will give a hint to exist gap in knowledge and finally describe the future demand. 
c 2006 journal of mechanical engineering. 
all right reserve. 
a comparative study prediction of construct treatment wetland performance with k near neighbor and neural network. 
k near neighbor knn support vector machine svm and self organize map som be apply to predict five day 20 degree c n allylthiourea biochemical oxygen demand bod and suspend solid ss and to assess novel alternative method of analyze water quality performance indicator for construct treatment wetland. 
concern the accuracy of prediction som show a well performance compare to both knn and svm. 
moreover som have the potential to visualize the relationship between complex biochemical variable. 
however optimize the som require more time in comparison to knn and svm because of its trial and error process in search for the optimal map. 
the result suggest that bod and ss can be efficiently estimate by apply machine learning tool with input variable such as redox potential and conductivity which can be monitor in real time. 
their performance be encouraging and support the potential for future use of these model as management tool for the day to day process control. 
prediction of catalytic residue use support vector machine with select protein sequence and structural property. 
background the number of protein sequence derive from genome sequence project be outpace our knowledge about the function of these protein. 
with the gap between experimentally characterized and uncharacterized protein continue to widen it be necessary to develop new computational method and tool for functional prediction. 
knowledge of catalytic site provide a valuable insight into protein function. 
although many computational method have be develop to predict catalytic residue and active site their accuracy remain low with a significant number of false positive. 
in this paper we present a novel method for the prediction of catalytic site use a carefully select supervised machine learn algorithm couple with an optimal discriminative set of protein sequence conservation and structural property. 
result to determine the good machine learn algorithm 26 classifier in the weka software package be compare use a benchmarke dataset of 79 enzyme with 254 catalytic residue in a 10 fold cross validation analysis. 
each residue of the dataset be represent by a set of 24 residue property previously show to be of functional relevance as well as a label 1/ one to indicate catalytic non catalytic residue. 
the well perform algorithm be the sequential minimal optimization smo algorithm which be a support vector machine svm. 
the wrapper subset selection algorithm far select seven of the 24 attribute as an optimal subset of residue property with sequence conservation catalytic propensity of amino acid and relative position on protein surface be the most important feature. 
conclusion the smo algorithm with seven select attribute correctly predict 228 of the 254 catalytic residue with an overall predictive accuracy of more than 86. 
miss only 10.2 of the catalytic residue the method capture the fundamental feature of catalytic residue and can be use as a catalytic residue filter to facilitate experimental identification of catalytic residue for protein with know structure but unknown function. 
micrometer scale fabrication and assembly use focused ion beam. 
as nanotechnology advance fabrication technique base on focused ion beam fib be expect to be useful in manufacture complex microstructure. 
we develop a micro manufacture method with superior micro assembly capability by employ fib milling fib assist deposition a rotational type side entry stage and a micro sample system. 
after be machine by fib milling micro sample be assemble into a 25 mu m diameter micro universal joint. 
a one mu m diameter micro joint be also successfully manufacture in the same manner. 
result of tem observation of the interface between the deposited layer and the substrate suggest that fib assist deposition can be apply to the formation of micro joint in a micro machine manufacturing process. 
this micro manufacture method be a powerful tool for the fabrication and assembly of micro machine. 
c 2005 elsevier b.v. 
all right reserve. 
a machine learn information retrieval approach to protein fold recognition. 
motivation recognize protein that have similar tertiary structure be the key step of template base protein structure prediction method. 
traditionally a variety of alignment method be use to identify similar fold base on sequence similarity and sequence structure compatibility. 
although these method be complementary their integration have not be thoroughly exploit. 
statistical machine learning method provide tool for integrate multiple feature but so far these method have be use primarily for protein and fold classification rather than address the retrieval problem of fold recognition find a proper template for a give query protein. 
result here we present a two stage machine learning information retrieval approach to fold recognition. 
first we use alignment method to derive pairwise similarity feature for query template protein pair. 
we also use global profile profile alignment in combination with predict secondary structure relative solvent accessibility contact map and beta strand pair to extract pairwise structural compatibility feature. 
second we apply support vector machine to these feature to predict the structural relevance i.e. 
in the same fold or not of the query template pair. 
for each query the continuous relevance score be use to rank the template. 
the foldpro approach be modular scalable and effective. 
compare with 11 other fold recognition method foldpro yield the good result in almost all standard category on a comprehensive benchmark dataset. 
use prediction of the top rank template the sensitivity be similar to 85 56 and 27 at the family superfamily and fold level respectively. 
use the five top rank template the sensitivity increase to 90 70 and 48. 
subdivision surface base finish machining. 
subdivision surface combine smooth spline surface and polygonal mesh together therefore a smooth design model and discrete machining model may be unified and subdivision surface may be use as a common representation for geometric design and machining. 
motivate by the idea this paper present the study of finish machining of object represent by subdivision surface with emphasis on geometric error control involve in tool path generation. 
first give a design model chordal error be control during finish model building. 
a chordal error drive adaptive subdivision method be use to build finish model with less datum. 
second a surface decomposition machining strategy be use to control the cusp height error. 
a simple iso slope curve tracing and surface decomposition algorithm be present to partition the model into. 
at and steep region. 
contour map tool path be generate in the steep region while iso planar tool path be generate in the. 
at region. 
the gouge problem be easily handle through two dimensional 2d tool path correction algorithm. 
the implementation result demonstrate that subdivision be capable of serve as a unified representation for both geometric modelling and machining. 
memo a hybrid sql xml approach to metabolomic datum management for functional genomic. 
background the genome sequence project have show our limited knowledge regard gene function e. 
g. 
s. 
cerevisiae have five 6,000 gene of which nearly 1,000 have an uncertain function. 
their gross influence on the behaviour of the cell can be observe use large scale metabolomic study. 
the metabolomic datum produce need to be structure and annotate in a machine usable form to facilitate the exploration of the hide link between the gene and their function. 
description memo be a formal model for represent metabolomic datum and the associated metadata. 
two predominant platform sql and xml be use to encode the model. 
memo have be implement as a relational database use a hybrid approach combine the advantage of the two technology. 
it represent a practical solution for handle the sheer volume and complexity of the metabolomic datum effectively and efficiently. 
the memo model and the associated software be available at http://dbkgroup.org/memo/. 
conclusion the maturity of relational database technology be use to support efficient datum processing. 
the scalability and self descriptiveness of xml be use to simplify the relational schema and facilitate the extensibility of the model necessitate by the creation of new experimental technique. 
special consideration be give to data integration issue as part of the system biology agenda. 
memo have be physically integrate and cross link to related metabolomic and genomic database. 
semantic integration with other relevant database have be support through ontological annotation. 
compatibility with other datum format be support by automatic conversion. 
the inventor. 
amongst australian anaesthetist there have be many whose ingenuity and mechanical knowledge produce ingenious device. 
lidwill and geoffrey kaye come immediately to mind and their contribution be well describe elsewhere. 
in this paper two invention with contrast fate be describe the grant humidifier and the komesaroff single use analgesia device. 
graham grant s invention address the problem of rain out in a most ingenious manner the device be compact efficient and deserve great commercial success but a similar apparatus develop in new zealand be well support and capture most of the market. 
grant have a degree in engineering acquire before his medical degree but david komesaroff spend only a year in the engineering faculty before transfer to medicine. 
nevertheless he have remain interested and in touch with technical matter and have a number of other device to his credit. 
mention be briefly make of other stoke of the suction bullet bill cole an early volatile specific vaporiser fisk the paediatric ventilator and noel cass the cass needle these achievement be by no mean the end of the road. 
already an australian design single use laryngoscope be be manufacture and launch on both the national and international market. 
use mega fuzzification and datum trend estimation in small datum set learn for early fms scheduling knowledge. 
provide with plenty of datum experience datum mining technique be widely use to extract suitable management skill from the datum. 
nevertheless in the early stage of a manufacturing system only rare datum can be obtain and build scheduling knowledge be usually fragile. 
use small datum set this research s purpose be improve the accuracy of machine learning for flexible manufacturing system fms scheduling. 
the study develop a data trend estimation technique and combine it with mega fuzzification and adaptive network base fuzzy inference system anfis. 
the result of the simulated fms scheduling problem indicate that learn accuracy can be significantly improve use the propose method involve a very small datum set. 
c 2004 elsevier ltd. 
all right reserve. 
map of dispersion for machine process. 
during product design the design office define dimensional and geometrical parameter accord to the use criterion and product functionality. 
the manufacture department must integrate the manufacturing and the workpiece position dispersion during the choice of tool and the machine operating mode and parameter value to respect the functional constraint. 
in this article the author suggest a model for the turn dispersion take into account not only geometrical specification of position or orientation but also the experience of method actor. 
a representation use the principle of know how map in two or three dimension be privileged. 
the most interesting aspect be that these map include tacit and explicit knowledge. 
an experimental study realize on a machine tool hes 300 allow one to elaborate knowledge map especially for the turning process. 
artificial intelligence and data mining for toxicity prediction. 
tool for artificial intelligence and datum mining can derive quantitative structure activity relationships q)sars for toxicity in an objective and reproducible manner. 
this review provide a conceptual description of the most important data mining algorithm for the identification of chemical feature and the extraction of relationship between these descriptor and toxic activity. 
we will discuss the compliance of these technique with the oecd guideline for q)sar requirement as well as performance implication. 
special emphasis will be give to validation procedure for q)sar model. 
advanced design methodology for single and dual voltage wound core power transformer base on a particular finite element model. 
the paper present an accurate and cost effective three dimensional finite element model for the analysis and design of wound core shell type power transformer focus on the short circuit impedance evaluation. 
the model efficiency lie on the detailed representation of the transformer geometry along with the adoption of a particular reduce scalar potential formulation enable three dimensional magnetostatic problem solution without prior source field calculation. 
its accuracy be validate through local field measurement and through comparison of the calculate short circuit impedance value with the measure one for several commercial wound core shell type transformer. 
in such transformer involve extensive wind part out of the core window the detailed representation of the transformer geometry include the winding cool duct provide accurate result for low density of the three dimensional finite element mesh result to reduction of the required calculation time. 
the model be use in the development of a computational tool which enable the automated and accurate transformer characteristic prediction adopt to the manufacturing process. 
this tool have also be apply in the impedance calculation for different winding connection of dual voltage transformer thus provide the information need for the achievement of an accurate design and the enhancement of the manufacturer s ability to reduce design margin. 
the methodology present in this paper have be incorporate in the design process of a transformer manufacturing industry. 
c 2005 elsevier b.v. 
all right reserve. 
application of the learning curve analysis to the lhc main dipole production first assessment. 
about two third of the lhc main dipole have be deliver by the three supplier charge of the production. 
the training of the staff mostly hire just for this manufacture and the natural improvement of the procedure with the acquire experience decrease naturally the time necessary for the assembly of a unit. 
the aim of this paper be to apply methodology like the cost base learning curve and the time base learning curve to the lhc main dipole compare the estimated learn percentage to the one experience in other industry. 
this type of analysis still in a preliminary phase and here apply to about 40 of the total production of the lhc magnet that will end by 2006 show that our production have a relatively high learning percentage and it be similar to aerospace and complex machine tool for new model. 
therefore with the lhc project accelerator magnet seem to have reach industrial maturity and this production can be use as bench mark for other large scientific project imply series production. 
evolutionary neural network for anomaly detection base on the behavior of a program. 
the process of learn the behavior of a give program by use machine learn technique base on system call audit datum be effective to detect intrusion. 
rule learn neural network statistic and hide markov model hmm be some of the kind of representative method for intrusion detection. 
among they neural network be know for good performance in learn system call sequence. 
in order to apply this knowledge to real world problem successfully it be important to determine the structure and weight of these call sequence. 
however find the appropriate structure require very long time period because there be no suitable analytical solution. 
in this paper a novel intrusion detection technique base on evolutionary neural network enns be propose. 
one advantage of use enns be that it take less time to obtain superior neural network than when use conventional approach. 
this be because they discover the structure and weight of the neural network simultaneously. 
experimental result with the 1999 defense advanced research projects agency darpa intrusion detection evaluation ideval datum confirm that enns be promise tool for intrusion detection. 
a study on fault diagnosis and maintenance of cnc wedm base on binary relational analysis and expert system. 
the paper present a binary relational analysis and expert system base module for maintenance and fault diagnosis of cnc wire edm. 
the module propose a framework of integrated maintenance and fault diagnosis system. 
the study explore the binary code matrix system which play an important role in prediction and diagnosis of wire electrical discharge machining wedm fault on the spot by expert guidance. 
in this study 15 input be consider to observe eight probable cause with the help of the forward and backward propagation algorithm. 
input and output matrix be consider in the form of a square matrix. 
to explain the fault diagnosis and to realize the importance of maintenance through advice the detection of fault be investigate through forward and back propagation of matrix transformation on the spot. 
it be an integrate backup that can be individually focused when input and output parameter do not match. 
it be a time saving knowledge acquisition easy to maintain and capable of self learn system. 
to verify the develop framework 120 datum set be generate for proper analyzing of acquire output through graphical representation. 
the paper also present some of the important feature of maintenance schedule and probable cause of wire breakage with remedial action in tabular form. 
the developed system can help the operator trainee and manufacture engineer in achieve trouble free machine through quick detection of fault and proper maintenance of machine in actual practice. 
a machine learning approach to understand surgical performance. 
in this paper the hidden markov models hmm be use as a tool for understand minimally invasive surgical performance and human factor that characterize it in our experiment we study datum concern the tool positioning during exercise perform on a surgical simulator. 
by mean of hidden markov models theory we create a model of the expert surgeon performance able to evaluate surgical capability and to distinguish expert and novice surgeon performance. 
by analyze the train model and video acquisition we show that it be possible to deduce information about feature characterize the surgical expertise. 
an information and knowledge framework for multi perspective design and manufacture. 
although the advance of computer system continue to provide improved support to concurrent product development activity there be still several limitation that need to be address. 
a product need to be consider from multiple perspective or viewpoint to satisfy the many conflicting requirement that must be address during product development. 
the ability of software system to provide an information sharing environment that can support multiple viewpoint be therefore vital for a concurrent engineering environment. 
this paper present an approach to support flexible integration between multiple view. 
a novel framework be propose to capture the combination of information and knowledge in two separate but related layer. 
this approach provide a flexible environment that be easy to maintain and can operate on new perspective as they be introduce and as new knowledge be identify. 
injection mould design have be use as a focus for the experimental work and result be present which deal with interaction between design for function design for mouldability design for assembly and design for machining. 
automatic tool path generation of a feature base cad capp cam integrate system. 
cad cam development over the past few decade have significantly improve design and manufacturing efficiency. 
although cad capp and cam technology have advance greatly the link between these system be still weak. 
currently the information from cad and capp system can not be interpret directly by cam system. 
it be the user who interpret the information and make the connection between cad and cam system. 
the current method to generate tool path and nc program especially machine geometry preparation involve extensive manual interaction in a cam system. 
to improve production efficiency far a tight cad cam integration be need to automate the design to manufacturing process. 
the paper discuss the automation of tool path generation in an integrated cad capp cam system base on machine feature. 
machine feature be utilize to carry machine geometry information from capp to cam system. 
an integration layer between fbmach and unigraphics be implement to achieve an integrated cad capp cam system base on machine feature. 
the integration layer make product information as well as process information available immediately in an electronic form for the preparation of tool path. 
the integrated system automate the process of tool path generation from solid model and significantly reduce user interaction and the amount of time prepare tool path. 
quantile regression forest. 
random forest be introduce as a machine learn tool in breiman 2001 and have since prove to be very popular and powerful for high dimensional regression and classification. 
for regression random forest give an accurate approximation of the conditional mean of a response variable. 
it be show here that random forest provide information about the full conditional distribution of the response variable not only about the conditional mean. 
conditional quantile can be infer with quantile regression forest a generalisation of random forest. 
quantile regression forest give a non parametric and accurate way of estimate conditional quantile for high dimensional predictor variable. 
the algorithm be show to be consistent. 
numerical example suggest that the algorithm be competitive in term of predictive power. 
machining of novel alumina cyanoacrylate green ceramic compact. 
research at nottingham trent university have lead to the invention of an innovative technology prime. 
which produce novel alumina cyanoacrylate ceramic compact that can be machine use conventional method such as drilling turn and mill. 
powder reaction injection moulding engineering prime be a unique solution to the problem associate with the debinding of conventional wax or polymeric binder use in powder moulding since the cyanoacrylate binder superglue employ in prime de polymerise back to a monomer. 
traditionally debinde of wax and polymeric binder use in powder injection moulding be a very costly part of the process. 
thermal degradation and solvent wicke of polymeric binder can take hour or even day but cyanoacrylate have major advantage because of its ability to unzip in minute when expose to temperature great than 180 degree c. 
also can be collect for reuse. 
this enable a simple approach to powder moulding and a significantly decrease processing time. 
feedstock be prepare consist of a high volume fraction of powder 0.48. 
machine before sinter of a ceramic i.e. 
in the green state represent an alternative to other shaping process and offer a high degree of flexibility and economic efficiency for the machining of ceramic part. 
the study of green machining of a new ceramic material be also important for the future development and application of the material since this be a common manufacturing process in many industry. 
the fragility of conventional ceramic green compact generally provide considerable difficulty when machine. 
the alternative of diamond grind the fire product be an expensive process which be limit in the complexity of shape that can be produce. 
currently however around 80 of all machining of advanced ceramic be carry out in this way. 
although new physical and chemical p&c machining technique have be introduce the practical limitation to their use be high initial investment cost and restriction on the material that can be shape. 
this paper report the initial research result and demonstrate that cyanoacrylate can be use as an effective reactive binder with aluminium oxide to produce compact that can be machine use conventional carbide tool in order to manufacture engineering part. 
c 2005 elsevier b.v. 
all right reserve. 
a survey of statistical user simulation technique for reinforcement learning of dialogue management strategy. 
within the broad field of speak dialogue system the application of machine learning approach to dialogue management strategy design be a rapidly grow research area. 
the main motivation be the hope of building system that learn through trial and error interaction what constitute a good dialogue strategy. 
training of such system could in theory be do use human user or use corpus of human computer dialogue but in practice the typically vast space of possible dialogue state and strategy can not be explore without the use of automatic user simulation tool. 
this requirement for train statistical dialogue model have create an interesting new application area for predictive statistical user modelling and a variety of different technique for simulate user behaviour have be present in the literature range from simple markov model to bayesian network. 
the development of reliable user simulation tool be critical to further progress on automatic dialogue management design but it hold many challenge some of which have be encounter in other area of current research on statistical user modelling such as the problem of concept drift the problem of combine content base and collaboration base modelling technique and user model evaluation. 
the latter topic be of particular interest because simulation base learning be currently one of the few application of statistical user modelling that employ both direct accuracy base and indirect utility base evaluation technique. 
in this paper we briefly summarize the role of the dialogue manager in a spoken dialogue system give a short introduction to reinforcement learning of dialogue management strategy and review the literature on user modelling for simulation base strategy learning. 
we far describe recent work on user model evaluation and discuss some of the current research issue in simulation base learning from a user modelling perspective. 
the construction of wavelet network for speech signal processing. 
wavelet decomposition reconstruct a signal by a series of scale and translate wavelet. 
incorporate discrete wavelet decomposition theory with neural network technique wavelet network have recently emerge as a powerful tool for many application in the field of signal processing such as data compression and function approximation. 
in this paper four contribution be claim one from the point of view of machine learning we analyse and construct wavelet network to achieve the compact representation of a signal. 
two a new algorithm of construct wavelet network be propose. 
the orthogonal least square ols be employ to prune the wavelet network. 
three our experiment on speech signal processing result show that the wavelet network prune by ols achieve the good approximation and prediction capability among the representative speech processing technique. 
four our propose methodology have be successfully apply to speech synthesis for a talk head to read web text. 
hybrid specification storage retrieval and runtime application of clinical guideline. 
clinical guideline be a major tool in improve the quality of medical care. 
however most guideline be in free text be not machine comprehensible and be not easily accessible to clinician at the point of care. 
we have design and implement a web base modular distribute architecture the digital electronic guideline library degel which facilitate gradual conversion of clinical guideline from text to a formal representation in the choose target guideline ontology. 
the architecture support guideline classification semantic markup context sensitive search browsing run time application and retrospective quality assessment. 
the degel hybrid meta ontology include element common to all guideline ontology such as semantic classification and domain knowledge it also include four content representation format free text semi structured text semi formal representation and a formal representation. 
these format support increasingly sophisticated computational task. 
guideline can thus be in a hybrid representation in which guideline and even part of the same guideline might exist at different formalisation level. 
we have also develop and rigorously evaluate a methodology and an associated web base tool uruz for gradually structure and semi formalising free text clinical guideline. 
finally we have design implement and evaluate a new approach the hybrid runtime application model for support runtime application of clinical guideline that be not necessarily in a machine comprehensible format in particular when the guideline be in a semi formal representation and the patient s datum be either in an electronic medical record or in a paper format. 
the tool implement this new approach the spock module be customise at this point to the asbru guideline specification language and exploit the hybrid structure of guideline in degel. 
the spock module also exploit our temporal abstraction mediator to the patient record idan and our interactive intelligent visualisation tool knave h.. 
national center for biomedical ontology advance biomedicine through structured organization of scientific knowledge. 
the national center for biomedical ontology be a consortium that comprise lead informatician biologist clinician and ontologist fund by the national institutes of health nih roadmap to develop innovative technology and method that allow scientist to record manage and disseminate biomedical information and knowledge in machine processable form. 
the goal of the center be one to help unify the divergent and isolated effort in ontology development by promote high quality open source standard base tool to create manage and use ontology two to create new software tool so that scientist can use ontology to annotate and analyze biomedical datum three to provide a national resource for the ongoing evaluation integration and evolution of biomedical ontology and associate tool and theory in the context of drive biomedical project dbp and four to disseminate the tool and resource of the center and to identify evaluate and communicate good practice of ontology development to the biomedical community. 
through the research activity within the center collaboration with the dbp and interaction with the biomedical community our goal be to help scientist to work more effectively in the e science paradigm enhance experiment design experiment execution datum analysis information synthesis hypothesis generation and testing and understand human disease. 
this paper be part of the special issue of omics on datum standard. 
on the analysis of the expansion and reduction of thin walled tube use a die. 
the production of sound thin walled tubular part by expansion and reduction use a die be generally limit to component have geometrical feature within a compact range. 
basic design rule relevant to process and die design be mainly derive from the accumulate experience of both manufacturer of tubular part and supplier of machine tool. 
however gap of knowledge can still be find in understand the influence of process parameter on material flow and in provide an adequate description of the mode of deformation that be associate with the formability limit induce by ductile fracture wrinkling and buckle. 
the aim of the present paper be to extend the actual knowledge on the expansion and reduction of thin walled tube use a die by mean of a comprehensive theoretical and experimental investigation. 
the theoretical investigation be support by axisymmetric and three dimensional numerical simulation base on the finite element flow formulation. 
the experimental work perform on aa6060 aluminium alloy tube consist of specially design test that be carry out under laboratory control condition with the intention of support and validate the overall investigation. 
demonstration of two novel method for predict functional sirna efficiency. 
background sirnas be small rna that serve as sequence determinant during the gene silence process call rna interference rnai. 
it be well know that sirna efficiency be crucial in the rnai pathway and the sirna efficiency for target different site of a specific gene vary greatly. 
therefore there be high demand for reliable sirnas prediction tool and for the design method able to pick up high silence potential sirnas. 
result in this paper two system have be establish for the prediction of functional sirnas one a statistical model base on sequence information and two a machine learning model base on three feature of sirna sequence namely binary description thermodynamic profile and nucleotide composition. 
both of the two method show high performance on the two dataset we have construct for train the model. 
conclusion both of the two method study in this paper emphasize the importance of sequence information for the prediction of functional sirnas. 
the way of denote a bio sequence by binary system in mathematical language might be helpful in other analysis work associate with fix length bio sequence. 
a knowledge base auto reasoning methodology in hole machining process planning. 
in process planning how to obtain an optimal process planning be the essential of computer aid process planning capp system. 
the main goal of capp system be to derive manufacturing feature and machine operation from a design model and sequence the machining operation of the part in a feasible by some technological constraint and effective by some economical standard order. 
in this paper we construct a process planning model pp model for the hole s machining which consist of three part the feature framework the precedent relation net and the sequence mathematical model. 
the feature framework make a mapping from manufacture feature of hole into its machining operation. 
a semantic net name the precedence relation net reflect the precedence relationship among hole s machining operation. 
some vector and matrix be employ to construct a mathematical sequencing model. 
usually a hole should be machine in several operation direction nu(1 nu(2 nu(m. 
in each operation direction nu(i there be m basic geometrical unit to be operate namely u 1(l u 2(l u n(l. 
for each operation direction nu(i a vector and a matrix be define to memory the process planning and its operation object. 
the mathematical sequence model will generate an optimal process planning in each operation direction by minimize the number of tool change and decrease the number of operation step. 
therefore it can shorten processing time and consume less energy. 
finally two hole machine example be employ to illustrate our methodology. 
c 2005 elsevier b.v. 
all right reserve. 
development of a fuzzy net base in process surface roughness adaptive control system in turn operation. 
this paper discuss the development of an in process surface roughness adaptive control system for a cnc turning operation use fuzzy net modeling and tool vibration measure with an accelerometer. 
the goal of this system be to predict the surface roughness of a surface be turn determine if the surface roughness be generate be high than the desire specification and if so to adapt the feed rate of the turning operation in order to obtain a surface roughness no high than that specify. 
fuzzy net model for prediction of surface roughness and adapt feed rate be train use feed rate spindle speed tangential vibration and measure surface roughness datum collect during experimental run. 
a series of validation run indicate that the system could successfully meet its goal both in detect out of spec surface roughness condition and adapt the machine tool to obtain a final surface roughness at or slightly below the desire surface roughness. 
c 2005 elsevier ltd. 
all right reserve. 
maximize sensitivity in medical diagnosis use biased minimax probability machine. 
the challenging task of medical diagnosis base on machine learning technique require an inherent bias the diagnosis should favor the ill class over the healthy class since misdiagnose a patient as a healthy person may delay the therapy and aggravate the illness. 
therefore the objective in this task be not to improve the overall accuracy of the classification but to focus on improve the sensitivity the accuracy of the ill class while maintain an acceptable specificity the accuracy of the healthy class. 
some current method adopt roundabout wavs to impose a certain bias toward the important class they try to utilize some intermediate factor to influence the classification. 
however it remain uncertain whether these method can improve the classification performance systematically. 
in this paper by engage a novel learn tool the biased minimax probability machine bmpm we deal with the issue in a more elegant way and directly achieve the objective of appropriate medical diagnosis. 
more specifically the bmpm directly control the bad case accuracy to incorporate a bias toward the ill class. 
moreover in a distribution free way the bmpm derive the decision rule in such a way as to maximize the bad case sensitivity while maintain an acceptable bad case specificity. 
by directly control the accuracy the bmpm provide a more rigorous way to handle medical diagnosis by derive a distribution free decision rule the bmpm distinguish itself from a large family of classifier namely the generative classifier where an assumption on the data distribution be necessary. 
we evaluate the performance of the model and compare it with three traditional classifier the k near neighbor the naive bayesian and the c4.5. 
the test result on two medical dataset the breast cancer dataset and the heart disease dataset show that the bmpm outperform the other three model. 
learn the relationship between patient geometry and beam intensity in breast intensity modulate radiotherapy. 
intensity modulate radiotherapy imrt have become an effective tool for cancer treatment with radiation. 
however even expert radiation planner still need to spend a substantial amount of time adjust imrt optimization parameter in order to get a clinically acceptable plan. 
we demonstrate that the relationship between patient geometry and radiation intensity distribution can be automatically infer use a variety of machine learning technique in the case of two field breast imrt. 
our experiment show that give a small number of human expert generate clinically acceptable plan the machine learn prediction produce equally acceptable plan in a matter of second. 
the machine learning approach have the potential for great benefit in site where the imrt planning process be more challenging or tedious. 
or and neuron and the development of interpretable logic model. 
in this paper we be concern with the concept of fuzzy logic network and logic base datum analysis realize within this framework. 
the network under discussion be homogeneous architecture comprise of or and neuron originally introduce by hirota and pedrycz. 
be treat here as generic processing unit or and neuron be neurofuzzy construct that exhibit well define logic characteristic and be endow with a high level of parametric flexibility and come with significant interpretation ability. 
the composite logic nature of the logic neuron become instrumental in cover a broad spectrum of logic dependency whose character spread in between between those be capture by plain and and or logic descriptor connective. 
from the functional standpoint the develop network realize a logic approximation of multidimensional mapping between unit hypercube that be transformation from n to m. 
the way in which the structure of the network have be form be highly modular and become reflective of a general concept of decomposition of logic expression and boolean function as be commonly encounter in two value logic. 
in essence give a collection of input variable select be their subset and transform into new composite variable which in turn be use in the consecutive module of the network. 
these intermediate synthetic variable be the result of the successive problem mapping decomposition. 
the development of the network be realize through genetic optimization. 
this help address important issue of structural optimization where we be concern with a selection of a subset of variable and their allocation within the network and reach a global minimum when carry out an extensive parametric optimization adjustment of the connection of the neuron. 
the paper offer a comprehensive and user interactive design procedure include a simple pruning mechanism whose intention be to enhance the interpretability of the network while reduce its size. 
the experimental study comprise of three part. 
first we demonstrate the performance of the network on boolean datum that lead to some useful comparative observation consider a wealth of optimization tool available in two value logic and digital system. 
second we discuss synthetic multivalue datum that help focus on the approximation ability of the network. 
finally show the generation of logic expression describe select datum set come from the machine learn repository. 
the p norm generalization of the lms algorithm for adaptive filtering. 
recently much work have be do analyze online machine learning algorithm in a bad case set where no probabilistic assumption be make about the datum. 
this be analogous to the h infinity setting use in adaptive linear filtering. 
bregman divergence have become a standard tool for analyze online machine learning algorithm. 
use these divergence we motivate a generalization of the least mean square lms algorithm. 
the loss bound for these so call p norm algorithm involve other norm than the standard two norm. 
the bound can be significantly well if a large proportion of the input variable be irrelevant if the weight vector we be try to learn be sparse. 
we also prove result for nonstationary target. 
we only know how to apply kernel method to the standard lms algorithm i.e. p two. 
however even in the general p norm case we can handle generalize linear model where the output of the system be a linear function combine with a nonlinear transfer function e.g. 
the logistic sigmoid. 
adaptive support vector regression analysis of closed loop inspection accuracy. 
this study investigate how closed loop measurement error in cnc milling relate to two different inspection technique. 
the on line inspection of machining accuracy use a spindle probe have an inherent shortcoming because the same machine that produce the part be use for inspection. 
in order to use the spindle probe measurement as a means of correct deviation in machining the magnitude of measurement error need to be quantify. 
the empirical verification be make by conduct three set of cut experiment at the state of the art cincinnati arrow vertical machining center. 
three different material type and parameter setting be select to simulate a diverse cutting condition. 
during the cutting the cut force and spindle vibration sensor signal be collect and a tool wear be record use a computer vision system. 
the bore tolerance be gauge by a spindle probe as well as a coordinate measure machine. 
the difference between the two measurement be define as a closed loop measurement error and adaptive support vector regression analysis be use to predict these bore difference at various value of the explanatory variable. 
the result show the potential of improve production efficiency and part quality. 
c 2005 elsevier ltd. 
all right reserve. 
map an iterative experimental design methodology for the optimization of catalytic search space structure modeling. 
one of the main problem in high throughput research for material be still the design of experiment. 
at early stage of discovery program purely exploratory methodology couple with fast screening tool should be employ. 
this should lead to opportunity to find unexpected catalytic result and identify the group of catalyst output provide well define boundary for future optimization. 
however very few new paper deal with strategy that guide exploratory study. 
mostly traditional design homogeneous covering or simple random sampling be exploit. 
typical catalytic output distribution exhibit unbalanced dataset for which an efficient learning be hardly carry out and interesting but rare class be usually unrecognized. 
here be suggest a new iterative algorithm for the characterization of the search space structure work independently of learn process. 
it enhance recognition rate by transfer catalyst to be screen from performance stable space zone to unsteady one which necessitate more experiment to be well model. 
the evaluation of new algorithm attempt through benchmark be compulsory due to the lack of past proof about their efficiency. 
the method be detailed and thoroughly test with mathematical function exhibit different level of complexity. 
the strategy be not only empirically evaluate the effect or efficiency of sample on future machine learning performance be also quantify. 
the minimum sample size require by the algorithm for be statistically discriminate from simple random sampling be investigate. 
processing and classification of protein mass spectra. 
among the many application of mass spectrometry biomarker pattern discovery from protein mass spectra have arouse considerable interest in the past few year. 
while research effort have raise hope of early and less invasive diagnosis they have also bring to light the many issue to be tackle before mass spectra base proteomic pattern become routine clinical tool. 
know issue cover the entire pipeline lead from sample collection through mass spectrometry analytic to biomorker pattern extraction validation and interpretation. 
this study focus on the data analytical phase which take as input mass spectra of biological specimen and discover pattern of peak masse and intensity that discriminate between different pathological state. 
we survey current work and investigate computational issue concern the different stage of the knowledge disco very process exploratory analysis quality control and diverse transform of mass spectra follow by further dimensionality reduction classification and model evaluation. 
we conclude after a brief discussion of the critical biomedical task of analyze discover discriminatory pattern to identify their component protein as well as interpret and valid eat their biological implication. 
c 2006 wiley periodicals inc.. 
support vector machine base fault diagnosis for turbo pump rotor. 
most artificial intelligence method use in fault diagnosis be base on empirical risk minimisation principle and have poor generalisation when fault sample be few. 
support vector machine svm be a new general machine learn tool base on structural risk minimisation principle that exhibit good generalisation even when fault sample be few. 
fault diagnosis base on svm be discuss. 
since basic svm be originally design for two class classification while most of fault diagnosis problem be multi class case a new multi class classification of svm name one to other algorithm be present to solve the multi class recognition problem. 
it be a binary tree classifier compose of several two class classifier organise by fault priority which be simple and have little repeat training amount and the rate of training and recognition be expedite. 
the effectiveness of the method be verify by the application to the fault diagnosis for turbo pump rotor. 
c 2005 elsevier ltd. 
all right reserve. 
part selection and operation machine assignment in a flexible manufacturing system environment a genetic algorithm with chromosome differentiation base methodology. 
production planning of a flexible manufacturing system fms be plague by two interrelated problem part type selection and operation allocation on machine. 
the combination of these problem be term the machine loading problem which be a well know complex puzzle and treat as a strongly np hard problem. 
in this research a machine loading problem have be model take into consideration several technological constraint relate to the flexibility of machine availability of machining time tool slot etc while aim to satisfy the objective of minimize the system unbalance maximize throughput and achieve very good overall fms utilization. 
the solution of such problem even for moderate number of part type and machine be mark by excessive computation complexity and therefore advanced random search and optimization technique be need to resolve they. 
in this paper a new kind of genetic algorithm term a genetic algorithm with chromosome differentiation have be use to address a well know machine loading problem. 
the proposed algorithm overcome the drawback of the simple genetic algorithm and the methodology report here be capable of achieve a well balance between exploration and exploitation and of escape from local minima. 
the propose algorithm have be test on ten standard test problem adopt from literature and extensive computational experiment have reveal its superiority over early approach. 
self regulate heater for microluidic reactor. 
the paper describe a self regulate heater base on epoxy laminate and ceramic as a solid support. 
a carbon paste with positive temperature coefficient ptc be use as a resistive material. 
the paste be screen print over inter digitised metallic track. 
apply constant voltage to the heater its resistance be increase and simultaneously the current flow through it be decrease up to an equilibrium state at a designate temperature. 
the work temperature of the heater be in the range from 30 to 70 degree c. 
the main advantage of the manufacturing of such a heater be its self regulation simplicity and low cost. 
c 2005 elsevier b.v. 
all tight reserve. 
an analysis of the residual stress generate in inconel 718 tm when turn. 
inconel 718 be one of a family of nickel base superalloy that be use extensively by the aerospace industry in the hot section of gas turbine engine. 
the literature detail the effect of vary operate parameter on tool life when machine nickel base superalloy be comprehensive however relatively little of this datum refer to their effect oil machine work piece surface integrity and residual stress generation. 
greater knowledge of the effect of operate parameter on surface integrity be critical to the acceptance of new cut tool material tool geometry and strategy. 
the paper initially review prior work on the surface integrity achieve when turn inconel 718. 
follow on from this a series of experiment evaluate the effect of vary cut tool material geometry wear level and operating parameter be detail. 
the result show that the large influence on surface integrity be tool wear. 
cut with a worn tool result in great microstructural deformation microhardness change and high surface tensile stress. 
high tensile stress be also form in the surface layer when cut with a coated tool while cut with an uncoated tungsten carbide insert at the same operating parameter produce deep compressive stress beneath a reduced tensile layer. 
c 2006 elsevier b.v. 
all right reserve. 
method of predict splice sites base on signal interaction. 
background predicting and proper ranking of canonical splice site ss be a challenging problem in bioinformatics and machine learning community. 
any progress in sss recognition will lead to well understanding of splicing mechanism. 
we introduce several new approach of combine a priori knowledge for improved ss detection. 
first we design our new bayesian ss sensor base on oligonucleotide counting. 
to far enhance prediction quality we apply our new de novo motif detection tool mhmmotif to intronic end and exon. 
we combine element find with sensor information use naive bayesian network as implement in our new tool splicescan. 
result accord to our test the bayesian sensor outperform the contemporary maximum entropy sensor for five ss detection. 
we report a number of putative exonic ese and intronic ise splicing enhancers find by mhmmotif tool. 
t test statistic on mouse rat intronic alignment indicate that detect element be on average more conserved as compare to other oligo which support our assumption of their functional importance. 
the tool have be show to outperform the spliceview genesplicer nnsplice genio and netutr tool for the test set of human gene. 
splicescan outperform all contemporary ab initio gene structural prediction tool on the set of five utr gene fragment. 
conclusion design method have many attractive property compare to exist approach. 
bayesian sensor mhmmotif program and splicescan tool be freely available on our web site. 
numerical modeling of the flow of organic fertilizer in land application equipment. 
the knowledge of the flow behaviour of organic fertilizer in land application equipment as well as the machine product interaction be very sparse and empirical and can hardly contribute to the design of innovative high performance system or to the optimization of the operational parameter of available machine. 
to assess the potential of use numerical modeling as a tool to optimize the design and operation of land application equipment the specific objective of the work report herein be to model the flow of organic fertilizer in such machine and to validate the model against various parameter measure during field experiment use commercial spreader. 
the discrete element method dem be use to simulate the flow of compost while computational fluid dynamic cfd be apply to sludge spread. 
input parameter for both modeling method be derive from physical and theological property of compost and sludge. 
the operation of a spreader feature dual vertical beater be first simulate and the ground distribution and power requirement obtain be consistent with publish result for that type of machine. 
two type of compost be model in simulation aim at study the effect of a flow control gate on the discharge flow and energy requirement of the discharge conveyor. 
dimensionless parameter be develop to allow for comparison to be make between the scale simulation and the experimental result obtain with a full size spreader. 
simulated result for the discharge flow in the open gate configuration be in good agreement with measure datum. 
the mass efficiency value for dry compost which represent a dimensionless measure of the discharge rate be 1.21 and 1.22 for the measured and simulated case respectively. 
the effect of the gate on the power requirement of the discharge conveyor be replicate by the model. 
fracture behaviour observe in the bulk of product during field experiment be also replicate by the model. 
two type of sludge exhibit different theological property be model use a cfd code. 
field experiment be carry out with a sludge spreader to measure the discharge rate of the spreader for these type of sludge. 
the simulated flow rate curve closely replicate the experimental one for both sludge type. 
the simulated streamline during the unloading of the spreader be also well correlate to observation make during field experiment. 
the flow of sludge on a spinning disc be study use high speed photography and a scale spreader physical model. 
the velocity of the sludge on the disc could be calculate use two different parameter measure on the image. 
it be find that the viscosity of the sludge influence the spread pattern. 
the flow of sludge on the disc be also numerically simulate with cfd. 
the simulated and measure residence time of the sludge on the disc be influence by the viscosity of the sludge and be in close agreement. 
the measured and simulated residence time for fluid pasty sludge be 0.021 and 0.025 s respectively. 
the measured and simulated value for plastic pasty sludge be 0.037 and 0.033 s respectively. 
the dem be successfully apply to the flow of compost and cfd be effectively use to model the flow of sludge in a land application machine. 
both numerical modeling technique show promise result and have the potential to become more accurate through more detailed simulation and improvement in the product constitutive model. 
c 2005 elsevier b.v. 
all right reserve. 
application of support vector machine technology for weed and nitrogen stress detection in corn. 
this study be conduct to evaluate the usefulness of a new method in artificial intelligence the support vector machine svm as a tool for classify hyperspectral image take over a corn zea mays l. field. 
the classification be perform with respect to nitrogen application rate and weed management practice and the classification accuracy be compare with those obtain by an artificial neural network ann model on the same datum. 
the field experiment consist of three nitrogen application rate and four weed management strategy. 
a hyperspectral image be obtain with a 72 waveband compact airborne spectrographic imager at an early growth stage during the year 2000 grow season. 
nitrogen application rate be 60 120 and 250 kg n ha. 
weed control be none control of grass control of broadleaf weed and full weed control. 
classification accuracy be evaluate for three case combination of nitrogen application rate and weed infestation level nitrogen application rate alone and weed control alone. 
the svm method result in very low misclassification rate as compare to the ann approach for a the three case. 
detection of stress in early crop growth stage use the svm method could aid in effective early application of site specific remedy to timely in season intervention. 
c 2006 elsevier b.v. 
all right reserve. 
a comparison of machine learn algorithm for dynamic scheduling of flexible manufacturing system. 
dispatching rule be frequently use to schedule job in flexible manufacturing system fmss dynamically. 
a drawback however to use dispatch rule be that their performance be dependent oil the state of the system but no single rule exist that be superior to all the other for all the possible state the system might be in. 
this drawback would be eliminate if the good rule for each particular situation could be use. 
to do this this paper present a scheduling approach that employ machine learning. 
use this latter technique and by analyse the early performance of the system scheduling knowledge be obtain whereby the right dispatching rule at each particular moment can be determine. 
three different type of machine learn algorithm will be use and compare in the paper to obtain scheduling knowledge inductive learning backpropagation neural network and case base reasoning cbr. 
a module that generate new control attribute allow well identification of the manufacturing system s state at any particular moment in time be also design in order to improve the scheduling knowledge that be obtain. 
simulation result indicate that the propose approach produce significant performance improvement over exist dispatch rule. 
c 2005 elsevier ltd. 
all right reserve. 
a unified log base relevance feedback scheme for image retrieval. 
relevance feedback have emerge as a powerful tool to boost the retrieval performance in content base image retrieval cbir. 
in the past most research effort in this field have focus on design effective algorithm for traditional relevance feedback. 
give that a cbir system can collect and store user relevance feedback information in a history log an image retrieval system should be able to take advantage of the log datum of user feedback to enhance its retrieval performance. 
in this paper we propose a unified framework for log base relevance feedback that integrate the log of feedback datum into the traditional relevance feedback scheme to learn effectively the correlation between low level image feature and high level concept. 
give the error prone nature of log datum we present a novel learning technique name soft label support vector machine to tackle the noisy datum problem. 
extensive experiment be design and conduct to evaluate the propose algorithm base on the corel image datum set. 
the promising experimental result validate the effectiveness of our log base relevance feedback scheme empirically. 
the application of multi agent system for step nc computer aid process planning of prismatic component. 
for many year manufacturing firm have be seek more efficient way of manufacture component with cnc machine. 
the emerge standard iso 14649 and iso 10303 ap238 present an opportunity to revolutionize the way cnc machine be traditionally program. 
these standard well know as step nc replace the traditional tool movement description language with hierarchical datum structure that allow a new breed of cnc to store part geometry together with the work step of the operation require to manufacture the part. 
step nc provide the ability to store and utilise high level and detailed information from the cad system to the intelligent step compliant cnc controller. 
with the advent of step nc computer aid process planning have become a critical link in the cax process chain with the major requirement to generate interoperable process plan. 
the author therefore believe it be necessary to redefine capp to reflect the change from the traditional tool movement base programming to step nc base programming. 
this paper examine the application of distribute artificial intelligence method namely collaborative multi agent system in design an object orient process planning system for prismatic component in a step nc compliant environment. 
the specification and design of a prototype system entitle the multi agent system for computer aided process planning mascapp be outline. 
two test component have be design process plan simulate oil the machine controller and finally machine to demonstrate the capability of the system and illustrate the activity require to implement step compliant manufacturing. 
c 2005 elsevier ltd. 
all right reserve. 
an ecoinformatic tool for microbial community study supervised classification of amplicon length heterogeneity alh profile of 16s rrna. 
support vector machine svm and k near neighbor knn be two computational machine learning tool that perform supervised classification. 
this paper present a novel application of such supervised analytical tool for microbial community profiling and to distinguish pattern among ecosystem. 
amplicon length heterogeneity alh profile from several hypervariable region of 16s rrna gene of cubacterial community from idaho agricultural soil sample and from chesapeake bay marsh sediment be separately analyze. 
the profile from all available hypervariable region be concatenate to obtain a combined profile which be then provide to the svm and knn classifier. 
each profile be label with information about the location or time of its sampling. 
we hypothesize that after a learning phase use feature vector from label alh profile both these classifier would have the capacity to predict the label of previously unseen sample. 
the result classifier be able to predict the label of the idaho soil sample with high accuracy. 
the classifier be less accurate for the classification of the chesapeake bay sediment suggest great similarity within the bay s microbial community pattern in the sample site. 
the profile obtain from the v1+v2 region be more informative than that obtain from any other single region. 
however combine they with profile from the vi region with or without the profile from the v3 region result in the most accurate classification of the sample. 
the addition of profile from the v9 region appear to confound the classifier. 
our result show that svm and knn classifier can be effectively apply to distinguish between eubacterial community pattern from different ecosystem base only on their alh profile. 
c 2005 elsevier b v. 
all right reserve. 
machine learn for direct marketing response model bayesian network with evolutionary programming. 
machine learning method be powerful tool for datum mining with large noisy database and give researcher the opportunity to gain new insight into consumer behavior and to improve the performance of marketing operation. 
to model consumer response to direct marketing this study propose bayesian network learn by evolutionary programming. 
use a large direct marketing datum set we test the endogeneity bias in the recency frequency monetary value rfm variable use the control function approach compare the result of bayesian network with those of neural network classification and regression tree cart and latent class regression and apply a tenfold cross validation. 
the result suggest that bayesian network have distinct advantage over the other method in accuracy of prediction transparency of procedure interpretability of result and explanatory insight. 
our finding lend strong support to bayesian network as a robust tool for model consumer response and other marketing problem and for assist management decision making. 
a sophisticated platform for characterization monitoring and control of machine. 
the potential for improve the performance of machine tool be considerable. 
however for this to be achieve without tool failure or product damage the process must be sufficiently well understand to enable real time monitoring and control to be apply. 
a unique sophisticated measurement platform have be develop and apply to two different machining centre particularly for high speed machining up to 24 000 rpm. 
characterization and on line monitoring of the dynamic behaviour of the machining process have be carry out use both contact base method accelerometer force sensor and non contact method laser doppler vibrometry and magnetic shaker and numerical simulation finite element base modal analysis. 
the platform be apply both pre process and on line for study an aluminium testpiece base on a thin walled aerospace component. 
stability lobe diagram for this specific machine component combination be generate allow selection of optimal process parameter give stable cutting and metal removal rate some eight 10 time high than those possible in unstable machining. 
base on dynamic characterization and monitoring a concept for an adaptive control with constraint base machine tool controller have be develop. 
the developed platform can be apply in manifold machining situation. 
it offer a reliable way of achieve significant process improvement. 
critical failure orc improve model accuracy through enhanced model generation. 
ensure robust patterning after opc be become more and more difficult due to the continuous reduction of layout dimension and diminish process window associate with each successive lithographic generation. 
lithographer must guarantee high imaging fidelity throughout the entire range of normal process variation. 
as a result post opc verification method have become indispensable tool for avoid pattern printing issue. 
a post opc verification technique know as critical failure optical rule check cforc be recently introduce and have prove its efficiency for detect potential printing issue through the entire process window s.d. 
shang et al proc. 
spie 5040 2003 j. 
belledent et al proc. 
spie 5377 2004 a. 
borjon et al proc. 
spie 5754 2005. 
this methodology use optical parameter from aerial image simulation at single process condition. 
a numerical model build use support vector machine svm principle the nature of statistical learning theory second ed springer 1995 correlate these optical parameter with experimental datum take throughout the process window to predict print failure. 
this statistical method however lead to some false prediction. 
although false prediction may be unavoidable in statistical methodology it be possible to lower their rate of occurrence. 
in this study concentrate on contact layer pattern for the 90 nm node and the poly layer pattern for the 65 nm node the accuracy of cforc model be improve through several approach enhance the normalization algorithm optimization of fitting parameter and optimize the parameter space coverage. 
c 2006 elsevier b.v. 
all right reserve. 
influence of coating substrate system on chip and burr formation in precision manufacturing. 
high precision of manufacture part and surface reduction of processing time with simultaneous increase of tool life and fully automate production be the major aim of research and development in the field of cut. 
in order to fulfil the high demand and in addition to ensure a high process reliability new method for theoretical investigation be require. 
however the continuous development of new cutting tool with a complex microgeometry cover with improved coating and apply to manufacturing of advanced material require high resolution simulation and non linear method. 
this paper deal with new investigation base on the finite element method fem. 
burr formation have be investigate with finite element fe and also experimentally and the influence of coating substrate system will be point out. 
integration of tool geometry in prediction of cut force during mill of hard material. 
knowledge of the cut force owe to a predictive model be very interesting with respect to the choice of a machine tool power the cutting tool the optimization of cut condition for a give machining operation or the control of the occurrence of vibration. 
it could also be helpful in online wear monitoring during mill. 
as this technique be usually base on a limit level of the cut force it could allow the number of long and expensive test to be limit and the good tool geometry to obtain quasi constant and low cutting force which lead to a reduce tool wear and consequently a well tool life to be find. 
the objective of this study be the prediction of the effect of the rake and helix angle on the cut force variation and to integrate it into a cut relation. 
test be make on x38 crmov five aisi h11 die and mould steel with solid carbide mill cutter of various rake angle. 
a specific configuration have be use to create obliquity. 
cut force be measure for various feed rate. 
the result have improve the cut force model make it possible to choose the optimal rake and helix angle in a particular machining operation. 
towards a theory of practice in metaheuristic design a machine learning perspective. 
a number of methodological paper publish during the last year testify that a need for a thorough revision of the research methodology be feel by the operation research community see for example barr et al j. 
heuristic one 1995 nine 32 eiben and jelasity proceedings of the 2002 congress on evolutionary computation cec 2002 582 587 hooker j. 
heuristic one 1995 33 42 rardin and uzsoy j. 
heuristic seven 2001 261 304. 
in particular the performance evaluation of nondeterministic method include widely study metaheuristic such as evolutionary computation and ant colony optimization require the definition of new experimental protocol. 
a careful and thorough analysis of the problem of evaluate metaheuristic reveal strong similarity between this problem and the problem of evaluate learn method in the machine learning field. 
in this paper we show that several conceptual tool commonly use in machine learning such as for example the probabilistic notion of class of instance and the separation between the training and the testing dataset fit naturally in the context of metaheuristic evaluation. 
accordingly we propose and discuss some principle inspire by the experimental practice in machine learning for guide the performance evaluation of optimization algorithm. 
among these principle a clear separation between the instance that be use for tune algorithm and those that be use in the actual evaluation be particularly important for a proper assessment. 
hybrid adaptive layer manufacturing an intelligent art of direct metal rapid tooling process. 
a direct metal rapid tool making process. 
hybrid layered manufacturing hlm be develop for build metallic die and mold. 
this unique methodology have a numerical control system that integrate the transpulse synergic metal inert gas mig)/metal active gas mag welding process for near net layer deposition and computer numerical control cnc milling process for net shaping. 
a customize software program be make to calculate the required adaptive slice thickness for the deposition of the filler metal with welding process as successive layer from the low to the topmost layer direction and to generate the require nc code for machining from the top to the bottom layer direction of the deposit metallic layer for attain the require contour profile shape. 
to implement this propose process a low cost three axis manipulator be fabricate with stepper motor diver in open loop control and integrate with the weld machine. 
adequate isolation to protect the motion control electronic from weld spike be incorporate. 
synchronization of this two step processing of each layer yield near net deposition with welding process and near net shaping with cnc mill operation offer a new accelerator way of build metal tool and die. 
c 2005 elsevier ltd. 
all right reserve. 
detection of non coding rnas on the basis of predict secondary structure formation free energy change. 
background non code rnas ncrnas have a multitude of role in the cell many of which remain to be discover. 
however it be difficult to detect novel ncrnas in biochemical screen. 
to advance biological knowledge computational method that can accurately detect ncrnas in sequenced genome be therefore desirable. 
the increase number of genomic sequence provide a rich dataset for computational comparative sequence analysis and detection of novel ncrnas. 
result here dynalign a program for predict secondary structure common to two rna sequence on the basis of minimize fold free energy change be utilize as a computational ncrna detection tool. 
the dynalign compute optimal total free energy change which score the structural alignment and the free energy change of fold into a common structure for two rna sequence be show to be an effective measure for distinguish ncrna from randomized sequence. 
to make the classification as a ncrna the total free energy change of an input sequence pair can either be compare with the total free energy change of a set of control sequence pair or be use in combination with sequence length and nucleotide frequency as input to a classification support vector machine. 
the latter method be much fast but slightly less sensitive at a give specificity. 
additionally the classification support vector machine method be show to be sensitive and specific on genomic ncrna screen of two different escherichia coli and salmonella typhi genome alignment in which many ncrnas be know. 
the dynalign computational experiment be also compare with two other ncrna detection program rnaz and qrna. 
conclusion the dynalign base support vector machine method be more sensitive for know ncrnas in the test genomic screen than rnaz and qrna. 
additionally both dynalign base method be more sensitive than rnaz and qrna at low sequence pair identity. 
dynalign can be use as a comparable or more accurate tool than rnaz or qrna in genomic screen especially for low identity region. 
dynalign provide a method for discover ncrnas in sequenced genome that other method may not identify. 
significant improvement in dynalign runtime have also be achieve. 
gopet a tool for automate prediction of gene ontology term. 
background vast progress in sequence project have call for annotation on a large scale. 
a number of method have be develop to address this challenging task. 
these method however either apply to specific subset or their prediction be not formalise or they do not provide precise confidence value for their prediction. 
description we recently establish a learning system for automated annotation train with a broad variety of different organism to predict the standardise annotation term from gene ontology go. 
now this method have be make available to the public via our web service gopet gene ontology term prediction and evaluation tool. 
it supply annotation for sequence of any organism. 
for each predict term an appropriate confidence value be provide. 
the basic method have be develop for predict molecular function go term. 
it be now expand to predict biological process term. 
this web service be available via http:// genius. 
embnet.dkfz heidelberg. 
de menu biounit open husar conclusion our web service give experimental researcher as well as the bioinformatics community a valuable sequence annotation device. 
additionally gopet also provide less significant annotation datum which may serve as an extended discovery platform for the user. 
a user friendly fuzzy base system for the selection of electro discharge machining process parameter. 
this paper introduce a user friendly intelligent system for the selection of electro discharge machining edm parameter. 
in this system. 
a compact selection method base on expert rule which be obtain from experimental result and extract from the knowledge of skilled operator be present. 
expert rule be evaluate by the fuzzy set theory. 
the develop fuzzy model use fuzzy expert rule triangular membership function for fuzzification and centroid area method for defuzzification process. 
the system be develop on a pc use matlab fuzzy logic toolbox. 
inevitably there be many machining parameter discharge current pulse duration pulse interval gap control flushing rate etc that should be consider in edm process. 
selection of these parameter be still an ill define problem and generally rely on heuristic which be not easy to model and base on the experience of specialist. 
in this system discharge current pulse duration and pulse interval be the input while the output be electrode wear surface roughness and erosion rate. 
the remain parameter be consider at constant rate during machine. 
the system be a compact and homemade tool that can be easily use by an average operator and provide the edm parameter which lead to less electrode wear well surface quality and more erosion rate accord to the select operation finishing roughing etc. 
c 2005 elsevier b.v. 
all right reserve. 
modelling fuel cell performance use artificial intelligence. 
over the last few year fuel cell technology have be increase promisingly its share in the generation of stationary power. 
numerous pilot project be operate worldwide continuously increase the amount of operating hour either as stand alone device or as part of gas turbine combine cycle. 
an essential tool for the adequate and dynamic analysis of such system be a software model that enable the user to assess a large number of alternative option in the least possible time. 
on the other hand the sphere of application of artificial neural network have widen cover such endeavour of life such as medicine finance and unsurprisingly engineering diagnostic of fault in machine. 
artificial neural network have be describe as diagrammatic representation of a mathematical equation that receive value input and give out result output. 
artificial neural network system have the capacity to recognise and associate pattern and because of their inherent design feature they can be apply to linear and non linear problem domain. 
in this paper the performance of the fuel cell be model use artificial neural network. 
the input to the network be variable that be critical to the performance of the fuel cell while the output be the result of change in any one or all of the fuel cell design variable on its performance. 
critical parameter for the cell include the geometrical configuration as well as the operating condition. 
for the neural network various network design parameter such as the network size train algorithm activation function and their cause on the effectiveness of the performance modelling be discuss. 
result from the analysis as well as the limitation of the approach be present and discuss. 
c 2005 elsevier b.v. 
all fight reserve. 
a multi step approach to time series analysis and gene expression clustering. 
motivation the huge growth in gene expression data call for the implementation of automatic tool for datum processing and interpretation. 
result we present a new and comprehensive machine learn datum mining framework consist in a non linear pca neural network for feature extraction and probabilistic principal surface combine with an agglomerative approach base on negentropy aim at cluster gene microarray datum. 
the method which provide a user friendly visualization interface can work on noisy datum with missing point and represent an automatic procedure to get with no a priori assumption the number of cluster present in the datum. 
cell cycle dataset and a detailed analysis confirm the biological nature of the most significant cluster. 
availability the software describe here be a subpackage part of the astroneural package and be available upon request from the corresponding author. 
contact robtag@unisa.it supplementary information supplementary datum be available at bioinformatics online. 
list mania interpret microarray result with the l2l server. 
a new server for interpret microarray result list to list l2l be describe. 
this tool offer a unique approach to understand the meaning of microarray result base on compare they to previously identify list of differentially express gene. 
the usefulness of the server be demonstrate by study differential expression in primary tumour versus metastasis in colon cancer. 
generalized approach for modeling minimally invasive surgery as a stochastic process use a discrete markov model. 
minimally invasive surgery mis involve a multidimensional series of task require a synthesis between visual information and the kinematic and dynamic of the surgical tool. 
analysis of these source of information be a key step in define objective criterion for characterize surgical performance. 
the blue dragon be a new system for acquire the kinematic and the dynamic of two endoscopic tool synchronize with the endoscopic view of the surgical scene. 
model the process of mis use a finite state model markov model mm reveal the internal structure of the surgical task and be utilize as one of the key step in objectively assess surgical performance. 
the experimental protocol include tie an intracorporeal knot in a mis setup perform on an animal model pig by 30 surgeon at different level of training include expert surgeon. 
an objective learning curve be define base on measure quantitative statistical distance similarity between mm of expert and mm of resident at different level of training. 
the objective learning curve be similar to that of the subjective performance analysis. 
the mm prove to be a powerful and compact mathematical model for decompose a complex task such as laparoscopic suturing. 
system like surgical robot or virtual reality simulator in which the kinematic and the dynamic of the surgical tool be inherently measure may benefit from incorporation of the propose methodology. 
robust classification of eeg signal for brain computer interface. 
we report the implementation of a text input application speller base on the p300 event relate potential. 
we obtain high accuracy by use an svm classifier and a novel feature. 
these technique enable we to maintain fast performance without sacrifice the accuracy thus make the speller usable in an online mode. 
in order to far improve the usability we perform various study on the datum with a view to minimize the training time require. 
we present datum collect from nine healthy subject along with the high accuracy of the order of 95 or more measure online. 
we show that the training time can be far reduce by a factor of two from its current value of about 20 min. 
high accuracy fast learning and online performance make this p300 speller a potential communication tool for severely disabled individual who have lose all other mean of communication and be otherwise cut off from the world provide their disability do not interfere with the performance of the speller. 
face recognition use optimal linear component of range image. 
this paper investigate the use of range image of face for recognize people. 
3d scan of face lead to range image that be linearly project to low dimensional subspace for use in a classifier say a near neighbor classifier or a support vector machine to label people. 
learn of subspace be perform use an optimal component analysis a stochastic optimization algorithm on a grassmann manifold to find a subspace that maximize classifier performance on the training image set. 
result be present for face recognition use fsu face database and be compare with standard component anlyse such as pca and ica. 
this provide an efficient tool for analyze certain aspect of facial shape while avoid a difficult task of geometric surface modeling. 
c 2005 elsevier b.v. 
all right reserve. 
fuzzy net base in process surface roughness adaptive control system in end mill operation. 
a fuzzy net base in process adaptive surface roughness control fn asrc system be develop to be able to adapt cut parameter in process and in a real time fashion to improve the surface roughness of machine part when the surface roughness quality be not meet customer requirement in the end mill operation. 
the fn asrc system be comprise of two sub system one fuzzy net in process surface roughness recognition fn ipsrr and two fuzzy net adaptive feed rate control fn afrc sub system. 
to test the system while the machining process be take place the fn ipsrr system predict the surface roughness which be then compare to the desire surface roughness. 
if the desire surface roughness be not meet then the fn afrc system propose a new feed rate for the machining process. 
once the feed rate be change and the cutting continue the output of the surface roughness of the new feed rate be compare with the desire surface roughness. 
this propose fn asrc system have be demonstrate to be successful use 25 experimental test with 100 success rate. 
an optimization base system for adaptive planning in a discrete part manufacture environment. 
an optimization base decision support tool that can be use for adaptive planning in a discrete part manufacturing environment be present in this paper. 
in adaptive planning the process plan be modify base on the status of the manufacturing system to achieve a high level of success in the production of part. 
modification to the process plan could be in the form of route change operational tolerance adjustment or generation of a new process plan. 
the mathematical model propose in this paper cover the first two case. 
solution to the mathematical model generate operational tolerance assign machine to operation provide a measure of process plan feasibility identify source of infeasibility recommend alternative machine and identify the require process capability to make an infeasible process plan feasible. 
experimental result confirm the effectiveness of the propose model. 
guide curve base interpolation scheme of parametric curve for precision cnc machining. 
real time parametric interpolation have play a key role in the computer control of machine tool. 
to achieve high quality part generate trajectory not only describe the desire toolpath accurately but also have smooth dynamic profile. 
this paper present a novel parametric interpolator base on guide curve. 
the relationship between geometric property and kinematic property be firstly discuss. 
then with a consideration of the important effect of the curvature of curvilinear path on the machine dynamic a corresponding formula which describe the relation of the maximum allow feed acceleration deceleration and the maximum allow rate of change of curvature radius of path be build. 
thus base on a near arc parameterization and through modify the curvature radius curve to deal with corner key region and other case adaptive feedrate schedule be complete accord to the reconstructed smooth curvature radius curve. 
consequently confine chord error corner on the path and the acceleration deceleration capability of the machine tool be simultaneously consider and incorporate into the guide curve base parametric interpolation system without use look ahead scheme. 
simulation result indicate the feasibility and precision of the propose interpolation method. 
c 2005 elsevier ltd. 
all right reserve. 
investigation of micro cut operation. 
the miniaturization of machine component be perceive by many as a requirement for the future technological development of a broad spectrum of product. 
miniature component can provide small footprint low power consumption and high heat transfer since their surface to volume ratio be very high. 
to create these component micro meso scale fabrication use miniaturized mechanical material removal process have a unique advantage in create 3d component use a variety of engineering material. 
the motivation for micro mechanical cutting stem from the translation of the knowledge obtain from the macro machining domain to the micro domain. 
however there be challenge and limitation to micro machining and simple scaling can not be use to model the phenomenon of micro machining operation. 
this paper survey the current effort in mechanical micro machining research and application especially for micro mill operation and suggest area from macro machining that should be examine and research for application to the improvement of micro machining process. 
c 2005 elsevier ltd. 
all right reserve. 
torque dependent compliance control in the joint space for robot mediate motor therapy. 
this paper be focus on the design of interaction control of robotic machine for rehabilitative motor therapy of the upper limb. 
the control approach try to address requirement derive from the application field and adopt a bioinspire approach for regulate robot behavior in the interaction with the patient. 
an inner outer loop control scheme be propose. 
in order to tune the level of force and improve robot adaptability in the interaction with the patient a classical outer force control loop be use. 
for the inner loop a novel control law for low level timing of robot compliance be introduce that be borrow from study on the biological mechanism for regulate the elastic property of the human arm. 
a dedicated simulation tool which model the dynamic of an operational robotic machine interact with a human subject have be develop. 
validation of basic adaptability and safety requirement of the control scheme be carry out in simple task reach and contact noncontact transition as well as in simulated situation of typical motor exercise. 
in particular the simulation test demonstrate the adaptive capability of the propose control scheme in counterbalance patient incorrect movement relate to the various level of disability. 
moreover preliminar experimental test carry out on a real robotic system demonstrate the possibility of use the propose approach for guarantee safe interaction with the patient. 
additive regularization trade off fusion of training and validation level in kernel method. 
this paper present a convex optimization perspective towards the task of tune the regularization trade off with validation and cross validation criterion in the context of kernel machine. 
we focus on the problem of tune the regularization trade off in the context of least square support vector machines ls svm for function approximation and classification. 
by adopt an additive regularization trade off scheme the task of tune the regularization trade off with respect to a validation and cross validation criterion can be write as a convex optimization problem. 
the solution of this problem then contain both the optimal regularization constant with respect to the model selection criterion at hand and the correspond training solution. 
we refer to such formulation as the fusion of training with model selection. 
the major tool to accomplish this task be find in the primal dual derivation as occur in convex optimization theory. 
the paper advance the discussion by relate the additive regularization trade off scheme with the classical tikhonov scheme. 
motivation be give for the usefulness of the former scheme. 
furthermore it be illustrate how to restrict the additive trade off scheme towards the solution path correspond with a tikhonov scheme while retain convexity of the overall problem of fusion of model selection and training. 
we relate such a scheme with an ensemble learning problem and with stability of learn machine. 
the approach be illustrate on a number of artificial and benchmark dataset relate the propose method with the classical practice of tune the tikhonov scheme with a cross validation measure. 
improve classification of mass spectrometry database search result use new machine learning approach. 
manual analysis of mass spectrometry datum be a current bottleneck in high throughput proteomic. 
in particular the need to manually validate the result of mass spectrometry database search algorithm can be prohibitively time consume. 
development of software tool that attempt to quantify the confidence in the assignment of a protein or peptide identity to a mass spectrum be an area of active interest. 
we seek to extend work in this area by investigate the potential of recent machine learn algorithm to improve the accuracy of these approach and as a flexible framework for accommodate new data feature. 
specifically we demonstrate the ability of boost and random forest approach to improve the discrimination of true hit from false positive identification in the result of mass spectrometry database search engine compare with thresholding and other machine learning approach. 
we accommodate additional attribute obtainable from database search result include a factor address proton mobility. 
performance be evaluate use publically available electrospray datum and a new collection of maldi datum generate from purified human reference protein. 
kernel method and the exponential family. 
the success of support vector machine svm have give rise to the development of a new class of theoretically elegant learning machine which use a central concept of kernel and the associated reproducing kernel hilbert space rkhs. 
exponential family a standard tool in statistic can be use to unify many exist machine learning algorithm base on kernel such as svm and to invent novel one quite effortlessly. 
a new derivation of the novelty detection algorithm base on the one class svm be propose to illustrate the power of the exponential family model in an rkhs. 
c 2005 publish by elsevier b.v.. 
far field noise survey use gps technology. 
interpretation of any sound level datum require knowledge about the distance from the source to the measurement location. 
measurement be often perform at distance of one to three m from the noise source. 
for this type of measurement it be not difficult to accurately determine short distance from any device. 
outdoor noise measurement of source such as large industrial facility may require sound measurement at distance of hundred to thousand of meter. 
these distance may be quite difficult to determine use traditional length measurement tool such as a tape measure or wheeled ruler. 
this paper discuss the use of a low cost global positioning system gps receiver during the acoustical survey of a very loud and large source a portable rock crush machine. 
a comparison of the measured and compute excess attenuation term be make. 
estimate of the measurement uncertainty associate with different gps technology be use to determine which gps system should be use over what range of distance. 
c institute of noise control engineering. 
pm modelling overview and industry standpoint. 
finite element modelling be widely use in technological application. 
the benefit of use simulation be clear reduce time and cost when introduce new product to market well knowledge of part dynamic and static property and the opportunity to replace life cycle machine test among other. 
unfortunately powder metallurgy do not yet belong to this select club. 
much effort have be put into simulate powder filling compaction and sintering the hard material and ceramic industry be more interested in modelling of sinter than ferrous part maker whose main concern be compaction and in a further step fill process. 
however to date none of the model for powder compaction can effectively meet part maker requirement with respect to tool life and crack prediction. 
the progress towards these goal in dienet be briefly review. 
exploration of rough set theory use for manufacturing process monitoring. 
the ability to automate and implement active prediction of a degradation process and potential failure of critical machine component be a press concern in modern manufacturing. 
the increase prediction reliability and significant cost saving potential have stimulate the introduction of numerous artificial intelligence technique into the manufacturing arena. 
the need to explore and understand the capacity of these new method be extremely important to define their suitable application. 
this paper explore use of a classifier base on rough set theory rst. 
the result show very good performance over several criterion in a cut tool wear monitoring application. 
automatic maintenance payload on board of a mexican leo microsatellite. 
few research institution from mexico work together to finalize the integration of a technological demonstration microsatellite call satex aim the launching of the first ever fully design and manufacture domestic space vehicle. 
the project be base on technical knowledge gain in previous space experience particularly in develop gascan automatic experiment for nasa s space shuttle and in some support obtain from the local team which assemble the mexico oscar 30 microsatellite. 
satex include three autonomous payload and a power subsystem each one with a local microcomputer to provide intelligent and dedicated control. 
it also contain a flight computer fc with a pair of full redundancy. 
this enable the remote maintenance of processing board from the ground station. 
a fourth communication payload depend on the flight computer for control purpose. 
a fifth payload be decide to be develop for the satellite. 
it add value to the available on board computer and extend the opportunity for a develop country to learn and to generate domestic space technology. 
its aim be to provide automatic maintenance capability for the most critical on board computer in order to achieve continuous satellite operation. 
this paper present the virtual computer architecture specially develop to provide maintenance capability to the flight computer. 
the architecture be periodically implement by software with a small amount of physical processor fc processor and virtual redundancy payload processor to emulate a hybrid redundancy computer. 
communication among processor be accomplish over a fault tolerant lan. 
this allow a versatile operating behavior in term of datum communication as well as in term of distribute fault tolerance. 
obtain result payload validation and reliability result be also present. 
c 2005 elsevier ltd. 
all right reserve. 
use cellular automata image and pseudo amino acid composition to predict protein subcellular location. 
the avalanche of newly find protein sequence in the post genomic era have motivate and challenge we to develop an automate method that can rapidly and accurately predict the localization of an uncharacterized protein in cell because the knowledge thus obtain can greatly speed up the process in find its biological function. 
however it be very difficult to establish such a desire predictor by acquire the key statistical information bury in a pile of extremely complicated and highly variable sequence. 
in this paper base on the concept of the pseudo amino acid composition chou k. 
c. 
proteins structure function and genetics 2001 43 246 255 the approach of cellular automata image be introduce to cope with this problem. 
many important feature which be originally hide in the long amino acid sequence can be clearly display through their cellular automata image. 
one of the remarkable merit by do so be that many image recognition tool can be straightforwardly apply to the target aim here. 
high success rate be observe through the self consistency jackknife and independent dataset test respectively. 
xkey a tool for the generation of identification key. 
this paper present the development of xkey a tool for generate taxonomical identification key by mean of decision tree construction. 
the tool be base on an xml standard for the representation of general taxonomical information which make it ideal for different field of application. 
the article analyse the problem by examine the adaptation of machine learn technique to the sphere of biology so as to incorporate the viewpoint of biologist and computer science expert. 
it also analyse the effect of use various division criterion on a set of real datum the gymnosperm plant group present in the iberian peninsula. 
c 2005 elsevier ltd. 
all right reserve. 
fuzzy mule induction in a set covering framework. 
class of algorithm and their correspond knowledge representation for the induction of fuzzy logic classification rule include for example cluster and fuzzy decision tree. 
this paper introduce a new class of induction algorithm base on fuzzy set cover principle. 
we present a set covering framework for concept learning use fuzzy set and develop an algorithm fuzzybexa base on this approach to induce fuzzy classification rule from datum. 
unlike the induction of fuzzy decision tree that follow a divide and conquer strategy this algorithm perform a separate and conquer general to specific search of the instance space. 
we show that the description language allow a partial ordering of candidate hypothesis lead to a lattice of conjunction to be search. 
property of the lattice allow the develoment of new heuristic to guide the search for good concept description and to terminate the search early enough in the induction process. 
the operation of the algorithm be illustrate and then compare with other well know crisp and fuzzy machine learning algorithm. 
the result show that highly accurate and comprehensible rule be induce and that this methodology be an important new tool in the arsenal of fuzzy machine learning algorithm. 
semantic web services in factory automation fundamental insight and research roadmap. 
one of the significant challenge for current and future manufacturing system be that of provide rapid reconfigurability in order to evolve and adapt to mass customization. 
this challenge be aggravate if new type of process and component be introduce as exist component be expect to interact with the novel entity but have no previous knowledge on how to collaborate. 
this statement not only apply to innovative process and device but be also due to the impossibility to incorporate knowledge in a single device about all type of available system component. 
this paper propose the use of semantic web services in order to overcome this challenge. 
the use of ontology and explicit semantic enable perform logical reasoning to infer sufficient knowledge on the classification of process that machine offer and on how to execute and compose those process to carry out manufacturing orchestration autonomously. 
a series of motivating utilization scenario be illustrate and a research roadmap be present. 
webguard a web filter engine combine textual structural and visual content base analysis. 
along with the ever grow web come the proliferation of objectionable content such as sex violence racism etc. 
we need efficient tool for classify and filter undesirable web content. 
in this paper we investigate this problem and describe webguard an automatic machine learning base pornographic web site classification and filter system. 
unlike most commercial filter product which be mainly base on textual content base analysis such as indicative keyword detection or manually collect black list checking webguard rely on several major datum mining technique associate with textual structural content base analysis and skin color relate visual content base analysis as well. 
experiment conduct on a testbed of 400 web site include 200 adult site and 200 nonpornographic one show webguard s filter effectiveness reach a 97.4 percent classification accuracy rate when textual and structural content base analysis be combine with visual content base analysis. 
further experiment on a black list of 12,311 adult web site manually collect and classify by the french ministry of education show that web(guard score a 95.62 percent classification accuracy rate. 
the basic framework of webguard can apply to other categorization problem of web site which combine as most of they do today textual and visual content. 
a step ap224 agent base early manufacturability assessment environment use xml. 
early design assessment activity have a significant impact on reduce the cost of manufacture. 
the efficient utilisation of the product development time and the level of coordination of the early design activity between the major stakeholder be become key factor for success in manufacturing today. 
the paper report on a new distribute early design manufacturability assessment methodology use collaborative autonomous agent. 
a product data model compliant with step ap224 and corresponding process and facility datum model be propose to support the decision making process. 
xml be use as a medium for exchange of request and information between design manufacturing and facility planning agent. 
a prototype web enable system for rapid product manufacturability assessment in the extended enterprise have be develop use distribute multi agent corba object. 
the reported research be a step towards the development of a generic prototype tool for collaborative design evaluation and rapid assessment of the manufacture feasibility and resource availability at different stage of the product development process. 
fuzzy similarity base rough set method for case base reasoning and its application in tool selection. 
case base reasoning cbr embody in die and mold nc machining will extend the application of knowledge base system by utilize previous case and experience. 
however redundant feature may not only dramatically increase the case memory but also make the case retrieval algorithm more complicated. 
additionally traditional method of feature weighting limit the development of cbr methodology. 
this paper present a novel methodology to apply fuzzy similarity base rough set algorithm in feature weighting and reduction for cbr system. 
the algorithm be use in tool selection for die and mold nc machining. 
the propose method do not need to discretize continuous or real value feature include in case from which can effectively reduce information loss. 
the weight of feature a(i be compute base on the difference of its dependency define as gamma(a gamma(a) ({ai which also represent the significance of the correspond feature. 
if the difference be equal to zero the feature be consider to be redundant and should be remove. 
finally a case study be also implement to prove the propose method. 
c 2005 elsevier ltd. 
all right reserve. 
use machine learning to guide architecture simulation. 
an essential step in design a new computer architecture be the careful examination of different design option. 
it be critical that computer architect have efficient mean by which they may estimate the impact of various design option on the overall machine. 
this task be complicate by the fact that different program and even different part of the same program may have distinct behavior that interact with the hardware in different way. 
researcher use very detailed simulator to estimate processor performance which model every cycle of an execute program. 
unfortunately simulate every cycle of a real program can take week or month. 
to address this problem we have create a tool call simpoint that use datum cluster algorithm from machine learning to automatically find repetitive pattern in a program s execution. 
by simulate one representative of each repetitive behavior pattern simulation time can be reduce to minute instead of week for standard benchmark program with very little cost in term of accuracy. 
we describe this important problem the datum representation and preprocesse method use by simpoint the cluster algorithm at the core of simpoint and we evaluate different option for tune simpoint. 
volumetric error compensation of multi axis laser machine center for direct patterning of flat panel display. 
a new direct laser pattern system for improve the quality of the pattern on the glass substrate of large flat panel displays fpd be develop which consist of the laser machining center the laser measurement system and the adaptive rotational mirror system. 
the new system be distinguish from the exist system by its control mechanism which compensate for the laser beam error cause by the volumetric error of the multi axis machine. 
the new system in comparison with exist system which control each stage of multi axis use a fast steering mirror fsm and adaptive laser optic to compensate for the error of the laser beam on the substrate. 
through this study a mathematical model of the volumetric error of the multi axis laser machining center be develop to quantify the geometric and the kinematic error of each machine axis and their contribute effect on the substrate. 
the information contain in the mathematical model be express in a volumetric error matrix. 
far a mathematical model of the beam delivery be develop to measure the beam delivery on the substrate and its effect on. 
the quality of the patterning. 
the patterning error be correct by use an fsm which have two rotational angle. 
the viability of the propose scheme be demonstrate through simulation and experiment. 
edm process adaptation system in toolmake industry. 
a design adaptation system for machine in toolmaking dasmt be propose in order to avoid the knowledge cap between product and tool designer. 
the focus of the present paper on the development of the design adaptation system for edm das edm. 
this system help the designer to check the viability of individual feature to their machinability by edm process. 
the system reveal feature which be critical for edm machining and make suggestion to the designer to alter the feature by keep the overall functionality of the product. 
c 2005 elsevier b.v. 
all right reserve. 
characterise the behaviour of workpiece under the effect of tangential cut force during nc turning application to machining of slender workpiece. 
turn slender workpiece usually mean a tailstock centre have to be use to in order to achieve geometric tolerance for cylindricality. 
indeed tight tolerance mean the grind phase can be perform quick or even render superfluous. 
to limit use of the tailstock centre that limit tool access when produce slender workpiece use turning knowledge of the spindle chuck workpiece assembly s behaviour be essential. 
it be propose to characterise this assembly s behaviour under the action of machine load in order to introduce a method that in some case will dispense with the need to use the tailstock centre while keep the geometric quality of the machined workpiece. 
c 2005 elsevier b.v. 
all right reserve. 
combination of multimodal imaging and molecular genetic information to investigate complex psychiatric disorder. 
multimodal imaging the combination of several brain imaging technique in one subject provide a wealth of parameter and favour the interpretation of complex model in schizophrenia research. 
moreover new imaging tool allow the investigation of distinct neurotransmitter system and their modulation by pharmacological intervention. 
an important feature of multimodal imaging be the possibility to characterize the activation dependency of different neurotransmitter and provide the experimental tool to test system model of brain function and dysfunction. 
the combination of measurement technique with high temporal resolution e.g. 
meg eeg and high spatial resolution e.g. 
fmri facilitate the understanding of local and global system as well as time characteristic. 
moreover the association of image parameter with genetic variation of neurotransmitter system allow the investigation of neurotransmitter activity and its role in the pathophysiology of schizophrenia. 
to overcome the limitation of standard statistical method new approach in machine learning have to be adapt to handle multiple parameter obtain from brain imaging and genetic measurement. 
will my protein crystallize a sequence base predictor. 
we propose a machine learn approach to sequence base prediction of protein crystallizability in which we exploit subtle difference between protein whose structure be solve by x ray analysis or by both x ray and nuclear magnetic resonance nmr spectroscopy and those protein whose structure be solve by nmr spectroscopy alone. 
because the nmr technique be usually apply on relatively small protein sequence length distribution of the x ray and nmr dataset be adjust to avoid prediction bias by protein size. 
as feature space for classification we use frequency of mono di and tripeptide represent by the original 20 letter amino acid alphabet as well as by several reduced alphabet in which amino acid be group by their physicochemical and structural property. 
the classification algorithm be construct as a two layered structure in which the output of primary support vector machine classifier operate on peptide frequency be combine by a second level naive bayes classifier. 
due to the application of metamethod for cost sensitivity our method be able to handle real dataset with unbalanced class representation. 
an overall prediction accuracy of 67 be achieve in a 10 fold cross validation experiment indicate that the propose algorithm may be a valuable tool for more efficient target selection in structural genomic. 
discover semantic feature in the literature a foundation for build functional association. 
background experimental technique such as dna microarray serial analysis of gene expression sage and mass spectrometry proteomic among other be generate large amount of datum relate to gene and protein at different level. 
as in any other experimental approach it be necessary to analyze these datum in the context of previously know information about the biological entity under study. 
the literature be a particularly valuable source of information for experiment validation and interpretation. 
therefore the development of automate text mining tool to assist in such interpretation be one of the main challenge in current bioinformatics research. 
result we present a method to create literature profile for large set of gene or protein base on common semantic feature extract from a corpus of relevant document. 
these profile can be use to establish pair wise similarity among gene utilize in gene protein classification or can be even combine with experimental measurement. 
semantic feature can be use by researcher to facilitate the understanding of the commonality indicate by experimental result. 
our approach be base on non negative matrix factorization nmf a machine learn algorithm for datum analysis capable of identify local pattern that characterize a subset of the datum. 
the literature be thus use to establish putative relationship among subset of gene or protein and to provide coherent justification for this cluster into subset. 
we demonstrate the utility of the method by apply it to two independent and vastly different set of gene. 
conclusion the present method can create literature profile from document relevant to set of gene. 
the representation of gene as additive linear combination of semantic feature allow for the exploration of functional association as well as for cluster suggest a valuable methodology for the validation and interpretation of high throughput experimental datum. 
snosid a proteomic method for identification of cysteine s nitrosylation site in complex protein mixture. 
reversible addition of no to cys sulfur in protein a modification term s nitrosylation have emerge as a ubiquitous signaling mechanism for regulate diverse cellular process. 
a key first step toward elucidate the mechanism by which s nitrosylation modulate a protein s function be specification of the target cys sno cys residue. 
to date s nitrosylation site specification have be laboriously tackle on a protein by protein basis. 
here we describe a high throughput proteomic approach that enable simultaneous identification of sno cys site and their cognate protein in complex biological mixture. 
the approach term snosid sno site identification be a modification of the biotin swap technique jaffrey s. 
r. erdjument bromage h. ferris c. 
d. tempst p. 
snyder s. 
h. 
2001 nat. 
cell. 
biol. 
three 193 197 comprise biotinylation of protein sno cys residue trypsinolysis affinity purification of biotinylate peptide and amino acid sequence by liquid chromatography tandem ms. 
with this approach 68 sno cys site be specify on 56 distinct protein in s nitrosoglutathione treat two 10 mu m rat cerebellum lysate. 
in addition to enumerate these s nitrosylation site the method reveal endogenous sno cys modification site on cerebellum protein include alpha tubulin beta tubulin gapdh and dihydropyrimidinase relate protein two. 
whereas these endogenous sno protein be previously recognize we extend prior knowledge by specify the sno cys modification site. 
consider all 68 sno cys site identify a machine learning approach fail to reveal a linear cys flank motif that predict stable transnitrosation by s nitrosoglutathione under test condition suggest that undefined 3d structural feature determine s nitrosylation specificity. 
snosid provide the first effective tool for unbiased elucidation of the sno proteome identify cys residue that undergo reversible s nitrosylation. 
automatic discovery of cross family sequence feature associate with protein function. 
background method for predict protein function directly from amino acid sequence be useful tool in the study of uncharacterised protein family and in comparative genomic. 
until now this problem have be approach use machine learning technique that attempt to predict membership or otherwise to predefine functional category or subcellular location. 
a potential drawback of this approach be that the human designate functional class may not accurately reflect the underlie biology and consequently important sequence to function relationship may be miss. 
result we show that a self supervise data mining approach be able to find relationship between sequence feature and functional annotation. 
no preconceive idea about functional category be require and the training datum be simply a set of protein sequence and their uniprot swiss prot annotation. 
the main technical aspect of the approach be the co evolution of amino acid base regular expression and keyword base logical expression with genetic programming. 
our experiment on a strictly non redundant set of eukaryotic protein reveal that the strong and most easily detect sequence to function relationship be concern with target to various cellular compartment which be an area already well study both experimentally and computationally. 
of more interest be a number of broad functional role which can also be correlate with sequence feature. 
these include inhibition biosynthesis transcription and defence against bacteria. 
despite substantial overlap between these function and their correspond cellular compartment we find clear difference in the sequence motif use to predict some of these function. 
for example the presence of polyglutamine repeat appear to be link more strongly to the transcription function than to the general nuclear function location. 
conclusion we have develop a novel and useful approach for knowledge discovery in annotated sequence datum. 
the technique be able to identify functionally important sequence feature and do not require expert knowledge. 
by view protein function from a sequence perspective the approach be also suitable for discover unexpected link between biological process such as the recently discover role of ubiquitination in transcription. 
computational approach to support large scale analysis of photoreceptor enrich gene expression. 
retinal photoreceptor cell be responsible for light detection and phototransduction. 
the understanding of molecular mechanism regulate photoreceptor gene expression during retinal development may have important implication in clinical neuroscience. 
use self adaptive neural network and pattern validation statistical tool this paper explore large scale analysis of photoreceptor gene expression. 
base on the analysis of datum generate by serial analysis of gene expression sage in the develop mouse retina significant expression pattern for the in silico detection of photoreceptor enrich gene be reveal. 
this study demonstrate how machine learning and statistical technique may be effectively combine to detect key complex relationship encode in sage datum. 
such approach may support inexpensive functional prediction prior to the application of experimental methodology. 
machine learn technique to enable closed loop control in anesthesia. 
the grow availability of high throughput measurement device in the operating room make possible the collection of a huge amount of datum about the state of the patient and the doctor practice during a surgical operation. 
this paper explore the possibility of extract from these datum relevant information and pertinent decision rule in order to support the daily anesthesia procedure. 
in particular we focus on machine learning strategy to design a close loop. 
controller that in a near future could play the role of a decision support tool and in a further perspective the one of automatic pilot of the anesthesia procedure. 
two strategy direct and inverse for learn a controller from observed datum be assess on the basis of a database of measurement collect in recent year by the ulb erasme anaesthesiology group. 
the preliminary result of the learning approach apply to the regulation of hypnosis through the bispectral index bis in a simulated framework appear to be promise and worthy of future investigation. 
the development of a distribute surface machining system. 
this paper focus on the development of a distribute surface machining system. 
traditional manufacturing engineering activity analysis have be conduct in develop the propose system structure. 
the advantage of a distribute system structure such as easy to manage high expandability and flexibility will enhance the efficiency of an integral system operation and achieve the goal of networked manufacture. 
the idef0 be use to describe each stage of the traditional surface machining activity and then uml unified modeling language technology be adopt to verify the feasibility and accuracy of the establish integrate system. 
the developed distribute system structure and sub functional module cad cam capp haze be implement base on the propose systematic approach and a freeform surface have be use as an example for verification. 
the propose approach have be successfully implement and could be adopt to assist engineer in integrate machining activity that be locate in disperse place and various domain expert also can exchange their expertise among themselves. 
thus the development time of a product machining process can be shorten and so be its enhancement on the competitive advantage. 
in addition i this distribute system have also integrate multi functional ontology and service agent to facilitate the selection and reconfiguration in manufacture customization. 
the propose system have present the feasibility in incorporate the agent base technology in a distribute freeform surface machining environment. 
service agent communicate via pre defined performative underlie knowledge query and manipulation language kqml for the surface machining capability. 
the develop system have then successfully demonstrate the feasibility in implement the agent base technology into a distribute surface machining system. 
study of machine error forecast in nc lathe. 
this paper bring forward a kind of machine error forecast principle in nc lathe simulation system. 
it combine the method of math dynamic material and mechanism etc sum up the factor which can affect the machining error coalescent knowledge of mechanism manufacture technique and interconvert characteristic map the change of physics factor in cut process into virtual manufacture system by mathematical model. 
on the platform of windows 2000 and visual c apply program be develop by use of c. 
the lean warehouse of matlab be transfer in order to command matlab on the language platform of matlab and then the curve of the result be draw by the outcome of calculation which be base on the mathematical model in order to manifest the simulation result in the pattern of datum and curve. 
a hybrid artificial neural network base scheduling knowledge acquisition algorithm. 
it be a key issue that construct successful knowledge base to satisfy an efficient adaptive scheduling for the complex manufacturing system. 
therefore a hybrid artificial neural network ann base scheduling knowledge acquisition algorithm be present in this paper. 
we combine genetic algorithm ga with simulated anneal sa to develop a hybrid optimization method i in which ga be introduce to present parallel search architecture and sa be introduce to increase escape probability from local optima and ability to neighbor search. 
the hybrid method be utilize to resolve the optimal attribute subset of manufacture system and determine the optimal topology and parameter of ann under different scheduling objective ann be use to evaluate the fitness of chromosome in the method and generate the scheduling knowledge after obtain the optimal attribute subset optimal ann s topology and parameter. 
the experimental result demonstrate that the propose algorithm produce significant performance improvement over other machine learning base algorithm. 
development of a reconfigurable platform for manufacture equipment control. 
in modern manufacturing equipment control area controller be require to deliver high computing capability for adopt advanced algorithm to meet speed and accuracy requirement and reconfigurabilitie for change or and add feature or function. 
this paper present a methodology in design and implementation of a high performance and reconfigurable platform for manufacture equipment control. 
this methodology be in virtue of system on a programmable chip sopc technology but replace the on chip processor by an external high performance float point digital signal processor dsp. 
the application of the dsp be design as a multi threaded framework which have more flexibility than a traditional single loop one. 
furthermore the field programmable gate array fpga system can be reconfigure easily and quickly to meet a new requirement by drag and drop pre build component in a sopc building environment. 
as a result the controller platform be more reconfigurable in term of algorithm and function. 
this platform be implement in a three axis mill machine control and the result indicate that the design and implementation present in this paper be feasible. 
research on framework of digital process planning platform. 
digital factory technology be a research focus in academe and industry which be an advanced manufacturing technology that be propose to bridge product development and manufacturing. 
for apply digital factory technology in machine domain a concept of digital process planning and its framework be suggest its component include machine domain knowledge model machine knowledge base machine resource base and process planning system be study. 
the framework of digital process planning be of value for implement digital factory technology in machine industry. 
the utilisation of peer to peer technique in autonomous mobile phone device management efficient framework for advanced device self management. 
this contribution aim at automate an increasingly complex and expensive task of real time introspection and inspection of large scale distribute system like a mobile phone fleet by use state of art machine learn probabilistic reasoning and information theoretic approach. 
achieve advanced device self manage adsm capability in end to end reconfigurable mobile phone system and network be a central goal of e(2)r2 which be consider an inevitable next step in the evolution of today s management tool like the open mobile alliance oma device management dm. 
this framework be so far predominantly target towards the update of already sell mobile by the device manufacturer. 
another main aspect be the provisioning of operator dependent setting. 
give the incredible rapid growth in network size complexity and consider desire ability like dynamic spectrum management for spectrum trading move the management plane to a high abstraction layer be essential to keep track. 
this paper focus on the enable peer to peer p2p routing and collaborate basis as a common knowledge foundation. 
organization orient chemical programming for the organic design of distribute computing system. 
biochemical information processing find in nature be know to be robust self organize adaptive decentralize asynchronous fault tolerant and evolvable. 
a couple of approach be already use the chemical metaphor such as gamma mgs amorphous computing membrane computing and reaction diffusion processor. 
however in accordance with conrad s tradeoff principle program a chemical computer appear to be difficult. 
therefore in order to far exploit the mention property new programming technique be require. 
here we describe how chemical organization theory can serve as a tool for chemical programming. 
the theory allow to predict the potential behavior of a chemical program and thus support a programmer in the design of a chemical like control system. 
the approach be demonstrate by apply it to the maximal independent set problem. 
we show that the desire solution be predict by the theory as chemical organization. 
furthermore the theory uncover undesirable organization represent uncompleted halting computation due to insufficient amount of molecule. 
finally we discuss an architecture for a chemical virtual machine. 
integration of multimodal multimedia device and hardcopy textbook for support pervasive learning. 
the sharable content object reference model scorm be a specification toward a standard for asynchronous distance learning. 
it be widely use in the development of author tool learn management system lmss and repository for distance learning content. 
most learning relate system be base on multimedia and web technology on pc. 
we aim to build a pervasive learning environment which allow learner to read scorm compliant textbook with integration of the multimodal multimedia device. 
we call it hard scorm. 
a pen like ocr optical character reader device call hyper pen be use as an input mechanism. 
a computer a pda or a cellular phone can be integrate with the scorm compliant textbook for present the multimedia learning resource. 
with respect to the learner behavior while read hardcopy textbook we propose a hard scorm machine for supervise the proper interaction perform. 
therefore user can read hardcopy textbook in a traditional manner while behavior of reading be compatible with the scorm specification. 
critical voltage monitoring use sensitivity and optimal information machine learning. 
this paper be motivate by the basic need to develop method for on line detection of abnormal condition in large electric power system. 
in order to implement truly effective near automate tool for this purpose it be necessary to overcome several problem such as one excessive computational complexity b unacceptable approximation and three dependence on full state measurement. 
in an attempt to overcome these major roadblock we combine tool capable of produce accurate result over broad range of condition such as off line datum mining and machine learning with the approximate well understand deterministic method such as sensitivity base method. 
the result approach indirectly overcome the dependence on full state measurement the actual choice of the most relevant measurement become a result of such a combined approach. 
the propose approach be illustrate on an example of detect a give voltage threshold violation. 
a generic large scale simulator for ubiquitous computing. 
the complexity associate to gather and process contextual datum make testing mobile context aware application and service difficult. 
furthermore the lack of standard data set and simulation tool make the evaluation of machine learning algorithm in context aware setting an even hard task. 
to ease the situation we introduce a generic simulator that have be design with the above mention purpose in mind. 
the simulator have also prove to be a good demonstration tool for mobile service and application that be aim at group. 
the simulator be highly customizable and it can output context information of individual entity both through an interactive gui and as datum stream consist of comma separate value. 
to support a wide range of task and scenario we have separate the three main information source behavior of agent the scenario be simulate and the use context variable. 
the simulator have be implement use java and the datum stream have be make available through a web service interface. 
support vector machine for nonlinear system on line identification. 
neural network be a very popular black box identification tool. 
but it suffer some weakness for nonlinear on line identification. 
for example the learning process can only arrive local minima. 
the training algorithm be slow. 
support vector machine svm can overcome these problem. 
but the svm need all datum to find optimal solution it be not suitable for online identification. 
in this paper we propose a new method to use svm for on fine identification. 
we call it as recursive support vector machine rsvm where the kernel be not depend on all datum it be calculate by a recursive method the svm be also recursive. 
so we can realize on line identification via svm. 
two example be propose to compare our rsvm with normal svm. 
a tool for intelligent customer analytic. 
business collect and keep large volume of customer datum as part of their process. 
analysis of this datum by business user often lead to discovery of valuable pattern and trend that otherwise would go unnoticed and that can lead to prioritization of decision on future investment. 
the majority of tool currently available to business user be typically limit to compute summary statistic simple visualization and reporting of datum. 
more complex tool that could offer possible explanation for observation discover knowledge or allow make prediction be usually aim at an academic audience or at user who be highly train in analytic. 
however it be business user with little experience in analytic who require access to tool that allow they to easily model customer behavior and build future scenario. 
in this paper we present a tool we develop for business user to perform advanced analysis on customer datum. 
next generation bioimaging system. 
the question i would like to help answer be what be the role and what can image do for system biology in recent year the focus in biological science have shift from understand single part of large system sort of vertical approach to understand complex system at the cellular and molecular level horizontal approach. 
thus the revolution of omic project genomic and now proteornic. 
understand complexity of biological system be a task that require acquisition analysis and sharing of huge database and in particular high dimensional database. 
for example in the current project on location proteomic the fluorescence microscopy datum set can have a dimension as high as five two spatial dimension z stack time series and different color channel different color probe for different protein. 
process such huge amount of bioimage visually by biologist be inefficient time consume and effor prone. 
therefore we would like to move towards automate efficient and robust processing of such bioimage datum set. 
moreover some information hide in the image may not be readily visually available. 
for example in the same project we use image of two protein reside in the golgi apparatus giantin and gpp130. 
these two protein can not be distinguish well than randomly by human while when employ datum mining method they can be tell apart. 
therefore we do not only replace human by machine for fast and more efficient processing but also because new knowledge be generate through use of sophisticated algorithm. 
the ultimate dream be to have distribute yet integrate large bioimage database which would allow researcher to upload their datum have it process share the data download. 
datum as well as platform optimize code etc and all this in a common format something akin to the dicom format for clinical imaging. 
to achieve this goal we must draw upon a whole host of sophisticated tool from signal processing machine learning and scientific computing. 
while such tool be widely present in clinical medical imaging they be not as widespread in imaging of biological system at cellular and molecular level. 
this be a huge challenge and require integration of interdisciplinary team. 
i will address some of these issue in this presentation. 
a novel online learn algorithm of support vector machine. 
support vector machine svm have be prove as powerful tool in wide variety of learn problem but it be confront with the problem of a large amount of computation. 
in this paper the exist online learn algorithm of svm have be discuss in detail we analysis the possible change of support vector after new sample be add a novel online learn algorithm of svm be present. 
the experimental result be give to show that the accuracy of approach be comparable to the batch algorithm effectively keep classification accuracy discard useless old sample and save the memory. 
fuzzy logic thermal error compensation for computer numerical control noncircular turnne system. 
with the new emerge technology of high performance machining and the increase demand for improved machining accuracy in recent year the problem of thermal deformation of machine tool structure be become more critical than ever. 
the computer numerical control cnc turn system for noncircular section piston be design with giant magnetostrictive actuator gma as the turning module. 
when the temperature of the cooler system of the gma vary for about six degree c the dimension error of the surface contour vary for about 20 micron and can not meet the precision requirement of the piston s contour dimension. 
in this paper a method use fuzzy logic control for the compensation of the thermally induce error be develop. 
the fuzzy rule be use to compensate directly for the nonlinearity and uncertainty of the cooler system. 
the rule development strategy for the compensation system be to change the feed quantity of gma to control the tool the piston dimension. 
the fuzzy logic control develop here be a two input single output controller. 
the two input be the temperature deviation from setpoint error and error rate. 
the output be the compensated value of the feed system. 
the triangular membership function be use to define the input linguistic variable and the output linguistic variable. 
the fuzzy logic approach incorporate many advantage of use fuzzy logic such as the incorporation of heuristic knowledge ease of implementation and the lack of a need for an accurate mathematical model. 
the experimental result be present and the effectiveness of the fuzzy thermal error compensation control technique be discuss. 
accuracy be greatly improve use the develop error compensation system. 
intelligent fault identification base on wavelet packet energy analysis and svm. 
in the machinery fault diagnosis field many new and powerful method play the important role in improve the veracity and the reliability. 
fault feature extract be the premise for the fault diagnosis. 
wavelet packet transform wpt be a mathematical tool that have a special advantage over the traditional fourier transform in analyze non stationary signal. 
it adopt redundant basis function and hence can provide an arbitrary time frequency resolution. 
the signal be decompose into different frequency band with the wpt then the energy percent of every frequency band component be calculate as the fault detection index. 
in this paper the fault signal be sample from one gear with pit fault. 
accord to the characteristic of the gear pitting signal decompose the signal with the wpt and the change of the energy percent in the frequency band include the gear natural frequency will be use as the fault index. 
fault style identification be the other vital issue of the fault diagnosis process. 
support vector machine svm be a new general machine learn tool for classification forecasting and estimation in small sample case. 
the principle and the process of gear pitting identification use svm be present. 
this paper only show the availability for pit fault diagnosis with the integration of the wpt and svm but the conclusion be also flexible for other machinery fault style classification. 
functional prediction of snake neurotoxin. 
snake neurotoxin be important experimental tool in pharmacological research. 
over the year the number of snake neurotoxin sequence identify be increase at a very fast pace. 
however only a small portion of they be experimentally characterize from more than 200,000 variant estimate to exist in nature. 
in this paper we report a systematic functional analysis on snake neurotoxin use a statistical machine learning method near neighbour approach for functional prediction together with a set of rule. 
base on this method we build a highly accurate functional prediction tool for putative annotation for snake nettrotoxin. 
data mining method for protein protein interaction. 
in this paper recent bioinformatics method use datum mining technique be present to analyze protein protein interaction datum gather from recent large scale biological study. 
novel approach be suggest to tackle some of the challenge in this area. 
protein protein interaction datum can provide a wealth of information to well understand the biology of a cell. 
the analysis of these interaction be also important for the discovery of disease associate protein. 
the datum can also he use for the identification of novel cellular site that be crucial for the development of new and improved pharmaceutical drug. 
knowledge discovery and data mining kdd be the process of extract implicit information from large amount of datum use mathematical and statistical method. 
it grow in synergy with computer technology create new analytical tool and use they for knowledge discovery in large volume of datum. 
a multidisciplinary science and technology with link in statistic machine learning datum base system and computer programming and visualization kdd have prove to be a promising solution to various problem in molecular biology and gene analysis. 
an overview of various datum mining technique be present in this paper with specific example of their application in protein protein interaction datum analysis. 
while some of the most widely use datum mining technique for explore protein interaction datum set be cluster include supervised and unsupervised classification and association rule discovery other be base on method for mining interaction information from scientific source such as pubmed and medline. 
there be area such as prediction and profiling that have not be explore much for mining information in protein protein interaction. 
we propose method to employ these novel technique to analyze protein protein interaction datum. 
advanced image exploitation tool for surveillance and target detection with eo sensor. 
to well assist image analyst in deal with an increase volume of datum the optronic surveillance data exploitation group at drdc valcartier develop cut edge software tool for change detection classification atd atr. 
this paper present an overview of some activity focus on image coregistration with the automated multi sensor image registration amir software a comparison of the classification performance of various reasoning sheme implement in the fuzzy reasoning for image intelligence furii toolbox and an assesment of the capability of the holographic neural technology to perform incremental learning. 
creative activity model for handle surprise in asymmetric attack. 
asymmetric warfare today have become a mean for less militarily advanced troop to battle against the more militarily advanced one. 
this may also be extend onto civilian ground and many of these attack have lead to priceless loss of life and social well be. 
one of the common characteristic of many of these attack be the element of surprise. 
those who carry out the attack normally try their good to ensure that no one know what or where the attack be to take place in order to ensure the high degree of damage. 
in this work we propose a framework for develop a decision support tool for defence personnel in deal with this kind of threat. 
the framework integrate three well know machine learning concept result from research in artificial intelligence and machine learning. 
by reasoning base on the historical attack pattern the use of the propose framework allow one to realise what may happen give a set of previous act and a set of factor currently observe. 
local information base overlaid text detection by classifier fusion. 
when implement in hardware image processing algorithm should be robust to memory limitation because some hardware architecture may not have memory size as large as the whole frame size. 
although this be not generally a problem for low level processing high level understanding such as object detection demand novel solution because the available information may in some case be very local only a partial view of the object could fit in the available memory size. 
in this paper we propose a novel hardware orient overlaid text detection algorithm that can detect text with height as large as five time the memory size. 
the algorithm integrate a connected component cc) base algorithm with a texture base machine learning approach. 
the cc base algorithm use character level feature in the horizontal direction whereas the texture base algorithm extract block base feature to integrate information from all direction. 
furthermore the texture base algorithm employ a support vector machine svm to benefit from the strength of machine learning tool. 
in order to detect text of large font size we also propose a novel hardware orient height preserve multi resolution analysis. 
finally the result of the two classifier as well as color and edge cue be use for the final pixel base text non text decision. 
a hybrid mpi simulator. 
performance analysis of large scale application and predict the impact of architectural change on the behavior of such application be difficult. 
traditional approach to measure application usually change their behavior require recompilation and need specialized tool to extract performance information. 
often the tool be program language specific and not suitable for all application. 
if instead an application be to be model to gather the same kind of information then in depth knowledge of the application be require. 
furthermore parameter that control the behavior of the application on a specific machine have to be adjust often in way that be more art than science. 
in this paper we describe an approach that be a hybrid between run a parallel application in stand alone mode and simulate the network it use for am datum exchange. 
the discrete event network simulator be execution drive by the application. 
we explain how our early prototype work and how it can be use. 
we mention several experiment that we have already perform with this prototype and show its potential for future research. 
fusion model and human machine collaborative solution for automate sensory inspection system. 
manufacturing process be actually alive because the factor of the process change continuously and suddenly. 
in response to the change problem sophisticated knowledge of skilled human expert have be apply to solve they flexibly. 
however this kind of solution be subjective inconsistent and dependent on certain expert. 
deskilling be a key to realize stable manufacturing with reasonable quality cost and delivery. 
many type of automate system have be deploy at the manufacturing process for realize the deskilling. 
however there still remain problem in flexibility against the change. 
in this article an automate sensory inspection system be employ to discuss the problem and the flexible solution against the change. 
base on the discussion two type of solution be propose. 
the first one be fusion model and the second human machine collaborative decision make. 
both solution be consider the datum distribution maturity in the manufacturing line. 
transductive support vector classification for rna relate biological abstract. 
support vector machines use a set of related supervised learning method for classification and regression. 
when use for classification the svm algorithm create a hyper plane that separate the datum into two class with the maximum margin. 
give positive and negative training example a maximum margin hyper plane be identify where it split the positive from the negative example while maximize the margin. 
transductive inference enhance the learning process by attempt to achieve the low error rate possible give a small sample of training example. 
in this research we develop a set of software tool to convert scientific abstract into support vector that could be use with an implementation of support vector machine call svm light to classify the abstract. 
three distinct classification experiment be conduct first to classify abstract about rna research out of a set of randomly select abstract. 
second to classify abstract about specific type of rna research out of a set of abstract that all contain the expression rna. 
third to classify trna mrna snrna and rrna abstract individually out of a set of abstract pertain to the four category of rna. 
support vector regression base tool wear assessment in face mill. 
in this work an accurate method for real time assessment of tool wear in face milling base on the cut force signal use support vector machine learning be present. 
new combination of signal processing technique be use to extract relevant signal feature which be robust against random process variation external chance disturbance and presence of outlier from the acquire datum. 
relationship between the extract feature and the observed value of tool wear be build use the support vector regression technique. 
this machine learn algorithm be accurate and robust for estimation of complex and non linear relationship among the process variable. 
grid search method be adopt to select the optimum model parameter. 
the develop model be validate on unseen testing datum for their predict capability. 
significant result be obtain use the propose method for both laboratory and industrial datum. 
a multimedia system for route sharing and video base navigation. 
trip planning and in vehicle navigation be crucial task for easy and safe driving. 
the exist navigation system be base on machine intelligence without allow human knowledge incorporation. 
these system give turn guidance with abstract visual instruction and have not reach the potential of minimize driver s cognitive load which be the amount of mental processing power require. 
in this paper we describe the development of a multimedia system that make driving and navigation safe and easy by offer tool for route sharing in trip planning and video base route guidance during drive. 
the system provide a multimodal interface for a user to share his her route with other by draw on a digital map naturally incorporate human knowledge into the trip planning process. 
the system give drive instruction by overlay navigational arrow onto live video and provide synthesized voice to reduce the driver s cognitive load in addition to present landmark image for key maneuver. 
we describe our observation which have motivate the development of the system detailed architecture and user interface and finally discuss our initial test finding in the real road drive context. 
label disambiguation and sequence modeling for identify human activity from wearable physiological sensor. 
wearable physiological sensor can provide a faithful record of a patient s physiological state without constant attention of caregiver. 
a computer program that can infer human activity from physiological recording will be an valuable tool for physician. 
in this paper we investigate to what extent current machine learning algorithm can correctly identify human activity from physiological sensor. 
we far identify two challenge that developer need to address. 
the first problem be that the label of training datum be inevitably noisy due to difficulty of annotate thousand hour of datum. 
the second problem lie in the continuous nature of human activity which violate the independence assumption make by many learning algorithm. 
we approach the first problem of noisy labeling in the multiple label framework and develop a conditional markov models to take temporal context into consideration. 
we evaluate the propose method on 12,000 hour of the physiological recording. 
the result show that support vector machines be effective to identify human activity from physiological signal and effort of disambiguate noisy label be worthwhile. 
real option approach to find optimal stop time in compact genetic algorithm. 
the real option technique have emerge as an evaluation tool for investment under uncertainty. 
it explicitly recognize future decision and the exercise strategy be base on the optimal decision in future period. 
the real option approach have be apply to many economic and financial problem but few be in computer science and engineering. 
the novelty of this work lie in apply real option to a computational problem. 
this paper propose use the real option technique to find an optimal stopping decision for the compact genetic algorithm. 
the compact genetic algorithm a kind of genetic algorithm represent the population as a probability distribution over a set of solution. 
this distribution automatically capture the underlying uncertainty of the problem which can be simulate to obtain an evolutionary process of the algorithm. 
the experiment show preliminary result of employ the real option approach to determine the optimal stopping time for the compact genetic algorithm. 
the propose technique can be apply to analyze other machine learning algorithm such as neural network or other variation of genetic algorithm. 
debris flow hazard assessment base on support vector machine. 
debris now hazard assessment be a basic work of hazard monitoring forecast alleviation and control. 
seven factor include the maximum volume of once now l1 occurrence frequency of debris flow l2 watershed area s1 main channel length s2 watershe relative height difference s3 valley incision density s6 and the length ratio of sediment supplement s9 be choose as evaluation factor of debris flow hazard degree. 
use support vector machine svm theory 259 basic datum of 37 debris flow channel in yunnan province be select as learn sample in this study then a kind of debris now hazard assessment model base on svm be produce. 
first instance application give encourage result. 
after cross validation test accuracy of this model come to 70.00. 
through verify seven group of test datum classification accuracy come to 85.71. 
the model show that it have the advantage of good generation convenience and high precision. 
svm be regard as a broadly applicative tool in debris flow hazard assessment. 
model selection via bilevel optimization. 
a key step in many statistical learning method use in machine learning involve solve a convex optimization problem contain one or more hyper parameter that must be select by the user. 
while cross validation be a commonly employ and widely accept method for select these parameter its implementation by a grid search procedure in the parameter space effectively limit the desirable number of hyper parameter in a model due to the combinatorial explosion of grid point in high dimension. 
this paper propose a novel bilevel optimization approach to cross validation that provide a systematic search of the hyper parameter. 
the bilevel approach enable the use of the state of the art optimization method and their well support software. 
after introduce the bilevel programming approach we discuss computational method for solve a bilevel cross validation program and present numerical result to substantiate the viability of this novel approach as a promising computational tool for model selection in machine learning. 
boosted modified probabilistic neural network bmpnn for network intrusion detection. 
most of the currently available network security technique be not able to cope with the dynamic and increasingly complex nature of the attack on distribute computer system. 
an automated and adaptive defensive tool be imperative for computer network. 
one of the emerge solution for network security be the intrusion detection system ids. 
however this technology still face some challenge such as low detection rate high false alarm rate and requirement of heavy computational power. 
to overcome these difficulty this paper propose an innovative machine learning algorithm call boosted modified probabilistic neural network bmpnn which utilize semi parametric learning model and adaptive boost technique to reduce learn bias and generalization variance in difficult classification. 
in this paper bmpnn be implement as a classifier to detect different type of network anomaly in the kdd 99 benchmark. 
extensive experimental outcome indicate that the propose bmpnn outperform other state of the art learning algorithm in term of detection accuracy and model robustness at an affordable computational cost. 
an autonomous diagnostic and prognostic framework for condition base maintenance. 
this paper present an innovative on line approach for autonomous diagnostic and prognostic. 
it overcome limitation of current diagnostic and prognostic technology by develop a generic framework that be relatively independent of the type of physical equipment under consideration. 
propose diagnostics and prognostics framework dpf be base on unsupervised learning method reduce the need for human intervention. 
the procedure use in dpf be design to temporally evolve the critical parameter with monitoring experience for enhance diagnostic prognostic accuracy a critical ability for mass deployment of the technology on a variety of equipment/ hardware without need extensive initial tune up. 
this framework be currently under deployment in a major automotive manufacture plant in michigan usa. 
result from this pilot program to date be very satisfactory. 
computation intelligence tool for modeling and control pharmacogenomic system genetic programming and neural network. 
pharmacogenomic system pg be very high dimensional nonlinear and stiff system. 
mathematical modeling of these system as system of nonlinear couple ordinary differential equation ode be consider important for understand they unfortunately it be also a very difficult task. 
at least as important be to adequately control they through input which be drug dosage regimen. 
in this paper we investigate new approach base on compuational intelligence tool genetic programming gp and neural network nn for these difficult task. 
we use gp to automatically write the model structure in a computer programming language c++ and to optimize the model s constant. 
in some circumstance the propose method not only give an accurate mathematical model of the pg system but they also give insight into the subjacent molecular mechanism. 
we also show that nn feedback linearization fbl can adequately control these system with or without a mathematical model. 
the drug dosage regiman will determine the output of the system to track very wen a therapeutic objective. 
to our knowledge this be the first time when a very large class of complex pharmacological problem be formulate and solve in term of gp modeling and nn modeling and control. 
adaptive force control in high speed machining by use a system of neural network. 
the contribution discuss the use of combine the method of neural network fuzzy logic and pso evolutionary strategy in modeling and adaptively control the process of ball end milling. 
a combination of off line feedrate optimization and on line adaptive force control be use to maintain a reference peak cut force during end mill for safe accurate and efficient machining. 
the basic control principle be base on the neural control scheme unks consist of two neural identiricator of the process dynamic and primary artificial controller. 
design parameter for the adaptive controller be select use an experimentally validate machining process model. 
the controller be successfully apply to computer numerical control cnc mill machine heller. 
experiment have confirm efficiency of the adaptive control system which reflect in improve surface quality and decrease tool wear. 
comparison of ans nema and iec requirement for low voltage motor control center. 
if engineering design we be able to apply either iec or nema style product we need to know the difference between nema and iec design. 
both style design have feature and benefit designer criterion will be guide in obtain the optimum design for particular case. 
the proper motor and motor control center selection require to know many criterion for select they. 
effective selection of modern motor control center mcc require a strong work knowledge of rotate machine basic as well as an in depth awareness of the late technical development. 
when a few motor starter be need they be typically instal within a standardized vertical enclosure with all the required relay instrument and control that require of an effective deep knowledge of the standard for the correct installation. 
this paper present a revision and summarize reflexive of the state of the art for proper mcc selection to show the work present in this area in way of take out a practical guide for the correct design of mcc and develop a methodology as tool for the design establish for this a comparison of the american standard ansi nema and the international standard iec for particular case. 
towards the adaptation of a robotic wheelchair for cognitive disabled child. 
in this paper we describe the adaptation of an autonomous robotic wheelchair for cognitive disabled child. 
the constraint impose by these user require develop specific human machine interface adapt to their limitation. 
in most case it be necessary to develop additional tool to teach the child the spatial relation between the wheelchair its motion and the environment. 
in addition to this it be important to interact closely with the child and their educator. 
the paper describe the whole process follow to make the child use the autonomous wheelchair and the lesson learn during the validation phase with the wheelchair and the child. 
performance improvement of track control for a planar parallel robot use synchronize control. 
in order to improve trajectory tracking accuracy for a three degree of freedom dof planar parallel robot in this paper we develop a new control approach base on adaptive control with the use of the so call synchronization error. 
similar to the contour error propose for machine tool the define synchronization error represent the degree of coordination amongst the active joint in the parallel robot which be substantially different from the traditional tracking error. 
by use the synchronization error all active joint in the parallel robot be control to move in a synchronous manner so that the trajectory tracking accuracy of the robot end effector be substantially improve. 
in addition with the use of adaptive control the synchronization error and the pose error of the platform be guarantee to converge to zero simultaneously while uncertain parameter in the system dynamic model be guarantee to converge to their true value. 
experiment conduct on the planar parallel robot verify the above claim and evaluate performance of the propose control approach compare with conventional pid control. 
behavior base web page evaluation. 
this paper describe our effort to investigate factor in a user s browse behavior to help automatically evaluate web page that the user show interest in. 
to evaluate a web page automatically we have develop a client side logging analyze tool the ginis framework. 
we do not focus on click scroll navigation or duration of visit alone but we propose integrate these pattern of interaction to recognize and evaluate a user s response to a give web page. 
unlike most previous web study that have analyze access see at proxy or server this work focus primarily on client site user behavior use a customize web browser. 
first ginis unobtrusively gather log of user behavior through the user s natural interaction with the web browser. 
then it analyse the log and extract effective rule to evaluate web page use a machine learn method eventually ginis will be able to automatically evaluate web page use these learn rule after which the evaluation can be utilize in a variety of user profiling. 
wetcat web enabled translation use corpus base acquisition of transfer rule. 
in this paper we present a web interface to a japanese english rule base machine translation system. 
one main feature of our translation system be that the transfer rule have not be design by hand but be learn automatically from a parallel corpus. 
the user can customize the rule base by simply correct translation result. 
in addition it be possible to display token list parse tree and transfer rule which make our system also a very useful tool for language student. 
the system have be implement in amzi prolog use the amzi logic server cgi interface to develop the web application. 
a hybrid backpropagation network base scheduling knowledge acquisition algorithm. 
it be a key issue that construct a successful knowledge base to satisfy an efficient adaptive scheduling for the complex manufacturing system. 
so a hybrid backoropagation bp) based scheduling knowledge acquisition algorithm be present in this paper. 
we combine genetic algorithm ga with simulated anneal sa to develop a hybrid optimization method in which ga be introduce to present parallel search architecture and sa be introduce to increase escape probability from local optima and ability to neighbor search. 
the hybrid method be utilize to resolve the optimal attribute subset of manufacture system and determine the optimal topology and parameter of bp under different scheduling objective bp be use to evaluate the fitness of chromosome in the method and generate the scheduling knowledge after obtain the optimal attribute subset optimal bp topology and parameter. 
the experimental result demonstrate that the propose algorithm produce significant performance improvement over other machine learning base algorithm. 
particle swarm optimization base svm application power transformer incipient fault syndrome diagnosis. 
base on statistical learning theory support vector machine svm have be well recognize as a powerful computational tool for problem with nonlinearity have high dimensionality. 
in this paper we present a successful adoption of the particle swarm optimization pso algorithm to improve the performance of svm classifier for the purpose of incipient fault syndrome diagnosis of power transformer. 
a pso base encoding technique be apply to improve the accuracy of classification. 
the propose scheme remove irreverent input feature that may be confuse the classifier and optimize the kernel parameter simultaneously. 
experiment on real operational datum demonstrate the effectiveness and high efficiency of the propose approach which make operation fast and also increase the accuracy of the classification. 
statechart base elevator controller and its verification. 
for design modern automation system event drive complex reactive system which continuously react to external stimulus it be necessary to define guideline method and tool that allow to carry out the design within an overall development methodology that permit to specify these system in an easy and safe way to maintain traceability along the different phase of the design and to have the need knowledge about the behavior of the define system. 
basic issue relate to current specification technology have be discuss in. 
a methodology base on statechart have be propose in and to be present in the same conference. 
the current paper describe the present status of our work in validate this methodology on the control of an elevator system. 
an elevator system be usually equip with a fairly large number of sensor make it a real scale application but simple enough to serve in demonstrate the basic principle involve with clarity. 
entire system be design use state chart and implement in a programmable logic device. 
to demonstrate the feasibility a prototype system be simulate use micro controller and the result be present in the paper. 
however in this implementation statechart be only use as formal specification of control which provide the basis for functional decomposition of the program into communicate finite state machines fsm port structure propose in for reconfigurable implementation be not yet incorporate. 
hence the current paper discuss primary issue of modular controller implementation use statechart specification. 
verification have be do by simulate the controller on pic 16f877 mc in proteous six for select operation. 
formal verification methodology of will be validate in the next stage of this research. 
hardware implementation of traffic controller use fuzzy expert system. 
this paper present the design of traffic controller hardware use fuzzy expert system algorithm for traffic light control purpose. 
the process use the knowledge base of a fuzzy system rule base and parameter. 
this knowledge base system aspect make the design more simple and efficient especially when compare with traditional trial and error method. 
a functional fuzzy traffic controller ftc which utilise fuzzy logic algorithm to achieve a smart and a flexible knowledge base system in hardware design while achieve well efficiency in the traffic control and minimize traffic jam occurrence at interchange on road area. 
we describe a hardware platform for evolve system by use knowledge base of a fuzzy system to develop the system the behaviour level of ftc algorithm have develop use very high speed integrated circuit vhsic hardware description language vhdl under max+plus h cad environment. 
the finite state machine fsm of the ftc have be code in vhdl program for control the specific traffic flow application. 
later on the fpga express synthesis tool have use to get a fully gate level synthesis architecture for the whole fuzzy base hardware chip. 
the design code of the ftc have download onto the upi fpga field programmable gate array educational board altera flex10 k for verify the ftc hardware chip functionality. 
the performance of an expert fuzzy system base chip for control traffic tight be evaluate. 
a numerical test platform for large synchronous machine also useful as a design optimization tool. 
this paper deal with the determination of large synchronous machine characteristic quantity use an extended 2d finite element method and base on the knowledge of the geometry and of the physical property of the electrical and magnetic circuit of the machine. 
in this respect sudden no load three phase short circuit and short circuit in the quadrature axis under load condition at cos phi zero be simulate in rotation use a numerical virtual test platform. 
the saturation effect the eddy current in the damper circuit and in the rotor solid iron part be take into account. 
the result of these two test lead to all characteristic quantity in both axis of the machine. 
other test can be perform on this numerical test platform standstill frequency response dc decay low speed symmetrical and asymmetrical load test which can also be use as a design optimization tool. 
comparison between calculation and measurement for three large exist unit turbo generator hydro generator be present. 
a web architecture for datum mining in biology. 
in this paper we present a current cooperative work involve different institute around the world. 
our aim be to provide an online inductive logic programming tool. 
this be the first step in a more complete structure for enable e technology for machine learning and bio informatic. 
we describe the main architecture of the project and how the datum will be format for be send to the ilp machinery. 
we focus on a biological application yeast fermentation process due to its importance for high add value end product. 
research on the technology of laser machining interior contour. 
a viable green manufacturing method be provide the theory and application of laser machining interior contour be propose. 
the interaction physics theory between laser and transparent material the knowledge of cad cam and ultrasonic vibration be combine to manufacture the transparent material and remove chip. 
adopt the method in manufacturing the distortion of machine noise and chemic pollution can be eliminate. 
classroom presentation use tablet pc and writeon. 
tablet pc combine a standard notebook computer with a digitizing screen and a pen like stylus device to produce a computer that allow ease of input of natural writing and drawing. 
the tool writeon be develop to allow the user to effectively draw on top of any application show on the tablet pc screen. 
conceptually set up as a virtual transparency writeon allow a presenter to annotate on an operational window as the target application dynamically run in the visible background. 
information from screen activity can lie record and/or broadcast to the classroom participant in real time. 
student can store a local copy of the fully annotate presentation on their machine for later review. 
writeon have be show to be a very useful tool for improve both the presentation of information as well as the interactivity in classroom instruction. 
classroom testing of the tool and student assessment of its effectiveness will lie discuss. 
introduce tablet pc initial result from the classroom. 
tablet pc tpc s be draw interest as a potential tool for improve teaching and learn in engineering education. 
several school have obtain the machine and be look at effective use. 
a recent initiative at penn state involve thirty one engineering faculty from eleven different discipline. 
all of these faculty be try out tpc in their course and have agree to do so for the next year and one half. 
this paper report on the initial stage of the project in which the research question focus on how engineering undergraduate perceive the effectiveness of the tpc as a teaching and learn tool. 
over 100 student in three course respond to an online survey relate to specific use of the tpc in their class. 
response from the student be overwhelmingly positive. 
this research be significant due to the increase availability of tpc the lack of empirical evidence relate to their effectiveness and their potential for improve teaching and learning. 
improve the use of visual interactive simulation as a knowledge elicitation tool. 
knowledge elicitation be a well know bottleneck in the production of knowledge base system kbs. 
this be mainly due to the tacit property of knowledge which make it difficult to be explicate and hence analyse. 
past research have show that visual interactive simulation vis could effectively be use to elicit episodic knowledge that be appropriate for machine learning an ai capability that include inductive learning purpose with a view of build a kbs. 
nonetheless the vis base elicitation process still have much room for improvement. 
base in the ford dagenham engine assembly plant a research project be be undertake to investigate the individual joint effect of visual display level and mode of problem case generation on the elicitation process. 
this paper look at the methodology employ and some issue that have be encounter to date. 
the use of ict in engineering education opportunity and pitfall. 
it be often claim that use of information and communication technology ict can enhance the present nature of teaching which be generally quite static with one way communication from a teacher to a learner. 
many of the claim be that ict can create interactive learning and provide student centre learning environment both in the university and from anywhere else. 
however in the author s experience high exposure to or the use of ict method be actually find to be a hindrance to a student s teaching and learning especially in the early year of engineering education. 
there be several reason for this. 
the unreliable infrastructure poor network datum navigation and datum security problem poor technical backup and inadequate staff training in ict be important reason that contribute to the failure of ict. 
it be generally find that machine can crash at crucial time discussion tool such as web discussion board and e mail be misuse by student and these result in waste of time particularly in the early year of study. 
development of an intelligent jig and fixture design system. 
the jig and fixture be an important basic equipment in the machining process and mechanical assembly. 
with the development of the cad capp cam and the wide application of cnc technique in the manufacturing the traditional method for the jig and fixture design have not adapt to the demand of complexity and variety in the practical production with update of product more and more rapid. 
computer aided fixture design cafd be an effective way for the situation. 
the designer s participation and experience be necessary for the traditional cafd system. 
a new design system be develop in the article for the special purpose jig and fixture by apply artificial intelligence ai technology into the cafd system use the theory of the expert system and technology of the 3d modelling. 
it discuss the configuration the general function module the knowledge representation the reasoning mechanism and the standard component base of the jig and fixture. 
this paper explore the technology of intelligence and optimization in the process of the jig and fixture design. 
finally an example of virtual assembly be give design by the cafd system. 
a self training system that learn through experimentation. 
the use of medgift and easyir for imageclef 2005. 
this article describe the use of medgift and easyir for three of four imageclef 2005 task. 
all result rely on two system the gnu image finding tool gift for visual retrieval and easyir for text. 
for ad hoc retrieval two visual run be submit. 
no textual retrieval be attempt result in low score than those use text retrieval. 
for medical retrieval visual retrieval be perform with several configuration of gabor filter and grey level color quantisation as well as combination of text and visual feature. 
due to a lack of resource no feedback run be create an area where medgift perform well in 2004. 
for classification a retrieval with the target image be perform and the first n one five 10 result use to calculate score for class by simply add up the score for each class. 
no machine learning be perform so result be surprisingly good and only top by system with optimise learning strategy. 
an innovative approach in support the operation of complex equipment machinery the kobas project case. 
this paper present an innovative approach in support the operation of complex equipment. 
the concept be develop in the context of the kobas project knowledge based customized services for traditional manufacturing sectors provide by a network of high tech sme whose main objective be the development of new knowledge base tool for an intelligent use and management of more sophisticated manufacturing machine and the creation of an innovative extended network of high tech sme for use customize support and make business out of the new development tool. 
as a concrete example the paper present a kobas solution base on the machine maintenance. 
this solution allow one to know the machine condition to detect and diagnose machine failure to manage ordinary and extraordinary maintenance plan and maintenance work order and to provide training support for maintenance intervention. 
computer base pedestrian landscape design use decision tree template. 
machine learning algorithm can act as a valuable analytical tool in design research. 
in this paper we demonstrate the application of a decision tree learn algorithm for design pedestrian landscape that encourage walk for health. 
the domain knowledge be capture use intercept survey that query response to cognitive physical and social attribute that influence pedestrian spatial analysis. 
decision tree extract from the knowledge base be use in the design of pedestrian landscape which be test in a transportation simulator. 
the observed match between the change in the participant response to manipulation of physical variable in the simulated world with those predict by the decision rule indicate the appropriateness of apply decision tree rule as guideline during the process of pedestrian landscape design and research. 
c 2005 elsevier ltd. 
all right reserve. 
dynamic workshop scheduling and control base on a rule restrain color petri net and system development adopt extend b s d mode. 
because of the dynamic characteristic of a manufacturing system long term production plan and schedule be not feasible neither be complete analysis of the manufacturing system and process in advance. 
in the paper after the gap between theoretic research and practical application of workshop scheduling be analyze the hierarchical framework of agile manufacture orient workshop scheduling and control base on mas be put forward. 
accord to practical application requirement traditional petri net be expand and rcpn be put forward to model workshop activity. 
then the architecture of workshop scheduling system base on rcpn be present. 
finally the scheduling system that adopt three layer b s d mode be develop on internet intranet by use web database and java the application of the system develop have be use at machine tool large part workshop of shaanxi qinchuan machinery development co. ltd and the system have be prove to be effective. 
enhanced registration procedure with nav for mitigated contentions in m2 m communications. 
in machine to machine m2 m communication base on ieee 802.11ah protocol a single access point ap should support up to 8000 station within a coverage range of one km use relatively low sub 1ghz wireless communication channel. 
the registration of a large number of station at network initialization or at any reboot of ap after a power failure usually take more than one minute that prohibit agile cognitive sensing and adaptive control. 
in this paper we propose an enhance registration procedure for m2 m communication base on ieee 802.11ah with mitigated contention. 
in the propose registration procedure the authentication request response and association request response message be extend to carry network allocation vector nav to allocate the communication channel for combine processing of authentication and association to minimize contention generate by massive wireless channel access from up to 8000 station. 
we also analyze the optimal configuration of parameter of authentication control threshold act) based contention mitigation in registration. 
the simulation experiment show that the propose registration procedure with combine authentication and association reduce more than 15 of registration time for 8000 station compare to currently exist solution. 
optimize the casting length of single diameter steel billets base on minimum cost. 
the hot rolling process use as raw material round bar cast use continuous casting at the steel make plant. 
from here a limited number of cast billet in term of length can be deliver. 
the supply order for the rolling process be unpredictable and imprecise thus in this scenario the current paper intend to offer a solution to the industrial partner as to optimize the cast length of billet consider the restriction of the casting process and to achieve minimum production cost. 
an order be convert into a number of billet that should be cast at an ideal length. 
two different method be propose an analytical one design by the author and the linear programming method in order to generate an optimal solution to the state problem base on minimize a cost function. 
the analytical method s result be the optimal number of steel block that need to be cast at a single length from the limited set. 
the linear programming method s result be the optimal number of block that need to be cast from each available length. 
the result obtain from both method be compare base on a set of cast order via successive simulation. 
study of controlled motion of an exoskeleton performing obstacle avoidance during a single support walking phase. 
this paper discuss a problem of obstacle avoidance for a low limb exoskeleton. 
the paper describe an approach that rely on generate a new collision free trajectory. 
the method of generate collision free trajectory. 
the method be present in detail and be illustrate with an example. 
the method use a bounding sphere that enclose the obstacle replace the piece of trajectory that lie inside the sphere with a new one that lie on the sphere. 
a numerical experiment be carry out simulation motion of a low limb exoskeleton during the single support phase of its gait. 
it be show that a safety margin parameter influence the shape of the trajectory generate by the algorithm. 
control algorithm for a class of systems describe by ts fuzzy uncertain models. 
the paper treat a class of nonlinear uncertain model describe by fuzzy model. 
first the ts model associate with the uncertainty of system be analyse. 
a constructive lyapunov base proof of convergence of the control algorithm be carry out. 
an unique action rule control system be propose. 
technique base yakubovich kalman  popov lemma be use to prove the stability criterion. 
frequency plot be propose for control parameter design. 
numerical simulation of a technical model be present. 
frequency criterion for balancing robot control describe by uncertain models. 
the paper focus on a method of design pd controller for a class of balance robot cart and pole system. 
the uncertainty of model parameter be introduce as constraint in state space. 
pd controller be design by use the frequency criterion. 
the stability of the control system be determine by lyapunov technique and kalman yakubovichpopov lemma. 
control performance be prove and numerical simulation illustrate the quality of motion. 
control of level systems by arduino via pc platform. 
nowadays a great variety of industrial process have an extreme necessity of improve the quality of control tank level due to the fact that this type of control and process be widely find in the industrial environment. 
the objective of this work consist to create a tank system aim to represent in small scale an industrial level process seek exemplify application mode of use and control technique. 
firstly there be the need to identify the system response of the open loop to be adjust the good controller in accordance with the good method of tune. 
as control platform arduino microcontroller be use to establish a serial communication with a pc workstation. 
the result be quite satisfactory consider its functionality in industrial system represent in small scale. 
case study level system control perform with lpc2148 microcontroller via pc platform. 
this paper aim to show the development and methodology of pi controller tune by ant colony optimization aco. 
it be an optimize technique that use other method for this purpose base on metaheuristic. 
which solve the problem of the travel salesman among other. 
the pi controller have two parameter that must be determine to start the process control. 
the aco technique be use to optimize these constant. 
in this work will be present the step need to identify and tune a first order delay time fodt system and create an ant colony optimization method through a supervisory system develop in java programming language. 
the applicability of this pi tuning technique depend on the knowledge of the desire response. 
in this work it be essential that the process of optimization provide the shortest possible settling time response and no or almost no overshoot. 
reduced attention output feedback control of linear systems with bounded disturbance. 
one of the main challenge in networked control systems be to make well use of share communication and compute resource while preserve closed loop stability and good performance of the control process. 
herein we present an output feedback control strategy that reduce the communication overhead of the networked control system by increase the time between control and measurement sample. 
the control design be base on self trigger control and ensure closed loop stability and ultimate boundedness of the state vector despite the presence of bound input and output disturbance. 
the current work assume that not all state variable be available for measurement and employ a reconstruction technique to estimate the state vector. 
since the sampling be time vary this paper also present result on the preservation of reconstructability and observability of linear system under aperiodic sampling. 
two numerical example be present to illustrate the performance of the state estimation and reduced attention control strategy. 
improved balancing for general and structured eigenvalue problems. 
badly scale matrix or matrix pencil can reduce the reliability and accuracy of computed result for various numerical problem include the computation of spectra and basis of invariant or deflating subspace which be use in many basic procedure for optimal and robust control model reduction spectral factorization and other domain. 
standard balancing technique can often improve the result but sometimes the solution of the scale problem be much bad than that for the original problem. 
this paper present an improved balancing technique for general or structured matrix and matrix pencil and illustrate its good performance in solve eigenvalue problem and algebraic riccati equation for large set of example from well know benchmark collection. 
simple adaptive control of externally hxcite synchronous machine. 
this paper propose a control strategy for a high power externally excited synchronous machine eesm base on simple adaptive control technique. 
a cascade control scheme be design in the rotor reference frame. 
in the current control loop a sac approach be describe while for the speed control loop a robust controller be propose. 
the rotor and stator reference current be determine base on a maximum torque per ampere mtpa and field weakening fw strategy. 
variation of parameter be simulate in order to evaluate the performance of the control method. 
numerical simulation be perform in matlab simulink. 
design of a low cost cad cam convertor for cnc application. 
this paper focus on reduce cost for cad cam software convertor and on position control of the motor use on modern cnc. 
to achieve the propose goal free software package be use and integrate with low cost motion controller. 
a g code to triobasic language convertor be develop and validate use an experimental cnc machine for print circuit board mill. 
mpc base optimal input design for nonlinear system identification. 
a combine nonlinear model predictive control with extended kalman filter strategy have be propose for optimal input design. 
as the design controller depend on the identify parameter the achievable performance highly depend on the quality of the identify information. 
the degradation in achieve the desire control performance be quantify by introduce an optimality criterion which minimize the error covariance matrix of the identify parameter. 
the major contribution be use the information of the system parameter at every sample time to improve the control performance at next time step. 
the the performance of the propose algorithm be verify by numerical simulation for a example system. 
application of artificial neural networks for modeling drug release from a bicomponent hydrogel system. 
artificial neural networks anns have be use as modeling tool for prediction of drug release pattern from bicomponent hydrogel system base on poly(n isopropylacrylamide and sodium alginate. 
the process modeling be perform use an artificial neural network train with an evolutionary algorithm the last one have the role of develop the neural model in an optimal form. 
the ann be train with this algorithm use the available experimental datum as the training set. 
the divergence of the root mean squared error rmse between the output and target value of test set be use as stop criterion. 
the simulation result show that drug release profile from the choose hydrogel can be model accurately use anns the model prediction be closely correlate with the experimental datum. 
effect of disabled neurons in classical and quantum networks information processing. 
in this study the effect of miss or broken element on the memory preservation in classical and quantum neural network be analyze. 
the network be build by consider each node as a bit or qubit neuron like processing unit. 
the qubit neuron be analyze from two perspective one that involve consideration of quantum coupling between they alongside with specific network connection and another that use only non quantum network connection between they. 
the same classical architecture and learning be apply to both network that contain classical and quantum node. 
the analysis of memory preservation in such network consist in monitor change in memory state as result of interruption of different connection between node. 
from this perspective the comparative classical and quantum network response to broken or missing element be analyze compare and contextualize. 
optimal hardware implementation of a low cost multiplier use multifunctional registers with decoded mode inputs. 
in this paper the author propose a new optimal method for hardware implementation of a multiplication algorithm use multifunctional register mfr with decoded input base on transfer matrix method. 
the implementation cost be calculate emphasize the most economical solution. 
low cost be take into account. 
the modern design tool handle digital system with many output and represent they by cube for efficiency reason. 
talk as optimal hardware implementation of the digital automata can be reduce to a combinational one synthesis use logic gate primitive and use floor planning design. 
the digital logic network that generate the control signal of the finite state machine fsm can be synthesize use transfer matrix. 
automatic estimation of the noise level function for adaptive blind denoising. 
image denoising be a fundamental problem in image processing and many powerful algorithm have be develop. 
however they often rely on the knowledge of the noise distribution and its parameter. 
we propose a fully blind denoising method that first estimate the noise level function then use this estimation for automatic denoising. 
first we perform the non parametric detection of homogeneous image region in order to compute a scatterplot of the noise statistic then we estimate the noise level function with the least absolute deviation estimator. 
the noise level function parameter be then directly re inject into an adaptive denoise algorithm base on the non local mean with no prior model fitting. 
result show the performance of the noise estimation and denoising method and we provide a robust blind denoise tool. 
robust scoring of voice exercise in computer based speech therapy systems. 
speech therapy be essential to help child with speech sound disorder. 
while some computer tool for speech therapy have be propose most focus on articulation disorder. 
another important aspect of speech therapy be voice quality but not much research have be develop on this issue. 
as a contribution to fill this gap we propose a robust scoring model for voice exercise often use in speech therapy session namely the sustain vowel and the increase decrease pitch variation exercise. 
the model be learn with a support vector machine and double crossvalidation and obtain accuracy from approximately 73.98 to 85.93 while show a low rate of false negative. 
the learned model allow classify the child s answer on the exercise thus provide they with real time feedback on their performance. 
new evaluation scheme for software function approximation with non uniform segmentation. 
modern application embe complex mathematical processing base on composition of elementary function. 
a good balance between approximation accuracy and implementation cost memory space requirement and computation time be need to design an efficient implementation. 
from this point of view approach work with polynomial approximation obtain result of a monitor accuracy with a moderate implementation cost. 
for software implementation in fix point processor accurate result can be obtain if the segment on which the function be compute i be segment accurately enough to have an approximate polynomial on each segment. 
non uniform segmentation be require to limit the number of segment and then the implementation cost. 
the propose recursive scheme exploit the trade off between memory requirement and evaluation time. 
the method be illustrate with the function exp root x on the segment and show a mean speed up ratio of 98.7 compare to the mathematical c standard library on the digital signal processor c55x. 
robust reconstruction for cs based fetal beats detection. 
due to its possible low power implementation compressed sensing cs be an attractive tool for physiological signal acquisition in emerge scenario like wireless body sensor networks wbsn and telemonitore application. 
in this work we consider the continuous monitoring and analysis of the fetal ecg signal fecg. 
we propose a modification of the low complexity cs reconstruction sl0 algorithm improve its robustness in the presence of noisy original signal and possibly ill condition sense reconstruction procedure. 
we show that while maintain the same computational cost of the original algorithm the propose modification significantly improve the reconstruction quality both for synthetic and real world ecg signal. 
we also show that the propose algorithm allow robust heart beat classification when sparse matrix implementable with very low computational complexity be use for compressed sensing of the ecg signal. 
signal processing techniques for on line partial discharge detection and classification. 
partial discharge pd detection play a fundamental role in monitor the health of medium voltage mv system. 
this paper present a method for pd detection and source recognition in mv sub station base on a combination of signal processing technique. 
firstly pd detection and signal conditioning be carry out. 
then pd of different source be separate and finally classify by mean of the extension set theory. 
the obtain result show a classification effectiveness of 100 on single source pd and an effectiveness of 72.5 in multisource pd where pd from many source be capture in the same data set. 
data compression for snapshot mosaic hyperspectral image sensors. 
recent achievement in hyperspectral imaging hsi demonstrate successfully a novel snapshot mosaic sensor architecture enable spectral imaging in a truly compact way. 
integration of this new technology in handheld device necessitate efficient compression of hsi datum. 
however due to the specific mosaic structure of the acquire image traditional compression method tailor to full resolution hsi datum cube fail to exploit the special spatio spectral interrelation among the pixel. 
this paper introduce an efficient and computationally tractable compression technique for mosaic hsi image. 
specifically an appropriate decorrelator be construct for exploit the spatio spectral redundancy among the pixel by model the filter arrangement on the mosaic hsi sensor as a multiple input multiple output antenna array. 
do so the decorrelator depend only on the sensor and not on the datum to be compress. 
comparison with state of the art compression method design for hsi datum cube reveal that our approach achieve well reconstruction quality at low bit per pixel rate. 
human expert supervised selection of time frequency intervals in eeg signal for brain computer interfacing. 
in the context of brain computer interfacing base on motor imagery we propose a method allow a human expert to supervise the selection of user specific time frequency feature compute from eeg signal. 
indeed in the current state of bci research there be always at least one expert involve in the first stage of any experimentation. 
on one hand such expert really appreciate keep a certain level of control on the tuning of user specific parameter. 
on the other hand we will show that their knowledge be extremely valuable for select a sparse set of significant time frequency feature. 
the expert select these feature through a visual analysis of curve highlight difference between electroencephalographic activity record during the execution of various motor imagery task. 
we compare our method to the basic common spatial pattern approach and to two fully automatic feature extraction method use dataset 2a of bci competition iv. 
our method mean accuracy m 83.71 14.6 std outperform the good compete method m 79.48 12.41 std for six of the nine subject. 
active noise cancellation in headphones by digital robust feedback control. 
active noise cancellation anc may complement passive insulation of headphone by actively cancel low frequency component of acoustical background noise. 
in system with a single error microphone pointing towards the ear canal a feedback controller perform the compensation task. 
we be focus on fix feedback controller for broadband attenuation of arbitrary ambient noise. 
we use method and optimization routine from control theory. 
in this discipline the key element be the so call controller which be in term of signal processing a digital filter. 
the controller be design by an optimization approach call the mix sensitivity h infinity synthesis which require an accurate estimate of the secondary path between the cancel loudspeaker and the error microphone and the knowledge of the secondary path uncertainty as well as a specification of the closed loop sensitivity. 
the advantage of this method be the convenient formulation of performance and uncertainty requirement in the frequency domain. 
we describe the design process and evaluate the controller which be realize in state space form within a real time system. 
the real time measurement show a good match with the expect behavior. 
they furthermore confirm the feasibility of broadband attenuation by fix time invariant feedback controller in a digital system. 
the novelty of this contribution comprise of the specific design process of a discrete robust feedback controller for broadband noise reduction roughly 250 hz and the digital real time system implementation. 
an approach to joint sequential detection and estimation with distributional uncertainty. 
joint detection and estimation be an important yet little study problem that arise in many signal processing application. 
in this paper a sequential and robust solution approach be present. 
to design the test fulfil constraint on the error probability and the quality of the estimate the problem be convert into an unconstrained form and subsequently solve use linear programming. 
to handle model uncertainty a band model for both hypothesis be use and a concept for determine the pair of least favorable distribution be adopt to devise a robust detection scheme. 
for the robust estimation an upper bound of the estimation cost base on maximize a kullback leibler divergence be derive. 
the result test meet the specification on the error probability and the quality of the estimate for every feasible pair of distribution. 
numerical result be provide for the pair of least favorable distribution and for a pair of randomly select distribution. 
time effect in sentiment analysis. 
sentiment analysis be a trend topic that be widely study in the recent year. 
as a result of social medium be use actively company use machine learning system to monitor and understand their customer feedback. 
over the time a give classical sentiment analysis system be be affect because of some phrase disappear and some other word emerge. 
on the other hand a label dataset be require to analyse tweet datum but because of find label datum be hard active learning method become the proper solution to the problem. 
main aim of the active learning be to achieve same or well result with less training datum. 
in this study active learning method be apply to two different tweet dataset use several different active learning method such as cluster and choose actively query sample iteratively to investigate time effect. 
more accurate result be obtain by active learning method accord to the random selection. 
sign language recognition by image analysis. 
the sign language recognition slr problem be a highly important research topic because of its ability to increase the interaction between the people who be hear impair or impediment in speech. 
we propose a simple but robust system. 
the propose system consist of three main step. 
first we apply segmentation to the face and hand region by use fuzzy c means clustering fcm and thresholde. 
fcm be a cluster technique which employ fuzzy partition in an iterative algorithm. 
after the face and hand be segment the feature vector be extract. 
the feature vector be choose among the low level feature such as the bounding ellipse bounding box and center of mass coordinate since they be know to be more robust to segmentation error due to low resolution image. 
in total there be 23 feature for each hand. 
after the feature vector be extract they be use for recognition with discrete hidden markov model hmm. 
recognition stage be compose of two stage namely training and classification. 
the baum welch algorithm be use for hmm training. 
in classification part the likelihood of each hmm be calculate and the hmm with the high likelihood be choose. 
in order to measure the success rate of the system the enterface dataset be use. 
in this dataset eight different american sign language example classify and in user independent case be show to be work with 94.19 accuracy. 
a comparison of classification methods for local binary patterns. 
texture recognition be an important tool use for content base image retrieval face recognition and satellite image classification application. 
one of the most successful feature for texture recognition be local binary pattern lbp which compute local intensity difference for a pixel with respect to its neighbor pixel. 
in many study in the literature histogram base similarity measure be employ to classify lbp feature. 
in this study we investigate the performance of support vector machine linear discriminant analysis and linear regression classifier to improve the success of lbp feature. 
we achieve 84.4 classification success use linear regression classification. 
3d modeling of a scene with an autonomous robot. 
in today s technology the popularity of the robotic system be getting increase due to the fact that they facilitate daily life and that they be become more functionality. 
in line with it the robot that be cheap and easy to obtain be get crucial. 
in the current study a robot be create use material cheap and easy to provide. 
after that an autonomous navigation algorithm be design and a 3d modeling system be form with kinectfusion algorithm use an asus xtion camera which be able to give a rapid depth map on a graphic card with an embed nvidia jetson tk1 have a rapid graphic processor. 
then this be integrate on the robot. 
in this way it be aim to create an autonomous robot be able to give a three dimensional model of the scene by move autonomously and without strike the obstacle around. 
balanced random forest for imbalance datum stream. 
datum with highly imbalance class distribution be common in real life. 
machine learning application domain such as e commerce risk management environmental and health monitoring often suffer from class imbalance since the interesting case occur rarely. 
yet another layer of complexity be add when datum arrive as massive stream. 
in such a setting it be often of interest that a learn algorithm be update in an incremental fashion for scalability and model adaptivity reason while still handle the class imbalance. 
in this paper we propose an ensemble algorithm for imbalance datum stream base on the offline balanced random forest idea. 
we also show on a recent dataset that the algorithm be useful for the buyer prediction problem in large scale recommender system. 
a mail discrimination study use network basis tool. 
today many method use for the junk e mail spam discrimination. 
for example blacklist and some machine learning method. 
blacklist consist of ip address and domain name of spammer who previously send e mail and catch as spam. 
machine learning method be also among many other study in which many study have be do in recent year. 
train machine use e mail header information e mail content and sender domain information decide newly incoming e mail message as spam or not. 
in this study a new spam filter technique which use machine learning with support vector machine svm use header information of an e mail and some network tool have be propose. 
experimental performance analysis for mobile data offloading in heterogeneous wireless network. 
wireless fidelity wifi offload be become a dominant use case scenario application of wifi technology for mobile operator in order to satisfy their subscriber increase demand for mobile bandwidth. 
in fact design and integrate a convergent infrastructure of 3gpp and non 3gpp network inside mobile operator that can manage connectivity of their subscriber be a challenging task due to existence of several optimization attribute. 
in this paper the performance of such a connectivity management platform in a multi user scenario that use a multiple attribute decision making madm algorithm for wifi offload in heterogeneous wireless network be present. 
through experimental result sensitivity analysis of the propose algorithm be provide in detail. 
the experimental result indicate that there be trade off between the number of connected user to the platform and the attribute value of the greedy madm algorithm. 
dynamically reconfigurable real time hardware architecture for channel utilisation analysis in industrial wireless communication. 
automation in industrial production be get more important so the need for high datum rate low latency and low power wireless communication be grow. 
this require efficient use of bandwidth in particular for unlicensed band. 
in this paper we present a hardware architecture for analyse the channel utilisation which be need in real time coexistence management system. 
additionally we compare the solution to a software implementation with respect to performance and real time capability. 
the hardware implementation support real time channel utilisation sense calculate fast fourier transform and logarithm. 
as show in the result chapter the hardware solution exceed software approach by more than five order of magnitude in term of throughput calculate the fast fourier transform and logarithm of a 1024 value wide vector in 17.26 mu s at a clock frequency of 60 mhz. 
the fft size can be dynamically reconfigure use control signal drive by software which enable reuse in multi carrier system such as gfdm when coexistence management be not active. 
fault tolerant cooperative control of wmr under actuator faults base on particle swarm optimization. 
this paper investigate fault tolerant cooperative control ftcc of multiple wheel mobile robot wmrs in the presence of severe actuator fault. 
initially a team of robot be move in pre define formation configuration. 
when actuator fault occur in one or more robot and the faulty robot( can not complete the mission the rest of robot start reconfigure the formation to compensate the fault effect on the whole mission. 
first the new formation reconfiguration be generate by solve an optimal assignment problem where each healthy robot should be assign to a unique place. 
then the new formation can be reconfigure by recast the reconfiguration problem as an optimization problem while the objective be to minimize the time to achieve the new formation reconfiguration within the constraint of the robot dynamic and collision avoidance. 
a hybrid approach of control parametrization and time discretization cptd and particle swarm optimization pso be propose to solve the optimization problem. 
the result of the numerical simulation demonstrate the effectiveness of the propose algorithm. 
fdd and ftc for ramp type actuator fault use intelligent output estimator. 
in this paper fault detection and diagnosis fdd and active fault tolerant control aftc algorithm be propose to compensate for a ramp type loss of effectiveness loe actuator fault apply on the quadrotor system. 
base on the model free concept an output estimator design call intelligent output estimator ioe be present to estimate the output of the system and then use to improve the estimation of the actuator fault. 
then the estimation be use to detect and isolate the faulty actuator by generate fault symptom. 
finally the estimation value be integrate into the control law to compensate for the variable actuator fault. 
real tlight result validate the propose algorithm and show the actuator fault accommodation process. 
kalman filtering and zonotopic state bounding for robust fault detection. 
two usually distinct paradigm exist to model uncertainty. 
the stochastic one deal with random uncertainty. 
strong assumption about their probability distribution be often make especially when online computation be require. 
for instance assume independent gaussian distribution be common practice when use standard version of the famous kalman filter. 
though efficient to deal with measurement noise the assumption of know probability distribution find its limit to characterize epistemic uncertainty. 
indeed the lack of a precise knowledge about disturbance such as the load torque of a motor may be well characterize by interval bound with no assumption about the value distribution. 
this be the usual motivation for use the set membership paradigm to model uncertainty. 
though explicitly compute set can achieve a so call guarantee robustness to the bad case result from the specify uncertainty bound the boundederror paradigm however usually suffer from a poor management of random measurement noise. 
in this semi plenary talk a joint zonotopic and gaussian kalman filter zgkf will be present. 
it will be show to provide a solution for the robust fault detection of uncertain discrete time system simultaneously subject to bound disturbance and gaussian noise. 
the covariation of a zonotope will be introduce as a set membership analog to covariance make it possible to compute a time vary optimal observer gain jointly minimize both kind of uncertainty bound zonotopic and gaussian. 
then give a maximal probability of false alarm an innovation base detection test will be show to merge the usually mutually exclusive benefit grant by set membership technique robustness to the bad case within specify bound domain computation and stochastic approach take noise distribution into account probabilistic evaluation of test. 
numerical simulation will illustrate the significantly improved tradeoff between the sensitivity to fault and the robustness to disturbance noise while the computation prediction update optimal gain confidence domain adaptive threshold detection test remain explicit and can be efficiently implement. 
then the new notion of set membership and probabilistic merger spm will be introduce and particularize to zonotopic and gaussian mergers zgm. 
the ezgkf algorithm an extended version of zgkf to non linear filtering will be also present and discuss as an outline to future work. 
robust diagnosis base on bg modelling online implementation in the rear suspension motorcycle. 
in this paper a bond graph of the rear suspension motorcycle be propose. 
the model be use to study the robust diagnosis of the consider process. 
the analytical redundancy relations arrs be generate for monitor system. 
the bond graph and lft form linear fractional transformation be exploit to the graphical representation of parametric uncertainty. 
the simulation and experimental result on rear suspension of bmw r1200gs motorcycle validate the studied approach. 
a fault tolerant control architecture for constrain system subject to sensor stuck fault. 
in this paper a sensor stick fault tolerant control framework for linear time invariant plan model subject to input state constraint and bound disturbance be propose. 
by take advantage of a recent contribution on actuator stick scenario of the same author a recede horizon control reconfigurable scheme be propose to contrast undesired effect due to sensor malfunction. 
the main merit of the propose strategy rely on its intrinsic capability to quickly identify fault occurrence and to take a decision on the adequate control action. 
this be formally obtain by jointly exploit set theoretic polyhedral idea and the certainly equivalence concept. 
two numerical example be provide and the control performance contrast with a well repute competitor fault tolerant control scheme. 
a self heal control method for satellite attitude tracking base on simultaneous fault estimation and control design. 
this paper propose a novel self heal control method for satellite attitude tracking base on simultaneous fault estimation and control design. 
the propose method integrate the fault estimation and fault tolerant control unit in a dynamic system which be less complex and more reliable than the separately design self heal architecture. 
in this paper the model reference approach be use to obtain a tracking error dynamic equation. 
follow this an augmented error system be construct by take the fault as an auxiliary vector. 
base on the augmented error system a fault estimator controller be design to achieve robust fault tolerant control and robust fault estimation simultaneously. 
the design condition for the propose fault estimator controller be transform as a set of linear matrix inequality which can be easily solve. 
finally numerical simulation result be give to demonstrate the effectiveness of propose method. 
photovoltaic module health monitoring and degradation assessment. 
all industrial system or machine be subject to degradation process which can be relate to the operating condition. 
this degradation can cause unwanted stop and the need of urgent maintenance at any time. 
prognostic activity be now recognize as a key feature in maintenance strategy and conditional base maintenance it give to operator a potent tool in decision make by quantify how much time be leave until functionality be lose. 
the reason be to plan the heavy intervention and to manage the stock of spare part. 
in addition it can be use for degradation assessment and remain useful life rul estimation. 
in this paper we will develop a new smart prognostic method for photovoltaic module health degradation which be base on online diagnosis and data drive prognosis to achieve more accurate prediction. 
this framework of forecast integrate the strength of real time monitor in the first approach and relevant vector machine in the second. 
the result show that the propose method be plausible due to the good prediction of rul and can be effectively apply to many system for monitoring and prognosis. 
support the shift towards continuous pharmaceutical manufacturing by condition monitoring. 
over the last decade there have be an increase interest in the pharmaceutical industry to shift the manufacturing process of drug from batch to continuous operation. 
the continuous manufacturing of pharmaceutical provide significant benefit saving in cost time and material to name but a few. 
the implementation of a continuous manufacturing strategy however be challenge. 
to gain profit from a continuous process one have to ensure its proper operation a long time span until the next prospective unscheduled downtime. 
thus the instal operation unit have to be one robust against disturbance by engineering design principle and by advanced fault tolerant control scheme respectively and two the condition of the operation unit have to be monitor reliably to trigger in case of need appropriate intervention strategy in a timely manner. 
in this paper the focus be on the monitoring aspect. 
here a model base fault detection and identification framework be implement which select the most data support model candidate from a set of predefined model hypothesis include the reference model normal behavior as well as failure model. 
in addition to enable an improved diagnosis the system under study can be steer deliberately base on the propose concept result into an active fault diagnosis framework. 
preliminary result be demonstrate by an academic three tank system. 
lmi base design of cascade reconfiguration control structure. 
the paper consider the problem of control reconfiguration to retain fault tolerance in control of linear continuous time system with plant dynamic fault. 
follow the concept of reference model control the main idea be to keep untouched the nominal control parameter where in addition the nominal controller remain a part of the reconfigure control loop. 
the full state control tenet be apply for nominal control strategy and the static output control principle for the compensation control law specification in the so call cascade reconfiguration structure. 
analyze as a mixed control problem new condition for control structure parameter design be introduce and prove. 
the obtain result offer the sufficient and necessary design condition be illustrate with a numerical example to note the effectiveness of the propose approach. 
from safety analysis of reconfigurable systems to design of fault tolerant control strategies. 
the design of fault tolerant control strategy require a perfect knowledge of both the possible reconfiguration of the system and of the behavior of this system when failure occur. 
in this paper it be show that the use of a model base safety analysis mbsa framework able to cope with repairable and reconfigurable phase mission system be helpful for the choice of the good reconfiguration strategy to be implement in the control system. 
the core of this approach be base on the integration of a model of the system structure fault tree a model of the dysfunctional behavior of the component of the system switched markov processes and a model of the reconfiguration mechanism moore machines. 
the syntax and semantic of the different model and their integration be first define. 
the benefit of this approach for performance evaluation of fault tolerant control strategy be afterwards illustrate through an application example. 
fault tolerant control and diagnosis for lpv system with h infinity virtual sensor. 
a robust h infinity virtual sensor design be the aim of this paper. 
such a sensor be use in a fault tolerant control scheme which can be apply to wide class of non linear system. 
to deal with system non linearity a linear parameter vary system be consider. 
a robust virtual sensor be develop in such a way that the level of disturbance attenuation can be reach in relation to the fault estimation error. 
use similar approach in the control scheme the level of disturbance attenuation can be reach in relation to the tracking error. 
finally the design scheme end with solve a number of linear matrix inequality which can be efficiently realise use numerical solver implement in matlab. 
the empirical verification which demonstrate the performance of the present approach be give in the final section of this paper. 
coplanar waveguide integrate with micro strip line on a through glass via substrate. 
a wideband coplanar waveguide integrate with micro strip line on a through glass via substrate be present. 
the design of the ultra wideband micro strip to coplanar waveguide transition which be use at input output port. 
vertical via connect the top coplanar waveguide to the ground plane on the bottom of the substrate to achieve the short signal transmission distance. 
simulate the maximum to limit the minimum thickness of the glass dielectric layer epsilon(r)=5.5 from 200 mu m to 500 mu m have all implement up to 30gz frequency band. 
we have design a coplanar waveguide with the center conductive width of 120 mu m and space of 22 mu m to connect a micro strip line with the conductive width of 210 mu m finally reach 50 omega impedance matching of overall structure. 
the simulation result have a low insertion loss of less than 0.09db and the reflection loss of below  20db at 30 ghz frequency band. 
the non contact respiratory monitoring system use thermal image processing. 
the physiological information of respiration behavior indicate both of lung and chest operating status. 
general speak the traditional measurement be usually to apply the wearable or contact instrument which cause subject to be inconvenient and uncomfortable. 
this paper adopt the non contact respiration monitoring system combine image processing and datum analysis. 
we implement the infrared thermal camera to obtain the gray scale to oand split it into two part namely face and nose. 
firstly the face be extract from the image and nose be locate from it. 
secondly we capture respiratory signal from the nose part of the image. 
finally the respiratory signal be divide into the inhale and exhale behavioristic. 
the datum from inhale and exhale behavioristic be record and the analisyst be do to the respiratory behavior. 
kinematic analysis and development five axis milling machine base on parallel mechanisms. 
machine tool with parallel structure be the subject that usually discuss in many research. 
user be still largely unaware of the advantage offer by these new machine structure. 
this paper present the development of a mathematical model describe the kinematic problem and analysis workspace of five axis mill machine fmm base on six degree of freedom 6dof structure. 
in addition reachable workspace feature and parameter optimization as criterion of the maximum of working volume for pm be consider. 
the implementation and applications of low voltage distribution line theft supervisory system. 
in this paper microprocessor in association with gprs zigbee plc power line carrier and voltage current acquisition circuit be adopt to prepare wireless cable theft detection module with detection capability of conductive cable theft for distribute low voltage circuit include overhead line and underground cable. 
the great feature of this module be its capability to monitor simultaneously electricity carry cable and non electricity carry cable for the electricity carry conductor voltage current acquisition circuit monitoring method be mainly use to be associate with zigbee wireless communication and the non electricity carry conductor such as ground line and neutral line be mainly monitor by plc if the communication fail it could be judge as abnormal and this can be use as multiple way of confirmation to avoid wrong reporting. 
meanwhile the line status can be send back to control center through gprs and the conduct cable status can be display on the human machine interface. 
if there be any abnormity a short message and mail will be send to assign personnel meanwhile the full time camera in the road side will be use together when the alarm occur the server host will search out the close circuit tv cctv image in time to be provide to the police as favorable evidence to enhance the successful rate of case. 
detailed simulation model of the two phase brushless dc motor design for vfd integration. 
due to the modern technique and technology development a thorough attention on simulation of autonomous variable frequency system be pay. 
the advantage of the electric machine take as a basis for this modeling leave no doubt for use it in aggressive environment. 
the design model of a two hase brushless dc electric motor be specifically design to be connect to a model of pwm inverter describe the process occur in the motor and also allow to simulate abnormal situation to predict possible failure. 
the study be carry out by build a simulation model in the programming environment matlab simulink. 
parameterizing move target defense. 
move target defense mtd be the concept of control change across multiple system dimension aim to disrupt the adversary in the attack sequence for intrusion prevention. 
to date there be a lack of progress in mtd modeling and evaluation to test the effectiveness of mtd technique. 
in this paper we develop two analytical model base on closed form solution and stochastic petri nets to analyze the effect of a dynamic platform technique base mtd on attack success rate. 
the numerical result from these two model agree with one another provide cross validation. 
furthermore the output of these model indicate the existence of parameter setting that decrease the security of the protect resource and setting that make mtd most effective in term of minimize the attack success probability. 
behavioral service graphs a big data approach for prompt investigation of internet wide infection. 
the task of generate network base evidence to support network forensic investigation be become increasingly prominent. 
undoubtedly such evidence be significantly imperative as it not only can be use to diagnose and respond to various network relate issue i.e. performance bottleneck routing issue etc but more importantly can be leverage to infer and far investigate network security intrusion and infection. 
in this context this paper propose a proactive approach that aim at generate accurate and actionable network base evidence relate to group of compromise network machine. 
the approach be envision to guide investigator to promptly pinpoint such malicious group for possible immediate mitigation as well as empower network and digital forensic specialist to far examine those machine use auxiliary collect datum or extract digital artifact. 
on one hand the promptness of the approach be successfully achieve by monitor and correlating perceive probe activity which be typically the very first sign of an infection or misdemeanor. 
on the other hand the generate evidence be accurate as it be base on an anomaly inference that fuse big datum behavioral analytic in conjunction with formal graph theoretical concept. 
we evaluate the propose approach as a global capability in a security operation center. 
the empirical evaluation which employ 80 gb of real darknet traffic indeed demonstrate the accuracy effectiveness and simplicity of the generate network base evidence. 
achieve intelligent traffic aware consolidation of virtual machines in a data center use learning automata. 
cloud computing cc be become increasingly pertinent and popular. 
a natural consequence of this be that many modern day datum center experience very high internal traffic within the data center themselves. 
the vm with high mutual traffic often end up be far apart in the datum center network force they to communicate over unnecessarily long distance. 
the consequent traffic bottleneck negatively affect both the performance of the application and the network in its entirety pose non trivial challenge for the administrator of these cloud base datum center. 
the problem can quite naturally be compartmentalize into two phase which follow each other. 
first of all the vm be consolidate with a vm clustering algorithm and this be achieve by utilize the toolbox involve learning automata la. 
by map the cluster problem onto the graph partitioning gp problem our la base solution successfully reduce the total communication cost by amount that range between 34 to 85. 
thereafter the result cluster be assign to the server rack use a cluster placement algorithm that involve a completely different intelligent strategy one that invoke simulated annealing sa. 
this phase far reduce the total cost of communication by amount that range between 89 to 99. 
the analysis and result for different model and topology demonstrate that the optimization be do in a fast and computationally efficient way. 
indeed as far as we know this paper pioneer the application of la in the traffic aware consolidation of virtual machine in datum center and also pioneer a strategy which serialize the tool in la and sa to optimize cc. 
towards user center privacy risk detection and quantification framework. 
with the prevalence of privacy incident and recurrent leak privacy protection have become a concern of user and datum protection entity. 
previous research in privacy risk prevention have mostly follow the collect and prevent philosophy by apply anonymization technique to the user datum on the back end. 
these approach neglect the user right to informational self determination since the privacy risk analysis and prevention take place once the data be out of control of the user. 
in this paper we present an architecture for user center privacy risk detection and quantification framework base on combinatorial and probabilistic mathematical model couple with advanced machine learning classifier. 
the framework empower user to take informed privacy prevention action prior to unwanted revelation. 
a helical shaped slot microstrip band pass filter base on siw technology for wlan and bluetooth applications. 
a new compact wideband substrate integrated waveguide siw band pass filter utilizing of a helical shape slot be present. 
this filter be consist of four slot such that each one occupy a corner. 
construction and evaluation of the propose model have be do use the em simulator of microwave studio suite from computer simulation technology cst. 
the overall size of filter be 10 mm x 10 mm use a substrate with relative permittivity of six and height of 0.254 mm this filter be design to meet compact size good return loss and low insertion loss. 
the obtain result exhibit a return loss below  40 db and insertion loss approach to zero db over the passband with a  three db fractional bandwidth of about 70 center at 2.4 ghz. 
the simplicity gain with this structure lead to freely control the position of the pass band through do simple alteration of the helical slot dimension. 
as a result this make the propose filter candidate for operate in wireless application like wireless local area network wlan and bluetooth application. 
condition assessment of power transformer use svm base on dga. 
the possibility of power transformer failure increase over the time as the age and rate of utilization increase. 
since internal fault specially be the main cause of these failure there be many way and method use to predict incipient fault and thus prevent the power transformer from fail by monitor its condition. 
in oil immerse transformer the dga be use as one of the well establish tool to predict incipient fault occur inside the body of power transformer. 
with already in existence of more than five know method of dga fault interpretation there be the chance that all may give different condition result for the same sample. 
use a combination of more than one of the method and support vector machine will result in increase accuracy of the interpretation and so reduce the uncertainty of the transformer condition monitoring. 
synthesisable recursion for c plus plus hls tools. 
c base hls tool continue to improve in analysis and optimisation but be still restrict to a subset of c functionality. 
a c language feature miss from all common hls tool be recursion which make it difficult and time consume to write many type of program in hls. 
this paper present a technique for implement recursion as an embedded domain specific language edsl in c++ utilise the c++ front end of a hls compiler to build the state machine and stack while ensure the code present to the back end be completely synthesisable. 
while the edsl be not pure c it provide a user friendly language that can be trivially translate from a recursive c program and can contain call to plain c for compute intensive leaf function. 
hlsrecurse be a platform independent library that allow the same program to be compile use g++ clang legup or vivado hls and have the same execution semantic. 
the performance of hlsrecurse be evaluate in software and hardware use three micro benchmark of the underlie state machine builder and five practical example of real recursive program include a sudoku solver strassen multiplication and adaptive monte carlo integration. 
we show that for vivado hls the dsl provide the same area time product as manually convert program while in legup the dsl increase the area time product by 1.5x. 
parallel float point expansion for extended precision gpu computation. 
gpu be an important hardware development platform for problem where massive parallel computation be need. 
many of these problem require a high precision than the standard double float point fp available. 
one common way of extend the precision be the multiple component approach in which real number be represent as the unevaluated sum of several standard machine precision fp number this representation be call a fp expansion and it offer the simplicity of use directly available and highly optimize fp operation. 
in this article we present new data parallel algorithm for add and multiply fp expansion specially design for extended precision computation on gpu. 
these be generalize algorithm that can manipulate fp expansion of different size from double double up to a few ten of double and ensure a certain bad case error bind on the result. 
design and validation of multi core embedded systems under time to prototype and high performance constraints. 
this work deal with the problem of develop embed multi core system under time to prototype and high performance constraint by exploit reconfigurable logic. 
in particular the paper focus on the early analysis activity perform by mean of native simulation technology and then on the full development of an embed multi core platform compose of four leon3 soft processor and able to support the execution of openmp base application. 
moreover in order to evaluate software execution time at run time a distribute hardware profiling mechanism have be insert into the final implementation to monitor the whole system. 
the final goal be the definition and the exploitation of a high level design and validation methodology able to exploit both a well know parallel execution paradigm and a run time system monitoring service. 
correctness and performance of such a platform have be evaluate by mean of specific benchmark. 
a framework to support active management and communication of cultural objects. 
ict base technological innovation have not yet make substantial advantage although desirable in the cultural heritage field both as regard the management and as regard the use of asset. 
it be still weak the receipt of the paradigm of the internet of things iot. 
conversely ict base technology could play a main role in the following we discuss how iot can make a valuable contribution to emphasize the knowledge process through augmentation of past memory with information interface and allow a complete management of the heritage artefact from conservation to communication. 
vessel monitoring and design in industry 4.0 a data driven perspective. 
the main purpose of this work be to build a data drive model to create realistic operating profile in order to assess and compare different design solution. 
the propose approach take advantage on the new generation of automation system which allow gather a large amount of datum from on board machinery. 
a data drive modeling of the operational profile of the vessel and in general of the fleet could provide a tool both to diagnose and predict the vessel s state e.g. 
for condition base maintenance purpose for improve the performance and the efficiency of the vessel and for improve design solution. 
the diagnosis and prognosis of the ship s performance can be use as decision support in determine when action to improve performance should be take. 
the developed model will be test on a real damen vessel where on board sensor datum acquisition be available from the automation system. 
an automatic scaling procedure for a wearable and portable hand exoskeleton. 
the design of an aid for the hand function base on exoskeleton technology for patient who have lose or injure hand skill because of neuromuscular or age disease be one of the most influential challenge in modern robotic to assure they an independent and healthy life. 
this research activity be focus on the design and development of a low cost hand exoskeleton system hes for support patient affect by hand opening disability during the activities of daily living adls. 
in addition the device able to exert suitable force on the hand can be use during the rehabilitative session to implement specific task useful to restore the dexterity of the user s hand. 
the hand exoskeleton system develop by the mdm lab mechatronic and dynamic modelling laboratory of the department of industrial engineering university of florence italy be base on a single phalanx architecture and consist of a mechanical part mechanism and electronic actuator control unit and battery pack. 
in this paper the author propose a scaling procedure to automatically adapt the hand exoskeleton to different patient. 
start from the acquisition of the hand trajectory of the patient obtain through a 3d motion capture mocap system a suitable optimization algorithm be use to determine the dimension of the mechanism part that allow to replicate at good the acquire trajectory. 
the optimization process show satisfy result permit to obtain device which tailor the hand of generic patient and able to reproduce the natural kinematic of the finger. 
a web base monitoring application for textile machinery industry. 
today globalization and more stringent requirement push manager to optimize all system involve in their organization and in particular the operation process which have great impact on productivity. 
in this scenario concept as availability and time to repair play a key role for achieve the desire key performance indicators. 
to this end the advanced of communication technology can support practitioner in manage more efficiently production process use advanced approach to plant machine monitoring. 
traditionally supervisory control and data acquisition scada system can support operation activity mainly production and maintenance and allow operator to monitor and supervise the entire production process. 
this paper present a web base solution development for scada system base on web service. 
the solution allow operator to constantly monitor operating state and real time datum of machinery in order to prevent machine failure or handle they as soon as possible. 
at the same time datum be collect and store in a server in order to extract information and make historical analysis about productivity and efficiency use analytic approach. 
the managerial implication of this approach be quite evident the traditional monitoring approach be reactive and aim at receive information about the state of machine without anticipate the event or customize the information require. 
the propose monitoring system try to fill this gap provide analytic approach in order to anticipate failure or diagnostic it when occur in order to enable the intervention and for instance provide also a context awareness information system which can be customize on specific employee. 
towards better scalability for iot cloud interactions via combined exploitation of mqtt and coap. 
it be manifest the grow research and industrial interest in scalable solution for the efficient integration of large amount of deploy sensor and actuator internet of things iot device and cloud host virtualized resource for elastic storage and processing include big datum online stream processing. 
such relevant attention be also demonstrate by the emergence of interesting iot cloud platform from industry and open source community as well as by the flourish research area of fog edge computing where decentralize virtual resource at edge node can support enhanced scalability and reduce latency via locality base optimization. 
in this perspective this paper propose an innovative distribute architecture combine machine to machine industry mature protocol i.e. mqtt and coap in an original way to enhance the scalability of gateway for the efficient iot cloud integration. 
in addition the paper present how we have apply the approach in the practical experience of efficiently and effectively extend the implementation of the open source gateway that be available in the industry orient kura framework for iot.. 
polluino an efficient cloud base management of iot device for air quality monitoring. 
the internet of things paradigm originate from the proliferation of intelligent device that can sense compute and communicate data stream in a ubiquitous information and communication network. 
the great amount of datum come from these device introduce some challenge relate to the storage and processing capability of the information. 
this strengthen the novel paradigm know as big data. 
in such a complex scenario the cloud computing be an efficient solution for the managing of sensor datum. 
this paper present polluino a system for monitor the air pollution via arduino. 
moreover a cloud base platform that manage datum come from air quality sensor be develop. 
design of a html5 scada system. 
the scada supervisory control and data acquisition system be one of the most important component of the industrial automation. 
they be use as the interface for production machine line and entire plant. 
the industrial solution be usually base on desktop application and require a continuous presence of operator close to the hmi human machine interface. 
in the last decade the evolution of the internet and all the correlate technology allow to extend the way of communicate interact and manage information in this context the evolution of the industrial world must engage the consumer world introduce innovation in the process. 
a html5 solution for the scada allow to extend the system capability as the possibility of distribute the hmi on different hardware architecture activate push notification of alarm establish the direct connection of the plant to the erp and the company management system. 
this paper present the prototype of a html5 scada this solution contribute to the development of a sophisticated context awareness system allow to filter and provide the need information to specific user. 
the target be to achieve all this together with reactive interface to provide good performance consider the web datum transmission bottleneck. 
build a smart maintenance architecture use smart device a web 2.0 base approach. 
in industrial environment to optimize and to improve maintenance operation could be one of main goal to achieve for enhance revenue for machinery manufacturer provide after sale service to their customer. 
especially remote maintenance and diagnosis be aspect investigate in literature and in real environment in the last year. 
in fact remote access and role specific datum distribution can become the next level upgrade of maintenance diagnostic and flow control management use smart sensor actuator and smart consumer device smartphone tablet etc. 
in this paper a real case study have be propose a new web service base server application in order to have remote access to the data stream and to analyze they in an italian machinery company manufacturer have be provide. 
this solution permit to have the machine status available on a web page very strict time response a well user profiling and innovative control system base on line smart device monitor machine datum and send notification sound when need. 
the result be a platform connect by use the internet of things iot paradigm industrial machinery with a smart device android app and with a web application build with web 2.0 base technology. 
flip chip bonded silicon carbide mosfet as a low parasitic alternative to wire bonding. 
this paper present flip chip bonding as an alternative to wire bonding for commercially available silicon carbide sic mosfet. 
a process be develop for the wire bondless attachment of a sic power mosfet onto a substrate. 
the gate and source bond pad of commercially available mosfet be typically make of aluminum to aid the wire bonding process. 
the process for obtain a finish suitable for soldering or sinter on these pad be describe in this paper. 
an additional concern during the flip chip bonding of a mosfet be the possible shorting of the source and gate pad. 
the gate and source terminal of the power mosfet be typically in very close proximity with each other on the die make the flip chip process susceptible to the formation of conductive bridge when soldering or sinter. 
a procedure for address this concern be present. 
the performance benefit of the flip chip scheme be analyze and compare with the traditional wire bonding process through die shear and pull test. 
implementation of a digitally controlled sic cmos pwm generator use a tunable current starve delay generator for high temperature switch mode regulator. 
this paper describe the design of a sic pulse width modulation pwm signal generator in the hitsic r cmo process from raytheon systems limited. 
the high temperature application of the circuit include motor control in heavy equipment deep earth drilling dc dc voltage converter and power inverter. 
the result present in this paper be for the pwm circuit operate with an input clock frequency of 100 khz and a supply voltage range of 12 to 15 v. 
the building block for the pwm include a current starve delay generator a comparator and xnor gate. 
the delay be control by a six bit binary input that allow the user to dynamically tune the duty cycle. 
experimental result show the circuit to have a tunable duty cycle between 16.3 and 84.3 at 400 degree c.. 
novel evaluation methods of end turn stress grading materials for converter fed high voltage rotating machine. 
carbon base semi conductive material corona armor tape or cat and sic base nonlinear grading material have be use widely to reduce the electric field in the region where the stator bar exit from the slot in form wound rotate machine. 
recent study show that electric field and local heating in the end turn stress grade system become severe under pwm waveform and high frequency repetitive pulse. 
in this paper method for accurate measurement of cat conductivity as well as select the appropriate conductivity to control both the electric field and local heating be investigate base on transient nonlinear fem computation. 
the method propose in this paper should be adequate to optimize end turn stress grade system of the rotate machine. 
lu qr and cholesky factorizations programming model performance analysis and optimization techniques for the intel knights landing xeon phi. 
a wide variety of heterogeneous compute resource range from multicore cpu to gpu and coprocessor be available to modern computer make it challenge to design unified numerical library that efficiently and productively use all these varied resource. 
for example in order to efficiently use intel s knights landing knl processor the next generation of xeon phi architecture one must design and schedule an application in multiple degree of parallelism and task grain size in order to obtain efficient performance. 
we propose a productive and portable programming model that allow we to write a serial look code which however achieve parallelism and scalability by use a lightweight runtime environment to manage the resource specific workload and to control the dataflow and the parallel execution. 
this be do through multiple technique range from multi level datum partition to adaptive task grain size and dynamic task scheduling. 
in addition our task abstraction enable unified algorithmic development across all the heterogeneous resource. 
finally we outline the strength and the effectiveness of this approach especially in regard to hardware trend and ease of program high performance numerical software that current application need in order to motivate current work and future direction for the next generation of parallel programming model for high performance linear algebra library on heterogeneous system. 
towards parallel implementation of associative inference for cogent confabulation. 
the superb efficiency and noise resilience of human cognizance come from the extensive highly associative memory. 
for example it be easy for human to recognize occlude or incomplete text image base on its context. 
associative inference in the neocortex system be a concurrent process. 
serial implementation of this concurrent process not only hinder its performance but also limit the quality of recall. 
this paper investigate parallel implementation of associative inference use cogent confabulation model which be a highly cross dependent and cyclic knowledge network that support probabilistic inference. 
by break the fix processing order which be typical in sequential processing and introduce randomness generate from the race condition in parallel processing we do not only reduce the runtime but also improve the accuracy. 
further improvement can be achieve by schedule the lexicon processing intermittently which provide time for the change to settle down. 
use sentence construction as a case study we demonstrate that the parallel implementation provide up to 93.4 reduction in computation time and five improvement in recall accuracy. 
toq.jl a high level programming language for d wave machine base on julia. 
quantum computer be become more widely available so it be important to develop tool that enable people to easily program these computer to solve complex problem. 
to address this issue we present the design and two application of toq.jl a high level programming language for d wave quantum anneal machine. 
toq.jl leverage the metaprogramme facility in julia a high level high performance programming language tor technical computing and use d wave s toq programming language as an intermediate representation. 
this make it possible for a programmer to leverage all the capability of julia and the d wave machine be use as a co processor. 
we demonstrate toq.jl via two application one a pedagogical example base on a map color problem and two a linear least square problem. 
we also discuss our experience use toq.jl with a d wave 2x particularly with respect to a linear least square problem which be of broad interest to the scientific computing community. 
transient stability of a hybrid micro grid with multivariable droop and virtual synchronous generator. 
integration of distribute generation dg in the power grid pose major technical challenge. 
many of the dg comprise of power electronic converter which be result in low system inertia and be create the challenge of voltage and frequency control during micro grid switch event. 
this paper investigate hybrid micro grid frequency and voltage control technique in particular multivariable droop and virtual synchronous generator vsg for transient load sharing between inverter base dg and a low inertia synchronous generator base dg. 
numerical simulation result show that frequency control performance be well achieve with the implementation of virtual synchronous generator compare with droop base control. 
data analytics in smart distribution network application and challenge. 
the large volume of datum that will be produce by ubiquitous sensor and meter in future smart distribution network represent an opportunity for the use of datum analytic to extract valuable knowledge and thus improve distribution network operator dno planning and operation task. 
indeed application range from outage management to detection of nontechnical loss to asset management can potentially benefit from datum analytic. 
however despite all the benefit each application present dno with diverse datum requirement and the need to define an adequate approach. 
consequently it be critical to understand the different interaction among application monitor infrastructure and approach involve in the use of datum analytic in distribution network. 
to assist dno in the decision making process this work present some of the potential application where datum analytic be likely to improve distribution network performance and the correspond challenge involve in its implementation. 
application of key performance indicator in circuit breaker online monitoring. 
the technology of circuit breaker online monitoring be mature but the datum the system provide be too professional to read. 
also the course of electrical equipment status change often last very long time. 
the change in numeric be too small to notice the problem of equipment. 
by acquire and process different kind of datum such as real time datum historic datum off line datum from production management system and manual intervention datum this study apply key performance indicator kpi in online monitoring system to provide more readable result of circuit breaker status. 
the new system have be apply in many smart substation and get positive response. 
trip and close coil modeling of circuit breaker and its control circuit fault diagnosis. 
this paper present a coil model of circuit breaker use matlab simulink and propose a weighted morphological filter with dual structuring element ses to process the coil current of the circuit breaker. 
in order to make sure that the simulink model of the trip and close coil be accurate enough the genetic algorithm ga be apply to optimize its parameter target the minimum difference between the current waveform of the model and the actual one. 
the simulation result have show that the propose morphological filter perform well in noise removal and the ga can optimize the parameter of the simulink model so that the current waveform generate by the model be almost identical to those obtain from field test. 
base on the datum produce by the optimize simulink model a method combine extrema extraction with fast template matching be use to monitor the condition of circuit breaker. 
a low power third order delta sigma modulator use ring amplifiers with power save technique. 
this paper present a delta sigma modulator with ring amplifier to decrease the power consumption. 
the propose delta sigma modulator employ a technique of cut off the current of ring amplifier after they be settle in each clock cycle. 
the optimum cutting off timing can be determine by monitor the output sndr. 
the propose one bit third order delta sigma modulator be design in 65 nm cmos process. 
from schematic level circuit simulation 76 db sndr be obtain at signal bandwidth of one mhz and clock frequency of 128 mhz. 
more than 40 percent of the power be save at clock frequency of 128 mhz and power scalability be obtain. 
operate diagram editor through unistroke gestures. 
in software development process diagram editor play an important role. 
for instance editor for create uml diagram be often use in early stage of software development. 
three input methodology can be distinguish traditional mode base editor sketch editor and gesture base editor. 
most of today s diagram editor be mode base and use the mouse as an input device. 
multi )touch input have not be integrate very well yet although a variety of touch input device such as multi )touch monitor and tablet computer be quite common today. 
in this paper we present an integration of an off the shelf unistroke recognizer into an exist diagram editor framework. 
this allow to reduce the number of different interaction mode in diagram editor as user perform editing task such as create modifying and delete by unistroke gesture. 
in order to examine the effect on the usability of such editor we conduct a pilot study use a statechart editor and present some preliminary finding here. 
diagnostic visualization for non expert machine learning practitioners a design study. 
as machine learning ml become increasingly popular developer without deep experience in ml who we will refer to as ml practitioner be face the need to diagnose problem with ml model. 
yet successful diagnosis require high level expertise that practitioner lack. 
as in many complex datum orient domain visualization could help. 
this two phase study explore the design of visualization to aid ml diagnosis. 
in phase one twelve ml practitioner be ask to diagnose a model use ten state of the art visualization seven design theme be identify. 
in phase two several design theme be embody in an interactive visualization. 
the visualization be use to engage practitioner in a participatory design exercise that explore how they would carry out multi step diagnosis use the visualization. 
our finding provide design implication for tool that well support ml diagnosis by non expert practitioner. 
tool demo operate diagram editor through unistroke gestures. 
in software development process diagram editor play an important role. 
for instance editor for create uml diagram be often use in early stage of software development. 
three input methodology can be distinguish traditional mode base editing sketch base editing and gesture base editing. 
most of today s diagram editor be mode base and use the mouse as an input device. 
multi )touch input have not be integrate very well although a variety of touch input device such as multi )touch monitor and tablet computer be quite common today. 
in this paper we provide some insight into the integration of an off the shelf unistroke gesture recognizer into an exist diagram editor framework and give some detail about three example diagram editor that incorporate a new interaction mode the so call gesture mode. 
an approach to gesture base editing of diagram. 
in software development process diagram editor play an important role. 
for instance editor for create uml diagram be often use in early stage of software development. 
three input methodology can be distinguish traditional mode base editor sketch editor and gesture base editor. 
most of today s diagram editor be mode base and use the mouse as an input device. 
multi )touch input have not be integrate very well yet although a variety of touch input device such as multi )touch monitor and tablet computer be quite common today. 
i present an approach for gesture base editing of diagram. 
the idea be that mode base diagram editor be extend by off the shelf unistroke gesture recognizer. 
in these diagram editor user can perform editing task such as create modifying and delete component by unistroke gesture. 
a survey of communication technologies for smart grid connectivity. 
the traditional electric power system be examine a transformation process to an intelligent efficient and cost effective smart grid sg system. 
the sg have different subsystem for its accurate functionality. 
among these subsystem the communication subsystem play a vital role for real time datum sharing between device and system connect in sg domain. 
in this paper a survey of smart communication subsystem be provide and several communication technology that have strong potential for implementation in future sg application by electric utility company be discuss. 
the advantage and disadvantage of each communication technology in the sg domain be also present. 
finally a hybrid communication model be suggest for reliable communication between smart meter and control system in the sg. 
digital controller design for full bridge boost rectifier use singular perturbation method base on pseudo continuous approach with power factor correction. 
the systematic approach of design a robust digital controller to solve output regulation problem for a full bridge boost rectifi with unknown external disturbance and vary parameter be discuss. 
the design of digital controller base on the so call pseudo continuous approach by use singular perturbation be present where this controller be the result of continuous time controller discretization. 
in the paper the control scheme for full bridge boost rectifier begin with the assertion that inductor current be fast state and capacitor voltage be slow state. 
this assertion must be true for power factor correction converter to allow independent control of current and voltage. 
the continuous time controller use proportional integral approach in feedback be use and the effect of discretization at discrete time instant have be take into account by inclusion of a zero order hold transfer function. 
the pseudo continuous time model of a control loop with the pure time delay be use to calculate the parameter of a digital controller where the pure delay be a result of the zero order hold transfer function approximation. 
numerical simulation for full bridge boost rectifi in discrete mode be present. 
mras and luenberger observers use a siflc controller in adaptive mechanism based sensorless fuzzy logic control of induction motor. 
most industrial application require high performance speed sensorless operation and demand new control scheme in order to obtain fast dynamic response. 
in this paper we present a comparison between mras and luenberger observer base fuzzy logic control siflc type. 
we also present a speed sensorless fuzzy logic control siflc of induction motor im. 
this command be a powerful tool to reject disturbance. 
however the chatter phenomenon present a major disadvantage for variable structure system. 
to reduce this problem a saturation function be use to limit chatter effect. 
mras and luenberger observer base on fuzzy logic adaptive mechanism be design for speed estimation. 
these propose scheme will allow a large reduction in computation time of such a drive and thus facilitate its implementation. 
numerical simulation result of the propose scheme illustrate the robustness against load torque disturbance and the good performance of sensorless induction motor. 
method for fluorescence image processing for low cost system. 
in this paper we demonstrate the feasibility of a low cost system for fluorescence signal detection and measurement. 
base on raw image format our experiment show that a consumer digital camera dc can be use as a fast and inexpensive tool for fluorescence measurement. 
from the three component r g and b three channel be form for multispectral discrimination of a fluorophore mixture. 
the three channel allow to improve the snr and the dynamic range be extend by control the exposure time. 
result show that a mixture of a three fluorophore can be correctly quantify and concentration less than eight ng ml can be correctly detect. 
burr grinder advanced effective post weld toe treatment to optimize fatigue life of welded structure. 
earth move machine be expose to the repeat fluctuating stress which cause fatigue crack at the toe and throat of weld joint due to the metallurgical imperfection. 
so weld joint be the weak region for the component of all earth move machine and act as a determine factor of expect life of earth move machine. 
also due to this weld joint must be fully understand to improve the fatigue and service life of the earth move machine. 
here failure at throat can be minimize by achieve optimum strength but problem of weld toe crack only be eliminate by reduce stress concentration at weld toe. 
to do this r d work have be initiate by prepare set of five t joint weld sample have eight mm sample f to j throat thickness with one as weld sample j without post weld toe treatment for benchmarke purpose have be prepare use gmaw welding process. 
for the toe grind of sample f to j post weld toe grind treatment as per iiw guideline with cylindrical hemispherical burr tool cutter a24pbf and flap disc grinder respectively have be apply to reduce the stress concentration at weld toe by make smooth transition at weld toe with undercut of one mm. 
use ug nx 7.5 solid model of t joint shape with sample size of 170 x 192 x eight mm have be create from the image of etched weld toe profile. 
post weld toe treat with hemispherical burr tool have give maximum optimization in fatigue life of 76 as compare to as weld sample j and validate by hardness testing at heat affect zone haz of etch sample which show that graph of alternate stress and fatigue limit show almost parallel trend and differ by proportionality constant. 
in search of a scalable file system state of the art file systems review and map view of new scalable file system. 
file be a super abstraction of hypothetically huge volume of information store in container disk block which be persist for very long time memory abstraction. 
file be linear array of bite and block of byte access by multiple client which be control by file system. 
file system function be disk seek read maximum information from container and map file name and offset to disk block for well read and write operation. 
file system be logic to device how information be stockpile and how effectively to retrieve it. 
file system manage reference pointer to memory block and assist to seek information in feasible manner. 
without which datum would be place in large heap of memory at location unknown to operate system to manage resource effectively. 
file system be structure and sense rule accustom in manage cluster of datum be term as file system. 
current age be age of high performance information processing and intelligent knowledge generation which urge for well scalable file system. 
current file system come with numerous limitation as architecture design pattern limitation i o operational component failure reliability issue datum decomposition fault tolerance etc. 
this manuscript give a first survey first step towards synchronize research. 
this be our first research article on scalable file system which facilitie view map of new scalable file system. 
beta survey methodology be be incorporate with pattern of abstract methodology and scope write for every research article relate to scalable file system survey. 
the key point answer of conclusion be luster a scalable file system which have be use as core in development of world top 100 supercomputer which fulfill key space to be scalable file system future research work would be implementation of luster file system and evaluation on parameter of global name space iops and luster file size no of client and ost s use with throughput mbps and read write pattern evaluation. 
crosstalk mitigation of network on chip an analytical review. 
as per international technology roadmap of semiconductors itrs network on chip noc become suitable example of the integration of several core on single die. 
now a day s die size be continuously grow large but at the same time minimum feature size be continuously shrink. 
although small transistor size can result in small circuit delay a small feature size for interconnect do not reduce the signal propagation delay thus the signal propagation delay in interconnect have be the dominant factor in determine the delay of a circuit. 
to lighten this problem interconnect be make thick to reduce the sheet resistance. 
unfortunately this induce crosstalk noise between adjacent interconnect because of capacitive and inductive coupling. 
this be refer to as a signal integrity problem and it be extremely difficult to detect. 
this paper provide the comparative analysis of various error correction code like bsc dap mdr sec cadec and jtec. 
a comparative analysis have be base on the block size power dissipation area overhead and path delay algorithm structure processing time speed and reliability. 
these analysis conclude good error correction technique. 
effect of fractional order under different condition. 
the frequency response method be most powerful in conventional control system. 
the impulse response characteristic be relate to the location of pole of f(s. 
in this paper we discuss impulse response of 1/(s(2)+as+b)(q for different fractional value of q where 0.5 q 1.5 under different condition a(2 4b zero a(2) 4b zero a2 4b zero where a b zero. 
the different character of the impulse response be show in numerical example. 
the number of figure be present to explain the concept. 
fiber wireless fi wi architectural technologies a survey. 
the paper aim to present various architectural technology of fiber wireless fi wi network base on previous and current interest of researcher. 
fi wi network recently become more powerful impactful in the access technology solution prototype. 
the survey overviews the architectural knowledge enable technology involve and compare it with future development of wireless optical network respectively. 
radio over fiber rof transmission be use to achieve high level of integration with simplified wireless base station. 
on the other hand radio and fiber r&f network be the most beneficial architecture implementation which be use to build wireless local area network wlan base fi wi network. 
patient assistance system in a super speciality hospital use a kinect sensor camera. 
recent advancement in depth imaging sensor technology have result in effective and inexpensive depth camera which be actively use for 3d motion capture surveillance system human tracking monitoring user recognition system and activity recognition. 
tremendous development have be carry out in communication and networking for the design of smart ward systems use in health monitoring system. 
sws empower hospital staff to focus more on patient by enable the collection of datum at the bedside and remove the need for duplication and double handling. 
uniquely sws have a rigorous evidence base to demonstrate reduce cost through improved patient safety. 
the propose work be perform by detect and recognize the gesture obtain through the kinect camera. 
here the training include datum collection and feature extraction. 
secondly the train datum be classify use k nearest neighbors support vector machines and artificial neural networks method. 
to adopt the good classifier this paper compare the accuracy of all the above technique. 
mode selection operation have be test with three different classifier and svm be prove to be good out of they. 
the evaluation be do base on various performance metric like classification effectiveness accuracy and recognition rate. 
ramanujan sums based image kernels for computer vision. 
in the recent history kernel method have establish themselves as powerful tool for computer vision. 
in this paper we introduce an integer image kernel function base on ramanujan sums which find its place in image vision. 
the paper prove the validity of kernel function theoretically and also show the application of the kernel in image vision. 
ramanujan sums be base on number theory and hence the new kernel matrix will contain only the integer value. 
since the image processing involve complex matrix manipulation the processing base on the new kernel will be computationally effective. 
the paper show the applicability of the kernel in various context of image processing. 
by apply the theory of ramanujan sums for image kernel we will show the intervention of numerical mathematic in machine learning which give new direction for future research. 
workflow scheduling in cloud computing environment use firefly algorithm. 
cloud computing be the new generation of network that use remote server host on the internet for various use such as datum storage datum management software usage etc. 
there be huge amount of resource provide and user can make use of the resource in any way they want to. 
today researcher attempt to find new way for workflow scheduling which could work well in the cloud environment. 
workflow scheduling be the most important task in cloud computing field and user have to pay for resource that be use base in a pay per usage scheme. 
hence workflow scheduling play a vital role in get maximum benefit from the resource that be provide. 
another important element to be consider about cloud computing be load balance. 
this controlling of fill assure that every exclusive machine do the very same amount of labour at any immediate of time. 
to make sure this we want to recommend on use the idea of fill control. 
here in this document we recommend heuristic criterion know as firefly criterion for effective fill control in reasoning processing. 
this criterion be base on the travel behaviour of the firefly which go look for the close possible maximum alternative. 
we employ firefly algorithm to schedule the job and thereby evenly distribute the load and in turn reduce the overall completion time makespan. 
a multi objective optimization use a combined approach of principal component analysis and topsis during electric discharge machining of h 11 die steel use p m process cu cr ni metal matrix composite. 
the present experimental investigation deal with the electric discharge machining of h 11 die steel use metal matrix composite mmc as tool electrode. 
the mmc be prepare use powder metallurgy p m route at a sinter temperature of 800 degree c a comparative study have be make use conventional cu and powder metallurgy p m process cu cr ni mmc as tool electrode. 
the effect of input parameter like peak current i p pulse on time t on duty cycle dc and gap voltage vj on response variable like material removal rate mrr tool wear rate twr surface roughness sr and diametral overcut doc have be analyze. 
multi objective optimization have be do use a hybrid method of principal component analysis pca and technique for order preference by similarity to ideal solution topsis to obtain the optimal set of parameter for copper and cu cr ni tool. 
the optimum parameter set for copper tool be find to be at i p 3a t on=200 mu s dc=9 v g=50v and for cu cr ni tool be find to be at i p=6a t on=150 mu s dc=9 v g=30v.. 
development of a heuristic algorithm for finding optimum machine loading sequence in fabrication shop with job shop layout. 
sequence and scheduling technique be the mean for take decision about the order and time in which a set of job be to be process through a set of machine(s to get the output of finished product in a desire order and time. 
among all the industry where the scheduling problem exist job shop scheduling jss problem be consider to be the most difficult and complicated one to be solve and as such it be consider to be a nondeterministic polynomial time hard nphard category problem. 
hence the number of technique develop so far be not enough to compute the optimum result. 
look at this aspect the present work be an attempt to solve jss problem by develop a heuristic algorithm. 
the datum be collect from the fabrication shop of a sheet metal processing industry with job shop js layout. 
it be find that the algorithm be useful in minimize the value of makespan and machine idle time along with reduced number of new machine setup require. 
to test its validity the collect datum be also analyse by use some standard dispatch rule and when the result be compare it be find that the developed algorithm be produce well result. 
moreover by follow the obtain sequence it be see that the inter departmental co ordination be establish and internal customer satisfaction be attain in respect of component availability at the time of their requirement. 
automatic code generation with business logic by capture attributes from user interface via xml. 
the integrated development environment ide base development tool like. 
net framework windows builder net bean be popular for easy and comparably fast project development which be also need of an hour. 
these tool have capability of drag and drop dnd with tool box with control which help developer to design graphical user interface gui just with mouse click. 
but none of these tool can generate complete working code with business logic bl embed automatically in source code. 
in routine development process developer spend time to do the repeat task of code for same event. 
the vendor specific tool like oracle application express oae microsoft vb. 
net and similar tool from ibm can design and develop the product for analysis and reporting purpose but these tool strictly need the proprietary db to develop the project. 
the oae from oracle need oracle as a backend whereas ibm need db2. 
moreover none of these tool give work code with bl in any language. 
our tool rapid project builder rpb address these problem thereby avoid the time consume task of code the same business logic repeatedly. 
the tool also perform automatic code generation acg in specific language like c++ java etc. 
once the application s ui with dnd be design along with the specification of form and field of various control like text box label button and the like with operation like add delete search or modify for button of the application rpb automatically embe code of bl to these control in language code. 
the acg with bl automatic db generation with table and validation code generation be do with the help of ui specification which be store as xml meta file. 
multiple attribute decision make use hesitant triangular fuzzy set. 
multiple attribute decision make madm be an inevitable part of our daily life which be immensely use in managerial economic constructional problem etc. 
in real world there be many situation where one have to take a decision in a highly uncertain environment. 
in that case of decision making since a linguistic term be close to human cognitive process it be more convenient and realistic for the decision maker to provide his assessment in linguistic form. 
nevertheless sometimes the decision maker can not easily provide a single linguistic term as an expression of his knowledge about a particular outcome. 
the current study present an extension of technique for order preference by similarity to ideal solution topsis use hesitant triangular fuzzy set htfs to solve madm problem. 
herein the importance weight of different attribute and the rating of alternative base on these attribute by the decision maker be consider to be htfs. 
the propose technique be demonstrate by take an example of supplier selection in supply chain management for a fertilizer make industry. 
the linguistic term such as very low vl low l medium m high h and very high vh be use to be the constituent of htfs represent the importance weight of attribute. 
and linguistic term such as very poor vp poor p fair f good g and very good vg will constitute the htfs represent the rating of different alternative under the give set of attribute in a madm problem. 
optimization of inconel 600 use wire edm by moora and taguchi s method. 
the present experimental work deal with examine the effect of machine parameter such as wire feed rate pulse on time ton pulse off time toff and voltage in wedm on the machining characteristic of inconel 600 be investigate. 
wire edm be a procedure of cut material which be electrically conductive in nature follow a predefined programmed path accord to the requirement. 
inconel 600 be a nickel chromium alloy generally use where corrosion and high temperature resistance be in demand. 
the experimental analysis have be do use taguchi s l9 orthogonal array. 
the signal to noise ratio associate with the observed value in the experiment have be determine by moora method. 
the most optimal machining parameter for maximum material removal rate and minimum machining time surface roughness and overcut be find out use taguchi s methodology. 
the aim of this paper be to find out the optimal parameter for machine. 
it have be observe that different process parameter have different effect on machine hence multi objective optimization have be use to find out the optimal setting. 
optimization of reconfigurable fabric of dsp processor with image processing. 
in recent scenario design complexity increase which motivate system designer to innovate continuously. 
while design complex system with tight coupling various block designing be become a choice. 
the strongly emerge class coarse grained reconfigurable architecture cgra be currently receive due attention have excellent performance as well as flexibility in fabrication. 
cgra be have one of the important block as reconfigurable array or fabric. 
in this paper design of reconfigurable fabric with various combination of processing element be present. 
also this design be analyze with area power and delay t achieve optimization of dsp processor use various fpga. 
extraction of speech signal based on power normalized cepstral coefficient and mel frequency cepstral coefficient a comparison. 
speech processing be emerge as one of the important application area of digital signal processing. 
power normalized cepstral coefficients pncc and mel frequency cepstral coefficient mfcc be mainly use in feature extraction of speech signal. 
the problem of real time speaker segmentation in speech processing be enormous in which no prior knowledge about the number of speaker and the identity of speaker be available. 
in this paper the performance of the pncc and mfcc be compare and the experimental result demonstrate that pncc processing provide improvement in recognition accuracy in the presence of various type of noise and in environmental change. 
the performance of pncc method be robust to natural and unpredictable situation. 
tweeple s microblogs on illegal immigration in usa. 
opinion mining have become the center of attention for many researcher and scientist. 
that s because people share their thought and opinion as text precisely in microblog such as on facebook and twitter. 
this research present a process for opinion mining of tweeps the people who tweet on twitter. 
the immigration topic be choose specifically in comparison with other important topic of politic because it have remain as an unsolved problem for decade. 
the datum for this research be collect after the us republican presidential election debate on october 28 2015 at university of colorado in boulder for a period of approximately 10 day. 
the three major category of opinion identify be reform or give citizenship to illegal immigrant deport all illegal immigrant or deport only the criminal illegal immigrant. 
in a manual walkthrough of the datum the majority of the opinion be find to be bias towards the second category which be deport all illegal immigrant. 
binary classification for first two opinion for and against and multinomial classification for all three opinion be do. 
random forest multinomial naive bayes linear support vector machine and logistic regression classifier be use for this purpose. 
the result obtain use all four classifier for both the pathway be strongly and dramatically convincing. 
linear support vector machine and ensemble approach use random forest classifier show well accuracy for each class and low percentage error. 
model the process parameter of rp fdm use anova and response surface methodology for pc abs material. 
this paper describe an experimental design technique for determine the optimum surface finish dimensional accuracy and porosity of a part build by fused deposition modelling fdm process and mathematical modelling of the process parameter. 
it also explain the contribution effect of slice height raster width air gap orientation and raster angle on surface roughness dimensional accuracy and porosity. 
experiment be do by taguchi s design of experiment with two level. 
the analysis be do by both anova and response surface methodology. 
the good and optimum process parameter find out to be be slice height of 0.1270 mm raster width as 0.6096 mm air gap zero mm orientation as 30 degree and raster angle as zero degree. 
avail internet of thing in industrial decision make a survey. 
internet of thing be a transpire technology in the field of it where heterogeneous thing communicate with each other over internet. 
the thing allude to everything and anything that surround we. 
development of industry play a vital role in the growth of country. 
as technology be advance day by day it be be aggrandize for growth of industry. 
decision make process have exigency in escalation of the industry. 
in the present era iot play a major role in industrial decision make as well as in monitor manufacturing process. 
this paper address internet of thing its architecture protocol comparison of protocol and the deployment of iot in various industrial decision make process. 
optimisation of grind parameter for wheel loading and dressing. 
grind be a finish process often use to produce desire surface roughness with require precision and quality. 
the performance of grind wheel significantly depend on the nature of the wheel morphology of the abrasive grit and the grind parameter namely speed feed and depth of cut. 
as the wheel be perform its grind operation its cut surface be be load with metal particle of the workpiece. 
this wheel loading also affect the surface finish of the workpiece. 
hence monitor the grind wheel loading and dress at proper time interval become mandatory to get the desire surface finish. 
in the quest of develop a low cost monitoring system it be good enough to analyse the wheel loading on widely use metal specimen such as mild steel hchcr steel and aluminium under optimise cut condition use the conventional silicon carbide and aluminium oxide wheel for well evaluation of the result. 
in this work the grind parameter be optimise by use anova technique. 
a full factorial experiment be carry out at five level of significance at 95 confidence level. 
neural network base intelligent sensor fault detection in a three tanks interacting level process. 
this paper present sensor fault detection in a three interact level system and fault detection and control under sensor failure condition. 
train back propagation neural network estimate the process state. 
the fault detection and isolation be do by decision logic. 
if any failure be identify the control law be modify accordingly use the estimate value as the substitution for the fail process sensor output to implement the fault tolerant control. 
the individual failure of three level sensor be consider in this paper. 
the result show that the system be able to control the level in the interact tank perfectly in all the failure situation. 
an efficient vm consolidation use penguin search optimization algorithm pesoa for make cloud greener. 
cloud computing be apace raise the most recent technology. 
high power consumption be the main drawback of cloud. 
the prevail system provide a reactive and proactive virtual machine vm provision approach for the cloud. 
the prevail system be tough to produce an honest exchange between power and performance. 
in the propose system a unique approach to consolidate multiple virtual machine in exceedingly cloud base distribute hosting surrounding. 
the propose system use penguin search optimization algorithm pesoa to create an economical vm consolidation and help plan go up with the several concurrent virtual machine with different application. 
this system agree to split vm source along with apply program the amount of need vm be also decrease. 
the current strategy provide automate planning and realistic go up of several concurrent application on specify feature as favor think in an extremely allocate host atmosphere. 
an intelligent question answering system for ict. 
demand for question answering system be increase day by day since they deliver short precise and question specific answer. 
huge amount of redundant datum from irrelevant document through the world wide web have give rise to an information technology it question answer system to be use by secondary student. 
the main aim of develop such a system be to allow student obtain concise and relevant information about the it subject in a short time period without have to search thousand of document or website. 
hence an interactive platform have be develop which allow the user to pose question and the system respond by display the most relevant answer. 
text mining technique have be use to select document across the web which contain answer to it question and use these document to form a structure knowledge base. 
algorithm have be derive to extract basic component from question and method to match and compare these with the knowledge base and to finally display the most relevant answer. 
design and development of wireless flow transmitter. 
this paper present the development of a wireless flow transmitter use rotameter and operational amplifier base signal conditioning circuit. 
the rotameter be a linear gravity base flow measure device. 
it consist of a display unit which directly display the flow rate. 
for industrial application a new circuitry be require to transmit the measure flow rate to the control unit at remote area. 
a ferromagnetic wire attach to the float of rotameter act as a core of an inductance pickup coil constitute the flow sensor. 
the self inductance of the coil change accord to the change in flow rate. 
an operational amplifier base circuit be use for the measurement of self inductance. 
the voltage correspond to the flow rate be finally convert into four 20 ma current. 
a wireless readout be provide use a microcontroller unit and a bluetooth module. 
the result show a linear relation between the variation of self inductance of a pickup coil as well as transmitter output with respect to flow rate. 
the theoretical equation and the simulation result be add in this paper. 
an experimental approach for precise temperature measurement use platinum rtd pt1000. 
temperature measurement refer to the process of evaluate a current local temperature for immediate or later assessment. 
this research paper describe the design and development of circuit module for lab experiment. 
monitoring follow by control maintain the temperature of instrument payload fly in a spacecraft be very important application. 
secondly scientific laboratory require different kind of heater hot plate whose temperature have to be monitor and control precisely. 
instrumentation be develop to give the appropriate electrical signal in the range of analog input to the microcontroller after signal conditioning. 
it provide an efficient alternative to the exist temperature measure technique with comparable performance. 
the system can also be interface with matlab or a custom make gui to log and plot temperature time graph. 
simulation modeling and analysis of labour intensive small and medium sized enterprise for choose the good alternative production system. 
to stay ahead of open competition labour intensive small and medium sized enterprise such as leather textile and garment resort to choose the good alternate production system that be popular in other sector. 
this paper discuss a simulation as a decision make tool to choose the good alternate production system for leather small and medium sized enterprise lsmes. 
the simulation model be develop and analyze for each production system. 
the simulation be use to evaluate the relative performance of each production system. 
base on the analysis a conceptual hybrid production system hps build on some of the fundamental concept use for implement total quality management tqm and lean manufacturing lm be propose for labour intensive small scale industry. 
big data acid versus base for database transactions. 
database developer all know the acid acronym. 
it say that database transaction should be atomic consistent isolated and durable. 
these quality seem indispensable and yet they be incompatible with availability and performance in very large system. 
for example suppose you run an online book store and you proudly display how many of each book you have in your inventory. 
every time someone be in the process of buy a book you lock part of the database until they finish so that all visitor around the world will see accurate inventory number. 
that work well if you run the shop around the corner but not if you run amazon. 
com. 
amazon might instead use cached datum. 
user would not see not the inventory count at this second but what it be say an hour ago when the last snapshot be take. 
also amazon might violate the i in acid by tolerate a small probability that simultaneous transaction could interfere with each other. 
for example two customer might both believe that they just purchase the last copy of a certain book. 
the company might risk have to apologize to one of the two customer and maybe compensate they with a gift card rather than slow down their site and irritate myriad other customer. 
there be a computer science theorem that quantify the inevitable trade off. 
eric brewer s cap theorem say that if you want consistency availability and partition tolerance you have to settle for two out of three. 
for a distribute system partition tolerance mean the system will continue to work unless there be a total network failure. 
a few node can fail and the system keep go an alternative to acid be base basic availability soft state eventual consistency. 
prediction of parkinson s disease use speech signal with extreme learning machine. 
speech impairment analysis have be use as an efficient tool for early detection of parkinson s disease pd. 
in this paper we have propose an efficient approach use extreme learning machine to predict parkinson s disease accurately utilise speech sample. 
the performance of the method have be assess with a reliable dataset from uci repository. 
the propose method distinguish parkinson diseased subject and healthy subject with an accuracy of 90.76 and 0.81 mcc for the training dataset. 
when test with an independent dataset comprising of parkinson diseased patient the propose method give 81.55 accuracy. 
the performance of our method be compare with exist technique such as neural network and support vector machine. 
the result obtain depict that the proffered method be reliable for identify the parkinson s disease. 
condition monitoring of gas turbine power plant use image processing(cmgtppip. 
in the gas turbine power plant the image of the flame be obtain from the video image capture by the infrared camera. 
this flame image be analyze for image processing detection recognition and to understand the combustion condition. 
the flame image obtain be classify by soft sensor use feed forward neural network train with back propagation algorithm bpa. 
classification and other process be do base on the colour of the flame image which be determine by the combustion quality. 
first for each flame image a feature vector be determine. 
the feature vector describe seven feature of the flame like brightness of flame the area of high temperature flame brightness of high temperature flame the rate of area of high temperature flame the flame centroid. 
image classification and feature vector be do to measure the temperature and flue gas emission from the colour of the flame obtain from the image. 
here 51 sample image be take for training testing and with propose algorithm which be then recognize and classify. 
fault diagnosis of rolling element bearing base on vibration current signatures an optimal network parameter selection. 
as far as the asset reliability be concern the condition based maintenance be a major issue. 
the old maintenance strategy like break down preventive hold not good any time for many production system. 
to create competitiveness sustain in market cbm be a good tool. 
rolling element bearing be a major component of machinery which be very prone to failure. 
researcher have propose many condition monitoring method base on different type of fault characteristic. 
in the present industrial scenario 70 bear vibration 20 wear particle be use as fault characteristic remain 10 cover all the ndt non destructive testing include eddy current measurement. 
now current monitoring method be come out from its old position be in trend due to its various advantage over the other. 
to merge the benefit and increase the efficiency an integrate condition monitoring method base on vibration and current be present in this work. 
feature be collect from an appropriate experimental setup. 
bpnn back propagation neural network be use for bear fault classification. 
the optimal network parameter be select for batter result. 
result be simulate use malab proclaim that propose method can be use for roll element bear fault diagnosis. 
keyword search in information retrieval and relational database system two class view. 
information retrieval and web search domain revolve around search and retrieve methodologies keyword search have be most popular and easy to use technique. 
popular search engine like google bing at core have this methodology in operation. 
keyword be term extract from document or single sentence generating sense when cluster in context. 
same keywords might be present in different document but structure and position of keyword build different meaning this highlight keyword importance. 
keyword be daily use atomic term which when use in two or more group to represent information form phrase or short sentence and require concept generate by keyword. 
success of keyword technology be simple match of document consist question keyword. 
even though irrelevant result be retrieve due to word sense ambiguity wsd necessitate concept extraction web information be multiply in petabyte and daily 20 petabyte of information be process by google still core technique of search remain on keyword as good even today. 
a lot effort have be take to extend this keyword search pattern to relational database system from last four decade. 
a large volume of information be store in datum which be as large as size of static web. 
extend keyword search to relational datum base system would eliminate requirement of specialized datum processing and manipulation language like sql. 
database would be handle by nontechnical person simply with assistance of word. 
relational database system be operate with precise query retrieve all match record restrict query dimension on other hand ir system rank and present information document contain cluster and focus on user experience and precision. 
extend keyword pattern search on relational database management system also require extend index ranking cluster to database management system with specially construct component perform above task. 
this research work be dedicate to keyword search and give two viewpoint of its application in ir and database system. 
article present prototype of machine a and b where a present innovative ir system and b present discover approach relational database management system. 
article focus more on extend keyword search to database management system as it less address topic and more challenging. 
analysis of machine b show that performance evaluation need to address with effective evaluation like query workload memory utilization for flexible and scalable optimize machine development. 
rather than evaluation parameter like time delay etc. 
hybrid scalable document retrieval system be build and evaluate on memory utilization and search space be reduce by half with two layer algorithm. 
further scope of system be develop hybridization at machine level and work with image as input query. 
720 degree performance appraisal an effective tool to efficiency of modern employees. 
take you all my wealth take all my machine but leave my man alone and i will become hendry ford again say henry ford. 
these word of henry highlight and uphold the human resource as a prime resource before all other resource. 
it s in fact true that the well utilize human resource never lead to disparity or failure. 
in this line the role of performance appraisal have a tremendous role to play in develop the effectiveness and efficiency of employee. 
for a man the unexamined life be not worth live say the greek philosopher socrate. 
similarly an employee whose performance be not examine and enhance do not lead to fruition. 
throughout the globe the performance appraisal system have be utilize as a method of evaluate an employee s job performance. 
it be rightly say that encouraged people achieve the good dominate people achieve second good neglect people achieve the least. 
as recognition and reward at the right time be the good encouragement. 
from the time human being have evolve they have employ different method to appraise the performance start from the traditional comparison method to the modern 720 degree appraisal method. 
720 degree appraisal method aim at monitoring measure give feedback and encourage the employee to achieve the goal and for the organization in turn. 
a new technology use decision control algorithm with adaptive multi criterion vertical handover for hwn. 
the next invention of mobile wireless communication system be expect to include heterogeneous broadband wireless network that will coexist and use a universal ip core to propose a diverse range of high data rate multimedia service to end user with modern day mobile device that be equip with multiple network interface since the network have characteristic that balance each other. 
a authentic study by mean of the integration of wireless wide area network and wireless local area network as an example show that our propose vertical handover decision algorithm be able to verify when a handover be necessary and select for the optimum way in network that be optimize to network condition value of service requirement consumer choice and service lie out. 
this require the combination and interoperation of heterogeneous network and the provision of vertical handover. 
here we use a fuzzy inference method to process a multi criteria vertical handover decision metric. 
locality based data partitioning in map reduce. 
big datum be a broad term for data set so large or complex the traditional data processing application be inadequate. 
challenge include analysis capture data duration search sharing storage transfer visualization querying and information privacy. 
the processing and storage of big datum although make efficient and easy by hadoop there be two thing to be consider a storage part hadoop distributed file system and a processing part map reduce. 
the performance of a map reduce depend on how the datum be partitioned and then control in parallel manner. 
the current method be far from optimal. 
the skew aware partition technology be use to detect the problem relate to datum partition that affect performance. 
in this paper we enhance the split mechanism of hadoop without make it hard than exist. 
there be a series of work on datum partition in database community we want to employ more intelligent method like sample datum for record skew program code analysis for computation cost estimation etc to enhance our work for optimize data partition in mapreduce. 
experiment result demonstrate that our solution can improve the mapreduce processing performance remarkably than traditional hadoop implementation. 
elucidation of polishing mechanism use in magnetic polishing brush. 
in recent time there have be grow demand for environmentally friendly method for finish freeform surface e.g. molding die surface. 
this demand have generate interest in the development of a new polishing technology that use less abrasive slurry and employ magnetic abrasive finishing. 
however it be well known that the traditional magnetic polishing method be unstable and produce insufficient surface smoothness. 
in the present paper we discuss the reason cause instability in conventional magnetic polishing. 
we systematically investigate the magnetic pressure distribution characteristic and measure the pressure distribution of the magnetic brush during machine. 
furthermore we propose a new magnetic brush that use steel ball steel ball brush and abrasive slurry and compare this brush with a brush that use iron powder paste employ in the traditional magnetic polishing method. 
finally we present the processing mechanism of the propose brush for polish a flat surface on a three axis machining center. 
improvement in both transient and steady state response in a sample data control system. 
this study discuss a design method for a sample datum multi rate control system in which the sampling interval of the plant output be an integer multiple of the hold interval of the control input. 
in this study a pre design multi rate control law be extend such that the sample behavior be maintain. 
use the extended control law both the transient and steady state intersample behavior can be redesign independently of the sample behavior. 
the effectiveness of the extended method be demonstrate through numerical example. 
step nc interpreter for intelligent and open cnc. 
it be necessary for the step nc controller to interpret step nc file directly in order to make use of high level product manufacture information. 
in this paper a step nc interpreter be propose and implement base on open cnc platform. 
two interface name iinterpreter and itaskgenerator be define and encapsulate into com module by use c++. 
the mechanism for interpret and execute step nc file be build base on multi thread and share memory technology. 
a test part that contain six machining feature be machine on the machine tool to demonstrate the function of step nc interpreter. 
the experiment result indicate that the step nc controller be able to interpret and execute step nc file directly without compile it to motion control command. 
learning features from vibration signal for induction motor fault diagnosis. 
aim at automated and intelligent state monitoring of induction motor which be an integral component of a broad spectrum of manufacturing machine this paper present a deep belief network dbn) based approach to automatically extract relevant feature from vibration signal that characterize the work condition of an induction motor. 
the dbn model employ a structure with stack restrict boltzmann machine rbms and be train by an efficient learning algorithm call greedy layer wise training. 
vibration signal be use as the input to the dbn and the output from activation function of the train network be the feature need for fault diagnosis. 
compare to traditional feature extraction method for induction motor fault diagnosis such as wavelet packet transform the propose method be able to learn feature directly from the vibration signal to achieve comparable performance with high classification accuracy. 
experiment conduct on a machine fault simulator have verify the effectiveness of the propose method for induction motor fault diagnosis. 
use catalog datum mining in support of determining micro end milling condition. 
a grow number of requirement be be place on micro fabrication use end mill with high operating degree of freedom. 
in particular when the minor diameter of the end mill be 1.0 mm or less the handling of tool become difficult because of the influence of the characteristic size effect and bending of the cutting portion. 
furthermore it be hard for engineer to derive the cut condition that can serve as index in the early stage of end milling with small minor diameter. 
to solve this problem in this research on a basis of workpiece material characteristic and tool shape parameter a system that can make instantaneous decision on the tool shape and cut condition to be use be build and its usefulness be evaluate. 
this system be develop by apply datum mining technique together with non hierarchical and hierarchical clustering method on tool catalog datum. 
the result of the analysis find that the characteristic of the workpiece material be significant in make decision regard the cut condition for the minor diameter of the end mill. 
moreover the cutting speed be find to have a significant effect on the tool shape parameter whereas difference as to the processing method side milling or slotting do not have a significant effect. 
experimental and numerical study of wire vibrations in bonded abrasive wire saw processing. 
bonded abrasive wire baw see slicing be a popular method for silicon carbide wafer production however the wire be highly susceptible to vibration. 
in this paper a vibration model of the wire saw be present and a numerical analysis of this model which be confirm by experiment be develop. 
the experiment show that the model can predict vibration characteristic of wire see with no processing or processing and the big error of model in frequency domain be 10.6. 
moreover the wire tension be an important factor for wire see vibration. 
the experiment show that a 50 increase in tension may make a 43.2 increase in vibration frequency and the relationship be not linear depend on tension control device. 
on demand real time scheduling strategy for cnc system based on embedded multi core processor. 
multi core processor can provide high performance to complex multi task real time control system such as cnc system but most real time kernel do not support multi core processor very well which couldn t utilize the advantage of multi core processor. 
to enlarge the cpu utilization and promote the system real time performance of multi core processor base cnc system a demand base real time scheduling strategy for smp processor be propose. 
hard real time cyclic task in the cnc system be trigger by hardware timer periodically which make it possible to realize short task cycle than traditional time tick triggering method. 
soft real time task be schedule accord to the real time system demand in a first come first serve manner. 
to evaluate the functionality of the develop real time kernel a prototype cnc system be develop and the buffer status monitoring result have show the feasibility and validity of the propose scheduling strategy. 
decision of target shape position and posture in machine simulator corresponding to actual workpiece. 
multi tasking machine tool have be increase to shorten production time and improve productivity. 
it be indispensable for the operator of such machine tool to avoid collision among the machine structure. 
in order to solve this problem machine simulator be widely use before machine operation. 
in a commercial machine simulator however unexpected collision often occur when the setup of a workpiece or a jig differ from the 3d model create in advance. 
therefore this study propose a machine simulator utilize 3d model create by measure the shape and position of the workpiece and jig on the machine tool. 
in case the workpiece differ from the assume one it be need to determine the suitable position and posture of target shape base on the obtained workpiece. 
as a result this study deal with a method which determine the position and posture of target shape use the workpiece obtain by on machine measurement. 
cut simulation of drill with cutter runout. 
a force model be present to analyze cut process in drilling with cutter runout. 
in the simulation three dimensional chip flow in drilling be model by pile up the orthogonal cutting in the plane contain the cutting and the chip flow direction. 
the cut model in the chip flow therefore be make use the orthogonal cutting datum in the coordinate system include the direction of the cutting velocity. 
the cutter runout then be consider by the rotate coordinate system. 
the cut simulation be perform in drilling of aluminum die cast base on the force model present. 
first the force model be validate in comparison of the simulation with the measure cutting force. 
then the cut force be predict in drill with the cutter runout. 
the cut force load on the edge be compare each other. 
integrated vibration and acoustic datum fusion for chatter and tool condition classification in milling. 
improve datum quality and availability along with low computation cost have generate interest in sensor base tool condition monitor technology. 
in this study an integrated vibration and acoustic sensor be use for tool condition monitoring particularly for chatter detection and tool condition classification. 
base on feature extraction in the time and frequency domain chatter and tool condition classification study be conduct use linear support vector machines. 
the combination of acoustic and vibration datum be find to have a high classification accuracy as compare to the individual datum source. 
on line chatter recognition and supression in milling based on smart cnc. 
the development tendency of manufacturing will be dominate by advanced machine tool which integrate intelligent machining technology. 
in this paper the function of signal processing and intelligent control in smart cnc be propose with the aim of on line chatter recognition and suppression. 
to effectively recognize chatter the algorithm of estimation of signal parameters via rotational invariance techniques esprit be use to get the frequency characteristic of acceleration signal and cut process could be divide into different state. 
the model of chatter recognition be build by train a hidden markov model. 
to implement real time chatter suppression in cnc kernel the algorithm of fuzzy control be use to determine the relationship between cut force and spindle speed and relate cutting parameter could be adjust timely once the chatter be identify. 
the model of chatter recognition and propose smart cnc system be experimentally validate. 
development of a tandem table type cnc lathe with four axis synchronized control. 
in the present study we describe a newly develop cnc lathe for realize non axisymmetric curve surface turn nacs turning. 
the newly develop lathe can be control along four axis x1 x2 z and c and have a three linear motor drive system for the x1 x2 and z axis to control precise highspeed motion. 
the tandem table unit which move along the x1 and x2 axis can move at a maximum acceleration of 98.1 m s(2 synchronously with the spindle rotational position. 
therefore in order to realize high speed cutting motion of a machining curve surface as well as suppress the vibration transmission the inertial force be make to cancel each other. 
in the present study the fundamental dynamic performance and vibration suppression effect of the tandem table be examine. 
process planning system of five axis machining center consider constraint condition. 
this study propose the method of the process planning for five axis machine tool. 
in our previous study the process planning in which the total removal volume be divide by the plane parallel with the xy yz or zx plane to analyze machining sequence from top to bottom of the target product be propose. 
in this study the process planning system in which the total removal volume be divide you all plane include slope plane exist on the target product be propose. 
furthermore the design constraint or the designer s intention such as discontinuous through hole which have the same central axis be consider in this process planning. 
a case study be conduct and the result show that the propose method can design efficient multiple process plan for the machining operation. 
these multiple process plan or machine sequence allow user to select adaptively the suitable process plan or machining sequence base on the property of five axis machine tool to be use under the design constraint. 
intelligent diagnosis method use probability density distribution and principal component analysis  application gear rotating machinery. 
this paper propose a novel fault diagnosis method by combine statistic filter sf and probability density function pdfs. 
first the vibration signal be process use sf to reduce the noise automatically. 
second pdfs be introduce to reflect the feature of the vibration signal. 
the segment value of the pdfs svpdfs be integrate into symptom parameter isp through multivariable analysis method and use for recognize signal state instead of the conventional symptom parameter sp. 
in the condition survey step the parameter of sf which be name select discrimination index sdi be optimize accord to the accuracy rate of the identification. 
in the precise diagnosis the optimize sdi and isp be use for diagnose the state of the signal. 
the efficacy of this method be confirm by the result of the condition diagnosis for gear on the experimental device. 
burr prediction due to flank wear in end milling. 
a new model to predict burr formation due to tool wear of a cut tool in end milling be propose. 
the model show that the burr size vary accord to flank wear of a cut tool. 
a system be develop to simulate burr to be form at each edge point on machine surface base on flank wear of a cut tool and cut condition by use the propose model. 
in addition the experimental work of steel with a 0.45 carbon and aluminum alloy almg0.5si with solid carbide tool be execute to investigate the relationship between burr size and tool flank wear and comparison between experimental result and predict result be discuss. 
the comparison result show that the propose model could help to predict burr size under the effect of tool flank wear with high accuracy. 
study on the evaluation method for finished surface based on human visual characteristic. 
in the machining of mold and die it be quite important that the finished surface have no visible glitch. 
the purpose of this study be to develop the evaluation method for finished surface base on the human visual characteristic. 
in order to achieve the purpose visual resolution and recognition limit of normal vector change of the machine shape be investigate. 
the visual resolution of the human eye be evaluate base on tool mark on the machine surface. 
the recognition limit of normal vector change be evaluate base on the workpiece which have normal vector change in its shape or surface profile. 
an evaluation method for the finished surface be propose base on the investigate characteristic. 
in order to confirm the usability of the propose method evaluation test of actual machine surface influence by the machine tool motion error be carry out. 
as the result it be clarify that the propose method can accurately evaluate visibility of the glitch on the machine surface. 
novel tuning rules for stable dead time processes with dominant leave half plane zero. 
this paper present a modification of recently report general rule for design complex controller. 
the present approach be here apply to control stable process include dead time with a dominant left half plane zero. 
the introduced modification enable improvement in the form of well disturbance rejection and small lie integrated absolute error. 
the solution to design procedure lead to practically realizable controller. 
the effectiveness of the propose method be verify via numerical simulation on several example result into well performance and robustness index of the closed loop system compare to recently report procedure which do not take into consideration the effect of dominant left half plane zero. 
a neuro adaptive control of nonlinear slow process. 
a veuro adaptive internal model base control naimc use the fast clustered radial basis function network fcrbfa equip by the stochastic gradient descent sgd learn algorithm be propose to control the nonlinear plant with slow dynamic. 
as a first step in this design approach the classical feedback controller be apply to improve the overall dynamic characteristic of the obtain local closed loop. 
such local loop be far on consider as an equivalent plant to which the naimc can be apply the improved characteristic of the equivalent plant can be usually obtain by some kind of the pd control law and we use this approach at the naimc design of the nonlinear slow process. 
to achieve a zero steady state error in case of the piecewise constant change of the reference and disturbance at output of the plant we apply the method of gain scheduling gs for adjust the gain of the q controller in the naimc base structure. 
we illustrate the performance of the propose naimc design use simulation result for the control of a double tank system. 
start up vibration analysis for novelty detection on industrial gas turbines. 
this paper focus on industrial application of start up vibration signature analysis for novelty detection with experimental trial on industrial gas turbine igt. 
firstly a representative vibration signature be extract from healthy start up vibration measurement through the use of an adaptive neuro fuzzy inference system anfis. 
then the first critical speed and the vibration level at the critical speed be locate from the signature. 
finally two s  and v health index be introduce to detect and identify different novel fault condition from the igt start up in addition to traditional similarity measure such as euclidean distance and cross correlation measure. 
through a case study on igt it be show that the present approach provide a convenient and efficient tool for igt condition monitoring use start up field datum. 
structural and parametric synthesis of positioning systems of electromechatronic module. 
research be devote to synthesis of positioning system of electromechanical module with set time frequency and robust feature. 
structure and analytical expression for parameter of static and astatic regulator and input filter be receive. 
bessel root distribution be test in position regulator static astatic 1st and 2nd order. 
parameter of time response expression for calculation of established positioning error be calculate at a constant linearly and parabolically change mechanical load. 
the analysis of time and frequency characteristic be make. 
the fix adjustment provide robustness of position system at a variation of module inertance be define. 
application recommendation of the synthesized system in machine tool construction and robotic be develop. 
implementation of electric drive of withdrawal roll set in horizontal continuous casting machine for the production of small billets. 
metallurgical industry have appreciate advantage of continuous casting machine for produce a variety of high quality product make of steel and special alloy. 
design feature of horizontal continuous casting machine make it possible to use this type of machine on mini plant with annual productivity low than hundred of thousand ton of end product. 
the paper examine the construction of continuous cast machine of horizontal type and principle of operation of the modern continuous cast machine intend for production of billet make of carbon quality steel and special alloy from 40 to 80 mm in diameter describe basic requirement for withdrawal device and its operation cycle. 
the experimental datum analysis be conduct for reveal of different combination of basic parameter of the cast cycle and their influence on electric motor equivalent torque. 
base on the result of trial operation further mechanism improvement of withdrawal and its control method be propose. 
adaptive system for compensation of periodic disturbances in servo drive. 
the presence of parasitic torque ripple be characteristic of a synchronous machine with permanent magnet pmsm. 
nonsinusoidal magnetic flux distribution in the air gap and the variable magnetic resistance of the stator slot be the reason for these ripple. 
as a result speed ripple and angular position ripple exist. 
this paper propose an adaptive controller that solve this problem. 
basis of adaptive compensator for periodic disturbance be periodic change of control parameter through measure parameter of error harmonic with frequency of disturbance. 
adaptation to change parameter of the periodic disturbance be the feature of adaptive controller. 
simulation result in matlab simulink show that the use of the adaptive compensation system greatly reduce the influence of torque ripple. 
improvement of an unwinding machine electric drive on a high strengh rebar production line. 
improvement of electric drive s control system on rebar production line be one of the key factor that lead to the rebar quality increase and imperfect product percentage reduce. 
know technical implementation for the drive be make without consideration of the effect of their parameter to the rebar quality particularly to the depth of notch on it. 
the objective of this work be to analyze how the line electric drive affect the depth of notch and base on the analysis the development of the electric drive control system which should decrease imperfect product percentage cause by the depth of notch deviation from desire value. 
solution to the objective be base on analytical method for solve algebraic problem computer modeling method and statistical processing of the datum concern depth of notch and the line s electric drive load torque variation. 
novelty of the paper be in propose new technological requirement to the unwind machine electric drive development of a calculation method for the wire tension effect to the rebar depth of notch unwind machine electric drive s break torque alteration method with the view of wire tension stabilization on a specified level at the inlet of profile stand. 
as a result of industrial test of the develop unwind machine electric drive control system on an active production line there be obtain decrease in rebar percentage that have depth of notch out of allowable range from 7.2 to 1.1. 
condition monitoring and reliability of bearing units of induction machines. 
in this paper the issue of bearing condition monitoring of induction motor have a squirrel cage rotor be consider. 
experimental result and their analysis be present. 
the work be during the test of induction motor at rate nominal mode with bearing healthy and alternatively with two fault which have defect inner and outer part of bear frame. 
benefit of a learn factory in the context of lean management for the pharmaceutical industry. 
the past have show that the successful implementation of lean in organization need employee with sufficient knowledge about method and principle of lean management. 
the mediation of these skill during the ongoing production be know as a more efficient concept than other approach. 
consequence could be an additional cost and time pressure. 
therefore the fraunhofer ipk and tu berlin have develop a training concept together with a german pharmaceutical company which make it possible for the employee to acquire the new knowledge under real condition and without disruption of production. 
the paper introduce this concept of a lean factory for pharmacy. 
c 2016 the authors. 
publish by elsevier b.v.. 
transfer of model of innovative smart factory to croatian economy use lean learning factory. 
croatia s manufacturing industry face many problem and obstacle that have a large impact on its competitiveness. 
insufficiently educate and unskilled personnel particularly in the production and management field be decrease competitiveness that be necessary for survival in the global market. 
objective of project innovative smart enterprise be to establish a special learning environment in one laboratory aslean learning factory simulation of a real factory through specialized equipment. 
the lean learning factory s mission be to integrate needed knowledge into the engineering curriculum. 
therefore lean learning factory at university of split be in continuous develop process to support practice base engineering curriculum with possibility of learn necessary tool and method use didactic game or real life product and equipment. 
solution proposal for good balance between toy and real product consider design and production line development for product karet. 
it be a traditional and original product from croatia so it will raise enthusiasmin learning process in both student and industry employee. 
two assembly line will be develop one traditionally equip and one intelligent networked flexible and fully improve by lean tool. 
by deep analysis of both assembly line hybrid assembly line could be design to balance on one side assembly tact time accord to customer demand and total cost of installation and run on the other side. 
method and tool adapt and implement in both design and analysis process for optimization of this hybrid assembly line would be scale and adjust for industry use as part as knowledge transfer from university to enterprise. 
c 2016 the authors. 
publish by elsevier b.v.. 
ethercat integrate processing machine with full local task redundancy. 
a numerically control processing machine integrate over ethercat with full local redundancy in the axis to task space mapping have be design and build in a laboratory. 
the redundancy arise from a set of slow long range base axis manipulate a set of fast short range tool axis which again hold and manipulate the tool. 
the principle of the machine be time efficient in manufacturing application with high task detail and where the tool process be fast than the long  range axis. 
this paper will give an overview of construction of the machine and experimental trajectory planning. 
c 2016 the authors. 
publish by elsevier ltd.. 
intelligent sensor use for mero modular walking robots move on undeveloped terrain. 
one of the central problem of motion control of walk robot be the distribution of force between leg and the organization of robot motion within margin of static stability. 
support reaction need to be control during movement on undeveloped terrain the force torque sensor be an important component of the measure system and force control and slide contact with the ground uneven leg of the modular walking robot mero. 
determination of the real force distribution in the shift mechanism of a walk locomotion system which move in undeveloped terrain at low speed be necessary for the analysis of stability. 
the paper will analyze an intelligent sensor develop by the author with an important role in the complex system control slip when move walk robot mero on undeveloped terrain. 
contribution of stance and swing leg movement to human walking dynamics. 
minimalistic gait model assume massless leg e.g. 
model base on spring load inverted pendulum slip or invert pendulum ip template have be widely use to interpret human gait. 
although these model can describe basic gait feature like center of mass com trajectory or ground reaction force grf pattern it be rather challenging to investigate swing leg control strategy with these massless leg model. 
in this paper base on experiment datum we analyse how much swing leg stance leg and upper body movement contribute to total grf during single support phase of walk. 
the result show that in vertical direction swing leg and upper body create in phase m shape force pattern but stance leg do not contribute to the m shape force pattern. 
in walk direction the inertia force create by swing and stance leg cancel each other out while stance leg and upper body create similar inertia force in both shape and magnitude. 
the result suggest there be a phase locking mechanism for swing leg stance leg and upper body movement. 
it can help to refine current conceptual model which well describe human walking. 
a new proceeding of control strategy for a parallel structural biped robot. 
in the application of simulator accurate machining and soldering a parallel hexapod can usually be find. 
however it be still an innovative research object to implement this structure in a personal biped walking application. 
this article represent a realization of a walking mechanism imply parallel hexapod as move part. 
work principle and control structure be describe in this work. 
to realize a stable and ride comfortable walking mechanism the planning and control of stability be fatal. 
this aspect be inevitable tightly related to the pose recognition algorithm. 
to solve a forward kinematic problem fkp be always a difficulty in the recognition of pose. 
in this article a method integrate mems inertial measurement unit and length measurement be design. 
with the force sensor the center of pressure can also be confirm. 
this fusion of sensory system be furth to realize a steady and agile control of this biped walking robot. 
speed adaptive reference knee trajectory generation based on fourier function. 
for the intelligent control of low limb prosthesis kinematic reference trajectory be require. 
due to individual difference and various preferred reference walking speed a general reference knee angle trajectory be difficult to adapt different people and their different walking speed. 
to solve this problem gait kinematic information of thirty healthy subject be collect at their preferred speed and the relationship between kinematic model of knee joint and speed be analyze. 
each knee angle trajectory be model base on fourier function and the parameter of model be prove to be relate to walk speed. 
finally kinematic model for knee angle trajectory be reconstruct base on regression equation. 
the reconstructed trajectory not only can adapt to the various walking speed but also adapt to different people. 
the result of analysis show that the reconstructed trajectory match the measure motion trajectory well. 
ap positioning for estimating people flow as origin destination matrix for smart cities. 
control and regulate people flow and the access to the city service be major topic in the context of smart city management. 
flow surveillance provide valuable information about city condition useful for not only monitor and control the environmental condition but to optimize the exploitation of various city service. 
in this context it be mandatory to develop tool for assess people flow. 
this paper present a methodology for an effective placement of counter sensor to model flow with a statistically significant precision rate. 
comparative analysis be conduct with respect to real datum i.e. cab trace of the city of san francisco. 
several different placing methodology of wi fi access point have be test and compare to minimize the cost of ap installation. 
the research work describe in this paper have be conduct in the scope of the ec horizon 2020 fund project resolute http://www.resolute eu.org and for sii mobility. 
architectural compatibility beyond the eye of the beholder. 
purpose this paper revisit the concept of compatibility between old and new architecture to clarify its meaning. 
design methodology approach document analysis be employ to critically review relevant literature include charters and unesco recommendation. 
findings visual and/or tangible indicator such as form and material be often suggest in the literature to determine compatibility and to inform decision maker whether new architectural project should reproduce or reinterpret or rather contrast with historic building in situ. 
as a consequence compatible design becomes confine to a visual object base worldview. 
yet architecture transcend the sense of vision. 
research limitation implication example of architectural project be give to explain each design option but be not thoroughly describe. 
still this paper provide a useful reference for future dialogue and research that aim at reduce the conservation vs development struggle in historic place whether urban area or entire city such as world heritage cities. 
practical implication the lesson learn may stimulate reflection on the effectiveness of design criterion and other tool in guide decision maker in their search for and assessment of compatibility. 
originality value this paper reveal that compatibility be an evolve concept associate with human man make and natural indicator. 
design option be not simply aesthetic category. 
the author propose that the selection of a design option for new architecture should follow the process that guide the selection of a conservation treatment for old architecture. 
heritage value and legal rule identification and treatment of the historic environment via an adaptive regulatory framework part one. 
purpose exist regulatory framework for identify and treat historic building and place reflect deference to expert rule which privilege the value of a small number of heritage expert over the value of the majority of people who visit work and reside in historic environment. 
to address this problem the purpose of this paper be to explore a fundamental shift in how us federal and local preservation law address build heritage by suggest a dynamic adaptive regulatory framework that incorporate heterodox approach to heritage and therefore be capable of accommodate contemporary sociocultural value. 
design methodology approach the overall approach the author use be a comparative literature review from the field of heterodox orthodox heritage heterodox orthodox law adaptive management and participatory method to inform the creation of a dynamic adaptive regulatory framework. 
findings heterodox heritage emphasize the need for a bottom up stakeholder drive process where everyday people s value have the opportunity to be consider as be as valid as those of conventional expert. 
orthodox law can not accommodate this pluralistic approach so heterodox law be require because like heterodox heritage it deconstruct power value participation and community involvement. 
practical implication orthodox heritage conservation practice disempower most stakeholder and empower conventional expert this power differential be maintain by orthodox law. 
originality value to date there have be few if any attempt to address critical heritage study theory in the context of the regulatory environment. 
this paper appear to be the first such investigation in the literature. 
fastfm a library for factorization machines. 
factorization machines fm be only use in a narrow range of application and be not part of the standard toolbox of machine learning model. 
this be a pity because even though fm be recognize as be very successful for recommender system type application they be a general model to deal with sparse and high dimensional feature. 
our factorization machine implementation provide easy access to many solver and support regression classification and rank task. 
such an implementation simplifie the use of fm s for a wide field of application. 
this implementation have the potential to improve our understanding of the fm model and drive new development. 
bayesian decision process for cost efficient dynamic ranking via crowdsourcing. 
rank aggregation base on pairwise comparison over a set of item have a wide range of application. 
although considerable research have be devote to the development of rank aggregation algorithm one basic question be how to efficiently collect a large amount of high quality pairwise comparison for the rank purpose. 
because of the advent of many crowdsourcing service a crowd of worker be often hire to conduct pairwise comparison with a small monetary reward for each pair they compare. 
since different worker have different level of reliability and different pair have different level of ambiguity it be desirable to wisely allocate the limited budget for comparison among the pair of item and worker so that the global ranking can be accurately infer from the comparison result. 
to this end we model the active sampling problem in crowdsourced ranking as a bayesian markov decision process which dynamically select item pair and worker to improve the ranking accuracy under a budget constraint. 
we far develop a computationally efficient sampling policy base on knowledge gradient as well as a moment matching technique for posterior approximation. 
experimental evaluation on both synthetic and real datum show that the propose policy achieve high rank accuracy with a low labeling cost. 
distribute submodular maximization. 
many large scale machine learning problem cluster non parametric learning kernel machine etc. require select a small yet representative subset from a large dataset. 
such problem can often be reduce to maximize a submodular set function subject to various constraint. 
classical approach to submodular optimization require centralized access to the full dataset which be impractical for truly large scale problem. 
in this paper we consider the problem of submodular function maximization in a distributed fashion. 
we develop a simple two stage protocol greedi that be easily implement use mapreduce style computation. 
we theoretically analyze our approach and show that under certain natural condition performance close to the centralized approach can be achieve. 
we begin with monotone submodular maximization subject to a cardinality constraint and then extend this approach to obtain approximation guarantee for not necessarily monotone submodular maximization subject to more general constraint include matroid or knapsack constraint. 
in our extensive experiment we demonstrate the effectiveness of our approach on several application include sparse gaussian process inference and exemplar base clustering on ten of million of example use hadoop. 
local network community detection with continuous optimization of conductance and weighted kernel k means. 
local network community detection be the task of find a single community of node concentrate around few give seed node in a localized way. 
conductance be a popular objective function use in many algorithm for local community detection. 
this paper study a continuous relaxation of conductance. 
we show that continuous optimization of this objective still lead to discrete community. 
we investigate the relation of conductance with weight kernel k mean for a single community which lead to the introduction of a new objective function u conductance. 
conductance be obtain by set sigma to zero. 
two algorithm emc and pgdc be propose to locally optimize sigma conductance and automatically tune the parameter or. 
they be base on expectation maximization and project gradient descent respectively. 
we prove locality and give performance guarantee for emc and pgdc for a class of dense and well separate community center around the seed. 
experiment be conduct on network with ground truth community compare to state of the art graph diffusion algorithm for conductance optimization. 
on large graph result indicate that emc and pgdc stay localized and produce community most similar to the ground while graph diffusion algorithm generate large community of low quality.(1. 
the analytical basis for evaluation and comparison of the effectiveness of modern turning with rotary and conventional tools. 
the paper focus on tool with turn round insert rt rotary tool. 
rotary tool can be divide into sprt self propel rotary tool and drt drive rotary tool. 
rotary tool rt have significantly long tool life than conventional tool work in similar condition. 
an analysis of the time of technological operation with rt compare to conventional tool have be conduct. 
a model of an approximation insert as well as the correction coefficient of the insert tool life wr be present. 
the coefficient wr allow to compare the effectiveness of rotary and conventional tool with insert of any shape. 
factor such as performance cost and durability can be compare and evaluate. 
the insert model and the coefficient wr can also be useful in optimise performance and machining parameter. 
manufacture information acquisition system methodology as a tool support data acquisition for production management. 
this paper present the manufacturing information acquisition system mias methodology support development of customise datum acquisition system cover the datum need of it system and the company management. 
knowledge about the state of the manufacturing process be very important for any producer compete on the global market because proper company management usually support with the erp system be only possible when its database be continuously update with datum on the state of production process. 
datum on the state of production order machine material and human resource should be automatically acquire transmit archive and convert to a form compatible with business layer it system. 
method of datum acquisition and pre processing directly from the shop floor be describe. 
propose mias methodology be universal cover the need of different company various branch of industry level of production automation and type of technological process discrete continuous batch allow the design of a robust automaticaly operate datum acquistion system. 
pulsatory presses break down barrier in plastic forming of particulate material. 
two barrier face by the plastic form technology of particulate material be identify. 
the first be high and unjustified cost of feedstock due to low prevalence of this technology. 
the second be limited access to specialized press tool and auxiliary device. 
therefore study be undertake to design and manufacture pulsatory press with hydraulic drive and a set of tool for shape test material and product. 
comprehensive test be conduct on the device and process for press powder. 
study of pulsatory press of particulate material base on copper reveal the possibility of obtain the same density of compact with the press force reduce by up to 27 due to the change mode of friction between the powder particle and tool surface. 
during pulsatory ejection still great force reduction of 45 be possible by elimination of peak initiate compact movement in tool and self excite vibration at a later stage of the quasi static process. 
investigation into static stiffness of machine tools servo motors. 
the article present study deal with the influence of electrical and mechanical property of a servo drive of a machine tool on static stiffness. 
the analysis concern the role of parameter such as the type of a drive position of the work unit and the velocity amplification indicator. 
the research present in this publication be conduct by the use of two various method which enable we to establish the influence of the exciting force on static stiffness of the servo drive. 
a fuzzy base approach for classifying student emotional states in online collaborative work. 
emotion awareness be become a key aspect in collaborative work at academia enterprise and organization that use collaborative group work in their activity. 
due to pervasiveness of ict s most of collaboration can be perform through communication medium channel such as discussion forum social network etc. 
the emotive state of the user while they carry out their activity such as collaborative learning at university or project work at enterprise and organization influence very much their performance and can actually determine the final learning or project outcome. 
therefore monitor the user emotive state and use that information for provide feedback and scaffolding be crucial. 
to this end automate analysis over datum collect from communication channel be a useful source. 
in this paper we propose an approach to process such collect datum in order to classify and assess emotional state of involved user and provide they feedback accordingly to their emotive state. 
in order to achieve this a fuzzy approach be use to build the emotive classification system which be feed with datum from anew dictionary whose word be bind to emotional weight and these in turn be use to map fuzzy set in our proposal. 
the propose fuzzy base system have be evaluate use real datum from collaborative learning course in an academic context. 
a dependable small world communication processor. 
over many year the technology of circuit refinement have achieve a tremendous large scale integration so that vlsi system such as many core vlsi processor have emerge. 
however in the huge vlsi system various problem such as many communication problem of the vlsi network clock synchronization of the entire system and verification of concurrent processing must be solve in order to realize a dependable parallel system. 
in this paper we introduce a parallel architecture with short path communication feature a random connection in small world network and present network architecture without global clock use communicative process by csp synchronization method. 
hybrid analysis for mining network protocol s hidden behavior. 
reverse unknown protocol s hide behavior have play an important role in the field of network security. 
the propose work take the capture message and the binary code that implement the protocol both as the studied object. 
dynamic taint analysis combine with static analysis be use for protocol analyzing. 
firstly monitor and analyze the process of protocol program parse the message in the virtual platform hiddendisc prototype system develop by ourselves record the protocol s public behavior then base on our propose hidden behavior perception and mining algorithm static analyze the protocol s hide behavior trigger condition and hide behavior instruction sequence. 
accord to the hidden behavior trigger condition new protocol message with the sensitive information be generate and the hidden behavior be execute by dynamic triggering. 
hiddendisc prototype system can sense trigger and analyze the protocol s hidden behavior. 
accord to the statistical analysis result we propose the evaluation method of protocol execution security. 
the experimental result show that the present method can accurately mine the protocol s hidden behavior and can evaluate unknown protocol s execution security. 
real time motion capture an overview. 
many emerge motion relate application such as virtual reality decision making and health monitoring demand reliability and quick response upon input change. 
motion capture have be a well research topic in the past decade with application in many industry. 
the ability to capture motion go hand in hand with real time capability in a system. 
this paper give an overview on real time motion capture include framework recording device and algorithm. 
use real time motion capture as a tool to solve application problem be also describe. 
automatic production of an ontology with nlp comparison between a prolog base approach and a cloud approach base on bluemix watson service. 
nowadays most of the information available on the web be in natural language. 
extract such knowledge from natural language text be an essential work and a very remarkable research topic in the semantic web field. 
the logic programming language prolog base on the definite clause formalism be a useful tool for implement a natural language processing nlp system. 
however web base service for nlp have also be develop recently and they represent an important alternative to be consider. 
in this paper we present the comparison between two different approach in nlp for the automatic creation of an owl ontology support the semantic annotation of text. 
the first one be a pure prolog approach base on grammar and logic analysis rule. 
the second one be base on watson relationship extraction service of ibm cloud platform bluemix. 
we evaluate the two approach in term of performance the quality of nlp result owl completeness and richness. 
problem of adequate modelling of radio electronic device parameter distributions. 
increase the quality requirement for modern radio electronic apparatus for different purpose have emphasize the problem of accuracy assurance by complex optimization of the manufacturing process. 
this require the programme and model use to be of high flexibility and adequacy. 
conventional application of the classical law of random variable distribution in most case do not satisfy these requirement. 
the research perform have reveal the possibility of enhance adequacy of the model of real apparatus parameter distribution in the way of use the multiparametric function with independent parameter. 
automatic recognition of drill condition on the basis of image of drilled hole. 
this paper present an automatic algorithm to recognize the condition of drill on the basis of analysis of the drilling hole image. 
the algorithm include the image preprocessing lead to extraction of the diagnostic feature which be use as the input attribute for the classification system. 
the condition of drill be classify into two group the useful one the sharp enough state and wear out useless in production. 
ga base parameterization and feature selection for automatic music genre recognition. 
automatic music genre recognition can be do by collaborative filtering or by content base filtering. 
in collaborative filter the music be classify on the basis of the similarity to piece already classify by user it be implicitly assume that the user have proper knowledge to recognize music genre. 
the second approach the content base filtering be base on extract sound feature directly from music and use they for classification. 
this study present a content base classification system design to assign music track to genre. 
the classification process be do by two classifier a feed forward neural network and k near neighbor algorithm. 
the structure of the neural network the number of the near neighbor and the actual sound feature be select by a genetic algorithm ga. 
the present approach be test on a database comprise 10 main genre and 33 subgenre. 
intelligent shopping cart with quick payment based on dynamic target tracking. 
at present many supermarket be still use the traditional shopping cart and bar code scan. 
this shopping mode will make client feel tired to push cart forward and waste much time on wait in line. 
this paper present the design and implementation of a new application an intelligent shopping cart. 
this cart can accurately follow its master by identify the color and shape characteristic of the specific image that the master wear. 
also it implement quick payment to provide a more comfortable shopping mode. 
in this paper we firstly design an architecture of the intelligent shopping cart system. 
secondly we propose an approach to implement movement control. 
we improve an algorithm to realize the dynamic target track more accurately and present improved control system to improve the stability of the shopping cart system. 
thirdly we present rfid base automatic payment. 
finally we implement the propose novel system. 
the experimental result indicate that the propose intelligent cart system provide dynamic target tracking with high accuracy and significantly speed up the payment process. 
research on the technology of massive android application data process. 
with the explosive growth of mobile application more and more threat migrate from traditional pc platform to mobile device. 
mobile internet platform especially android platform be become a hotbed of malicious application. 
the security monitoring of massive application in application store be a focus in the field of information security. 
the study of related topic of security detection and defense of malicious application be badly need. 
this paper put forward a processing method of massive datum base on security detection of android application which intend to improve the efficiency of security detection engine in the face of a large number of concurrent detection task. 
by parallel extract characteristic property of apk and build local signature database the detection process can be simplify so as to achieve a good treatment effect. 
a method to detect android ad plugin based on decompiled digital sequence. 
as the android mobile terminal have become prevalent an increase number of developer build android application and get benefit from bonus of advertising sharing. 
however some mobile advertisement have serious security problem such as traffic consumption malicious deduction and privacy leak. 
white list and semantic analysis be propose to defect the problem recently. 
in this paper we put forward the work far by analyze the decompile digital sequence of ad plugin. 
we select appropriate decompiling tool to decompile the ad plugin to get the java file that we need. 
and then we traverse the java file to count the unique word of each file. 
the number of the unique word be the digital sequence of the file which could he apply as the feature of machine learn classifier to detect ad plugin. 
the experimental result show that the decompile digital sequence have very good performance in term of detect ad plugin which can not only avoid the situation of get less semantic feature but also solve white list method inadequate. 
group based non sparse localized multiple learning algorithm for image classification. 
multiple kernel learning be a new research focus in the field of kernel machine learning in recent year. 
localize multiple kernel learning be a promising strategy for combine multiple feature or kernel in term of their discriminative power for different local space. 
in this paper we propose a group base non sparse localize multiple kernel learn algorithm for image classification. 
there be two step in our algorithm. 
in the first step the sample be divide into group accord to a clustering algorithm. 
in the second step the svm model and local kernel weight be optimize by turn. 
by the process of clustering both inter cluster correlation and intra cluster diversity be take into concern. 
sinc the lp norm constraint be employ on the kernel weight a non sparse result of kernel be obtain. 
the performance of classifier be improve by adjust the sparsity of kernel. 
the experiment on the synthetic datum set show that our method obtain a well decision boundary the experiment on the image set verify the improvement of classification accuracy and training speed. 
towards the characterization of monitor smells in adaptive systems. 
adaptive systems as can adapt themselves to a change environment or new user need. 
monitor be essential in as be responsible for collect and processing datum from environment. 
there exist different kind of monitor with distinct characteristic. 
base on a literature review we have notice that monitor be usually design and implement in an inadequate way i make they obscure in the source code ii compelling all of they to have the same polling rate and also iii predetermine the execution order among they. 
this lead to maintenance evolution and performance problem. 
besides base on our observation this erroneous way monitor be implement follow a pattern and it be a recurrent practice. 
therefore we believe it can be classify as monitor smells of adaptive systems. 
in this paper we present two architectural smell we have identify the obscure monitor and the oppressed monitor. 
the first smell occur when the monitor be not evident in the source code. 
the second smell occur when monitor be compel to have the same poling rate and an immutable execution order at runtime. 
the presence of these smell compromise the reusability evolvability and maintainability. 
we have also conduct an exploratory study by compare the impact of maintenance task in the original version of an as call phoneadapter with a refactored version in which the smell be remove. 
the result indicate the maintenance be facilitated in the version without the smell. 
a simulation model for predict the development of cut lily base on photo thermal index. 
in order to provide accurate prediction of the development stage of cut lily which be crucial for decision making of the market schedule a simulation model base on photo thermal index pti be develop to estimate the phenophase day during greenhouse production. 
three experiment of lilium oriental hybrids cv. 
sorbonne with different planting date be conduct in a pc multi span greenhouse in nanjing from march 2009 to january 2010 for data collection use in model construction and validation. 
the result show the relative prediction error rrmse between the observed day and the simulated day for each development stage be 1.58d 2.23d 2.54d 1.58d respectively. 
the coefficient of determination r2 between the predict and the measure phenophase day be 0.97 with the error remain in three day which be more accurate than grow degree day gdd base model. 
the model develop in this study give satisfactory prediction of phenophase day hence can be use for florescence regulation in sorbonne production. 
multi pretraine deep neural network by dbn and sda. 
pretraining be widely use in deep neutral network and one of the most famous pretraine model be deep belief network dbn which be compose by stack restricted boltzmann machine rbm. 
the optimization formula be different during the pretraine process for different pretraine model. 
in this paper we pretraine deep neutral network by different pretraine model and hence investigate the difference between dbn and stacked de noise auto encoder sda compose by stack de noise auto encoder da when use as pretraine model. 
the experimental result show that dbn get a well initial model. 
however the model converge to a relatively bad model after the finetune process. 
yet after pretraine by sda for the second time the model converge to a well model if finetune. 
inconsistent neighborhoods and relevant properties in neighborhood rough set models. 
rough set theory be an important branch of datum mining and machine learning among which neighborhood rough set be present to deal with numerical datum and hybrid datum. 
in this paper we propose a new concept call inconsistent neighborhood and explore the relation between it and the exist notion in neighborhood rough set model. 
some interesting property be obtain accordingly. 
these property can generate some new solution to compute the quantity in neighborhood rough set which be often more direct and more quick to obtain the result than the previous solution. 
the approach of micro blog explosive events detection and analysis in real time. 
social network be an important platform for gather social focus information. 
explosive event from micro blog can be use in the analysis and decision making in government monitoring social phenomena research and other aspect. 
in this paper we propose an approach to detect and analysis explosive event from micro blog in real time. 
our approach greatly improve the efficiency of explosive event tracking and analysis. 
it provide complete solution for social medium event discovery. 
the experimental result show that the detection tracking and analysis algorithm in the whole micro blog event detection process can efficiently improve the result of social medium analysis in real time. 
efficient reading method of a single binary pulse curve. 
this paper present an efficient way to read a single binary pulse curve which can be use to process paper pulse graph to achieve the digitize form. 
for a single binary pulse curve the single value pulse curve datum can be obtain by the special design read algorithm for a multi value curve which aim at turn multi value point to single value point more accurately at the same time various kind of noise can be efficiently remove. 
far the broken point can be connect together base on the linear interpolation method to finish the single pulse reading. 
experiment have show that this method can read a single pulse curve accurately and efficiently. 
synchronization of underwater glider with uncertainty use adaptive fuzzy slide mode control. 
in this paper we study the synchronization of an underwater glider by mean of the adaptive fuzzy slide mode control technology. 
the sufficient condition for the synchronization be obtain even though the slave underwater glider be unknown. 
base on the lyapunov stability theorem the stability the synchronization be prove theoretically. 
numerical simulation far support the theoretical result of the paper and demonstrate the efficiency of the propose method. 
research on resource push technology of projectile multi dimensional design. 
in order to improve the level of the intelligent of product design this paper design resource push method base on projectile multi dimensional design knowledge which can be edit and update accord to the characteristic of the fixture and tool part because kbe be the key technology in the process of product design and manufacturing create the reasoning process of product design base on smart fixture and tool library. 
the smart fixture and tool library become the configuration and reusable resource around product design. 
an approach for remain useful life estimation base on combination of multidimensional information. 
previously the traditional approach for remain useful life rul prediction only use the one dimensional information relate to the malfunction. 
in actually it be very difficult to collect the information and the accuracy be low. 
the rul prediction be limit by previous reason. 
except for the traditional information relate to the malfunction there be many kind of information such as operation performance monitoring datum and maintenance record which can reflect the performance state and degenerative process. 
obtain and analyze the multidimensional information in operating condition should be effective for modeling degeneration and the estimation of remain useful life. 
this paper describe an approach for remain useful life estimation base on combination of multidimensional information. 
comparison of human resource planning and job analysis process in banking sector of pakistan. 
this paper give an explanation about human resource(hr practice in bank alfalah with the analysis in comparison to faysal bank focus on banking sector to complete the task analysis of human resource management(hrm practice and procedure for recruit suitable employee principle and procedure for monitor employee and employee exit process from organization. 
100 bank be target which respectively 50 for each and datum be collect through interview influence on banking sector. 
the main pillar human resource planning hrp job analysis systematic recruitment and exit process be discuss. 
essential motive of this research be to bring train personnel in their setup to cope with the new challenge efficiently. 
investigation of temperature rise and stiffness experiment of rolling bearing under preload with oil air lubrication. 
angular contact ball bearing use in machine tool usually work under high speed and light load condition. 
proper preload on bearing can decrease temperature rise and prolong life of bear. 
in order to illuminate the effect of preload on thermal and dynamic characteristic of bearing preload experiment of rolling bearing with oil air lubrication be study in this paper. 
comparison of position preload pressure preload and intelligent preload method be investigate result show that intelligent preload method can ensure high stiffness and low temperature rise of bear for large range of speed of bear system. 
research on load balancing and database replication base on linux. 
with development of computer and network technology people access to the internet grow exponentially datum become an integral part of people s life. 
more and more company begin to use load balancing and database replication technology to ease the pressure on access to network device and ensure datum integrity. 
in this paper the structure of load balancing cluster be analyze the process of integrate apache and tomcat base on linux os be describe. 
on this basis mysql database replication be complete. 
test result show that the performance of the load balance cluster system be significantly high than that of the single server to a certain extent database replication technology can ensure the integrity and accuracy of datum. 
the study of microscale forming effect on simulated annealing genetic algorithm. 
the reason of micro forming of sheet be conclude. 
use simulated anneal genetic algorithm do a kind of nonlinear optimization to reason of micro form of sheet control. 
the diagnosis knowledge warehouse and control parameter of micro forming of sheet be build. 
it greatly improve the method of convergence on use the adaptive stretch. 
a diagnosis of simulated anneal genetic algorithm be construct. 
at last analyze of testing good result be give. 
metal micro form be microscale effect in the process of classification and evaluation for the correct understanding of micro form and conventional form difference it be guide significance in the course of micro form technology similar to conventional forming which be apply to the datum and experience. 
the microscale effect be beneficial to accurate grasp of all kind of microscale effect in the form reasonable classification and evaluation. 
research on e commerce logistics system informationization in china. 
e commerce be an important drive force of the world economic development. 
the emergence of modern logistic in e commerce environment make the logistic in the development of informationization networking intelligent direction the logistic industry in china start late not modern enough restrict the development of e commerce logistic in china. 
this article research base on the domestic and international study of e commerce logistic analyze the characteristic and mode of e commerce logistic combine with the current situation and exist problem of e commerce logistic in china which propose the development trend of e commerce logistic system information technology in china be the integration of logistics and purchasing. 
a digital wireless led light source controller for machine vision. 
interconnect wire be sometimes difficult inconvenient and even impossible when the light source controller be instal in the industrial field. 
in order to solve the problem above a digital wireless led light source controller for machine vision be propose in this paper. 
firstly the hardware module include host computer software embed control unit program power supply module embed control unit display module light source drive circuit wireless serial communication module infrare remote controller and infrared receiver be describe in detail to build the hardware platform. 
secondly the host computer software and its interface be introduce in detail which be use to transmit the control instruction from the host computer. 
finally the control instruction be analyze by the embed control unit program and accord to the result of analysis the embed control unit adjust the duty cycle of the pwm wave so as to adjust the brightness of lead light source. 
this kind of light source controller with small heat productivity and reasonable structure can accurately and stably control the four channel of lead light source module at the same time. 
and it input control instruction by no contact way which be useful in case where interconnect wire be difficult inconvenient and even impossible and make it easy to be use in the actual installation process. 
the digital wireless led light source controller for machine vision be mainly apply into the industrial field on machine vision system. 
the qualification test design of reliability based on edm. 
the failure datum of electrical discharge machine(edm obey weibull distribution. 
with the mean time between failures(mtbf as test index the produce side risk user side risk identification ratio mtbf expectation value and shape parameter as know parameter we design edm reliability qualification test. 
for the test requirement that just need to determine the machine reliability and minimize test time and cost we choose sequential test method. 
for the shortcoming that sequential test can t end of self when the reliability of the machine tool be at a moderate level we have to improve and perfect it and we propose the truncated sequential test method. 
base on edm we compute the receive and reject condition censoring time number of failure of the specific scheme. 
thermal characteristic analysis for the spindle system of edm. 
the spindle system of edm be directly involve in the processing process and its thermal deformation seriously affect the processing accuracy. 
in this paper we can use the method of sequential coupling which base on the software of workbench ansys to analyze the characteristic of thermal structure coupling in the spindle system. 
the temperature field and thermal deformation of the spindle system have be calculate by the simulation. 
and the result of finite element analysis have be verify by experiment. 
the result show that the internal heat source of the spindle system have a serious influence on the temperature rise and thermal deformation and the maximum thermal deformation occur in the direction of x axis while the thermal deformation of other direction be not significant to the thermal deformation of the spindle system. 
the analysis result lay the foundation for far improve the temperature field of the spindle system and reduce the thermal deformation and it also provide a strong basis for the design of optimization and error compensation of the spindle system. 
design of formaldehyde monitoring system in wireless network. 
the monitoring of indoor formaldehyde and other harmful gas have attract more and more attention. 
in this paper the wireless sensor technology be introduce into the monitoring of formaldehyde gas. 
the realization of the hardware and software design of wireless sensor node the design of the real time monitoring software of the host computer the development of the communication protocol and finally achieve the goal of the successful operation of indoor formaldehyde concentration monitor network. 
the formaldehyde monitoring system mainly consist of the formaldehyde concentration collection system the datum of the wireless transceiver system and the host computer monitor system. 
the system can effectively complete the datum acquisition and processing and can be real time monitoring of the site. 
research on power quality analysis and detecting system. 
with the extensive use of modern power electronic device and non linear device the problem of pollution of power quality be get bad. 
the improvement of power quality assurance have become an important issue face by the electricity sector. 
it be for this reason that power quality monitoring and analysis have become a topic of great significance. 
this paper concisely present a research on the distribute power quality monitoring system base on digital signal processor dsp. 
the system be able to perform regional real time monitoring of power quality which be of prime importance to the power sector in enhance the supervision of power quality and also improve grid operation as well as management level. 
a pcb base engine air intake sensor application to a typical low power engine. 
this work concern the evaluation of a novel sensor for determine the air intake of a typical low power engine. 
the sensor be base on pcb technology enable effective thermal isolation and direct communication to the macroworld. 
the device be integrate into a diesel engine testbe for characterization purpose while a commercially available mass air flow sensor be employ as a reference the proper functionality of the develop prototype have be validate. 
key feature of the propose device be robustness simplicity and low cost suggest numerous potential application in the automotive area. 
c 2016 publish by elsevier ltd.. 
a novel neural probe for simultaneous electrical recording and local thermal control in sleep spindle oscillation study. 
slow wave sleep may have a role in memory consolidation. 
to understand well the temperature dependent change of its parameter it be necessary to use invasive method instead of common surface observation. 
in the following we introduce a novel single crystalline silicon base mems microelectrode name thermoelectrode which be able to record deep brain multiunit activity and local brain temperature simultaneously by four or eight channel platinum recording site and resistance thermometer respectively. 
these functionality be locate on the same electrode shaft within ten of mu m s so the result be from a very close volume while minimize brain tissue damage as well. 
further advantage be the simple extension of the fabrication process as it do not need additional technological step. 
after we present the technology we display fulfilled result make by our thermoelectrode. 
not only bench top calibration but in vivo validation as well. 
c 2016 the authors. 
publish by elsevier ltd.. 
development of a system concept for miniaturized cardiovascular multi sensor implants. 
long term monitoring of hemodynamic can be achieve by an implantable and telemetric multi sensor system. 
a concept to realize a system with high miniaturization level be present. 
the requirement regard a multifunctional transponder asic application specific integrated circuit which should combine signal processing telemetric communication and additional sensor in one chip be introduce. 
capacitive pressure sensor show low power consumption be test with laboratory setup with respect to the integration in this concept. 
first result be achieve and discuss concern two potential assembly technology for the integration of a pressure sensor. 
finally novel hermetic sealing and implant encapsulation technology be propose for further implant miniaturization. 
c 2016 the authors. 
publish by elsevier ltd.. 
force feedback control system dedicate for robin heart surgical robot. 
3d contact force sensor be develop and integrate in a demonstration system for test the feasibility of their application in minimal invasive surgery mis. 
piezoresistive mems base vectorial force sensor be design and fabricate by 3d silicon micromachine technology and package accord to their propose transducer and sensor application. 
in this work we demonstrate the integrability and functional applicability of the 3d force sensor in mis robotic system to improve their flexibility and reliability by provide real time force and tactile information during the operation. 
the final goal be to integrate the new subsystem in the robin heart surgery robot of frk. 
three different function be target one. 
micro joystick actuator to be integrate in the hilt of the laparoscope to easily control robotic movement during operation. 
two. 
force sensor inside the laparoscopic jaw to provide feedback to the surgeon by measure the grasp strength and 3.3d force tactile sensor which facilitate palpation for tissue diagnostic during operation. 
in this paper we demonstrate a feasibility study regard these propose application. 
c 2016 publish by elsevier ltd.. 
sic fet sensor for selective and quantitative detection of vocs down to ppb level. 
with the increase interest in development of cheap simple mean for indoor air quality monitoring and specifically in relation to certain well know pollutant substance with adverse health effect even at very low concentration such as different volatile organic compounds vocs this contribution aim at provide an overview of the development status of the silicon carbide field effect transistor sic fet base sensor platform for ppb level detection of vocs. 
optimize the transducer design the gas sensitive material(s composition structure and processing its mode of operation apply temperature cycle operation in conjunction with multivariate datum evaluation and long term performance it have be possible to demonstrate promising result regard the sensor technology s ability to achieve both single digit ppb sensitivity towards naphthalene as well as selective detection of individual substance in a mixture of different vocs. 
c 2016 the authors. 
publish by elsevier ltd.. 
a compact cmo compatible micro pirani vacuum sensor with wide operating range and low power consumption. 
a micro pirani vacuum sensor with an operating pressure range of more than five decade be describe. 
the device be fabricate by apply a low resolution and potentially low cost front side bulk micromachining step to a chip produce with a commercial cmos technology. 
maximization of the thermally couple surface have be obtain by stack all layer available by default in the cmos process. 
this design choice and the integration of a low noise low power readout interface allow achievement of state of art performance with a fabrication approach affordable even to sme and small university laboratory. 
c 2016 the authors. 
publish by elsevier ltd.. 
design of a passive flow regulator use a genetic algorithm. 
passive flow regulator be usually intend to deliver or drain a fluid at a constant rate independently from pressure variation. 
microfluidic device make of a stack of two plate be consider here the first plate comprise a flexible silicon membrane have through hole while the second plate be a rigid substrate with a cavity an outlet hole and pillar align with the through hole of the membrane. 
the liquid flow through the hole etch in the membrane and through the small gap between the bottom of the membrane and the pillar each hole can therefore be consider as a valve which progressively close as the pressure increase thus lead to a non linear fluidic behaviour. 
fem simulation have be perform to ensure a constant flow rate in the specified range of pressure. 
to make the design reliable the device characteristic have be optimize use an evolutionary algorithm. 
the fitness function notably take into account machining and alignment tolerance. 
typical design dedicate to drug delivery and hydrocephalus treatment be discuss. 
c 2016 the authors. 
publish by elsevier ltd. 
this be an open access article under the cc by nc nd license. 
chipless wireless temperature sensor for machine tools base on a dielectric ring resonator. 
this paper present a wireless temperature sensor design for the monitoring of machine tool where valuable workpiece be process and a defective tool can lead to costly damage to the workpiece. 
since cut tool quickly deteriorate at high temperature a measurement of the tool s temperature allow monitor its state. 
a wireless measurement be advantageous due to the high angular velocity achieve by the tool. 
the oil use to cool down the tool and the chip come out of the workpiece shadow the line of sight condition necessary for infrared measurement. 
in addition temperature above 200 degree c be achieve make the employment of silicon base chip hardly feasible. 
in this paper the temperature be read from the resonance frequency of a dielectric resonator mount on the tool by mean of radio frequency backscattering technique. 
a successful temperature measurement have be perform up to 300 degree c to test the stability of the sensor. 
furthermore system test have be perform in a real machine tool where the sensor be interrogate from outside the machine tool through its door with the tool rotate at up to 10,000 rpm. 
with this sensor real time monitoring of the tool temperature become feasible without alter the current workflow of the machine tool. 
c 2016 the authors. 
publish by elsevier ltd.. 
control of a hydrogel base thermal actuator in closed loop configuration. 
a closed loop hydrogel base thermal actuator be design simulate and test for improve the transient response. 
a system model of such a closed loop actuator be implement in matlab simulink where the voigt kelvin model be utilize to describe the viscoelastic behavior of polymeric hydrogel. 
the numerical simulation be use to investigate the influence of the parameter of the proportional integral pi controller on the transient response such as overshoot rise time and settle time etc. 
through the test this closed loop actuator show an at least 50 reduction in settle time compare to actuator in conventional open loop configuration. 
c 2016 the authors. 
publish by elsevier ltd.. 
design and fabrication of smart band module for measurement of temperature and gsr galvanic skin response from human body. 
in order to monitor health usually the wearable type smart band module to measure the physiological signal from human body be design fabricate and characterize. 
smart band module largely consist of two part one be flexible sensor module and the other one be signal processing and communication module. 
and then two module be interconnect with cu wire. 
finally flexible temperature sensor of the fabricate smart band module be test at the surface of ice pack desk and hot plate \with temperature in the range of 4.5 similar to 74.1 degree c include skin temperature around 30 similar to 33 degree c. 
and gsr datum be measure at the skin with high sensitivity and normal atmosphere to compare. 
measure datum from sensor be signally process and transmit using via bluetooth 4.0 wireless network so we could display successfully those datum use software on the lab top computer. 
in the near future conductive yarn will be use for the interconnection instead of general cu wire and we be go to measure the emotion change from physiological signal from human body during usual life. 
c 2016 the authors. 
publish by elsevier ltd.. 
low cost embedded spirometer based on commercial micro machine platinum thin film. 
there be great need for a low cost and low power consumption portable spirometer for the home care of respiratory disease. 
a mobile monitoring system utilize bluetooth with low power and cost hardware equipment be propose. 
a proof of concept prototype have be develop and implement to enable transmission of a flow or volume of gas during inspiratory and expiratory process signal of a patient which can be expand to include other vital sign. 
communication between a mobile smartphone and the spirometer be implement use the popular personal area network standard specification bluetooth. 
the flow measurement be do with commercial platinum hot wire anemometer manufacture with mems technology. 
owe to its smallness it have the advantage of introduce no modification of the spatial wind distribution. 
c 2016 the authors. 
publish by elsevier ltd. 
this be an open access article under the cc by nc nd license. 
a resonant pressure sensor capable of temperature compensation with least square support vector machine. 
resonant pressure sensor be widely use in pressure monitoring due to high accuracy long term stability and quasi digital output which however suffer from the key issue of temperature drift. 
this paper present a resonant pressure sensor capable of temperature compensation leverage the compensation algorithm of least square support vector machine. 
double h type resonator be arrange in a differential output pressure sensor where the pressure under measurement be translate to resonant frequency output. 
in comparison to two conventional algorithm which be support vector machine and polynomial fitting the new algorithm base on least square support vector machine can effectively improve the precision of temperature compensation for the develop micro sensor. 
experimental result show that the maximum temperature drift be reduce from 8901.4 pa without compensation to 2.0 pa with compensation in the full temperature and pressure scale temperature range of  40 degree c to 70 degree c and pressure range of 20 kpa to 260 kpa validate the effectiveness of the new algorithm in temperature compensation. 
c 2016 the authors. 
publish by elsevier ltd. 
this be an open access article under the cc by nc nd license. 
a degradation prevent method for the organic material in gas sensing application by use cmos submicron wire sensor. 
in this study we propose a degradation prevent sense method for organic material in gas sense application on polysilicon submicron wire poly si sw charge sensor chip. 
the poly si sw chip be fabricate by 0.35 mu m two polysilicon four metal 2p4 m cmos technology. 
the degradation of polymer material be reduce through the charge sense mechanism. 
compare with traditional sense method there be no current flow through polymer base sense film. 
moreover the lifetime response variation and durability performance of sensor be improve. 
base on cmos technology our poly si sw can be easily integrate with another system wireless and microfluidic system. 
therefore this work also present a good potential of polysi sw sensor chip to accomplish the goal of integrate multi sensor in one low power consumption chip. 
this demonstration successfully show organic sense material to accomplish the need in internet of things iot application. 
c 2016 the authors. 
publish by elsevier ltd. 
this be an open access article under the cc by nc nd license. 
scalable memory fabric for silicon interposer base multi core systems. 
three dimensional 3d integration be consider as a solution to overcome capacity bandwidth and performance limitation of memory. 
however due to thermal challenge and cost issue industry embrace 2.5d implementation for integrate die stack memory with large scale design which be enable by silicon interposer technology that integrate processor and multiple module of 3d stack memory in the same package. 
previous work have adopt network on chip noc concept for the communication fabric of 3d design but the design of a scalable processor memory interconnect for 2.5d integration remain elusive. 
therefore in this work we first explore different network topology for integrate cpu and memory in a silicon interposer base multi core system and reveal that simple point to point connection can not reach the full potential of the memory performance due to bandwidth limitation especially as more and more memory module be need to enable emerge application with high memory capacity and bandwidth demand such as in memory computing. 
to overcome this scaling problem we propose a memory network design to directly connect all the memory module utilize the exist route resource of silicon interposer in 2.5d design. 
observe the unique network traffic in our design we present a design space exploration that evaluate network topology and routing algorithm take process node and interposer technology design decision into account. 
we implement an event drive simulator to evaluate our propose memory network in silicon interposer memnisi design with synthetic traffic as well as real in memory computing workload. 
our experimental result show that compare to baseline design memnisi topology reduce the average packet latency by up to 15.3 and choose fastest path cfp algorithm far reduce by up to 8.0. 
our scheme can utilize the potential of integrated stacked memory effectively while provide well scalability and infrastructure for largescale silicon interposer base 2.5d design. 
power aware virtual machine mapping in the data center on a chip paradigm. 
it be project that hundred of core can be integrate into a chip at the sub 20 nm technology node. 
however some challenge exist in the many core architecture such as maintain memory coherence underutilize parallelism and increase inter core communication delay. 
this work propose the data center on a chip dcoc paradigm employ virtualization technology commonly use in today s datum center to reduce the overhead of maintain memory coherence and inter core communication and improve parallelism. 
in the dcoc paradigm user application with specific resource requirement need to be map onto different chip of a data center and different core of a chip in the form of virtual machine vms. 
by a judicious vm mapping method the datum center performance can be maximize while satisfy the power budget and power density constraint of the chip and the resource requirement of vm. 
to tackle the np hardness of the vm mapping problem we propose a two tier algorithm which effectively solve the mapping problem with polynomial time complexity. 
cnn merp an fpga base memory efficient reconfigurable processor for forward and backward propagation of convolutional neural network. 
large scale deep convolutional neural network cnns be widely use in machine learning application. 
while cnn involve huge complexity vlsi asic and fpga chip that deliver high density integration of computational resource be regard as a promising platform for cnn s implementation. 
at massive parallelism of computational unit however the external memory bandwidth which be constrain by the pin count of the vlsi chip become the system bottleneck. 
moreover vlsi solution be usually regard as a lack of the flexibility to be reconfigure for the various parameter of cnn. 
this paper present cnn merp to address these issue. 
cnn merp incorporate an efficient memory hierarchy that significantly reduce the bandwidth requirement from multiple optimization include on offchip datum allocation data flow optimization and datum reuse. 
the propose two level reconfigurability be utilize to enable fast and efficient reconfiguration which be base on the control logic and the multiboot feature of fpga. 
as a result an external memory bandwidth requirement of 1.94mb gflop be achieve which be 55 low than prior art. 
under limited dram bandwidth a system throughput of 1244gflop s be achieve at the vertex ultrascale platform which be 5.48 time high than the state of the art fpga implementation. 
pull off buffer borrowing cache space to avoid deadlock for fault tolerant noc routing. 
advance in semiconductor technology have lead to large chip multiprocessor cmp employ network on chip noc to provide scalable on chip communication. 
this high integration capacity on the other hand increase the possibility of fault. 
to tackle this challenge fault tolerant routing in noc become essential which allow packet to be route around faulty network component and maintain normal communication. 
however to tolerate a large number of fault the deadlock problem become very difficult to deal with. 
exist highly fault tolerant routing solution employ virtual channel vc or topology agnostic routing for deadlock avoidance but at the cost of low network performance and the demand for extra hardware. 
in this paper we show that it be possible to design a novel highly fault tolerant routing method without vc and topologyagnostic routing. 
we present pull off buffer pob a fifo buffer borrow the space already present in cache to avoid potentially exist deadlock. 
pob borrow cache space only from select node and only after the occurrence of fault. 
the space of cache at other node will not be affect. 
experimental result show that our solution can provide 2x to 3x high network throughput and reduce router area and power overhead when compare against exist highly fault tolerant routing method employ vc or topology agnostic routing. 
a statistical critical path monitor in 14 nm cmos. 
local variation of delay path have a significant impact on modern microprocessor performance and yield. 
a critical path monitor be report which extract time variability information on various critical path include sample processor path. 
the very compact circuit contain 256 copy of 15 different delay path enable measurement of the statistic of delay variation as a function of threshold voltage supply voltage fanout temperature and circuit topology. 
measurement of 14 nm soi finfet circuit path delay be present. 
the reported sensor can offer a variety of advantage on a processor chip range from testing time improvement to power saving. 
improve performance per watt of non monotonic multicore processors via bottleneck base online program phase classification. 
heterogeneous architecture offer the promise of high performance watt compare to symmetric multi core. 
recent work have propose the use of non monotonic nm heterogeneous architecture with diverse core type where each core have unique power and performance characteristic. 
however the power and performance benefit achieve by nm architecture be highly dependent on assignment of application to the most suitable core type for all program phase. 
in this paper we propose a novel online program phase detection technique that be base on the frequency of cache miss and processor stall which correspond to core resource bottleneck. 
we track performance monitor to formulate a bottleneck type vector btv that help direct the application to most appropriate core type for execution. 
we compare the propose btv base core assignment method to prior online core assignment approach and demonstrate as much as 22 improvement in average performance watt use instruction per second ips as the performance metric. 
speculative path power estimation use trace drive simulation during high level design phase. 
today power be an important design metric and the ongoing goal of microprocessor designer be to maximize performance within specify power target. 
the key to achieve this goal be the ability to accurately estimate power and performance design point of future product during the high level micro architectural design phase hld. 
these estimate be heavily use for feature analysis and product feasibility study. 
most performance and power simulator across the industry use the trace drive simulation model tdm as oppose to an execution drive model edm. 
this be because in general trace drive model i have fast turnaround time ii require significantly low resource in term of disk space cpu time and memory footprint and iii be more robust portable and well understand. 
however tdm simulation lack the ability to accurately capture the flow of speculative path or wrong path one execution follow a branch mispredict in an out of order processor pipeline. 
this lead to inaccuracy in power and performance estimate. 
on the other hand in the edm method input be an executable and the model can fetch and execute instruction down the speculative path on a branch mispredict. 
as such it enable we to accurately account for the impact of the speculative path activity. 
however it be slow prone to failure and have much high development and validation effort. 
in this paper we compare and analyze performance and power estimate from tdm and edm simulation for the same workload phase. 
we observe that the impact of wrong path on power estimate be significantly high than on the performance estimate. 
use result from our analysis we develop a methodology to account for power consumption during wrong path execution in tdm simulation. 
we show that the propose methodology can provide power estimate approach edm base accuracy while not sacrifice the speed and flexibility of the trace drive model. 
dll a dynamic latency aware load balance strategy in 2.5d noc architecture. 
as the 3d stacking technology still face several challenge the 2.5d stack technology gain well application prospect nowadays. 
with the silicon interposer the 2.5d stacking can improve the bandwidth and capacity of the memory system. 
to satisfy the communication requirement of the integrate memory system the free routing resource in the interposer should be explore to implement an additional network. 
yet the performance be strongly limit by the unbalanced load between the cpu layer network and the interposer layer network. 
in this paper to address this issue we propose a dynamic latency aware load balance dll strategy. 
our key innovation be detect congestion of the network layer via the average latency of recent packet and make the network layer selection at each source node. 
we leverage the free routing resource in the interposer to implement a latency propagation ring. 
with the ring the latency information track at destination node be propagate back to source node. 
we achieve load balance by use these information. 
experimental result show that compare with the baseline design a destination detection strategy and a buffer aware strategy our dll strategy achieve 45 14.9 and 6.5 of average throughput improvement with minor overhead. 
active heat dissipation system use adaptive recurrent wavelet neural network control. 
this paper propose a novel cool control system with the intelligent active technique which be base on the ni pxi system structure combine with the heat pipe cool chip. 
in order to far solve the control problem of nonlinear heat transfer system the propose intelligent system involve the pid control traditional control and the adaptive recurrent wavelet neural network controller arwnnc control technique. 
the traditional control there exist the undesirable control chatter the pid control the response of control can not be process immediately and the input voltage saturation phenomenon the adaptive recurrent wavelet neural network controller be employ to approximate the ideal controller while the correspond parameter be derive by the gradient steepest descent method thus be provide with the adaptive real time control ability. 
tooling design improvement of multistage cold forging of specialty shaped nut use cae and 3d printing. 
give its critical role in the fastener industry cold forging be widely perform in automotive production manufacturing aviation and 3c product. 
personnel experience and try error approach provide a subjective and unreliable background despite their extensive use in fastener form and die design owe to the difficulty in control the development schedule. 
this study use deform 3d analysis software to investigate the die service life from produce specialty shape nut in a multistage cold forging process. 
effective stress effective strain velocity field and other quantitative metric of die and work piece can be obtain from numerical simulation. 
herein 3d printing technology be also implement to create cold forging die and deform work piece for assess the dimension of tooling assembly. 
this process allow engineer to gain a well understanding of the tooling design at development phase and derive the part which be previously just simulation result from deform 3d form software. 
result can help a multistage processing factory establish a cold forming capacity for the development of new product. 
consequently the ability of self design and self manufacture of specialty shaped fastener in taiwan could be increase widely to enhance the international competitiveness of domestic industry. 
experimental study on tube jam through a wedge shaped hopper. 
a wedge shape hopper be frequently utilize as a tube feeder in the electric heater process. 
when fall from a wedge shape hopper the tube often form an arch near the outlet and stop the feeding process since a pile of tube pass through a small hopper outlet one by one. 
this research aim to investigate the effect of process factor on the tube feeding process by apply taguchi s method and to design a wedge shape hopper that never jam. 
choose process factor be the wall angle of the hopper outlet width of the hopper number of test tube vibration strength of the vibrator and tube material. 
experimental result show that a large wall angle a wide hopper outlet a few tube and a weak vibration be optimal setting. 
the wall angle and the outlet width of the hopper be more influential to reduce the jamming for all tube material. 
a hopper that hardly jam can be design by use optimum condition. 
the systematic design of planetary type grinding device for optical fiber ferrule and wafer. 
the traditional planetary grind device can only polish one optical fiber ferrule. 
the other grind device with donut polish trace be also propose for polish wafer. 
this grind device have a problem that is the polish quality of different point on the wafer be not the same. 
hence this paper propose a new planetary grind device for polish more optical fiber ferrule and more wafer. 
base on the kinematic of planetary gear train the equation of polish trace and velocity be derive. 
then the velocity deviation percentage v dp be calculate which be an important design parameter. 
area ratio a(r be define as polish area divide by grind pad area. 
the area ratio a(r be another important design parameter for design planetary grind device. 
in this paper two design example be use to illustrate the design process. 
the research result of this paper can provide an experience for the systematic design of planetary grind device. 
a self calibration method for articulated arm coordinate measuring machines. 
to improve the accuracy of articulate arm coordinate measure machine aacmm and simplify the calibration process an improved self calibration method be propose. 
unlike the traditional calibration method which need external expensive precision instrument and elaborate setup the propose self calibration method only require a gauge to assist the data acquisition operation. 
by design a movement trajectory of the aacmm a series of joint angle can be obtain to form overdetermine equation base on the kinematic model of the aacmm. 
therefore the structural parameter of the aacmm can be obtain by solve the equation. 
consequently the calibration can be achieve by solve these equation. 
the coefficient matrix of the equation be far analyze to simplify the equation and a constructive method be present to identify the structural parameter by solve the simplify equation with a modify simulated anneal algorithm in which an optimize search strategy be apply to improve the robustness and efficiency. 
experimental study on an aacmm validate the convenience and effectiveness of the propose aacmm self calibration approach. 
a low power high gain bandwidth e band lna. 
power by the availability of large fractional bandwidth several gbps communication be now possible at mm wave with simple modulation scheme. 
generation of high gain in a wide bandwidth be challenge as bandwidth usually trade off with gain. 
this work present the design of a high gbw e band lna in 130 nm sige bicmos technology. 
common emitter stage be stack in a current share configuration to allow low power consumption and couple through third order l c band pass network to extend the bandwidth. 
in addition the stage be stagger tune to maximize bandwidth and gain flatness. 
the lna achieve flat frequency response with 22.5db peak gain over a three db bandwidth of 21.6ghz from 66.4 88ghz with 5.6db average in band noise figure and 14.4mw power consumption. 
non invasive highly integrated transformer power detector for self healing pa in 130 nm h9soi fem cmos technology. 
this paper present a non invasive power detector pd fully integrate with a 5.8ghz differential power amplifier pa. 
a symmetrical balun provide the differential to single end transformation while present the optimal load to the pa. 
the pd be connect to a sense circuit place within the output network of the pa. 
this sensor consist of a third coil add in the center of the output balun to couple a very low part of the rf power go through the transformer. 
the pd remain non invasive for the pa performance. 
it achieve a dynamic range of 10db with an accuracy of 0.2 db with a power consumption low than 250 mu w. 
this paper highlight a way to realize output matching network for self heal differential pa by use a transformer which perform both output matching conversion mode and non invasive power sensing. 
highly linear fully integrated class o power amplifier in standard 65 nm cmos technology. 
this paper demonstrate a fully integrate class o power amplifier pa as a stand alone module. 
the pa be implement in a standard 65 nm cmo include input matching load transformation network and balun. 
thus no extra lumped component be need. 
the class o pa consist of a common drain cd and a common source cs amplifier. 
the cd provide excellent linearity due to the inherent feedback but low gain at rf frequency. 
the cs be employ to increase the gain. 
capacitive feedback be use to improve the stability of the class o pa. 
measure saturate output power p out be 26.7dbm and peak pae be 26.2 at 2.26 ghz under a vdd of 2.5 v for the fabricate pa module pcb and bonding loss be include. 
with a 64qam lte 20mhz signal apply an average p out of 18.8dbm be obtain while e utra aclr be below  30 dbc without dpd. 
an average pout of 22.5dbm and evm of 4.5 be achieve with wcdma standard. 
a 20w and broadband two stage ldmos power amplifier with high q cu integrated passive device for multi band and multi standard application. 
this paper present a 20w and broadband power amplifier use high q cu integrate passive device ipd. 
dual path and two stage broadband rfic pa use the late ldmos technology cover from 1.5 ghz to 2.5 ghz frequency band and perform exceptionally well in multi mode and multi band operation. 
the measure power gain and drain efficiency in class ab mode achieve more than 30 db and between 18 and 22 from 1.8 ghz to 2.5 ghz at 10 db power back off respectively. 
in order to validate the multi band operation the pa be linearize as the final stage of the low power line up by the nxp dfe dpd system under 145 mhz 3c lte signal and have more than 27 efficiency and  57 dbc correct aclr at the average output power of 36 dbm eight db back off. 
to the good of the author knowledge this be the first demonstration of broadband high power amplifier with excellent wideband dpd linearization and rf performance. 
progressive closed loop chance constrain control. 
chance constrain control be a difficult problem even if the consider system dynamic be linear. 
the difficulty stem from the fact that the chance constraint be difficult to evaluate and that the control law be nonlinear due to the constraint. 
in this paper we present a novel approach to chance constrain control where we solve the unconstrained control problem first and then use a progressive method to gradually introduce the chance constraint. 
this have significant advantage compare to traditional method because we do not require a feasible initial solution for the numerical optimization algorithm. 
finally we evaluate the novel method and compare it to an approach from literature. 
source behavior discovery for fusion of subjective opinions. 
information be at the center of decision make in many system and use case. 
in cooperative or hostile environment agent communicate their subjective opinion about various phenomenon. 
however source of these opinion be not always competent and honest but often erroneous or even malicious. 
furthermore malicious source may adopt certain behavior to mislead the decision maker in a specific way. 
fortunately the report of such misleading source be correlate to ground truth. 
use statistical method one can learn how likely a source distort the ground truth and the associate distortion model so that report from these source can still be fuse to enhance estimation of the ground truth. 
in this work we propose to learn a number of statistically meaningful opinion transformation that represent various behavior of information source. 
then we exploit these transformation while fuse opinion from unreliable source. 
use real datum from the web and through extensive comparison with recent trust base approach over simulation we show that our approach can be use to determine set of transformation that may lead to more accurate estimation of the truth. 
adaptive maxent modeling of distributed decision fusion without knowledge of prior probabilities of local decision. 
we introduce the method of the maximum entropy maxent model for fuse local decision in a distribute multiple sensor system. 
the fusion center receive local binary decision in the usual parallel architecture. 
no assumption be make about know any local decision rule. 
our approach be base on the concept of machine learning wherein the maxent parametric model be use for supervised classification and prediction serve as the central global decision rule. 
therefore the system be able to learn the detection performance of the sensor as a function of time without prior knowledge of the actual probability of local decision only require an initial set of random training datum. 
thus it be demonstrate that the system be adaptive and can learn contextual change of the sensor. 
furthermore we provide simulation result compare the maxent fusion center performance with publish result use both the bayesian formulation and neyman pearson criterion and with maxent achieve the good realistic detection performance demonstrate the effectiveness of the method. 
activity recognition base on inertial sensors for ambient assisted living. 
ambient assisted living aal aim to create innovative technical solution and service to support independent live among old adult improve their quality of life and reduce the cost associate with health and social care. 
aal system provide health monitoring through sensor base technology to preserve health and functional ability and facilitate social support for the age population. 
human activity recognition har be an enabler for the development of robust aal solution especially in safety critical environment. 
therefore har model apply within this domain e.g. 
for fall detection or for provide contextual information to caregiver need to be accurate to assist in develop reliable support system. 
in this paper we evaluate three machine learning algorithm namely support vector machine svm a hybrid of hidden markov models hmm and svm svm hmm and artificial neural networks anns apply on a dataset collect between the elderly and their caregiver counterpart. 
detect activity will later serve as input to a bidirectional activity awareness system for increase social connectedness. 
result show high classification performance for all three algorithm. 
specifically the svmhmm hybrid demonstrate the good classification performance. 
in addition to this we make our dataset publicly available for use by the machine learn community. 
speed up ia mechanically steered multistatic radar scheduling with gp gpu. 
in this paper we investigate speed up the execution time of interval algebra ia mechanically steer multistatic and multisite radar scheduling use a general purpose graphical processing unit gp gpu. 
multistatic multisite radar scheduling form part of jdl fusion level four process refinement and specifically draw from the multisensor management domain of knowledge. 
pseudo code for an open compute language opencl ia total path consistency algorithm be provide base on the original work of ladkin and maddux. 
monte carlo execution be run to solve randomly generate interval algebra network on a gp gpu and a single core of a multicore central processing unit. 
the result indicate that the opencl ia total path consistency algorithm execute on a gp gpu in parallel should be prefer for temporal constraint satisfaction problem where the network be more likely to be consistent. 
then for consistent network this parallel algorithm can provide execution time speed up between two and three time within the test limit that of the serial algorithm. 
we present suggestion as to constraint to the opencl ia total path consistency algorithm. 
fusion with sentiment score for market research. 
the recent surge in electronic and social medium have lead to an explosion of sentiment datum embed in public and private document fuel interest in sentiment analysis especially as individual brand and corporation look to manage their reputational risk which be directly correlate to company performance. 
in this paper we describe two approach to score sentiment from a large unstructured text corpus(1 to fuse with other relevant structured relational datum one a simple but effective and fast lexicon base approach where the score of a document be base on the occurrence of stem word represent positive and negative sentiment and two a supervised machine learning approach where the score be derive by make use of a kernel base classification model create from the training document. 
example application of these technique can be find in our text analytic tool call atext which can compute sentiment score of product review from amazon and tripadvisor to gain market insight to product and service. 
another example be the computation of sentiment score use atext for public and private company from credible financial source which be far fuse with market datum stock price to create a composite index for financial analyst and trader. 
factorized covariance intersection for scalable partial state decentralize data fusion. 
we propose a new conditionally factorize covariance intersection ci algorithm for perform partial state decentralize data fusion ddf. 
this be relevant for sensor network where platform must deal with mixed heterogeneous state estimation problem due to couple between uncertainty in share subset of externally monitor process state and private platform state. 
our approach enable scalable robust conservative ddf in ad hoc network through fusion only of external process state estimate that be jointly monitor by neighboring platform while still enable update to private platform state information via conditional inference. 
we also propose an additional enhancement to factorize ci which help to minimize unnecessary local information loss due to conservative data fusion. 
a networked multi platform target track simulation be provide to demonstrate the propose approach which can be extend to other bayesian ddf application involve networked fusion of heterogeneous state vector. 
object recognition and identification use esm data. 
recognition and identification of unknown target be a crucial task in surveillance and security system. 
electronic support measures esm be one of the most effective sensor for identification especially for maritime and air to ground application. 
in typical surveillance system multiple esm sensor be usually deploy along with kinematic sensor like radar. 
different esm sensor may produce different type of report ready to be send to the fusion center. 
the focus of this paper be to develop a new architecture for target recognition and identification when non homogeneous esm and possibly kinematic report be receive at the fusion center. 
a bayesian version of the new fusion architecture be evaluate use simulation to show the benefit of utilize different esm report such as attribute and signal level esm datum. 
optimal sample base fusion for distributed state estimation. 
in this paper we present a novel approach to optimally fuse estimate in distribute state estimation for linear and nonlinear system. 
an optimal fusion require the knowledge of the correct correlation between locally obtain estimate. 
the naive and intractable way of calculate the correct correlation would be to exchange information about every process measurement between all node. 
instead we propose to obtain the correct correlation by keep and process a small set of deterministic sample on each node in parallel to the actual local state estimation. 
send these sample in addition to the local state estimate to the fusion center allow for correctly reconstruct the desire correlation between all estimate. 
in do so each node do not need any information about measurement process on other node. 
we show the optimality of the propose method by mean of track an extended object in a multi camera network. 
motion segmentation and appearance change detection based 2d hand tracking. 
in this paper a novel method call macs for 2d hand tracking use motion and color information for headworn monocular color camera be present. 
many head mount device hmd like eye tracker or augmented reality glass be equip with only one color camera capture the field of view of the user from the ego perspective. 
to interact with the hmd hand gesture be an intuitive modality. 
hand tracking can be view as the first step towards hand gesture recognition. 
but to recognize hand gesture in industrial or commercial application the hand tracking process must produce robust estimation in each frame give any lighting condition inside and outside of a building. 
to achieve this the present method create a motion segmentation determine a foreground segment and track the color appearance of this segment over time to estimate robustly when and roughly where the hand be visible. 
a sophisticated skin color detection method fuse with the previously generate move foreground segment make the estimation of the hand trajectory more accurate use a simple particle filter with a specialized observation model. 
this allow for estimate the 2d hand position even in front of complex background and difficult lighting condition. 
a comparison of this new algorithm with other tracking method be conduct use a thorough evaluation methodology and challenge image sequence with more than 25,000 frame contain different wipe hand gesture. 
refining relation identification by combine soft and sensor data. 
in recent year homeland security be become increasingly sensitive to threat pose by the tactic of subversive group or individual with malicious intent. 
networked group and organization leverage various mean of communication range from simple phone call to more sophisticated form of collaboration. 
such datum provide a rich collection of evidence from which to infer relationship of individual or even the structure of network and organization. 
this paper describe an approach develop to combine information from disparate data source in order to identify relevant relationship in heterogeneous environment. 
the objective be to discover entity and the relationship they share by a joint combination of sensor and soft datum. 
by analyze pattern of sensor base communication and content of report the solution highlight entity association which be indicative of social relationship. 
first the approach identify a set of entity relation thank to sensor datum. 
then association rule extract relation from text by use a combination of part of speech feature provide by natural language processing tool and the entity type as label by a domain ontology. 
the overall approach be design for domain such as intelligence analysis where the analyst attempt to build a picture of relation hold between individual by combine sensor stream that can refer to real world ongoing event and more complex report provide by human source. 
result be evaluate over a heterogeneous datum set and experiment show that the combination of soft and hard datum outperform individual approach in term of recall. 
navigation of robotic platform for gait disorder monitoring. 
this paper be focus on control of a six wheeled robotic platform use for gait pattern recording. 
navigation of the platform have to be very precise to keep the path of the platform as narrow as possible and to maintain the distance between the subject and the platform to capture the gait pattern in the most natural way. 
a key component of the whole robotic platform be an ms kinect v2 device which track the patient gait. 
kinect also provide the information about the distance between the robot and the patient to a microcontroller which be responsible for the wheel control. 
to obtain straight trajectory there be a camera pointing forward on the front of the robot and a set of two beacon at the end of the operation area to be track by the camera. 
all datum obtain from the camera kinect and encoder attach to each wheel be use during an offline reconstruction of the patient gait. 
to process and save the data form kinect camera and other controller in real time a special multithread application be develop. 
study of failure mode effect and criticality analysis. 
as machine tool system become increasingly more complicated the improvement of system scale and function increase the probability of system failure. 
to avoid human injury cause by system failure improve system reliability and enhance the management of system failure and risk control reliability analysis technology call fmeca have be apply many industry since the 1950. 
this paper first introduce a brief history of fmeca and the current international standard. 
second the core concept and implementation procedure of fmeca will be present. 
finally the advantage and disadvantage of fmeca and conclusion be provide. 
internet protocol based digital counters for legacy fatigue testing machines. 
in present paper we describe a design and implementation of an information system base on base of embed client and linux application server architecture. 
present information system serve for remote collection store and processing information on the number of carry out mechanical cycle for group of old exist fatigue test machine in an automotive component production. 
this upgrade of exist infrastructure we build on the electronic counter module with ethernet interface and on the know internet protocol snmp. 
eight electronic counter module replace exist electromechanical digital totalizing counter and they count of output from eight piece of mechanical impulse test machine each of they with 2hz output frequency. 
the web and application server be build on the linux operating system. 
the mvc architecture model view controller serve as the base for web application and it be write together with backend application server around the ruby on rails web framework. 
the database be build on the mysql server. 
we carry out three way to verify of accuracy of this manner counting and collecting of mechanical cycle and we reach result comparable with manual collecting of datum. 
thank to automatic detection of end of fatigue test we reach more effective utilization of test machine more than 25. 
our solution of upgrading of the exist industrial infrastructure for fatigue test be very reasonably price and be suitable for old industrial facility. 
logboat a simulation framework enabling can security assessment. 
traditionally fieldbus network be operate in closed environment where all communication node be assume to be trustworthy. 
therefore the correspond standard do not consider any security requirement. 
new technology trend such as the upcoming internet of thing iot demand an interconnection between all component of an industrial infrastructure. 
as a consequence of this there be a need for tool enable security assessment and the simulation of protocol base security improvement. 
in this paper we introduce logboat a flexible python and linux base simulation framework for security assessment on controller area network can network and make some architectural and technology selection proposal. 
subsequently the different module of logboat and their capability be explain and a use case scenario be present the paper conclude with an outlook on upcoming research activity on can bus security where the present framework can be of help. 
design of an auto gain control transimpedance amplifier for optical sensing application. 
an auto gain control transimpedence amplifier tia system have be develop in this work for optical sensing application. 
in the design a digitally control variable resistor be implement in the tia as the feedback resistance gain which be control by a micro controller mu c base board. 
the mu c be program to monitor the tia output and automatically adjust the gain in the tia to keep the tia output stable. 
this avoid signal saturation due to a large input photocurrent or a high ambient environmental condition and stabilize the tia performance. 
in addition the mu c allow for a serial interface to a pc that enable the real time process analysis use a graphic user interface gui develop in labview. 
with the gui the real time tia gain and the voltage signal at the tia output can be record which make it easy for the calculation of the incident light s intensity and enhance the system s usefulness in the application where the intensity measurement be require. 
experimental result show that for the gain range up to 255 k omega the system develop be capable of automatically adjust the tia gain for the change of incident light to stabilize the tia performance. 
in addition by record the gain and output signal of the tia use the pc the real time photocurrent can be accurately calculate. 
pharmaceutical manufacturing and the quality by design qbd process analytical technology pat approach. 
this paper be the result of a literature review focus on the application of process analytical technology pat for the pharmaceutical industry in conjunction with the quality by design qbd framework. 
pat and the qbd framework put forward by the fda offer a holistic approach to manufacturing pharmaceutical emphasise the understanding of process variable on the end product characteristic and transmit this information upstream to control critical process parameter that effect the critical to quality attribute of a product. 
key component of qbd be discuss and their potential impact on current manufacturing process along with the technological capability of pat and the benefit associate with real time process monitoring and control. 
an approach for digital circuit error reliability propagation analysis base on conditional probability. 
the continuous transistor scaling and extremely low power constraint in modern vlsi chip can potentially supersede the benefit of the technology shrink due to reliability issue. 
due to external aggression factor radiation and temperature gradient the cmo device flawless function can not be guarantee any more. 
thus design time integrated circuits ic reliability assessment be now turn out to be a mandatory step in the ic design flow. 
in this work we present a novel cad analytical error reliability propagation analysis technique call conditional probabilistic error reliability propagation analysis cperpa algorithm. 
cperpa efficiently resolve reliability relate correlation include reconvergent fanout and relate error use a condition algorithm originate from the conditional probability theory which promote the accuracy at the expense of relatively low complexity enhancement. 
experimental result on several benchmark circuit demonstrate the accuracy and the simulation time advantage of our approach when compare to monte carlo simulation. 
the result obtain with the propose cperpa framework be within three average error and up to 1000 time fast when compare to monte carlo simulation. 
numerical algorithms for lyapunov stability analysis of interpolative control structure. 
the complexity and specificity of stability analysis apply to interpolative type control structure make the study of such property a difficult almost impossible task at least in the analytical manner. 
therefore a well solution could be represent by the numerical approach. 
in this context this paper start with develop some method and technique with applicability for analysis of the interpolative type controller base on lyapunov method perspective. 
these methodological aspect be gather together into a specific procedural algorithm. 
base on this algorithm a set of matlab simulink program able to offer in a flexible and user interactive way a possible solution to lyapunov stability analysis for a class of interpolative type control system with linear or non linear process of 2nd and 3rd order be develop. 
the solution base on the implement software package be finally validate through some practical example. 
select the right topic for industry academia collaboration in software testing an experience report. 
the global software industry and the software engineering se academia be two large community. 
however unfortunately the level of joint industry academia collaboration iac in se be still relatively very low compare to the amount of activity in each of the two community. 
select the right topic for a new iac have be report to be challenge and often a deal maker or breaker for the start of iac. 
motivate by the above need the goal of this paper be to propose experience base guideline from our 10 software testing iac in the past several year in canada and turkey to effectively and efficiently select right topic for iacs in software testing also easily generalizable to other area of se for the benefit of se researcher and practitioner in start new iac. 
the experience and evidence support the guideline in this paper be draw from the author past project and also seven on go software testing project in the context of a large turkish software and system company. 
the topic selection process have involve interaction with company representative in the form of both multiple group discussion and separate face to face meeting while utilize ground theory to find converge to topic which would be interesting and useful from both industrial and academic perspective. 
to increase the success of our topic selection process we also utilize two other source of information from the literature one a set of four fitness criterion for topic selection in industry experiment and two challenge and good practice for iac specific to project inception as synthesize in a recent systematic literature review. 
we believe the result of this paper would be helpful for other researcher and practitioner not only in software testing but also in software engineering in general in increase their chance of success in project inception and topic selection phase. 
generate evil test strings for regular expressions. 
regular expression be a powerful string processing tool. 
however they be error prone and receive little error check from the compiler as most regular expression be syntactically correct. 
this paper describe egret a tool for generate evil test string for regular expression. 
egret focus on common mistake make by developer when create regular expression and develop test string that expose these error. 
egret have find error in 284 out of 791 regular expression. 
prior approach to test string generation have traverse all possible path in the equivalent nondeterministic finite state automaton lead to the generation of too many string. 
egret keep the set of test string to a manageable number few than 100 test string be generate for 96 of the regular expression a manageable 307 test string be generate for the most complex regular expression. 
muvm high order mutation analysis virtual machine for c. 
mutation analysis be a method for evaluate the effectiveness of a test suite by seed fault artificially and measure the fraction of seed fault detect by the test suite. 
the major limitation of mutation analysis be its lengthy execution time because it involve generate compile and run large number of mutate program call mutant. 
our tool muvm achieve a significant runtime improvement by perform high order mutation analysis use four technique metamutation mutation on virtual machine high order split stream execution and online adaptation technique. 
in order to obtain the same behavior as mutate the source code directly metamutation preserve the mutation location information which may potentially be lose during bitcode compilation and optimization. 
mutation on a virtual machine reduce the compilation and testing cost by compile a program once and invoke a process once. 
high order split stream execution also reduce the testing cost by execute common part of the mutant together and split the execution at a seeded fault. 
online adaptation technique reduce the number of generate mutant by omit infeasible mutant. 
our comparative experiment indicate that our tool be significantly superior to an exist tool an exist technique mutation schema generation and no split stream execution in high order mutation. 
semantic base test case generation. 
software testing be a major v&v activity that revolve around quality test case. 
generate quality test case be inherently knowledge intensive tedious and expensive task that be traditionally do by human. 
therefore a great deal of research have be do to facilitate and automate test case generation as much as possible. 
give the knowledge intensity of software test case generation various knowledge management technique such as semantic base technique be applicable. 
the main focus of our research be automatic generation of quality test case use available knowledge from the early stage of software development the re. 
our goal be to develop a semantic web enable framework for integrate knowledge from various requirement model to generate effective and efficient test case automatically. 
we be go to apply semantic technology to facilitate the test case generation process by mean of ontology and web of data. 
skyfire model base testing with cucumber. 
in the software industry a behavior driven development bdd tool cucumber have be widely use by practitioner. 
usually product analyst developer and tester manually write bdd test scenario that describe system behavior. 
tester write implementation for the bdd scenario by hand and execute the cucumber test. 
cucumber provide transparency about what test scenario be cover and how the test scenario be map to executable test. 
one drawback of the cucumber bdd approach be that test scenario be generate manually. 
thus the test scenario be usually weak. 
more importantly practitioner do not have a metric to measure test coverage. 
in this paper we present a model base testing mbt tool skyfire. 
skyfire can automatically generate effective cucumber test scenario to replace manually generate test scenario. 
skyfire read a behavioral uml diagram e. 
g. a state machine diagram identify all necessary element e. 
g. transition of the diagram generate effective test to satisfy various graph coverage criterion and convert the test into cucumber scenario. 
then tester write cucumber mapping for the generate scenario. 
skyfire do not only generate effective test but be also completely compatible with the exist agile development and continuous integration ci rhythm. 
we present the design architecture and implementation of skyfire as well as an industrial case study to show how skyfire be use in practice. 
unit test generation during software development evosuite plugin for maven intellij and jenkins. 
different technique to automatically generate unit test for object orient class have be propose but how to integrate these tool into the daily activity of software development be a little investigated question. 
in this paper we report on our experience in support industrial partner in introduce the evosuite automate junit test generation tool in their software development process. 
the first step consist of provide a plugin to the apache maven build infrastructure. 
the move from a research orient point and click tool to an automate step of the build process have implication on how developer interact with the tool and generate test and therefore we produce a plugin for the popular intellij integrated development environment ide. 
as build automation be a core component of continuous integration ci we provide a further plugin to the jenkins ci system which allow developer to monitor the result of evosuite and integrate generate test in their source tree. 
in this paper we discuss the result architecture of the plugin and the challenge arise when build such plugin. 
although the plugin describe be target for the evosuite tool they can be adapt and their architecture can be reuse for other test generation tool as well. 
qoe aware service delivery a joint venture approach for content and network provider. 
the objective of this work be the investigation of a possible collaboration between over the top otts service provider and internet service providers isp which be center around the quality of experience qoe. 
initially we define a reference architecture with the required module and interface for the interaction between the two provider. 
then we focus on the modeling of the revenue whose maximization drive the collaboration. 
it be consider as depend on the user churn which in turn be affect by the qoe and be model use the sigmoid function. 
we illustrate simulation result base on our propose collaboration approach which highlight how the propose strategy increase the revenue generation and qoe for both player hence provide a ground for isp to join the loop of revenue generation between ott and user. 
ionospheric scintillation threat to gnss in polar region the demogrape case study in antarctica. 
this paper address the design and implementation of an ionospheric scintillation monitoring receiver base on the software defined radio paradigm. 
the monitoring platform exploit a digital data grabber and a gnss fully software receiver which grant a high level of flexibility for the processing strategy and the storage of raw sample of the signal in case of meaningful scintillation event. 
such an implementation approach yield valuable advantage in critical area such as polar region where resource be limited and installation or maintenance and replacement of gnss receiver may be critical. 
the paper describe the successful installation of the platform in two antarctic station provide result at the same quality level of professional gnss receiver use for ionospheric scintillation monitoring. 
lose control the case for emergent software systems use autonomous assembly perception and learning. 
architectural self organisation in which different configuration of software module be dynamically assemble base on the current context have be show to be an effective way for software to self optimise over time. 
current approach to this rely heavily on human lead definition model policy and process to control how self organisation work. 
we present the case for a paradigm shift to fully emergent computer software which place the burden of understand entirely into the hand of software itself. 
these system be autonomously assemble at runtime from discover constituent part and their internal health and external deployment environment continually monitor. 
an online unsupervised learning system then use runtime adaptation to explore alternative system assembly and locate optimal solution. 
base on our experience to date we define the problem space of emergent software and we present a working case study of an emergent web server. 
our result demonstrate two aspect of the problem space for this case study that different assembly of behaviour be optimal in different deployment environment condition and that these assembly can be autonomously learn from generalised perception datum while the system be online. 
hybrid planning for decision making in self adaptive systems. 
run time generation of adaptation plan be a powerful mechanism that help a self adaptive system to meet its goal in a dynamically change environment. 
in the past researcher have demonstrate successful use of various automated planning technique to generate adaptation plan at run time. 
however for a planning technique there be often a trade off between timeliness and optimality of the solution. 
for some self adaptive system ideally one would like to have a planning approach that be both quick and find an optimal adaptation plan. 
to find the right balance between these conflicting requirement this paper introduce a hybrid planning approach that combine more than one planner to obtain the benefit of each. 
in this paper to instantiate a hybrid planner we combine deterministic planning with markov decision process mdp planning to obtain the good of both world deterministic planning provide plan quickly when timeliness be critical while allow mdp planning to generate optimal plan when the system have sufficient time to do so. 
we validate the hybrid planning approach use a realistic workload pattern in a simulated cloud base self adaptive system. 
decentralized cluster detection in distributed systems base on self organize synchronization. 
in this work we propose a method for the decentralized detection of cluster or community in large scale network system. 
different from other approach that require global knowledge of the network topology the propose method be base on a fully decentralize protocol and allow a node to infer knowledge about the community membership of its near neighbour. 
it rely on the fact that topological characteristic of a network leave trace in the evolution of a self organize synchronization process. 
the preliminary result present in this report show a promising detection accuracy and justify a further investigation of our approach. 
two step power scheduling with adaptive control interval for network intrusion detection systems on multicores. 
network intrusion detection system nids be become an important element even in embed system as well as in datum center since embed computer have be increasingly expose to the internet. 
the demand for power budget of these embed system be a critical issue in addition to that for performance. 
in this paper we propose a technique to minimize power consumption in the nids by two step power scheduling with the adaptive control interval. 
in addition we also propose a cpu core control algorithm so that our scheduling technique can preserve the performance for other application and nids assume the case of multiplexe nids and they simultaneously on the same device such as a home server or a mobile platform. 
we implement our two step algorithm into suricata which be a popular nids as well as a one step algorithm with the adaptive interval and a simple fix interval algorithm for evaluation. 
experimental result show that our two step scheduling with both the adaptive and the fix 30 millisecond interval achieve 75 power saving compare with the ondemand governor and 87 compare with the performance governor in linux respectively without affect their performance capability on four arm cortex a15 core at the network traffic of 1,000 packet second. 
in contrast when the network traffic reach to 17,000 packet second our two step scheduling and the ondemand as well as the performance governor can maintain the packet processing capacity while the fix 30 millisecond interval process only 50 packet with two and three core and about 80 packet on four core. 
power management controller for online power saving in network on chip. 
grow chip integration density and increase frequency lead to tremendous leakage power and henceforth to chip heat problem. 
power management be one possibility to reduce the power consumption and get the temperature problem under control. 
current technology mainly focus on powergate technique on basis of multi core system but leave the network perspective out of scope. 
we provide a holistic concept bring together power gate and frequency scaling technique for network on chip. 
follow this network static power consumption could be minimize without affect the system performance. 
we present a light weight power management controller for network on chip with online monitoring to optimize the power consumption of network resource. 
our work comprise a hardware simulation model for design space exploration of vary technology specific parameter and an fpgs base prototype for verification. 
the power save potential heavily depend on the network communication load. 
our power controller add only 2.1 of resource while 28.11 of the total power could be save with clock gating. 
crecomp automated design tool for ros compliant fpga component. 
autonomous mobile robot require high performance computation to meet variety of requirement of function such as sense intelligent image processing and control actuator. 
we focus on fpga as a hardware platform for autonomous mobile robot system. 
however a fpga base system be not effective in development cost since it require hdl base design whose productivity be relatively low. 
in order to solve this problem we have already propose a design principle of ros compliant fpga component which be effective in easy integration of a fpga device into any robot system. 
although it allow ros base software to access easily to hardware circuitry in fpga high development cost of hdl base circuitry still remain as a large problem. 
so in this paper we propose crecomp which be an automate design tool to improve productivity of ros compliant fpga component. 
crecomp generate code of interface software and hardware automatically. 
we evaluate crecomp from two major aspect improvement in design productivity and operation speed of generate fpga component by crecomp. 
experimental result show that only less than one hour be enough for novice designer to implement a ros compliant fpga component into programmable soc. 
furthermore our result reveal that generate fpga component operate 1.85 time fast than the original software base component. 
programming model and method for heterogeneous parallel embed system. 
the grow complexity of digital signal processing application make a compelling case for the adoption of high level programming model such as dataflow for the implementation of application on programmable logic device and many multi core embed processor. 
past research work have show that raise the level of abstraction of design stage do not necessarily come at penalty in result in term of performance or resource requirement. 
dataflow program provide a high level behavioral description capable of express both sequential and parallel component of application algorithm and enable natural design abstraction modularity and portability. 
this paper present an overview of the main feature recent achievement and result of a design flow entirely dataflow base and the associate tool capable of implement and optimize complex signal processing system application on heterogeneous and massive parallel embed system. 
highly dependable multi processor socs employing lifetime prediction base on health monitor. 
this paper describe the usage of iddx monitor which provide periodic datum to be employ for predict the remain lifetime of processor core in homogeneous multiprocessor socs during their lifetime. 
this form the basis of self repair with no mean down time for these socs and dramatically improve their dependability. 
we accomplish this goal by optimally choose and combine our design health monitor such as delay and current monitor to provide non redundant measurement datum. 
these can be implement nowadays as ijatg compatible embed instrument. 
accelerated stress test be carry out use a set of processor core in combination with a number of health monitor provide historic datum. 
these result form the basis of a remain lifetime prediction model for delay processor clock frequency where the coefficient be determine by a genetic algorithm. 
after the final test of an individual soc these store coefficient can be periodically update in an embed processor during its lifetime by the health monitor. 
in the case of seriously degrading core counteraction be automatically take like core isolation and e.g. 
spare replacement. 
in this case use be make of advanced run time mapping software. 
the result be a zero mean downtime soc with 40 reliability improvement in our nine processor core soc.. 
model residual lifetime of an ic consider spatial and inter temporal temperature variation. 
in today s cmos technology reliability of integrate circuit be a significant concern. 
high temperature during circuit operation accelerate the device age. 
power dissipation in an ic exhibit both spatial and inter temporal variation hence various block age differently. 
however enduser only care about the reliability of the ic as a whole specifically they be only concerned about the residual life of the ic. 
several age monitoring sensor have be propose to track aging of an ic. 
however current solution be build around detection of aging of a single critical path. 
reliability modeling of ic consider spatial and inter temporal temperature variation have not receive adequate attention in the literature. 
in this paper we propose an analytical model to predict the residual lifetime of an ic consider spatial and inter temporal temperature variation. 
this model can dynamically re compute residual lifetime with change in operate temperature of various block. 
the most substantial integrate circuit age mechanism be electromigration time dependent dielectric breakdown hot carrier injection and negative bias temperature instability. 
for this study we focus on residual lifetime modeling base on electromigration. 
unlike prior work we consider the effect of both spatial and inter temporal temperature variation and propose a generalize model for calculate the residual lifetime. 
experience report automated system level regression test prioritization use multiple factor. 
we propose a new method of determine an effective ordering of regression test case and describe its implementation as an automate tool call suitebuilder develop by westermo research and development ab. 
the tool generate an efficient order to run the case in an exist test suite by use expect or observed test duration and combine priority of multiple factor associate with test case include previous fault detection success interval since last execute and modification to the code test. 
the method and tool be develop to address problem in the traditional process of regression testing such as lack of time to run a complete regression suite failure to detect bug in time and test that be repeatedly omit. 
the tool have be integrate into the exist nightly test framework for westermo software that run on large scale datum communication system. 
in experimental evaluation of the tool we find significant improvement in regression testing result. 
the re ordered test suite finish within the available time the majority of fault detect test case be locate in the first third of the suite no important test case be omit and the necessity for manual work on the suite be greatly reduce. 
scout a multi objective method to select components in designing unit testing. 
the creation of a suite of unit testing be precede by the selection of which component code unit should be test. 
this selection be a significant challenge usually make base on the team member s experience or guide by defect prediction or fault localization model. 
we model the selection of component for unit testing with limited resource as a multi objective problem address two different objective maximize benefit and minimize testing cost. 
to measure the benefit of a component we make use of metric from static analysis cost of future maintenance dynamic analysis risk of fault and frequency of call and business value. 
we tackle gap and challenge in the literature to formulate an effective method the selector of software components for unit testing scout. 
scout provide an automate extraction of all necessary datum follow by a multi objective optimization process. 
scout be a method able to assist tester in different domain and the android platform be choose to perform our experiment take nine lead open source application as our subject. 
scout be compare with two of the most frequently use strategy in term of efficacy. 
we also compare the effectiveness and efficiency of seven algorithm in solve a multi objective component selection problem. 
our experiment be perform under different scenario and reveal the potential of scout in reduce the market vulnerability compare to other approach. 
to the good of our knowledge scout be the first method to assist in an automate way software testing manager in select component for the development of unit testing combine static and dynamic metric and business value. 
wap understand the brain at software debugging. 
we propose that understand functional pattern of activity in map brain region associate with code comprehension task and more specifically to the activity of find bug in traditional code inspection could reveal useful insight to improve software reliability and to improve the software development process in general. 
this include help to select the good professional for the debug effort improve the condition for code inspection and identify new direction to follow for train code reviewer. 
this paper present an interdisciplinary study to analyze the brain activity during code inspection task use functional magnetic resonance imaging fmri which be a well establish tool in cognitive neuroscience research. 
we use several program where realistic bug represent the most frequent type of software fault find in the field be inject. 
the code inspector involve in the research include programmer with different level of expertise and experience in real code review. 
the goal be to understand brain activity pattern associate with code comprehension task and more specifically the brain activity when the code reviewer identify a bug in the code eureka moment which can be a true positive or a false positive. 
our result confirm that brain area associate with language processing and mathematic be highly active during code reviewing and show that there be specific brain activity pattern that can be relate to the decision make moment of suspicion bug detection. 
importantly the activity at the anterior insula region that we find to play a relevant role in the process of identify software bug be positively correlate to the precision of bug detection by the inspector. 
this finding provide a new perspective on the role of this region on error awareness and monitoring and of its potential predictive value in predict the quality of bug remove. 
anomaly detection and root cause localization in virtual network functions. 
the maturity of hardware virtualization have motivate communication service providers csp to apply this paradigm to network service. 
virtual network functions vnfs result from this trend and raise new dependability challenge relate to network softwarisation that be still not thoroughly explore. 
this paper describe a new approach to detect service level agreements slas violation and preliminary symptom of slas violation. 
in particular one other major objective of our approach be to help csp administrator to identify the anomalous vm at the origin of the detect sla violation which should enable they to proactively plan for appropriate recovery strategy. 
to this end we make use of virtual machine vm monitor datum and perform both a per vm and an ensemble analysis. 
our approach include a supervised machine learn algorithm as well as fault injection tool. 
the experimental testbed consist of a virtual ip multimedia subsystem develop by the clearwater project. 
experimental result show that our approach can achieve high precision and recall and low false alarm rate and can pinpoint the root anomalous vnf vm cause sla violation. 
it can also detect preliminary symptom of high workload trigger sla violation. 
goal drive deception tactic design. 
deception base defense rely on intentional action employ to induce erroneous inference on attacker. 
exist deception approach be include in the software development process in an ad hoc fashion and be fundamentally realize as single tool or entire solution repackage as honeypot machine. 
we propose a systematic goal drive approach to include deception tactic early in the software development process so that conflict and risk can be find in the initial phase of the development reduce cost of ill plane decision. 
the process integrate three phase system modeling produce a goal model of the application domain security modeling produce a threat model specify the typical security concern from the attacker perspective and deception modeling produce a deception tactic model a variability model and deception story model. 
the feasibility of the propose approach be show via a case study where deception defense strategy be design for a student presence control system for our university. 
program the network application software faults in software define network. 
software define networking sdn be a key new paradigm emerge in the industry in which network can be dynamically reconfigure in real time through software. 
sdn network be also be use in conjunction with cloud computing to extend virtualization and elasticity to the network level and as a foundation for the internet of things iot. 
a key concept in sdn be the separation of the network control and datum plane together with an application plane that support the programming of network application in general purpose language such as java and python. 
these network application can be develop by an enterprise service provider or vendor or purchase from third party through sdn application store. 
while the programmability of sdn provide tremendous flexibility and adaptability to change network condition and demand it also expose network to significant vulnerability through software fault in network application as well as in the control and datum plane. 
in this paper we demonstrate how faulty sdn application can compromise other sdn application or even crash an entire sdn network and describe relationship between software fault in sdn application and design fault in sdn controller. 
we also show how machine learning base anomaly detection and analytic can be use to identify sdn software fault and help guide real time network response through a proof of concept case study. 
safety assurance for emergent collaboration of open distributed systems. 
for the next generation of distribute system it be foresee to enable new powerful application base on system collaboration for dynamic integration of functionality. 
this require a certain level of autonomy for self manage system to change their effective and deterministic behavior during operation. 
in many application domain however collaboration process for new high level functionality be safety critical and an appropriate safety assurance approach be still miss. 
to ensure that the current operational situation base on an adapt system behavior be safe we propose a safety evaluation with dynamic safety contract between involve party. 
the approach be base on a continuous monitoring sharing and calculation of safety relate quality characteristic of system at runtime. 
we demonstrate the feasibility of our approach with a use case from the automotive domain. 
disruptive research and innovation. 
ever since clayton christensen coin the term disruptive technology and disruptive innovation in 1990s researcher and entrepreneur love the word disruptive because disrupt current knowledge or product help we accelerate knowledge discovery and move the society into a new era. 
what be disruptive research what be disruptive innovation how do they happen to answer such question in this talk i will share my experience from co lead the imagenet project which build a knowledge base for computer vision and machine learning community and from co found data domain inc. 
which build deduplication storage ecosystem to replace tape library infrastructure in datum center. 
mystic predictive scheduling for gpu base cloud servers use machine learning. 
gpu have become the primary choice of accelerator for high end datum center and cloud server which can host thousand of disparate application. 
with the grow demand for gpu on cluster there arise a need for efficient coexecution of application on the same accelerator device. 
however the resource contention among co executing application cause interference which lead to degradation in execution performance impact qos requirement of application and lower overall system throughput. 
while previous work have propose technique for detect interference the exist solution be either develop for cpu cluster or use static profiling approach which can be computationally intensive and do not scale well. 
we present mystic an interference aware scheduler for efficient co execution of application on gpu base cluster and cloud server. 
the most important feature of mystic be the use of learning base analytical model for detect interference between application. 
we leverage a collaborative filter framework to characterize an incoming application with respect to the interference it may cause when co execute with other application while share gpu resource. 
mystic identify the similarity between new application and the executing application and guide the scheduler to minimize the interference and improve system throughput. 
we train the learning model with 42 cuda application and consider another separate set of 55 diverse real world gpu application for evaluation. 
mystic be evaluate on a live gpu cluster with 32 nvidia gpu. 
our framework achieve performance guarantee for 90.3 of the evaluate application. 
when compare with state of the art interference oblivious scheduler mystic improve the system throughput by 27.5 on average and achieve a 16.3 improvement on average in gpu utilization. 
gather a closed chain of robots on a grid. 
we consider the following variant of the two dimensional gathering problem for swarm of robot give a swarm of n indistinguishable point shape robot on a two dimensional grid. 
initially the robot form a closed chain on the grid and must keep this connectivity during the whole process of their gathering. 
connectivity mean that neighboring robot of the chain need to be position at the same or neighboring point of the grid. 
in our model gather mean to keep shorten the chain until the robot be locate inside a 2x2 subgrid. 
our model be completely local no global control no global coordinate no compass no global communication or vision. 
each robot can only see its next constant number of left and right neighbor on the chain. 
this fix constant be call the view path length. 
all its operation and detection be restrict to this constant number of robot. 
other robot even if locate at neighboring or the same grid point can not be detect. 
only base on the relative position of its detectable chain neighbor can a robot decide to obtain a certain state. 
base on this state and their local knowledge the robot do local modification to the chain by move to neighboring grid point without break the chain. 
these modification be perform without the knowledge whether they lead to a global progress or not. 
we assume the fully synchronous fsync model. 
for this problem we present a gathering algorithm which need linear time. 
this result generalize the result from where an open chain with specify distinguishable and fix endpoint be consider. 
discrete cache insertion policies for share last level cache management on large multicores. 
multi core processor employ share last level caches llc. 
this trend will continue in the future with large multi core processor 16 core and beyond as well. 
at the same time the associativity of llc tend to remain in the order of sixteen. 
consequently with large multicore processor the number of core that share the llc become large than the associativity of the cache itself. 
llc management policy have be extensively study for small scale multi core four to eight core and associativity degree in the 16 range. 
however the impact of llc management on large multi core be essentially unknown in particular when the associativity degree be small than the number of core. 
in this study we introduce adaptive discrete and deprioritize application prioritization adapt an llc management policy address the large multi core where the llc associativity degree be small than the number of core. 
adapt build on the use of the foot print number metric. 
we propose a monitoring mechanism that dynamically sample cache set to estimate the footprint number of application and classify they into discrete distinct and more than two priority bucket. 
the cache replacement policy leverage this classification and assign priority to cache line of application during cache replacement operation. 
we far find that de prioritize certain application during cache replacement be beneficial to the overall performance. 
we evaluate our proposal on 16 20 and 24 core multi programmed workload and discuss other aspect in detail. 
exploit maximal overlap for non contiguous data movement processing on modern gpu enable system. 
gpu accelerator be widely use in hpc cluster due to their massive parallelism and high throughput per watt. 
data movement continue to be the major bottleneck on gpu cluster more so when datum be non contiguous which be common in scientific application. 
cuda aware mpi library optimize non contiguous datum movement processing use latency orient technique such as use gpu kernel to accelerate the packing unpack operation. 
although they optimize the latency of a single operation the inherent restriction of exist design limit their efficiency for throughput orient pattern. 
indeed none of the exist design fully exploit the parallelism abundantly available on gpu to provide high throughput and efficient resource utilization by enable maximal overlap. 
in this paper we propose novel design for cuda aware mpi library to achieve efficient gpu resource utilization and maximal overlap between cpu and gpu for non contiguous datum processing and movement. 
the propose design take advantage of several cuda feature such as hyper q multistreams and callback functionality to deliver high performance and efficiency. 
to the good of our knowledge this be the first such study that aim at achieve high throughput and efficient gpu utilization for non contiguous mpi datum processing and movement to from gpu. 
for intra node inter gpu ping pong experiment use ddtbench the propose design show up to 54 67 61 performance improvement on the specfem3d_oc specfem3d_cm and wrf_y_sa bench mark respectively. 
the propose design also deliver up to 33 improvement on the total execution time over the exist design for the haloexchange base application kernel that model the communication pattern of the meteoswiss weather forecasting model over 32 gpu node on wilkes gpu cluster. 
be static schedule so bad a case study on cholesky factorization. 
our goal be to provide an analysis and comparison of static and dynamic strategy for task graph scheduling on platform consist of heterogeneous and unrelated resource such as gpu and cpu. 
static scheduling strategy that have be use for year suffer several weakness. 
first it be well known that underlie optimization problem be np complete what limit the capability of find optimal solution to small case. 
second parallelism inside processing node make it difficult to precisely predict the performance of both communication and computation due to share resource and co scheduling effect. 
recently to cope with this limitation many dynamic task graph base runtime scheduler starpu starss quark parsec have be propose. 
dynamic scheduler base their allocation and scheduling decision on the one side on dynamic information such as the set of available task the location of datum and the state of the resource and on the other hand on static information such as task priority compute from the whole task graph. 
our analysis be deep but we concentrate on a single kernel namely cholesky factorization of dense matrix on platform consist of gpu and cpu. 
this application encompass many important characteristic in our context. 
indeed it involve four different kernel potrf trsm syrk and gemm whose acceleration ratio on gpu be strongly different from 2.3 for potrf to 29 for gemm and it consist in a phase where the number of available task if large where the careful use of resource be critical and in a phase with few task available where the choice of the task to be execute be crucial. 
in this paper we analyze the performance of static and dynamic strategy and we propose a set of intermediate strategy by add more static resp. 
dynamic feature into dynamic resp. 
static strategy. 
our conclusion be somehow unexpected in the sense that we prove that static base strategy be very efficient even in a context where performance estimation be not very good. 
gpu accelerate outlier detection for continuous data streams. 
outlier detection or anomaly detection be apply in numerous application such as fraud detection network intrusion detection manufacturing and environmental monitoring. 
due to the continuous and dynamic characteristic of streaming datum outlier detection over datum stream become a very challenging task. 
when analyze real time datum stream it be typically impossible to store the entire set of datum due to space limitation. 
also due to the high datum rate it be necessary to produce the result in a limited amount of time. 
parallel processing power of graphics processing units gpu can be use to accelerate the outlier detection process and thus address the challenge of outlier detection over datum stream. 
this paper propose a gpuaccelerated outlier detection algorithm for continuous datum stream use kernel density estimation approach. 
experiment show that the propose sod_gpu algorithm be efficient for detect outlier in high dimensional high speed datum stream and produce result in a timely manner without compromise the outlier detection accuracy. 
the propose method achieve up to 20x speedup compare to a respective multi core cpu implementation and the speedup increase with the number of datum attribute and the input datum rate. 
convex hull watchdog mitigation of malicious nodes in tree base p2p monitoring systems. 
monitor the global state in peer to peer network through decentralized mechanism allow targeted optimization and improvement of the peer to peer network. 
however malicious node could aim to distort the process of gather the global state through monitor. 
in this paper we propose domino a security solution for tree base peer topeer monitoring mechanism. 
it passively listen to incoming event datum and rate its suspiciousness base on outlier detection structural verification and sanity check mechanism. 
for our main objective which be to limit the monitoring error of the desire global view we perform an extensive evaluation. 
evaluation show tolerance with normal fluctuation but effective filtering of outlier that severely influence the global view. 
as our watchdog solution operate passively we do not add any cost nor create new surface for attack to the monitoring system. 
meta heuristic solution for dynamic association control in virtualized multi rate wlan. 
chaotic deployment of wireless local area networks wlans in dense urban area be one of the common issue of many internet service providers isp and wi fi user. 
it result in a substantial reduction of the throughput and impede the balanced distribution of bandwidth among the user. 
most of these network be manage independently and there be no cooperation among they. 
moreover the conventional association mechanism that select the access points aps with the strong received signal strength indicator rssi aggravate this situation. 
in this paper we present a versatile near optimal solution for the fair bandwidth distribution over virtualized wlan through dynamic association control. 
the propose scheme be call aco pf which be develop on top of ant colony optimization aco as a meta heuristic technique to provide proportional fairness pf among the greedy client. 
in fact it present a generic and centralized solution for isp that be use a common virtualized or overlap wlan infrastructure for serve their customer. 
we have evaluate the efficacy of aco pf through numerical analysis versus popular exist scheme for both downlink and uplink scenario. 
our propose technique have less complexity in term of the implementation and running time for large scale wlan and it can be easily develop and customize for different objective function. 
in addition it be implement in a testbed environment to investigate the key challenge of real deployment scenario. 
toward smart moving target defense for linux container resiliency. 
this paper present escape an informed move target defense mechanism for cloud container. 
escape model the interaction between attacker and their target container as a predator search for a prey search game. 
live migration of linux container prey be use to avoid attack predator and failure. 
the entire process be guide by a novel host base behavior monitor system that seamlessly monitor container for indication of intrusion and attack. 
to evaluate escape effectiveness we simulate the attack avoidance process base on a mathematical model mimic the prey vs predator search game. 
simulation result show high container survival probability with minimal add overhead. 
benchmark generation and simulation at extreme scale. 
the path to extreme scale high performance computing hpc pose several challenge relate to power performance resilience productivity programmability datum movement and datum management. 
investigate the performance of parallel application at scale on future architecture and the performance impact of different architectural choice be an important component of hpc hardware software co design. 
simulation use model of future hpc system and communication trace from application run on exist hpc system can offer an insight into the performance of future architecture. 
this work target technology develop for scalable application tracing of communication event. 
it focus on extreme scale simulation of hpc application and their communication behavior via lightweight parallel discrete event simulation for performance estimation and evaluation. 
instead of simply replay a trace within a simulator this work promote the generation of a benchmark from trace. 
this benchmark be subsequently expose to simulation use model to reflect the performance characteristic of future generation hpc system. 
this technique provide a number of benefit such as eliminate the datum intensive trace replay and enable simulation at different scale. 
the present work feature novel software co design aspect combine the scalatrace tool to generate scalable trace file the scalabenchgen tool to generate the benchmark and the xsim tool to assess the benchmark characteristic within a simulator. 
highly integrated quad channel transimpedance amplifier for next generation coherent optical receivers. 
this paper present a highly integrate high performance four channel linear transimpedance amplifier tia rfic with a footprint of 2mmx3.5 mm towards next generation 100g/400 g miniaturized coherent receiver. 
a tia of such form may become indispensable as the size complexity and cost of receiver continue to reduce. 
the design have be realize in a 130am sige bicmo process for a low cost high performance solution towards long haul metro application. 
the tia be capable of provide control function either digitally through an on chip four wire serial peripheral interface spi or in analog mode. 
analog mode be provide as an alternative control for real time control and monitoring. 
to provide high input dynamic range a variable gain control block be integrate for each channel which can be use in automatic or manual mode. 
the tia have a differential input differential output configuration that exhibit state of the art thd of 0.9 up to 500mv(pp output voltage swing for input current up to 2ma(pp and high isolation 40db between adjacent channel. 
a high transimpedance gain zt up to similar to seven k omega with a large dynamic range up to 37db and variable bandwidth up to 34ghz together with low average input noise density of 20pa root hz have be achieve. 
to the author knowledge these metric combine with diverse functionality and high integration have not be exhibit so far. 
this paper intend to report a state of the art high baud rate tia and provide insight into possibility for further integration. 
high performance slcfet for switched filter application. 
fet base switch filter do not occupy a large space in the literature due to the high loss of the switch relative to other technology. 
the super lattice castellated field effect transistor slcfet be a low loss high isolation broadband rf switch that meet this need. 
a four channel tunable band pass filter employ slcfet switch in a splitter combiner network be fabricate in order to demonstrate the enable capability of the slcfet for this application. 
each filter state employ a novel high q lc circuit. 
the insertion loss of the mmic passband be around  6.5 db of which  1.3 db be attributable to the six single pole double throw spdt switch in the network. 
breakout spdts be measure from 0.5 to 25 ghz. 
measure insertion loss at 18 ghz be  0.41 0.1 db and isolation be  28.8 0.1 db for 35 spdts on the wafer. 
a flexible robotic framework for autonomous manufacturing processes report from the european robotics challenge stage one. 
common industrial automation approach consist on heavy and fixed robotic manipulator work in separate and close production line. 
recent advance in sense and control yield flexible and versatile robotic manipulator platform which could work in barrier free production area and might be the next advance in industrial production. 
in our contribution we present a sophisticated and completely autonomous software framework for handle complex pick and place task use state of the art tool and algorithm. 
it cover applicable solution for 3d image processing motion planning grasp as well as error handling and task scheduling strategy. 
its competitiveness in term of robustness and performance have be prove by earn the first place among 39 team from all over europe in the simulation stage of the euroc. 
at the challenge two of this eu fund project a mobile robotic platform be use for intelligent flexible and highly automate production system. 
we discuss our result as well as the applicability of our framework to real industrial application. 
chess brain and autonomous chess playing robotic system. 
in this paper a four degree of freedom dof chess play robotic manipulator and computer vision base chess recognition system be present. 
the robotic system be capable of play chess game autonomously against human or another robotic system. 
the logical system consist of anti glare camera mount on the chessboard which act as an eye of robot personal computer for run time implementation of computer vision algorithm an open source chess engine use as chess brain of robotic manipulator which play chess algorithmic ally on behalf of robot and of course robot itself. 
on development side a simple image segmentation base computer vision algorithm be develop to find the legitimate chess move and human hand motion detection a software system be develop that enable the robot to pick and drop chess piece from prescribed chess box lastly communication channel be exploit for interface computer vision algorithm with chess engine. 
the whole robotic system be formulate from recycled machine part and open source tool. 
the convincing performance of computer vision algorithm and robotic manipulator testifie by its 1st position in ieee final year project competition lahore 2012. 
develop smart cities through optimal wireless mobile network. 
wireless mobile communication have become the interconnect technological platform through which seamless service of datum voice and other value add service can be deploy within local national and global platform. 
as a means to integrate smart service the mobile network must be efficient in term of coverage and quality of service. 
this paper therefore investigate large scale propagation model use to predict the signal strength with the aim of provide sufficient datum require for radio frequency planning and optimization which will engender flawless mobile network integration and consequent improved quality of service. 
datum analysis and optimization be carry out use root mean square statistical tool for which the cost231 model be optimize to ensure proper mobile network planning and improve quality of service. 
knowledge base management systems for the police force. 
knowledge based management systems enable new way to process and analyse knowledge to gain well insight to solve a problem and aid in decision making. 
in the police force such system provide a solution for enhance operation and improve client administration in term of knowledge management. 
the main objective of every police officer be to ensure the security of life and property promote lawfulness and avert and distinguish wrongdoing. 
the administration of knowledge and information be an essential part of policing and the police ought to be proactive in direct both explicit and implicit knowledge whilst add to their ability in knowledge sharing. 
in this paper the potential for a knowledge base system for the mauritius police be analyse and recommendation be also make base on requirement capture from interview with several long standing officer and surveying of previous work in the area. 
self tune flowchart a priority base approach to optimize diagnostic flowchart. 
flowchart have be use in problem diagnosis for a long time because of their effectiveness during process representation. 
however with time diagnostic flowchart can become unmanageably complex and incomprehensible thus lead to long decision path. 
a lengthy decision path also imply a time consume diagnosis process while at the same time be boring to end user utilize system contain diagnostic flowchart. 
this study investigate the extent to which diagnostic flowchart can be make dynamic so as to optimize the decision make process without reduce the number of node. 
in this endeavor the dynamic flowchart parser algorithm have be propose use a priority base approach to optimize diagnostic flowchart within a diagnostic tool name self tuning flowcharts. 
generation r why our grandchildren will grow up as the first generation of robotic native. 
robotic automation smart machine and artificial intelligence be currently in the center of public perception. 
we be face a disruptive megatrend that will have at least as much impact on the next half a century as the internet have on the last five decade. 
as robotic be steadily start to penetrate and enrich all domain of human society our grandchild will grow up as a generation r of robotic native. 
this paper explain the basic concept of the already broadly adopt concept of generation r. 
the method of linear inflation control in ambulatory blood pressure measurement at finger. 
in 24 hour non invasive blood pressure nibp measurement most of the automatic device use oscillometric method. 
accurate measurement of bp at finger use an oscillometric waveform omw remain a challenge particularly when the waveform be collect in inflation because of the bad signal to noise ratio. 
in the present work we aim at measure ambulatory blood pressure by extract oniw signal at finger with a new method of linear inflation control and digital signal processing. 
with the pid control of the pump and real time signal processing we implement the blood pressure measurement system and new algorithm. 
for the validation of our suggest method we compare the effect of our method and traditional method. 
finally the method be validate in a pilot study against welch allyn probp 3400 bp monitor. 
optimal input load disturbance rejection controller design for typical integrating processes base on imc structure. 
in this paper an h two optimal input load disturbance rejection ildr controller for three typical integrating process with dead time be propose base on the internal model control imc structure. 
different from other load disturbance rejection method the propose design method be to minimize the ildr criterion for integrate process with dead time. 
compare with previous advanced control method the propose design method have three main advantage. 
first the propose design method can optimally suppress the input load disturbance. 
second the design procedure be simple. 
no weight function need to be choose in the design method. 
the design controller be give in an analytical form. 
third the robustness stability can be achieve by monotonously tune the parameter give in the design controller. 
numerical simulation be give to illustrate the effectiveness of the propose method. 
pattern recognition of emg signal towards adaptive control of robotic arm. 
give the importance of hand as dexterous instrument to execute daily life task and the huge disability people suffer from when lose their limb this paper use the electrical activity of the muscle emg as control signal in a pattern recognition control system to manipulate the movement of a motorize 3d print robotic arm. 
a system to acquire the electromyography signal be first design and test. 
some feature be then extract from the emg signal to build a support vector machine classification model. 
the obtain result indicate the fidelity of acquire signal the efficiency of the exoskeleton and the accuracy of the classification process in achieve a robust myoelectric control system. 
the final result compose a backbone for a future development of a robust classification system to fulfill a complete prototype. 
augmented reality application a new implementation chain. 
augmented reality ar be a live view of a real world environment. 
with advanced ar technology artificial information about the environment and its object can be overlay on the real world. 
this paper present a complete augmented reality process for a video sequence capture by a move camera. 
the main goal be to construct a full chain compose of four block that correspond to the main step of augmented reality process feature detection feature extraction feature matching and image registration. 
our work propose an improved technique for image augmentation start from feature detection and end by image registration. 
we use the well know technique e.g. 
sift surf etc for feature detection and extraction in order to compare their performance. 
furthermore we add a feature learn step use svm knn and src to improve the image registration process. 
the final full chain use the good method in each block. 
this good combination be then apply on all video frame take by the camera. 
thereafter we obtain a video show the augmented object instead of the real one. 
a game theoretic approach to resource allocation in the cloud. 
different algorithm have be apply to solve the shared resource allocation problem in the cloud environment some of which be base on game theory with the aim to maximize the provider s profit while ensure good customer experience. 
however the traditional method do not account for the user rationality. 
in addition to be selfish by nature user gain experience and knowledge from their repetitive participation in a process. 
they can then choose the good action that guarantee their benefit. 
this learning process be not account for in static traditional queue theory base method. 
in game theory a player s payoff be not affect only by his choose action but also by the set of action profile choose by other player. 
in our paper we propose a strategic game model for resource allocation in the cloud environment. 
we take into consideration the interaction between two client the service level agreement between the client and the provider and the server load due to the allocation of other player. 
our result show that a nash equilibrium be achieve for some specific probability value assign along with the choice of a certain provider. 
datatags data handling policy spaces and the tags language. 
widespread sharing of scientific dataset hold great promise for new scientific discovery and great risk for personal privacy. 
dataset handling policy play the critical role of balance privacy risk and scientific value. 
we propose an extensible formal theoretical model for dataset handling policy. 
we define binary operator for policy composition and for compare policy strictness such that proposition like this policy be strict than that policy can be formally phrase. 
use this model the policy be describe in a machine executable and human readable way. 
we far present the tags programming language and toolset create especially for work with the propose model. 
tag allow composing interactive friendly questionnaire which when give a dataset can suggest a data handling policy that follow legal and technical guideline. 
currently create such a policy be a manual process require access to legal and technical expert which be not always available. 
we present some of tags tool such as interview system visualizer development environment and questionnaire inspector. 
finally we discuss methodology for questionnaire development. 
datum for this paper include a questionnaire for suggest a hipaa compliant datum handling policy and formal description of the set of datum tag propose by the author in a recent paper. 
privacy risk analysis base on system control structures adapt system theoretic process analysis for privacy engineering. 
to date top down effort to evolve and structure privacy engineering knowledge have tend to reflect common system engineering development life cycle activity. 
a different approach suggest a particular need for technical analytical method. 
to help address this need this paper propose to adapt for privacy engineer an exist technique system theoretic process analysis stpa develop for safety engineering. 
the foundation of stpa be discuss its security extension stpa sec be describe and modification to stpa sec be propose to produce stpa priv. 
stpa priv be then apply to a simple illustrative example. 
grammatical inference and machine learning approaches to post hoc langsec. 
formal language theory for security langsec apply the tool of theoretical computer science to the problem of protocol design and analysis. 
in practice most result have focus on protocol design show that by restrict the complexity of protocol it be possible to design parser with desirable and formally verifiable property such as correctness and equivalence. 
when we consider exist protocol however many of these be not subject to formal analysis during their design and many be not implement in a manner consistent with their formal documentation. 
determine a grammar for such protocol be the first step in analyze they which place this problem in the domain of grammatical inference for which a deep theoretical literature exist. 
in particular although it have be show that the high level category of the chomsky hierarchy can not be generically learn it be also know that certain subcategorie of that hierarchy can be effectively learn. 
in this paper we summarize some theoretical result for infer wellknown chomsky grammar with special attention to contextfree grammar cfgs and their generate language cfls. 
we then demonstrate that despite negative learnability result in the theoretical regime we can use long short term memory lstm network a type of recurrent neural network rnn architecture to learn a grammar for uris that appear in apache http access log for a particular server with high accuracy. 
we discuss these result in the context of grammatical inference and suggest avenue for further research into learnability of a subgroup of the context free grammar. 
a cooperative approach for 3d image segmentation. 
multi agent technology have be consider as an important approach for develop distribute intelligent system analyze computed tomography ct. 
due to the important interaction multi agent problem complexity can rise rapidly with the number of agent or their behavior. 
we present a mas solution that have spawn increase interest in machine technique to automate the search and optimization of image processing. 
in this survey we propose a three dimensional 3d segmentation process base on cooperation between different agent. 
the propose architecture analysis and segmentation that can integrate several mode of cooperation. 
new and low cost product solution for led matrix display. 
this paper describe a hardware and software design to display a dynamic message alphanumeric character as bitmap image in led matrix from conception design dimension to realization with the possibility of have fix or scrolling text adjustable brightness adjustable speed of scroll and support all language and symbol. 
the innovation be present in the message to be display ie from a monochrome bitmap image and by use a program that convert the image into a byte array we can display any message on the matrix and the variation of the brightness be do by software program by act on the cycle of a led s extinction and illumination in order to optimize the processing time to have an adjustable adaptation of the display to ambient light all in a low cost product. 
a simple present and past sentences machine translation from arabic language al to english language. 
the arabic language be a collection of spoken dialect and a standard write language. 
the dialect show phonological morphological lexical and syntactic. 
difference although the standard write language be the same throughout the arab world. 
the present work report our attempt in develop a bi lingual machine translation tool for simple present and past sentence in an elementary school domain. 
the work describe here be part of an ongoing research to automate the translation of user interface of knowledge base system. 
our project try to translate from a well structure arabic simple present and past sentence into a well structure english sentence by use a dictionary to translate a single word and a simple lexicon consist of word category and the meaning relative to category in appropriate format. 
the domain area be an arabic english dictionary and a set of well structure arabic sentence from many textbook in an elementary school. 
sentiment analysis for arabic e commerce website. 
sentiment analysis be a research area where study focus on the analysis and the processing of opinion find on the web content. 
it be about find the polarity of sentiment express by internet user in their interaction about a give subject in order to classify they on positive or negative. 
in this paper we propose the implementation of a tool for sentiment analysis able to find the polarity of opinion in review extract from e commerce magazine and blog in arabic language. 
to do this we conduct various experiment like test different technique of stemming and the performance of some classification algorithm to have the combination that give we satisfactory result. 
in spite of the huge difficulty that we find in this research area like the lack of resource in datum collection and the complexity of process the arabic language dialect the result be hopeful and satisfying. 
task scheduling algorithm in cloud computing environment base on cloud pricing model. 
the cloud computing be a most widely spread platform for execute task use virtual machine vms as processing element. 
therefore implement hpc use cloud computing be consider a powerful approach by isolate task reduce execution time as well as price and satisfy load balance. 
in this paper an enhancement task scheduling algorithm on the cloud computing environment have be introduce to reduce the make span as well as decrease the price of execute the independent task on the cloud resource. 
the principle of the algorithm be base on calculate the total processing power of the available resource i.e. vm and the total request processing power by the user task then allocate a group of user task to each vm base on the ratio of its need power relative to the total processing power of all vm. 
the power of vm have be define base on amazon ec2 and google pricing model. 
to evaluate the performance of the enhancement algorithm a comparative study have be do among this enhancement algorithm the default fcfs algorithm and the exist ga and pso algorithm. 
the experimental result show that the enhancement algorithm outperform other algorithm by reduce make span and the price of the running task. 
industrial maintenance with augmented reality two case studies. 
remote maintenance of industrial manipulator often be perform via telephone support. 
recent approach in the context of the industry 4.0 consider internet technology and augmented reality ar to enhance situation awareness between external expert and local service technician. 
we present two ar base case study first a mobile ar architecture base on optical see through glass be use for an on site local repair task. 
second a remote architecture base on a portable tablet pc and a high precision tracking system be use to realize an off site expert access. 
the to be service machine be visualize inside of a large area similar to a machinery hall and can be inspect by the expert walk around this virtual plant use the tablet and perspectively correct render to understand the production process and the operation context. 
both method have be evaluate in first user study. 
a case study on relation between roughness lubrication and fatigue life of rolling bearing. 
a spherical roller bearing under high radial loading constant speed and impose roughness for the contact surface be choose as case study. 
different lubrication regime be obtain by vary oil viscosity through the operate temperature. 
for bearing with especially machine contact surface lambda ratio be firstly determine and its value be use to estimate the particular value of the lubrication parameter kappa. 
use the lambda ratio approach the paper reveal the relationship between roughness amplitude and the modify rating life of rolling bearing. 
the roughness value correspond to good manufacturing practice be possible to be determine for each particular case. 
three group of random gaussian roughness be generate with the same value for the ra parameter as use in the modified life investigation. 
for medium and especially high radial load the contact between rough surface develop inside the shallow layer von mises equivalent stress high than the fatigue limit stress. 
for condition of lack of lubricant or starve lubrication these finding explain the initiation of the roll contact fatigue in the shallow layer close to contact surface. 
characteristic of material and thermal treatment apply to gearwheel obtain by plastic deformation. 
a variety of material be use in the manufacture of gearwheel. 
these material satisfy various working condition for gear. 
such gear be make of metallic material ferrous non ferrous and from plastic material. 
among ferrous material the following be use iron cast forge and roll steel among non ferrous material the following be use bronze aluminium alloy brass etc and of plastic the following be use textolite polyamide polyacetal. 
in the practice of exploitation and in the process of special research it be establish that the permissible load accord to teeth contact resistance be generally determine by the hardness of the material. 
the high hardness and respectively the small size and reduce mass of the transmission can be obtain in the manufacture of steel gear via thermal treatment. 
it be obvious that by plastic deformation at cold it can not be obtain gearwheel with complicated configuration as deform plastic metal will form crack cause by low plasticity. 
to improve processability by plastic deformation the moulding for gearwheel be heat. 
with increase the heating temperature plasticity increase and resistance to deformation decrease. 
electromechanical response of silicone dielectric elastomer. 
this paper present an experimental technique to investigate the electromechanical property of silicone dielectric elastomer actuate with high dc electric field. 
a non contact measurement technique be use to capture and monitor the thickness strain contraction of a circular film place between two metallic disk electrode. 
two active filler such as silica 10 15 and 30 wt% and barium titanate five and 15 wt% be incorporate in order to increase the actuation performance. 
thickness strain be measure at hv stimuli up to 4.5 kv and show a quadratic dependence against apply electric field indicate that the induce strain be trigger by the maxwell effect and/or electrostriction phenomenon as report in literature. 
the actuation process evidence a rapid contraction upon hv activation and a slowly relaxation when the electrode be short circuit due to visco elastic nature of elastomer. 
a maximum of 1.22 thickness strain be obtain at low actuate field intensity 1.5 v mu m comparable with those report in literature for similar dielectric elastomer material. 
parametric optimization in virtual prototype environment of the control device for a robotic system use in thin layer deposition. 
the paper deal with the optimal design of the control system for a six dof robot use in thin layer deposition. 
the optimization be base on parametric technique by model the design objective as a numerical function and then establish the optimal value of the design variable so that to minimize the objective function. 
the robotic system be a mechatronic product which integrate the mechanical device and the control operating device. 
the mechanical device of the robot be design in the cad computer aided design software catia the 3d model being then transfer to the mbs multi body systems environment adams view. 
the control system be develop in the concurrent engineering concept through the integration with the mbs mechanical model by use the dfc design for control software solution easy5. 
the necessary angular motion in the six joint of the robot in order to obtain the impose trajectory of the end effector have be establish by perform the inverse kinematic analysis. 
the positioning error in each joint of the robot be use as design objective the optimization goal be to minimize the root mean square during simulation which be a measure of the magnitude of the positioning error vary quantity. 
planning and leading of the technological process by mechanical work with microsoft project. 
nowadays fabrication system and method be be modify new processing technology come up flow sheet develop a minimum number of phase the flexibility of the technology grow up new method and instrument of monitor and lead the processing operation also come up. 
the technological course route entry scheme guiding refer to the series of the operation put and execution phase of a mark in order to obtain the final product from the blank be represent by a sequence of activity realize by a logic manner on a well determined schedule with a determined budget and resource. 
also a project can be define as a series of specific activity methodical structure which they aim to finish a specific objective within a fixed schedule and budget. 
within the homogeneity between the project and the technological course this research be present the defining of the technological course of mechanical chip removing process use microsoft project. 
under these circumstance this research highlight the advantage of this method the celerity use of other technological alternative in order to pick the optimal process the job scheduling be constrain by any kind the standardization of some process technological operation. 
concept and fundamental equation in thermodynamics with finite speed. 
this paper present the basic concept and fundamental equation of the thermodynamics with finite speed tfs result by the systematically study of the thermal reciprocate machine in relation with the piston finite speed and thermal molecular speed measure in the consider thermodynamic system. 
these concept be base on the idea that any propagation of the interaction in the thermodynamic system of finite dimension be achieve by finite speed one piston speed two average speed of the gas molecule inside the cylinder. 
a specific approach scheme of calculation for non equilibrium irreversible thermodynamic process be develop within tfs in order to find the fundamental equation appropriate for optimize efficiency or cop and power of thermal reciprocate machine. 
analytical equation for all five irreversible thermodynamic process in gas isometric isothermal isobaric adiabatic polytropic be deduce by integration of the combine first and second laws equation for process with finite speed. 
this paper be limit to irreversible processes with finite speed without take into account the friction and throttling effect. 
it also note the main moment in the development of tfs that lead to these concept and fundamental equation. 
a simple solution for evaluation of lubricant anti wear property. 
the present paper describe a simple four ball test device adapt for a classical drilling machine use standard methodology mean to evaluate the lubricate property of lubricant. 
the advantage of the method consist in the possibility of use any type of ball and a special device adapt to a common drilling machine. 
the evaluation of anti wear lubricant property can be do by compare the contact scar dimension obtain experimentally follow the procedure describe in en iso 20623 2003 international standard. 
the contact scar diameter be measure use an optic microscope equip with a camera and specialized software by compare the scar with a know body dimension. 
some experimental result obtain for the contact between four 12.7 mm bearing ball lubricate with grease be present as well. 
the contact scar dimension load dependency be similar to those present in literature and therefore validate the experimental setup. 
method for design and control compliant gripper. 
the compliant gripper be useful for high accuracy grasp of small object with adaptive control of contact point along the active surface of the finger. 
the spatial trajectory of the element become a must due to the development of mems. 
the paper present the solution for the compliant gripper design by the author so the planar and spatial movement be discuss. 
at the beginning of the process the gripper could work as passive one just for the moment when it have to reach out the object surface. 
the force provide by the element have to avoid the damage. 
as part of the system the camera be take picture of the object in order to facilitate the positioning of the system. 
when the contact be establish the mechanism be act as an active gripper by use an electrical stepper motor which have control movement. 
general kbe model with inheritance and multi cad support. 
knowledge based engineering kbe be a research field that study methodology and technology for capture and re use engineering knowledge. 
the primary objective of kbe be to reduce time and cost of product research process and/or product development which be primarily achieve through automation of repetitive design task while capturing retain and re use engineering knowledge. 
every cad system include kbe tools. 
the power of these tool be incremente by the use of external high level programming language. 
the model present in this paper have the aim to reduce time and cost of particular kbe models development by program inheritance concept and also the multi cad support. 
the model be implement through a c application that be also present. 
environmental impact management and recycling of construction demolishing waste in izmir. 
in this paper waste management of construction industry its impact to environment and recycling method be study for city of izmir turkey. 
the construction industry be one of the large sector of the world economy especially in develop country with increase population. 
a large amount of construction renovation and demolition activity take place especially in residential building road bridge utility due to many of the structure mention become old. 
these demolishing and renovation activity create in large volume of construction and demolition waste cdw that should be manage recycle and dispose. 
in addition to management of cdw there be also environmental effect of production of construction material such as cement and aggregate. 
stone mining or quarry crush stone be the most common method to produce construction material aggregate sand and cement. 
the stone pit be operate for long time. 
during operation the nature be alter rehabilitation of pit may be do after pit be closed. 
besides construction and demolishing waste be need to be store in large area. 
all these mention activity effect the environment. 
thus recycle solid material of cdw provide save both by reduction use of new material and management cost of waste material. 
assessment of polycyclic aromatic hydrocarbon urban air pollution use thuja occidentali. 
polycyclic aromatic hydrocarbon pah be a generally hazardous class of organic compound be ubiquitous environmental pollutant originate from both natural and anthropic source. 
combustion process be major source of their presence in atmospheric aerosol. 
accord to their origin pah compound that be present in environment be classify in two major group pyrolitic and petrogenic. 
due to their toxic mutagenic and carcinogenic potential pah compound be associate with health hazardous effect and be include in the list of priority pollutant of us epa and european union. 
the purpose of the present study be to monitor pah air pollution in cluj napoca 350,000 inhabitant romania use pah atmospheric deposition on thuja occidentalis leave. 
five representative monitoring point locate in urban suburban heavy traffic and residential area be select. 
total content of ten pahs select as representative on the thuja leave be then determine. 
separation of the compound of interest be perform by ultrasound assist extraction and pah be determine by high performance liquid chromatography. 
the result show variation of pahs content in thuja leave that can be correlate with the location of sample point. 
the measure value be situate between 58.45 537.74 ng g total pah in dry leave with maximum concentration in zone with high traffic and low concentration in suburban zone. 
in order to identify the source of pollution ratio of select pah compound such as the abundance ratio of two 3 ring hydrocarbon to four 6 ring hydrocarbon sigma lmiat ehmw abundance ratio of combustion result pah to total pah sigma com93 etotalpah isomeric ratio of anthracene/(anthracene phenanthrene fluoranthene/(fluoranthene pyrene benzo[a]anthracene/(benzo[a]anthracene chrysen pyrene/(benzo[a]pyrene be use. 
the result suggest that the source of pah be pyrolitic and generate by combustion engine. 
change in cold day frequency in extra carpathian area of romania. 
the begining of the 21st century have be mark by rise mean temperature for most station in europe. 
thus in the north and center of the continent mean temperature value record show significant increase in winter djf and in mediterranean area there be an increase in summer jja warming of the land surface be manifest in synchronous altitude. 
in this context this research focus on detect and highlight the change in the number of cold day tg 10thpercentile in the low troposphere under 700 hpa above the extra carpathians area of romania. 
for each select level respectively ground level 925 850 and 700 hpa be calculate index frequency and statistical significance of the trend by use non parametric mann kendall test. 
the result show a decrease in variable frequency with regional difference set by particularity of the low troposphere movement. 
develop a cyberinfrastructure for air quality management in an urban environment. 
the impact of air pollution such as particulate matter pm on human health have be widely present in literature. 
an efficient management of air quality require the acquisition and analysis of various type of datum that be usually collect at regional national and international level by various governmental agency or by researcher from academia and private sector. 
in this context both scientist and authority need to use the capability of an advanced cyberinfrastructure ci that facilitate a well understanding of air pollution process knowledge sharing visualization interaction and collaboration in multiple way. 
the present work describe the contribution on develop a ci for air quality management in an urban industrial area locate in south east of romania cover two city ploiesti and targoviste have in view the relationship between the presence of various air pollutant and increase of adverse effect on child health. 
this ci be develop as a main result of rokidair research project fund by european economic area grants and allow the examining of the trend in ambient air quality especially in the city of ploiesti which be under the emission impact of petrochemical industry and heavy traffic. 
the project aim to improve the urban air quality monitoring and forecasting activity focus on particulate matter effect on child s health. 
the rokidair cyberinfrastructure provide early warning concern the particulate matter pm level tailor to the end user requirement via several communication channel. 
datum be obtain from a self develop monitoring network system base on several pm micro station and artificial intelligence forecasting algorithm design within the project. 
issues relate to air quality monitoring in north east region romania. 
monitor air pollution be an important tool in environmental protection policy as it may reveal where air quality aq should be improve and may determine the effectiveness of control program. 
it provide background datum useful in order to understand how the pollutant may affect population s health and the environment and also to keep community inform about local aq. 
in romania measurement for aq assessment be perform by 142 automate station that make up the national network of air quality monitoring rnmca. 
the station be distribute in all county be equip with automatic analyser that should continuously provide datum for the ambient concentration of the main atmospheric pollutant. 
present paper aim to evaluate the efficiency of current aq monitoring system in romania by analyse non validate datum from the official national site www.calitateaer.ro in one year period of catch 2014 2015 for all automatic station in north east region romania. 
the background datum be evaluate by take into account their location in relation to the main source of air pollution especially in urban environment but also the consistency of provide datum in order to describe their actual impact on population and ecosystem. 
the result of the assessment converge towards highlight some major dysfunctionalitie of the actual monitoring system the insufficient number of station that make impossible any interpolation of datum in order to describe difference in aq within the city their placement in area that be not the most relevant for describe aq for the city as a whole as it sometimes depend on the availability of land own by city halls limited datum capture cause by the failure of sensor enhance by lack a strict control and delay in maintenance etc. 
therefore there be few station provide less and less datum while sometimes there be county with no datum for rather long period. 
the final conclusion lead to the necessity to rethink the efficiency of aq monitoring system but also the need to correlate the validate datum with atmospheric condition emission inventory and population health study in order to have an integrate approach that could be use for effective local and regional environmental policy. 
safety and health at work concern occupational exposure to noise in steel industry worker. 
noise be a common problem present in the work environment. 
a large number of worker in europe suffer from hear problem cause by exposure to high noise level in work place. 
thus law stipulation be aim at reduce risk of hear loss through noise reduction preferably at source and by use hear protection equipment. 
noise issue be of undeniable importance also economically speak generate significant decrease in work capacity. 
low efficiency cause by fatigue and burnout worker mistake make when perform various operation mainly cause by distraction be all cause by exposure to noise noxae. 
knowledge and assessment of occupational risk at every work place be the main objective of accident and occupational disease prevention activity. 
this paper examine how noise generate by technological process of steel industry influence work activity of employee. 
preventive work regard noise exposure should be base on measurement of noise level. 
in this regard the purpose of this paper be to analyze noise measurement take at a steel company and to compare they to limit value provide by the effective legislation in order to assess the degree of exposure to occupational risk factor present during regular working hour. 
universal approximation results for the temporal restricted boltzmann machine and the recurrent temporal restricted boltzmann machine. 
the restricted boltzmann machine rbm have prove to be a powerful tool in machine learning both on its own and as the building block for deep belief network multi layer generative graphical model. 
the rbm and deep belief network have be show to be universal approximator for probability distribution on binary vector. 
in this paper we prove several similar universal approximation result for two variation of the restricted boltzmann machine with time dependence the temporal restricted boltzmann machine trbm and the recurrent temporal restricted boltzmann machine rtrbm. 
we show that the trbm be a universal approximator for markov chain and generalize the theorem to sequence with long time dependence. 
we then prove that the rtrbm be a universal approximator for stochastic process with fi nite time dependence. 
we conclude with a discussion on e ffi ciency and how the construction develop could explain some previous experimental result. 
olps a toolbox for on line portfolio selection. 
on line portfolio selection be a practical financial engineering problem which aim to sequentially allocate capital among a set of asset in order to maximize long term return. 
in recent year a variety of machine learning algorithm have be propose to address this challenging problem but no comprehensive open source toolbox have be release for various reason. 
this article present the first open source toolbox for on line portfolio selection olps which implement a collection of classical and state of the art strategy power by machine learning algorithm. 
we hope that olps can facilitate the development of new learning method and enable the performance benchmarke and comparison of different strategy. 
olps be an open source project release under apache license version 2.0 which be available at https://github.com/olps/ or http://olps.stevenhoi.org/.. 
investigate the effect of the deep cryogenic heat treatment on the corrosion and corrosive wear behaviour of the carburised 16mncr5 steel. 
deep cryogenic heat treatment be a finish process apply to the vast variety of material and more specifically on steel. 
in this investigation the effect of the deep cryogenic heat treatment on the microstructure corrosion behaviour and corrosive wear behaviour of the carburised 16mncr5 steel be study. 
result show that the deep cryogenic heat treatment eliminate the retain austenite as well as increase the carbide percentage. 
these phenomena increase the wear rate of the sample as well as decline the corrosion rate of the deep cryogenically treat sample dct due to decrease the dissolved chromium atom in the structure. 
moreover it be clarify that the effect of corrosive environment during the wear test be more significant on the dct sample as compare with the conventionally treat one cht. 
discrete element simulation of particle behavior in mass finishing process a parametric study. 
many thin thickness part have be use in machinery and have stringent requirement on weight and space dimension. 
since part of this type often have such characteristic as poor rigidity complex structure irregular shape and high surface integrity it be feasible for the mass finishing process to improve the surface integrity. 
this paper discuss finish blade as an example and the velocity and force behavior of the abrasive particle for the mass finishing process of the blade be analyze use discrete element method. 
three main influencing factor namely rotary velocity finish depth and rotation angle be explore. 
temperature characteristics of high speed sleeve bearing with two viscosity fluids. 
the problem of temperature rise for journal bearing be one of main resistance of the speed increase for machine tool. 
the application of low viscosity can solve the temperature rise of high speed and super high speed machine tool. 
for high viscosity lubricant and low viscosity lubricant bush inner surface temperature be measure by infrared thermometer temperature rise of spiral oil wedge sleeve bearing be measure by thermocouple and compute by reynolds equation. 
the effect of viscosity rotate speed axial position and input pressure on bush inner surface temperature and temperature rise be study. 
the result show that the change trend of theoretical and experimental temperature rise with rotation speed be consistent and temperature rise decrease with the increase of input pressure. 
bush inner surface temperature and temperature rise increase with the increase of rotate speed bush inner surface temperature be large near the oil return hole. 
temperature rise and bush inner surface temperature for high viscosity lubricant be high distinctly than low viscosity lubricant. 
a rapid identification method for static stiffness of multi axis cnc machine tools. 
the deformation of machine tool by force affect the machining precision and efficiency directly. 
this paper propose a novel method that force induce error of cnc machine tool with three axis be model and distribution law of deformation variety in machine space between the end of machine tool be reveal. 
a polynomial model of the deformation error for the machine tool be establish use the homogeneous coordinate transformation method of multi rigid body. 
to get the coefficient of the model a ball bar which be use to conduct circular movement testing under loaded condition be design. 
through load different force on it the circular motion testing be conduct in xoy xoz and yoz plane respectively then the parameter of the model be obtain by identification. 
accord to the model the deformation error in any direction between the end of the three axis cnc machine tool be relate to not only the force in that direction but also the position of the point suffer the force in the machining space as well as the force value in the orthogonal direction. 
the research be significance of discover distribution law of deformation for the machine tool as well as the prediction and compensation of the force induce error. 
effect of technological parameter on total sugar content of red jujube during hot air drying. 
previous research about red jujube have focus largely on hygienic component pharmacology and processing technology with little effort be make to investigate the change and loss of nutritional ingredient during process. 
study the effect of technological parameter on jujube s total sugar content during the dry process be helpful to rate the quality of the dry red jujube. 
in this study jujube a type of red date produce in alar xinjiang be experiment at different dry temperature air speed and relative humidity by use a circular hot air drier that be one of the most widely use dry machine. 
the result show that dry temperature air speed relative humidity and their quadratic term have significant effect on total sugar content of the dry jujube. 
the combination of the optimal technological parameter be dry temperature 57.99 degree c air speed 1.54 m s and relative humidity 39.14. 
when the red jujube reach its safe moisture content the maximum total sugar content be 71.07. 
our experimental result provide a theoretical basis for optimize the dry process. 
adaptive chebyshev fusion of vegetation imagery based on svm classifier. 
a novel adaptive image fusion method by use chebyshev polynomial analysis cpa for application in vegetation satellite imagery be introduce in this paper. 
fusion be a technique that enable the merging of two satellite camera panchromatic and multi spectral to produce high quality satellite image to address agricurtural and vegetation issue such as soiling flood and crop harvesting. 
recent study show chebyshev polynomial to be effective in image fusion mainly in medium to high noise condition as per real life satellite condition. 
however its application be limit to heuristic. 
in this research we have propose a way to adaptively select the optimal cpa parameter accord to user specification. 
support vector machine svm be use as a classify tool to estimate the noise parameter from which the appropriate cpa degree be utilise to perform image fusion accord to a look up table. 
performance evaluation affirm the approach s ability in reduce the computational complexity to perform fusion. 
overall adaptive cpa fusion be able to optimize an image fusion system s resource and processing time. 
it therefore may be suitably incorporate onto real hardware for use on vegetation satellite imagery. 
analysis on the effect of stimulator parameter in electrical stimulation procedure on the human bicep muscle. 
while electrical stimulation have prove to produce positive outcome among patient electrical stimulation in post stroke rehabilitation face one main limitation muscle fatigue. 
muscle fatigue limit the training time hence affect the recovery process. 
this work analyze the occurrence of muscle fatigue with respect to the different stimulator parameter amplitude pulse shape and frequency. 
the detection of muscle fatigue will be monitor as force where the force sensitive resistor fsr sensor be use to detect the variation of the force exert by the muscle. 
in this work it be assume that the fatigue in muscle will happen when the force record reduce to 60 from its initial force over the stimulation period. 
the experiment result proof that the stimulator parameter amplitude pulse shape and frequency have different effect to the upper limb muscle with respect to muscle fatigue. 
the result also show that the exponential waveform can be consider in future rehabilitation program since the onset of muscle fatigue be delay later in the experiment when compare to the other signal. 
this allow extended training duration among stroke patient to benefit from the recovery window time frame especially for patient who be still in their early recover stage. 
tool path generation of contour parallel based on ant colony optimisation. 
in today s competitive market of manufacture industry short machining time be one of important factor for reduce the manufacturer s cost. 
this paper present the minimisation of machine time of computer numerical control cnc by eliminate the uncut region of sharp corner base on contour parallel mill method. 
each uncut region at sharp corner be represent by uncut line which consist of two node in x and y direction. 
an ant colony optimisation aco method be use to optimize the tool path length because of its capability to find the short tool path length. 
the optimisation of tool path length base on aco algorithm ascertain that the cut tool remove the uncut line once and able to eliminate the uncut region in the short tool path length. 
to observe the effectiveness of the aco performance the simulation result be compare with the result obtain by the previous method. 
finally the simulation result show the reduction of five machining time compare to previous method. 
construct an ontology based and graph based knowledge representation of english quran. 
this paper describe a work in construct two model of knowledge representation kr in aim to do evaluation of their achievement in contribute to increase performance of retrieve information on english quran domain. 
due to many approach available to construct a kr in provide datum for information retrieval process there be a need to find out in what model the kr could provide a valuable contribution for retrieve information. 
we focus on ontology base kr and graph database base kr. 
we use quranic arabic corpus that available at http://www.corpus.quran.com as a source to build the kr. 
we extract several datum from it english token token location and token part of speech pos. 
protege be use to construct the ontology and neo4j be utilize in develop the graph database. 
both kr model will be equip in develop of an english quran question answer system in order to evaluate their benefit. 
operational risk analysis for undesired polymerization in overhead condenser of butadiene column. 
an accident model base on fault tree analysis be develop and apply to analyze the recurrence of undesired reaction produce popcorn polymer in the overhead condenser of an industrial butadiene distillation column. 
the modeling framework incorporate reliability datum associate with asset integrity and human performance along with datum on select process variable. 
these variable pressure feed velocity and temperature of the condenser which be identify from root cause analysis of the incident provide dynamic contribution to the model and be represent in the form of weibull distribution function. 
the result obtain prove the potential of the propose methodology. 
base on the case study consider operating pressure be identify as the most influential process variable that need close monitoring. 
the methodology provide an opportunity for risk management to be implement dynamically to facilitate maintenance plan and management of change. 
a generic database forensic investigation process model. 
database forensic investigation be a domain which deal with database content and their metadata to reveal malicious activity on database system. 
even though it be still new but due to the overwhelming challenge and issue in the domain this make database forensic become a fast growing and much seek after research area. 
base on observation make we find that database forensic suffer from have a common standard which could unify knowledge of the domain. 
therefore through this paper we present the use of design science research dsr as a research methodology to develop a generic database forensic investigation process model dbfipm. 
from the creation of dbfipm five common forensic investigation process have be propose namely the i identification ii collection iii preservation iv analysis and v presentation process. 
from the dbfipm it allow the reconciliation of concept and terminology of all common database forensic investigation process. 
thus this will potentially facilitate the sharing of knowledge on database forensic investigation among domain stakeholder. 
monitor the flank wear use piezoelectric of rotate tool of main cutting force in end milling. 
tool condition monitoring tcm system in the industry be mainly use to detect tool wear breakage and chatter on the tool. 
tool wear of aisi p20 under various cutting condition have be investigate in end milling use cut force signal due flank wear progression. 
this study be focus on the piezoelectric sensor system which be integrate on rotate cut tool for tool wear monitoring system in milling process. 
the signal capture by piezoelectric sensor be analyze in time and frequency domain. 
the signal amplitude of main cutting force fc in time domain be increase while the peak of the amplitude in frequency domain be decrease as the flank wear and cut speed increase. 
by use 3d i kaz tm statistical analysis method the relationship and correlation between i kaz coefficient z(infinity value with resultant flank wear width datum vb be prove. 
the result show that 3d i kaz tm statistical analysis method can be effectively use to monitor tool wear progression use a wireless telemetry system during mill operation. 
wideband jean antenna with bending structure for microwave imaging application. 
in this paper a wideband jean antenna with bend structure for flexible microwave imaging application be present. 
coplanar waveguide cpw feeding structure with koch shape ground slot technique have be implement for widen the bandwidth. 
the design evolution process of the propose antenna be start from a simple cpw fed monopole antenna to bend circumstance. 
the propose antenna under normal condition bend circumstance and as well as on arm bend effect be simulate and optimize use cst microwave studio software and fabricate also test so as to validate the result. 
under normal condition the antenna provide measure bandwidth of 4500 mhz 1.5 six ghz in the case of |s11|<= 10 db while 4360 mhz 1.44 5.8 ghz for the measure bandwidth under bend circumstance be obtain. 
also there be a slight degradation on the reflection coefficient of the antenna under on arm bend so that measure bandwidth become narrow with operate frequency of 3800 mhz 2.2 six ghz. 
the measured gain of the antenna fluctuate between 2.5 5.6 dbi and 1.5 2.8 dbi with quasi omnidirectional pattern within the expect frequency band for normal and bend condition respectively. 
the propose antenna provide a good performance in term of its reflection coefficient and radiation characteristic. 
therefore due to insensitiveness to bend and body effect the propose antenna have become good candidate for microwave imaging application. 
mouldability of wood filler reinforced polypropylene composite for injection moulded engine cover use mould filing simulation. 
feasibility study about process lignocellulosic reinforce polymer composite by injection moulding have be receive widespread attention nowadays. 
the aim of this research be to identify the optimal selection of parameter significant parameter and effect of the injection moulding parameter during the post filling stage. 
in this simulation study the modelling of an automotive component namely the proton waja campro car engine cover require a three d model and mesh generation to obtain the mouldability of its composite material use the injection moulding process. 
autodesk moldflow insight(r be use to simulate and analyse the injection moulding process. 
therefore 60 wt% of wood filler reinforce polypropylene be evaluate under optimise injection parameter injection temperature mould temperature injection pressure and flow rate during the post filling stage simulation fill time average velocity volumetric shrinkage sink mark and shear stress. 
in addition numerical simulation by the taguchi method consist of s n ratio and anova be use in this research to determine which significant factor would affect all response. 
base on the numerical simulation result the flow rate show the most significant parameter for the reduction of fill time volumetric shrinkage sink mark and shear stress while also enhance the average velocity on the car engine cover. 
a proposed monitoring dashboard of smart cable guard scg. 
one of service that dnvgl provide to its customer be to continuously monitor distribution cable circuit for upcoming defect. 
this monitoring system call smart cable guard scg which monitor over 100 circuit with an average of five discharge circuit per minute. 
regardless of the amount of circuit and pulse discharge per minute the system should be able to complete all process within one hour or less. 
while in order to offer good service to the client dnvgl do analysis to the incoming smart cable datum apply define knowledge rule communicate to the customer for certain state of their cable circuit. 
to help the analyst monitor the ongoing process and enable they to take a decisive action at the right time propose a monitoring dashboard. 
dashboard be the solution when the nature of the work be to monitor day to day operational such as monitor strategic information operational information that change daily. 
reliability assessment for an automobile crankshaft under random loading. 
this paper present the stochastic process for reliability assessment base on the fatigue life datum under random loading for structural health monitoring of an automobile crankshaft due tofatigue failure. 
this be base on report failure of the component due to the effect of the random load that act on the component during its operating condition over a give period of time. 
since there be significant limitation of the experimental analysis in term of actual loading history therefore the reliability assessment be consider to be less accurate. 
hence the reliability assessment base on fatigue life datum use the markov process by incorporate loading datum to synthetically generate loading history have be propose in this study. 
the markov process have the capability of continuously update the loading history datum to reduce the interval between each datum point for reliability assessment base on the fatigue life datum. 
the accuracy of the propose monitoring system for reliability assessment be validate through its statistical method. 
the reliability assessment from the markov process correspond well by provide an accuracy of more than 95 when compare towards the actual sample datum. 
the reliability of the crankshaft base on the fatigue life assessment provide a highly accurate for the improvement and control of risk factor in term of structural health monitoring by overcome the extensive time and cost require for fatigue testing. 
mitigating operational technical and strategic risk in ict through knowledge codification technique. 
recently organisation have incorporate various method into their business process in mitigate risk. 
although information and communication technology ict practitioner be not capable mitigate the identify risk systematically due to the high magnitude of loss cause by operational technical and strategic risk. 
the ict practitioner need to improve their ability to identify and mitigate the risk to ict infrastructure. 
besides that ict practitioner in organization find it difficult to mitigate risk if they don t utilize completely their knowledge. 
there be need for ict practitioner to codify knowledge especially through the development of policy and practice to guide decision maker in mitigate risk in their organization. 
the aim of this paper be to develop a process model for capturing store disseminate and utilize risk knowledge of knowledge base support ict practitioner to make decision. 
quantitative research methodology be adopt for review of exist risk mitigation approach in ict and carry out a survey use questionnaire among ict practitioner. 
the questionnaire be use to validate the develop process model. 
finding from the questionnaire confirm that the develop process model can assist ict practitioner in mitigate operational technical and strategic risk base on the codification of past knowledge of risk expert. 
numerical and experimental study of a novel concept for hydraulically controlled negative load. 
this paper present a numerical and experimental investigation of a novel concept that eliminate oscillation in hydraulic system contain a counterbalance valve in series with a pressure compensate flow supply. 
the concept utilize a secondary circuit where a low pass filtered value of the load pressure be generate and feed back to the compensator of the flow supply valve. 
the novel concept have be implement on a single boom actuate by a cylinder. 
a nonlinear model of the system have be develop and an experimental verification show good correspondence between the model and the real system. 
the model be use for a parameter study on the novel concept. 
from the study it be find that the system be stable for large directional valve opening and that for small opening a reduction of the oscillatory behaviour of the system can be obtain by either lower the eigenfrequency of the mechanical hydraulic system or by lower the pilot area ratio of the counterbalance valve. 
lecture ii electrical technology application  oxide electronics from high tc superconductor to resistive random access memory re ram and so on. 
in this report we introduce interdisciplinary research which be carry out in tifrec tottori integrate frontier research center. 
the research on high tc superconducte oxide and neural network have be perform since 1988 and 1994 respectively. 
we mainly describe the development of research from 2010 to 2016. 
we succeed the preparation of high tc bi base superconductor bi2sr2can 1cunoy with a variety of form which be single crystal grow by a self flux method or a vertical bridgeman method whisker grow by asgqp an al2o3 seed glassy quench platelet method and thin film grow by rf magnetron sputter method. 
our target be the interdisciplinary research on oxide electronic from high tc superconducte oxide to re ram resistive random access memory and so on. 
numerical model to predict the temperature of the friction stir spot welding process. 
friction stir welding be a relatively new technique for join metal. 
in some case on aluminum joining fsw give well result compare with the arc welding process include the quality of weld and produce less distortion. 
the purpose of this study be to analyze the effect of high speed tool rotation and temperature simulation on friction stir spot welding fssw to the shear fracture load of the weld. 
response surface methods be use to analyze mu fssw parameter with the response. 
the welding material be aluminum a1100 with thickness of 0.4 mm. 
the tool be make of hss material which be shape by micro grinding process. 
tool shoulder diameter be four mm and the pin diameter 1.5 mm with length of pin be 0.6 mm. 
the spindle speed be fix at 33,000 rpm. 
the parameter that varied be the plunge speed two mm min three mm min four mm min and dwell time zero s two s four s. 
observation of micro structure and temperature be use to analyze shear load as output. 
temperature distribution measure around the tool and material and then temperature datum be use to build numerical model. 
from the result of experiment and analysis it be show that the numerical model in fssw be adequate for use in the prediction of the quality of the welding process. 
ifcaas information flow control as a service for cloud security. 
with the maturity of service orient architecture soa and web technology web service have become critical component of software as a service saas application in cloud ecosystem environment. 
most saas application leverage multi tenant datum store as a back end to keep and process datum with high agility. 
although these technology promise impressive benefit they put saas application at risk against novel as well as prevalent attack vector. 
this security risk be far magnify by the loss of control and lack of security enforcement over sensitive datum manipulate by saas application. 
an effective solution be need to fulfill several requirement originate in the dynamic and complex nature of such application. 
inspire by the rise of security as a service secaas model this paper introduce information flow control as a service ifcaas. 
ifcaas lay the foundation of cloud deliver ifc base security analysis and monitoring service. 
as an example of the adoption of the ifcaas this paper present a novel framework that address the detection of information flow vulnerability in saas application. 
our initial experiment show that the framework be a viable solution to protect against datum integrity and confidentiality violation lead to information leakage. 
recognize time efficiently local botnet infections a case study. 
the domain name system dns be often abuse by criminal as resilient infrastructure for their network architecture. 
example for malicious activity base on these network comprise phishing click fraud spam command and control structure of botnet. 
most of the propose detection method rely on machine learning base on complex feature set which require a considerable computational power. 
this paper investigate the approach of passively monitor and analyze dns traffic in a time efficient manner base on machine learning on a reduced and robust feature set. 
for the evaluation the full dns datum stream of a regional isp be use. 
to enhance the amount of traffic that can be label for the training process and reduce the number of false negative in the case study this be combine with a semi manual labeling approach which address domain create by domain generation algorithms dga. 
that allow also medium sized regional service provider to train classifier with typical dns traffic and to deploy system base on the approach propose here in the network of organization as an alternative to cloud service. 
the evaluation show that this approach be feasible and prototype be already deploy. 
hence this approach can serve as an important aspect of the internal risk management of organization. 
a log structure block preservation and restoration system for proactive forensic data collection in the cloud. 
preservation and datum collection in cloud environment be difficult because forensic datum be volatile and they be scatter in many server. 
this paper describe a novel surveillance mechanism for virtual block device on iaas cloud environment. 
we first describe some relate work on backup application versione file system and virtual machine introspection system that can be apply to cloud forensic. 
the propose log structure block preservation and restoration system can be use for record cloud consumer write operation on virtual block device and for restore the state of a virtual block device at an arbitrary point in time. 
this paper present a design and an implementation of the propose system by use xen hypervisor. 
the prototype implementation achieve well read and write performance compare to the baseline driver provide by xen when we run four or more virtual machine simultaneously. 
this paper show two forensic application for preserve data block a file tracking application and a novel diff command that support time travel. 
spot the malicious moment characterize malware behavior use dynamic feature. 
while mobile device have become more pervasive every day the interest in they from attacker have also be increase make effective malware detection tool of ultimate importance for malware investigation and user protection. 
most informative malware identification technique be the one that be able to identify where the malicious behavior be locate in application. 
in this way well understanding of malware can be achieve and effective tool for its detection can be write. 
however due to complexity of such a task most of the current approach just classify application as malicious or benign without give any further insight. 
in this work we propose a technique for automatic analysis of mobile application which allow its user to automatically identify the sub sequence of execution trace where malicious activity happen hence make further manual analysis and understanding of malware easy. 
our technique be base on dynamic feature concern resource usage and system call which be jointly collect while the application be execute. 
an execution trace be then split in short chunk that be analyze with machine learn technique to detect local malicious behavior. 
obtain result on the analysis of 3,232 android application show that collect feature contain enough information to identify suspicious execution trace that should be far analyse and investigate. 
lightweight encryption for smart home. 
smart home be one of the most popular iot internet of thing application which connect a wide variety of object and home appliance in a single logical network. 
smart home application have benefit from interaction and datum transmission among different device over the integrate network with or without human intervention. 
however like other technology smart home likely introduce new security vulnerability due to its dynamic and open nature of connectivity with heterogeneous feature. 
among such vulnerability be the breach of confidentiality which need to be address urgently as datum exchange between smart home device can contain crucial information relate to user s privacy and safety. 
however some of the challenge in provide smart home system with confidentiality service be the flexibility of key management and efficiency of computation and communication. 
these challenge should be address carefully as many small and resource constrain device be usually involve in smart home system. 
in this paper we address these challenge by propose a lightweight encryption scheme for smart home. 
this scheme will provide user and smart object with confidentiality service without incur much overhead cost associate with computation and communication. 
our propose scheme also support flexible public key management through adopt identity base encryption which do not require complex certificate handling. 
we provide a formal security analysis of our scheme and a performance simulation study. 
the simulation show that our scheme provide favorable level of efficiency in term of overhead cost associate with computation and communication. 
ctrl_s a security tool for sesar s design in security approach. 
to support the approach of design in security take by the sesar programme the author have iteratively develop a support tool know as ctrl_s that guide user through the security risk assessment process. 
whilst these risk be mostly generic base on prototype system architecture or extrapolation from current system the approach support the development of security control through to operation. 
key aspect of the ctrl_s tool have be to support cross sectional analysis of risk assessment and to create a collaborative knowledge base approach whereby user may take advantage of prior risk assessment in build new one. 
future development of the tool be propose include alignment with sesar s enterprise architecture modelling. 
misuse abuse and reuse economic utility function for characterise security requirement. 
negative use case in the form of misuse or abuse case have find a broad following within the security community due to their ability to make explicit the knowledge assumption and desire of stakeholder regard real and perceive threat to system. 
as an accepted threat model tool they have become a standard part of many secure software engineering sse process. 
despite this widespread adoption aspect of the original misuse case concept have yet to receive a formal treatment in the literature. 
this paper consider the application of economic utility function within the negative use case development process as a means of address exist challenge. 
we provide a simple demonstration of how exist practice might integrate economic factor to describe the business management and functional concern that surround system security and software development. 
tackle the cloud adoption dilemma a user centric concept to control cloud migration process by use machine learning technology. 
research study have show that especially enterprise in european country be afraid of lose outsource datum or unauthorized access. 
despite various exist cloud security mechanism company be currently hesitate to adopt cloud resource. 
this phenomenon be also know as cloud adoption dilemma. 
we think that datum classification be a promising technique that should be consider in the context of cloud security support cloud migration process. 
by use classification technique enterprise be able to control which document be suit for cloud computing and which cloud service provider be sufficient for protect sensitive document. 
in this work we present an efficient concept that involve enterprise employee and authority make it possible to apply powerful security policy in a simple way. 
we make use of a well establish machine learn algorithm in our develop tool identify security level for different type of document. 
thus cloud migration process can become more transparent and enterprise obtain the ability to discuss more openly about adopt innovative cloud service. 
the slandail monitor real time processing and visualisation of social media data for emergency management. 
the use of social medium platform have grow dramatically in recent time. 
combine with the rise of mobile computing user be now more connected and spend more of their time online. 
social medium have be use during emergency event where the public and authority have use it as a form of communication and to receive information. 
due to this emergency manager and first responder can use this information to increase their awareness about an ongoing crisis and aid decision make. 
the challenge here lie in process this deluge of information and filter it for insight that be useful for this purpose. 
this paper present the slandail monitor a system for harvesting and filter a social medium stream for emergency relate social medium datum. 
spatial and temporal datum attach to each message be use with the analyse content of each message to summarise ongoing emergency event as report on social medium. 
this information be combine with a visualisation component to allow a user to quickly assess an event by location time and by topic. 
issue about ethical datum harvesting and privacy be also address by the system in a computational way by log potentially sensitive information in the intrusion index. 
social analytics in an enterprise context from manufacturing to software development. 
although customer become more and more vocal in express their experience demand and need in various social network company of any size typically fail to effectively gain insight from such social datum and to eventually catch the market realm. 
this paper introduce the anlzer analytic engine that aim at leverage the social datum deluge to help company in their quest for deep understanding of their product perception as well as of the emerge trend in order to early embed they into their product design phase. 
the propose approach bring together polarity detection and trend analysis technique as present in the architecture and demonstrate through a simple walkthrough in the anlzer solution. 
the anlzer implementation be by design domain independent and be be test in the furniture domain at the moment yet it bring significant add value to software design and development as well through its experimentation playground that may provide indirect feedback on future software feature while monitor the reaction to exist release. 
a bandwidth adaptive pseudo code tracking loop design for bd ins integrated navigation. 
in modern beidou satellite communication receiver a simple pseudo code tracking loop have be unable to meet pseudo code synchronization in high dynamic strong interference environment. 
in such environment the traditional combination can not make pseudo code tracking loop to achieve optimal performance thus the integrate navigation have become a development direction. 
in this paper an error estimation module have be add base on the traditional bd ins integrated navigation system. 
the module use time from integral accumulator and the signal to noise ratio and acceleration from initial data module estimate the minimum tracking error of pseudo code tracking loop. 
the bandwidth selection signal generate by the module feedback to the initial data processing module adjust the bandwidth in the initial datum processing module. 
the design make the pseudo code tracking loop adjust bandwidth in real time base on high dynamic environmental condition so it will enhance environmental adaptability of the pseudo code tracking loop and improve the performance of the pseudo code tracking loop. 
design of multi point wireless multifunction monitoring system base on android. 
the design of the multi function wireless monitoring system base on android be design in this paper. 
the system consist of superior machine and low machine. 
the low machine take atmega16 as the core processor and rcv420 be the signal processor for measure and sample the four 20ma current signal. 
the superior machine be connect with low machine to receive and send datum by wifi module and acquire eight environmental real time variable. 
the superior machine be base on android development environment and javascript which use client to obtain real time variable and get with function such as curve display datum saving and warn prompt. 
the system can obtain an value of scale 2048 point by set the id number. 
the field experiment and application show that this system have good performance in remote monitoring of the multi point environmental value and industrial production with high accuracy and real time requirement. 
two sided time domain order reduction methods for linear control systems. 
large scale control system appear in many area of application so that the direct simulation and synthesis of such system be extremely time consume. 
model order reduction have become an essential tool to enable a fast numerical simulation in practice. 
in this paper we investigate two sided model reduction method for linear system in the time domain which be in contrast to the current one side method. 
base on chebyshev polynomial the chebyshev coefficient for the high derivative of system output be derive. 
with the aid of the specific structure of such chebyshev coefficient reduce model be produce in a two sided projection framework which preserve the information both of the time and the frequency domain simultaneously thereby provide a superior approximation compare to the one produce by one side method. 
the efficiency of our approach be verify by use a numerical example. 
switch base adaptive nonsingular sliding mode control for spacecraft formation fly. 
this paper investigate the relative position control problem for a two agent spacecraft formation. 
the modify nonlinear dynamic base on c w equation be adopt to describe relative position between the leader and follower. 
consider the system uncertainty and external disturbance adaptive slide mode control law base on linear and terminal slide surface be propose respectively. 
in addition a switching mechanism be employ to make a selection between the general and terminal surface so as to avoid singularity. 
the convergence of closed loop system be prove by lyapunov stability theory. 
numerical simulation illustrate the validity of the control law propose. 
design of remote monitor system for die cast unit. 
the paper focus on design and implementation of remote monitoring system for die cast unit which realize information management of die cast unit. 
the ethernet network architecture of the system be design in consideration of the communication distance communication quality and electromagnetic compatibility. 
the monitoring terminal use the opc interface and the ethernet technique to exchange datum with the software plc in industrial site. 
due to the advantage of perfect function and friendly user interface the industrial configuration software be use as a development tool for the human computer interface design. 
the function and the arrangement of the human machine interface be design accord to the requirement of the company. 
the system realize production process monitoring and production information management through datum collecting and processing. 
machine status operating parameter injection datum and production information could be find in hmi. 
pulverizing system fault diagnosis base on least square support vector machine. 
least square support vector machine be an excellent algorithm which can be use to model and classify. 
if appropriate mapping function and parameter be select the result should be well. 
an improved particle swarm optimization with changeable inertia parameter and velocity weight be present and then it be use to search well parameter to optimize support vector machine which be use to diagnose fault exist in coal powder produce process. 
simulation result show that the improved pso have high search precision and global search ability and the fault diagnosis algorithm couple pso and ls svm have high diagnosis accuracy rate. 
this diagnosis be reasonable and applicable. 
reusable meta model for crowdsourcing driven elastic systems. 
elastic system utilize both human and machine work unit to accomplish task that be eligible for crowdsource. 
the quality in the result of work complete by either type of compute unit be tantamount on the characteristic they bear. 
in this paper we draw parallel from our previous work into look at the suitability of work unit in complete viable task in crowdsource. 
we seek to understand characteristic for modeling task and worker within these type of system. 
base on our experiment and lesson learn in relate literature we propose a dynamic worker task information meta model with a corresponding operational workflow model that can be use in a variety of problem domain involve crowdsourced task to provide support in make this decision. 
monitor classification blindspots to detect drifts from unlabeled data. 
machine learning model deploy in real world application operate in a dynamic environment where the datum distribution can change constantly. 
these change call concept drift cause the performance of the learned model to degrade over time. 
as such it be essential to detect and adapt to change in the datum for the model to be of any real use. 
while model adaptation require label datum for retrain the detection process do not have to. 
labeling datum be time consume and expensive and if datum change be infrequent most of the labeling effort spend on verification be waste. 
in this paper an ensemble base detection method be propose which track the number of sample in the critical disagreement region of the ensemble to detect concept drift from unlabeled datum. 
the proposed algorithm be distribution and model independent unsupervised and can be use in an online incremental fashion. 
experimental analysis on four real world concept drift dataset show that the propose methodology give high prediction performance low false alarm rate and use only 11.3 overall labeling on average. 
principle base approach for semi automatic construction of a restaurant question answering system from limited datasets. 
question answer qa be an important research issue in natural language processing and most state of the art question answer system be base on statistical model. 
after wit nesse recent achievement in artificial intelligent ai many business wish to apply those technique to an automatic qa system that be capable of provide 24 hour customer service for their client. 
however o ne imminent problem be the lack of label training datum for the specific domain. 
to address this issue we propose to combine a knowledge base approach and an automatic principle generation process to build a qa system from limited resource. 
experiment conduct on a mandarin restaurant dataset show that our system achieve an average accuracy of 44 for 10 question type. 
it demonstrate that our approach can provide an effective tool when create a qa system. 
knowledge induction base on randomization in case base reasoning. 
case base reasoning cbr interest the scientific community whom be concern with scalability in knowledge representation and processing. 
cbr system scale far well than rule base system. 
rule base system be limit by the need to know the rule of engagement which be practically unobtainable. 
the work present in this paper pertain to knowledge generalization base on randomization. 
inductive knowledge be infer through subsumption and transmutation rule. 
knowledge be dynamically generate thus allow for a gain in the inferential space and research time. 
it be validate base on the domain user expertise. 
the approach be illustrate with an example and be see to be properly implement and test. 
lateral movement detection use distributed data fusion. 
attacker often attempt to move laterally from host to host infect they until an overall goal be achieve. 
one possible defense against this strategy be to detect such coordinated and sequential action by fuse datum from multiple source. 
in this paper we propose a framework for distribute data fusion that specify the communication architecture and datum transformation function. 
then we use this framework to specify an approach for lateral movement detection that use host level process communication graph to infer network connection causation. 
the connection causation be then aggregate into system wide host communication graph that expose possible lateral movement in the system. 
in order to provide a balance between the resource usage and the robustness of the fusion architecture we propose a multilevel fusion hierarchy that use different clustering technique. 
we evaluate the scalability of the hierarchical fusion scheme in term of storage overhead number of message update send fairness of resource sharing among cluster and quality of local graph. 
finally we implement a host level monitor prototype to collect connection causation and evaluate its overhead. 
the result show that our approach provide an effective method to detect lateral movement between host and can be implement with acceptable overhead. 
sirius neural network base probabilistic assertion for detect silent datum corruption in parallel program. 
the size and complexity of supercomputing cluster be rapidly increase to cater to the need of complex scientific application. 
at the same time the feature size and operating voltage level of the internal component be decrease. 
this dual trend make these machine extremely vulnerable to soft error or random bit flip. 
for complex parallel application these soft error can lead to silent datum corruption which could lead to large inaccuracy in the final computational result. 
hence it be important to determine the presence and severity of such error early on so that proper counter measure can be take. 
in this paper we introduce a tool call sirius which can accurately identify silent datum corruption base on the simple insight that there exist spatial and temporal locality within most variable in such program. 
spatial locality mean that value of the variable at node that be close by in a network sense be also close numerically. 
similarly temporal locality mean that the value change slowly and in a continuous manner with time. 
sirius use neural network to learn such locality pattern separately for each critical variable and produce probabilistic assertion which can be embed in the code of the parallel program to detect silent datum corruption. 
we have implement this technique on parallel benchmark program lulesh and comd. 
our evaluation show that sirius can detect silent error in the code with much high accuracy compare to previously propose method. 
sirius detect 98 of the silent datum corruption with a false positive rate of less than 0.02 as compare to the false positive rate 0.06 incur by the state of the art acceleration base prediction abp base technique. 
inside out reliable performance prediction for distributed storage systems in the cloud. 
many storage system be undergo a significant shift from dedicated appliance base model to software define storage sds because the latter be flexible scalable and cost effective for modern workload. 
however it be challenge to provide a reliable guarantee of end to end performance in sds due to complex software stack time vary workload and performance interference among tenant. 
therefore modeling and monitor the performance of storage system be critical for ensure reliable qos guarantee. 
exist approach such as performance benchmarke and analytical modeling be inadequate because they be not efficient in explore large configuration space and can not support elastic operation and diverse storage service in sds. 
this paper present inside out an automatic model building tool that create accurate performance model for distribute storage service. 
inside out be a black box approach. 
it build high level performance model by apply machine learn technique to low level system performance metric collect from individual component of the distribute sds system. 
inside out use a two level learning method that combine two machine learning model to automatically filter irrelevant feature boost prediction accuracy and yield consistent prediction. 
our in depth evaluation show that inside out be a robust solution that enable sds to predict end to end performance even in challenging condition change in workload storage configuration available cloud resource size of the distribute storage service and amount of interference due to multi tenant. 
our experiment show that inside out can predict end to end performance with 91.1 accuracy on average. 
its prediction accuracy be consistent across diverse storage environment. 
fill demand supply gap by adjust electricity selling price under stochastic acceptance. 
this study investigate the effect of stochastic behavior in an electricity market comprise farm owner an electricity company and a persuasive dialogue system. 
numerical simulation confirm the effect of such behavior on the electricity price. 
predict the quality of user contribution via lstm. 
in many collaborative system it be useful to automatically estimate the quality of new contribution the estimate can be use for instance to flag contribution for review. 
to predict the quality of a contribution by a user it be useful to take into account both the characteristic of the revision itself and the past history of contribution by that user. 
in several approach the user s history be first summarize into a number of feature such as number of contribution user reputation time from previous revision and so forth. 
these feature be then pass along with feature of the current revision to a machine learn classifier which output a prediction for the user contribution. 
the summarization step be use because the usual machine learning model such as neural net svm etc. 
rely on a fix number of input feature. 
we show in this paper that this manual selection of summarization feature can be avoid by adopt machine learning approach that be able to cope with temporal sequence of input. 
in particular we show that long short term memory lstm neural net be able to process directly the variable length history of a user s activity in the system and produce an output that be highly predictive of the quality of the next contribution by the user. 
our approach do not eliminate the process of feature selection which be present in all machine learning. 
rather it eliminate the need for decide which feature from a user s past arc most useful for predict the future we can simply pass to the machine learn apparatus all the past and let it come up with an estimate for the quality of the next contribution. 
we present model combine lstm and nn for predict revision quality and show that the prediction accuracy attain be far superior to the one obtain use the nn alone. 
more interestingly we also show that the prediction attain be superior to the one obtain use user reputation as a feature summarize the quality of a user s past work. 
this can be explain by note that the primary function of user reputation be to provide an incentive towards perform useful contribution rather than to be a feature optimize for prediction of future contribution quality. 
we also show that the lstm output change in a natural way in response to user behavior increase when the user perform a sequence of good quality contribution and decrease when the user perform a sequence of low quality work. 
the lstm output for a user could thus be usefully show to other user alongside the user s reputation and other information. 
an empirical evaluation of property recommender systems for wikidata and collaborative knowledge basis. 
the wikidata platform be a crowdsourced structured knowledgebase aim to provide integrated free and language agnostic fact which be amongst other use by wikipedia. 
user who actively enter review and revise datum on wikidata be assist by a property suggesting system which provide user with property that might also be applicable to a give item. 
we argue that evaluate and subsequently improve this recommendation mechanism and hence assist user can directly contribute to an even more integrate consistent and extensive knowledge base serve a huge variety of application. 
however the quality and usefulness of such recommendation have not be evaluate yet. 
in this work we provide the first evaluation of different approach aim to provide user with property recommendation in the process of curate information on wikidata. 
we compare the approach currently facilitated on wikidata with two state of the art recommendation approach stem ming from the field of rdf recolmmender system and collaborative information system. 
far we also evaluate hybrid recommender system combine these approach. 
our evaluation show that the current recommendation algorithm work well in regard to recall and precision reach a recall@7 of 79.71 and a precision@7 of 27.97. 
we also find that generally incorporate contextual as well as classify information into the computation of property recommendation can far improve its performance significantly. 
performance monitoring of a pmu in a microgrid environment base on iec 61850 90 five. 
reliable protection communication and control be the key feature of a digital protection scheme in a utility substation. 
microgrid be an alternative solution of instal long transmission distribution line could be cost prohibitive. 
there be number of intelligent electronic devices ieds which could find application in control and monitoring of power network in a microgrid set up and one such device be phasor measurement unit pmu. 
it be a microprocessor base intelligent device which gather high resolution datum check the power quality and record disturbance. 
however few issue that remain to be address such as interoperability in a multi vendor equipment and coordination between individual control system in an integrated scheme. 
in this paper an operational network technology opnet software model of a pmu have be design and test for its performance in a microgrid environment base on iec 61850 90 five standard. 
generation of a comprehensive tester measurement systems analysis. 
measurement systems analysis msa be a challenge in an automated testing environment ate. 
currently there be no standard procedure on perform a test msa which can either be statistically weak by be too simplistic or be too complex that it make it difficult to deduce conclusion. 
this project aim to create a standard test msa that generate statistically  sound conclusion without the need for additional complex hardware and procedure. 
the team have to one decompose the ate to its unique measurement system resource board two analyze each resource and identify the critical sense path and three use the diagnostic log to gather data point on test cover the identify circuitry. 
a unique msa study be then generate on each of the path govern with the premise the whole equal the sum of its part imply that a good tester will have its fundamental component work within the expect functionality. 
the methodology enable the team to specifically identify which tester component be problematic by simply take advantage of the diagnostic datum an activity commonly do in a production environment. 
not only do the author avoid expenditure on new but unproven tool but also open opportunity for other tester platform to be msa compatible by follow these principle. 
analysis of efficiency ladders use in apparel manufacturing line performance forecasting. 
apparel manufacturing be a highly labor intensive industry where the most operation require highly skilled human worker involvement. 
therefore the production performance of apparel manufacturing be mainly worker dependent. 
worker improve their performance in a task as repetition take place. 
this phenomenon be call as the learning curve study by researcher and be largely prevalent in the apparel industry. 
apparel manufacturer use production datum of manufacturing sewing line and experience of the production floor management staff to define an efficiency ladder el to forecast the performance with task repetition. 
our study investigate an average learning curve lc for sewing line which act as a measurement and a forecasting tool for the production performance. 
empirical datum from a high end apparel manufacturer be collect to model the lc. 
then the forecasting accuracy of the fit lc be compare with the el. 
this paper provide empirical evidence to the fact that lc be accurate in forecast the performance increment with repetition on daily basis thus well to use in production planning than the el. 
tool wear in machining aisi d2 steel with minimum quantity lubrication use alternative cutting fluids. 
minimum quantity lubrication mql be know to perform well than conventional flood cooling in machining. 
however no study on mql use alternative cut fluid with the choose work tool material combination be report in the literature. 
thus the aim of this study be to evaluate the effect of mql use alternative cut fluid on tool wear. 
the objective be to identify suitable alternative cutting fluid that can be use with the mql method and to study the tool wear for different alternative. 
alternative cutting fluid be identify use a literature review. 
then a set of simple turning operation use carbide coated tool and aisi d2 steel work piece be perform with the mql method use three identify alternative fluid. 
trial be also carry out with dry cutting conventional flood cooling with emulsion oil and mql method use emulsion oil. 
tool wear in each treatment be measure and graphically analyse to compare the performance of the cool method. 
coconut oil sun flower oil and waste cooking oil be identify as the alternative for conventional cutting fluid. 
coconut oil and sun flower oil perform the good while waste cooking oil be the bad. 
further experiment be nee with different combination of cut tool and work piece material to generalise the finding. 
iot base automatic storing and retrieval system. 
automation have gain the most famous and big attention in the industrial world lately. 
this be because it cause less man involvement high accuracy money and time saving unlike the conventional method. 
thus the internet of things iot concept come to the picture. 
this research paper reveal an implement method of iot concept for a manufacture line to inspect and control an automatic storing and retrieval system asrs with powerful feature. 
remote system control data processing and record keeping be some of they. 
the system be sync to an online cloud database and it store every action do by asrs. 
also the system be capable of categorize the product into specific order. 
this be useful for production floor which have more than one product in a production line. 
moreover anyone can view the process and the history of the system through a user interface. 
the simple and animate user interface be design for personal computer and for android device. 
the simplicity of the concept make the system speed and it consume minimum resource. 
simply the automatic product store and retrieval system can be view and control from anywhere in the world. 
a prototype application system be develop to verify the propose method in this research paper. 
this paper suggest very flexible cloud base asrs system. 
problem and exploration of task base teaching in primary school english teaching. 
as a new trend of communicative teaching method task base language teaching method appear in 1980s. 
the new english curriculum standard highly advocate the use of task base language teaching tblt in which teacher should try their good to avoid use traditional teaching method of inputte language knowledge and adopt task base teaching method to involve student active participation in the task performance so as to help they learn english through think discuss communicate and cooperating and other to learn and use english. 
it follow the principle of learn by do let student communicate with target language in real context complete the task of learn goal construct target language system in their own experience and form a comprehensive language use ability. 
the task base language teaching method change the traditional teaching mode which have its own advantage student be the center of the class and the teacher be not the dominator and instructor but participant and guider to match student in the entire learning process. 
student can understand and use language through learn and analyze to form comprehensive language use ability. 
employ tblt in primary school english teaching can develop student integrate language skill. 
growth mechanism of subcontracting enterprises base on project knowledge management. 
the relationship between lead international company and subcontracting enterprise like that of the relationship between project principal and the party to undertake the project both in oem project. 
as the core of the cooperation interaction between both of they contain a wealth of knowledge flow. 
for sub c enterprise the international sub c provide a favorable opportunity to access external new knowledge. 
sub c enterprise should constantly adjust itself to overcome a variety of obstacle that may exist in the project knowledge management process and try to get further knowledge from the oem project implementation process. 
the hardware system of online teach database system base on fpga and multi core dsp. 
these online teach database system be generate from online transaction email video audio image. 
they be store in database grow massively and become difficult to capture form store manage share analyze and visualize via typical database software tool. 
the adventure of large amount of datum and real time requirement present great challenge use traditional desktop computer. 
in this paper to tackle the specific problem with a critical requirement of 10ms for whole datum processing pipeline we propose a high performance embed system as oppose to personal computer. 
peripheral component interconnect pci for data transfer from computer to field programmable gate array fpga be propose to solve the problem and a custom design dual port dual channel ram to realize simultaneous datum exchange and datum processing which be implement use a six core digital signal processor dsp. 
the hardware system be design and test the performance of individual module as well as the integration of they as a whole. 
we report a total time use such pipeline of 7.5ms meet the critical requirement and demonstrate its feasibility in practical application. 
greenhouse environment monitoring system design and implementation. 
the supervise system of flower house s enviroment which be put into function by the popul. 
ar series of at89s52 single machine tablet mainly measure and control the major tempreture and humidity of enviroment which will be reveal by show system. 
the paper give an introduction of system s software hardware design and the process of perform. 
the system be easily manure with great utility.at the same time it worth be popularize and use. 
feature extraction method for fault diagnosis of rotate machinery base on wavelet and lle. 
feature extraction be an important procedure in the process of fault diagnosis for rotate machinery. 
base on wavelet and local linear embed lle a method be propose in this paper to extract feature from vibration signal of rotate machinery. 
firstly multiple feature be extract from the original vibration signal and their wavelet decomposition coefficient to construct a high feature set. 
then to reduce the dimension of the high feature set initially detection index di be take as an index to select several feature from the extract feature. 
after that lle be employ to conduct feature fusion on the initial obtain feature set and obtain low dimension fault feature for fault diagnosis of rotate machinery. 
to validate the propose method fault extraction experiment be conduct and the result show that the propose method can extract well feature for fault classification of rotate machinery. 
analysis of the influence factors of knowledge transfer in university industry collaborative innovation. 
whether knowledge can be transfer smoothly between the knowledge unit determine the performance of collaborative innovation. 
this paper be aim at find out the knowledge transfer influence factor in the process of university industry collaborative innovation to promote the performance of collaborative innovation. 
in the situation of university industry collaborative innovation knowledge transfer show many characteristic which be different from the traditional one. 
base on the analysis of the characteristic and process of university industry knowledge transfer this paper put forward a university industry knowledge transfer influence factor conceptual model combine with the perspective of information network and social network. 
it divide the influence factor into four respect the factor of knowledge subject characteristic the factor of collaborative innovation network characteristic the factor of collaborative innovation situation and the factor of external environment factor in collaborative innovation. 
finally the strategy to promote the knowledge transfer be give base on the analysis result. 
the real time computer numerical control base on rcs. 
with the science and technology progress cnc system be towards high performance high precision high speed high flexibility and modularity. 
the traditional computer numerical control cnc system be mostly special equipment user can t extend the function of the numerical control equipment to meet their special need. 
the reuse and reconfigurable ability for the control procedure be require in open cnc system. 
the real time control system library be apply in the software development process in numerical control system. 
in this paper a cnc system base on rcs be design. 
principle of communication base on rcs be firstly describe and then implementation of cnc base on rcs be complete. 
the modification of the specific behavior of the machine tool and operating be limit on local control program thus greatly improve the openness of cnc system. 
the influence of duration optimization on cost. 
the method and step of seek the low cost in the process of duration optimization be introduce under the condition of certain constrain in this paper through the compression of network plan effectively to find the optimal solution. 
besides it combine with engineering example to illustrate the principle of optimize project duration cost optimization in the practical application so as to achieve the purpose of control cost within reasonable project duration. 
dynamic focus capture method and its application. 
with the development of computer science and technology motion capture be increasingly apply in many field such as film production research analysis human computer interaction intelligent monitoring and so on. 
the main task of the motion capture be to analyze and process the datum from the sensor and abstract to recognize the action. 
how to achieve fast and accurate implementation of the action capture have be a hot research in recent year. 
analysis of information factors for designing intellectual mechatronic system. 
the paper propose to evaluate achievement of main result in operation of intellectual mechatronic system with digital control by the obtain information effect. 
in this respect common information requirement with intellectual component be consider as a basic information factor which influence on the process of mechatronic system design. 
therefore some parameter have be accentuate and they can help to provide rather complete description of the process use for obtain and use systematic information within the volume of the intellectual mechatronic system. 
conformity degree of control vector parameter synthesize by the system and identification result of its current state have be select as an information criterion of the control efficiency. 
a set of expect probability value for location of each parameter of an control object and a mechatronic system within the require tolerance have be use for formation of possible state. 
the paper show that when a complex information description of the system be use then it be expedient to use an expert assessment of selection probability for allowable control vector which ensure a system transfer to favorable state. 
this approach have make it possible to pinpoint main information and technical specification of the intellectual mechatronic system structural construction informational and technical compatibility and information matching of its component control object uncertainty of its state and information vector information capacity of the mechatronic system control action their hierarchy and entropic balance of control process managerial resource of mechatronic system function result informational effect and control efficiency criterion probabilistic selection of system state. 
in accordance with the fulfilled analysis it be possible to note the most effective direction for practical use of the propose informational approach for creation of the intellectual mechatronic system comparison of alternative design solution base on the analysis of calculation assessment on unconditional entropy of the control object and the system simulation with the aim to accept a final systematic option while construct digital control block of the create system complex application of expert knowledge most comprehensive introduction of knowledge to the process of mechatronic system designing. 
advanced cmp process for 450 mm applications. 
a 450 mm cmp tool be instal calibrate and process qualified on oxide cmp process before the sti w and cu process can be evaluate. 
with the new multi area polishing head the oxide removal rate similar to 1800 a(degrees)/min and the wiwnu% three sigma eight within the same polish table can be achieve with a fume silica base slurry on a traditional ic pad as the first trial. 
a small baseline of wafer run be perform on each process table and the wtw wafer to wafer and hth head to head removal rate variation be then calculate. 
in each polish table sufficient wtw removal rate variation be obtain and current good wtwnu(3 sigma be 1.1. 
the tuning of removal rate on each head polish table can be achieve with the manufacturer s advanced technology base on the signal and parameter pull from the tool during process. 
these signal and parameter allow process engineer to check if the wafer be process at the similar condition on the polishing pad. 
polish behavior of different silica base slurry fume colloidal silica on the same polishing pad be compare. 
more process result on sti application will be show in the final paper mainly on 450 mm blanket monitor wafer. 
novel walking assist device base on generic human motion tracking criteria. 
replace nurse and caregiver by human friendly robot be draw the attention of the next generation for elderly people assistance and those with special need. 
however the human machine cooperative control be still a key challenge in this domain. 
this paper present a new approach for walk assist control that use inertial measurement units imus fix on elderly people s body to track their posture and estimate its center of mass com and zero moment point zmp motion to be use by a differential mobile robot that synchronize with the user s walk motion. 
furthermore a manipulator mount on the mobile device to support the user from their back help they walk and assist in dangerous situation. 
in this study the walking be divide into phase accord to the fall index define and the impedance of the manipulator be change base on the stability of the situation. 
experiment of the walk assist control be carry out and by their result the validity of the propose approach be confirm and the fall avoidance be realize. 
design method of i pd force control system base on instantaneous state observer for industrial robot. 
to achieve force control of an industrial robot this paper propose an i pd force control system base on an instantaneous state observer. 
the structure of the propose system be base on a resonance ratio control system and a feedback signal of the reaction force response. 
in this paper the gain of a pseudo derivation be design as the feedback gain. 
from the result of the design gain the feedback gain k f be a negative value. 
hence the resonance ratio control system become equivalent to a state feedback. 
for the stability of the propose i pd force control system base on the acceleration control system and a state feedback a new analysis method be require. 
this paper analyze an open loop of the propose system consider the bandwidth of the observer. 
the result of an analysis show that an observer with a wide bandwidth be require. 
therefore the parameter of propose system use the instantaneous state observer be design base on the coefficient diagram method. 
the effectiveness of the propose method be confirm by perform numerical simulation base on the model of an industrial robot arm. 
the result show that the propose method be effective for the stable force control of an industrial robot arm. 
real time extension of ros base on a network of modular blocks for highly precise motion generation. 
in this paper a solution be present which extend the network of non real time capable ros node robot operating system by a modular network of configurable and real time capable block with control and path planning functionality. 
by mean of this solution ros can be couple with real time algorithm from the field of industrial path planning control such as spline interpolation e.g. 
akima b spline. 
furthermore the real time network can communicate directly with industrial hardware via real time bus protocol establish in the industrial automation technology. 
the available engineering tool allow to model the real time network in a user friendly way. 
custom real time block can be generate from c++ code. 
design of feedforward filling control for join thick materials use robotic welding systems. 
in this paper a filling control strategy be propose for robotic welding of thick material which require multi pass welding. 
the multi pass welding process be formulate as a closed loop control design problem. 
a pi controller be use in the baseline loop for regulate the seam boundary error in the current pass a non causal feedforward controller be design use the h infinity loop shaping technique for regulate the error from previous welding pass. 
simulation result show that as compare to without use a feedforward controller error propagation on the seam boundary will be eliminate within six pass for disturbance occur only in the first filling pass and error amplification be contain within four pass for disturbance occur at the same position in every filling pass. 
gaussian process base model predictive control for linear time varying systems. 
two main issue associate with model predictive control mpc be learn the unknown dynamic of the system and handle model uncertainty. 
in this paper unknown linear time varying ltv system with external noise be represent by use probabilistic gaussian process gp model. 
in this way we can explicitly evaluate model uncertainty as variance. 
as a result it be possible to directly take obtain variance into account when plane the policy. 
in addition through use analytical gradient that be available during the gp modelling process the optimization problem in gp base mpc can be solve fast. 
the performance of propose approach be demonstrate by simulation on trajectory tracking problem of a ltv system. 
an approach for coverage path planning for uav. 
in this paper an offline flight planner that compute an efficient coverage trajectory for a quad rotor uav be present. 
the planner consist of three step mission definition automatic path planning and trajectory generation. 
the propose planner as a useful tool allow an uav operator to easily define and generate a coverage trajectory for any specific task. 
the resultant trajectory can be dispatch to a quad rotor with trajectory track controller for the mission that require a complete area coverage. 
disturbance observer base multirate control for reject periodic disturbances beyond the nyquist frequency. 
periodic disturbance exist beyond the nyquist frequency will cause intersample oscillation and degrade the control performance. 
in this paper we propose a disturbance observer base multirate control scheme for reject such periodic disturbance. 
when the disturbance be a single sinusoid the solution for system output include the intersample information be derive in the steady state. 
base on the steady state output response a sufficient condition be give for reject periodic disturbance beyond the nyquist frequency. 
as a matter of fact solve the sufficient condition be a problem of quadratic programming with some constraint. 
to remove the constraint a periodic time vary filter be also suggest to enhance the disturbance rejection performance. 
a numerical example be present to demonstrate the effectiveness of the propose method. 
reverse engineering with trajectory generation base on bezier curve at dual drive machine. 
the objective of this paper be to design and implement a process about reverse engineering which will generate smooth trajectory without use a high cost controller. 
because contour of work piece be more complex today the trajectory planning and generation be essential in the whole process. 
in this paper use bezier curve to clarify the rough outline make the process of reverse engineering more accurate and clear. 
the pro and con of bezier curve and the comparison between bezier curve and nurbs be mention. 
additionally we implement this system without a high level expensive controller and to solve the complex curve problem efficiently and economically. 
we implement this system with dual drive machine that be design and implement in our lab previously. 
experimental result have be successfully conduct to prove the principle as propose. 
concept of a computerized numerical control kernel for execution on multi core processor. 
computerized numerical control be more and more execute on off the shelf system platform and can thus benefit from the development in the area of processor technology. 
multi core processor provide sufficient processing power for these control but require a specific system design that allow exploit the parallel processing unit. 
this paper present an approach on how computerized numerical control may be partition on a task and a functional level use task and datum parallelism for the efficient execution on multi core system platform. 
bincfp efficient multi threaded binary code control flow profiling. 
in many task of reverse engineering and binary code analysis e.g. hybrid disassembly resolve indirect jump and decouple taint analysis the knowledge of detailed dynamic control flow can be of great value. 
however the high runtime overhead beset the complete collection of dynamic control flow. 
the previous effort on efficient path profiling can not be directly apply to the obfuscated binary code in which an accurate control flow graph be typically absent. 
to address these challenge we present bincfp an efficient multi threaded binary code control flow profile tool by take advantage of pervasive multi core platform. 
bincfp rely on dynamic binary instrumentation to work with the unmodified binary code. 
the key of bincfp be a multi threaded fast buffering scheme that support processing trace buffer asynchronously. 
to achieve well performance gain we also apply a set of optimization to reduce control flow profile size and instrumentation overhead. 
our design enable the complete dynamic control flow collection for an obfuscated binary execution. 
we have implement bincfp on top of pin. 
the comparative experiment on spec2006 and obfuscate common utility program show bincfp outperform the previous work in several way. 
in addition bincfp s control flow profile size be only about 49.2 that of the conventional design. 
decentralized enforcement of artifact lifecycles. 
artifact centric workflow describe possible execution of a business process through constraint express from the point of view of the document exchange between principal. 
a sequence of manipulation be deem valid as long as every document in the workflow follow its prescribed lifecycle at all step of the process. 
so far establish that a give workflow complie with artifact lifecycle have mostly be do through static verification or by assume a centralized access to all artifact where these constraint can be monitor and enforce. 
we present in this paper an alternate method of enforce document lifecycle that require neither static verification nor single point access. 
rather the document itself be design to carry fragment of its history protect from tamper use hashing and public key encryption. 
any principal involve in the process can verify at any time that a document s history complie with a give lifecycle. 
moreover the propose system also enforce access permission not all action be visible to all principal and one can only modify and verify what one be allow to observe. 
generate domain specific process studio. 
typical business process management studio provide support for process design through generic language such as bpmn. 
this bring several shortcoming relate to process governance over time process ambiguity and complexity for non technical user. 
domain specific process language have the potential to correct these issue but they require strong enterprise tool support and integration in order to be successfully adopt. 
this paper propose a mechanism for generate intuitive yet feature rich graphical process studio for various business domain that be fully integrate with standard business process management solution. 
it reduce the need for costly development and maintenance of such studio while ensure that business user have consistent access to the ever evolve enterprise body of knowledge. 
the approach use model base transformation to generate and support the entire infrastructure require by the studio. 
this include the graphical user interface the conversion capability to and from bpmn embed of real time monitoring datum from business process engine and service orient platform live multi user collaboration support process governance and evolution domain know how management as well as service level agreement monitoring. 
the approach have be fully prototype and integrate with enterprise level tool and platform. 
the impact of enterprise social software on the innovation process. 
innovation be essential if company be to maintain and increase their competitiveness. 
thus company face the question how rather than whether to generate innovation. 
one possible parameter to design an innovation friendly environment be provide appropriate software such as enterprise social software ess. 
this motivate we to explore how the use of ess may impact the innovation process. 
we present result deduce from an exploratory case study. 
base on 26 interview and theoretical consideration about the innovation process our finding reveal that ess have the potential to support the different stage of the innovation process. 
furthermore the result indicate that ess usage create impact concern one the information process itself two daily work output and three measurable outcome at the organizational level. 
here particularly the generic process in the knowledge and implementation stage stand to benefit. 
an extensible meta model assistant. 
meta model play a pivotal role in model driven engineering mde. 
they be use to create domain specific model and to type model management operation like model transformation or code generator. 
however even though create meta model be a common activity it be currently mostly a manual activity which do not profit from exist knowledge. 
in order to facilitate the meta model task we propose an extensible meta model assistant. 
while primarily focusse on help in the creation of meta model it can also help in create model. 
the assistant permit the provision of heterogeneous datum description source like ontology rdf data xml schema database schemas and meta model and enable their uniform query. 
different kind of query be support and improve through synonym search. 
query result be prioritize through sense disambiguation can be graphically visualize and incorporate into the meta model be build. 
the assistant have be realize within eclipse and its architecture have be design to be independent of the meta model technology use. 
as a proof of concept we show its integration within dsl tao a pattern base meta model tool build by our group and two other tool develop by third party. 
the usefulness of the system be illustrate with a run example in the process modelling domain. 
informed active learning to aid domain expert in modeling compliance. 
modern enterprise face an unprecedented regulatory regime. 
traditional compliance practice in enterprise rely heavily on domain expert whose judgement determine what compliance mean and how to reflect regulation onto the enterprise process and datum to make they compliant. 
these activity be mostly manual in nature. 
we present a machine learn approach to model compliance. 
our key innovation be a use of active learning  a semi supervised system capable of learn interactively from the domain expert to identify regulation and b inform the feature representation of the active learner base on domain specific entity and relation to effectively build a domain model of regulation. 
early result show that our system reduce the burden on domain expert to a large extent enable latch domain expert knowledge and make further step in compliance easy by the use of model. 
a nlp base framework to support document verification as a service. 
many enterprise system be document intensive that require extensive manual verification in the form of maker and checker. 
however a maker checker base verification raise several challenge with respect to increase in cost and time of verification. 
furthermore any manual labor intensive verification be not free from human oversight and can lead to costly error. 
therefore to alleviate the challenge arise out of human verification of document intensive system we propose a rule base framework that enable automatic verification of document base system. 
the framework use ontology base knowledge representation technique along with appropriate natural language processing method to extract operational rule from business document and then use suitable reasoning engine for verification. 
the above framework be validate in the light of a real life case study namely international trade that deal with several critical financial document like letter of credit bill of lading commercial invoice etc. 
negotiation base scheduling for an efficient saas provisioning in the cloud. 
cloud computing be part of a highly dynamic market with heterogeneous resource provider and vary consumer need. 
this influence the provisioning process for highly scalable software as a service saas application which depend on both resource provider and consumer need. 
indeed for scale purpose saas provider need to rent virtual machines vms from infrastructure as a service iaas provider. 
since the objective of saas provider be to optimize their profit it be very important to efficiently decide when process client request to well assign virtual resource and scale up if need. 
thus saas provider need efficient scheduling strategy to perform such assignment and take adequate profit aware scheduling decision. 
current scheduling algorithm use take it or leave it strategy for request evaluation. 
consider customer satisfaction as a fix input parameter lead to an increase number of reject request and consequently loss in profit. 
in this paper we propose a negotiation base scheduling algorithm which aim to maximize saas provider profit and increase user satisfaction while deal with dynamic resource and consider customer negotiable need. 
conduct experiment validate our proposal and show that negotiation improve scheduling performance. 
information retrieval as a service for the web of thing a survey and a proposal of iraas architecture. 
the cloud age characterize by a revolution of data center infrastructure with powerful resource have leverage the as a service paradigm. 
nowadays the web of thing wot propose the abstraction of real world entity in a virtual web avatar to acquire process and present real time information with the ability to connect with the real world and to control real thing. 
a new generation of service can arise from these complementary paradigm. 
one of they be crucial for a daily basis interaction with this new smart world information retrieval ir mostly in the form of search engine can also evolve into more powerful tool. 
base on that a new architecture of this kind of service have to be define by the synergy and challenge that wot impose. 
we propose an ir as a service iraas architecture for the new era of the web of thing. 
it consider the high dynamic in wot which leverage a significant amount of change in the ir collection to merge efficiently conventional ir concept and the cloud power. 
our iraas approach take into account the big data characteristic of wot concern velocity volume volatility and the variety of datum. 
the architecture have two main pillar the indexing and analysis block and the querying and retrieval block. 
we propose build it drive in three dimension search scope resource and datum type. 
from these perspective we show and compare the related work and research. 
integrated hybrid switch capacitor converter for led driver in 180 nm cmo. 
this paper present a led driver base on a new hybrid switch capacitor converter h scc operate in the mhz range which use the internal pulse node of a dickson converter and an lc output network to provide output current dim. 
the converter be implement use 5v integrated capacitor and switch in a 0.18 mu m bulk cmos technology. 
the experimental result show that the propose led driver have a power density of 122mw mm(2 and an efficiency of 79 and only need a small 40nh inductor. 
dynamic modeling of the circular winding brushless dc cwbldc machine. 
a circular winding brushless dc cwbldc motor be essentially a trapezoidal emf multiphase permanent magnet machine with the associated commutation circuit. 
it can achieve the same level of torque ripple performance as pmsms yet boast much high torque density since the iron core be more fully utilize with trapezoidal emf. 
field circuit co simulation be an effective and accurate tool in study the operate principle of cwbldc motor. 
however it be too timeconsuming. 
this paper thus propose a dynamic model for the cwbldc motor. 
a 10 kw eight pole 46 slot and 23 phase cwbldc motor and associated commutation circuit have be model in the plecs simulation environment. 
the simulation result agree very well with field circuit co simulation and experimental test which verify the precision of the propose model. 
application of a kpca kica hssvm hybrid strategy in bear fault detection. 
in modern industrial bearing be common in rotate machine. 
the processing datum of bearing be nonlinear and they usually be complicated distribution which contain both gaussian and non gaussian distribution. 
if use a single data distribution detection method it will result in detect performance degradation. 
to solve the possible monitoring difficulty of complicated distribution and nonlinear characteristic in industrial system this paper propose a kpca kica hssvm hybrid strategy. 
the propose method use kpca kica and hssvm to establish detection model these model be work collaboratively in monitor the real time process datum to detect the possible fault. 
the propose approach be test and validate via a set of experimental datum collect from a bearing test rig. 
experimental result demonstrate the effectiveness of this approach. 
mechanical resonance suppression and disturbance rejection of two inertia system with observer base feedback control. 
mechanical resonance suppression and disturbance rejection be important research content of steel roll mill machine tool and other transmission mechanism. 
at present there be many research on mechanical resonance suppression or disturbance rejection but most of they be in the single side. 
few paper study the resonance suppression and disturbance rejection simultaneously not to mention the analysis of the contradiction of the two part. 
just for the contradiction of mechanical resonance suppression and disturbance rejection in the two inertia transmission system a method of solve the problem be propose in this paper base on the dual observer feedback control. 
in which fractional order disturbance observer(fo dob be use to suppress the mechanical resonance on the basis of this the state observer be use to feedback the load torque and the speed difference of load and drive side which can far improve the anti disturbance ability of the system. 
simulation verify the effectiveness of the propose method. 
unbalance weight detection in washing machine use band pass filter with variable center frequency. 
for the spinning operation in the washing machine the unbalance weight of tub cause by unevenly distribute clothe should be measure. 
this paper propose the unbalance weight detect algorithm by measure the torque ripple cause by unbalance weight. 
the propose algorithm can detect unbalance weight at accelerate speed range as well as at constant speed since the torque ripple be detect through the band pass filter with the variable center frequency synchronize to the motor speed. 
predictive current control of an induction machine by use dichotomy base method. 
this paper present a novel model predictive current control method for induction machine with constant switching frequency. 
use model predictive current control a cost function consider error between the reference current and the predict current be design. 
a numerical method of quasi continuous reference voltage calculation base on dichotomy be apply to generate the optimize reference voltage vector which be select as the input of pwm before switch the inverter. 
this can significantly improve the current quality reduce the torque ripple and ensure fixed switch frequency of the inverter. 
the propose method be verify by simulation in which the induction motor operate with high performance. 
behavioral modeling of ac solid state power controller. 
this paper develop a behavioral model of ac solid state power controller sspc base on mixed signal finite state machine fsm. 
state transition and impedance variation rule be summarize by analyze the working mode of ac sspc. 
the model define six work state and eight transition function to imitate the impedance variation of ac sspc during on off state zero voltage turn on zero current turn off operation. 
the model be implement by mixed signal finite state machine modeling tool in saber and configure by test result for accuracy verification. 
speed test result show that the propose behavioral model significantly improve computation efficiency. 
electromagnetic performance of surface mounted permanent magnet machines with third harmonic injected rotor and overlapping wind. 
this paper compare the electromagnetic performance of three phase 24 slot/8 pole surface mount permanent magnet spm machine with various permanent magnet shape in which the overlapping winding be employ. 
the permanent magnet pm on the rotor be designate as conventional one sine shape and sine shape with third harmonic injection. 
it be find that compare with machine with sine shape pms the average torque of machine with sine+3rdshape pms can be improve by nine but the cog torque increase. 
the increased cog torque can be reduce by optimize the configuration of machine such as the width of slot yoke and tooth. 
the third harmonic in the airgap flux density be introduce by the pm rotor of sine shape with third harmonic injection and thus the iron loss be also compare among the machine with different pm shape. 
technique and application of electrical equipment image processing base on improved mlp network use bp algorithm. 
this paper propose a new method combine infrared and visible image which be devote to monitor the electrical equipment. 
the key technology of infrared and visible image processing include two aspect. 
on the one hand it research on target localization base on visible image. 
we can get the horizontal and vertical adjustment of the refit cradle head camera through the coordinate of the electrical equipment in the image by mean of the strong ability for bp algorithm fitting nonlinear function on the other hand the infrared image be process by qualitative method base on the temperature difference the improved mlp network eliminate the harmful effect of the size of the partial derivative on the weight step. 
the network receive some feature as the input and classify the condition of equipment into two category which be defective and normal. 
experimental result show that the positioning error be less than five pixel and the classification accuracy rate reach 84.21 which mean that the method not only improve the measurement efficiency of the infrared detection technology which be not affect by the limitation of measurement environment. 
virtual unit delay for digital frequency adaptive t/4 delay phase locked loop system. 
digital micro controller processor enable the costeffective control of grid connect power converter system in term of system monitoring signal processing e.g. grid synchronization control e.g. grid current and voltage control etc. 
normally the control be implement in a micro controller processor with a fixed sampling rate consider the cost and complexity where the number of unit delay that have be adopt should be an integer. 
for instance in conventional digital control system a single phase t/4 delay phase locked loop pll system take 50 unit delay i.e. in a 50 hz system with a sample frequency of 10 khz to create a 90 degree lag voltage in order to achieve the grid synchronization with the orthogonal voltage system. 
however in practice the grid frequency be a time variant parameter due to various eventuality and thus round the number of the unit delay for the t/4 delay pll system should be do in its implementation. 
this process will result in performance degradation in the digital control system as the exactly require number of delay be not realize. 
hence in this paper a virtual unit delay vud have be propose to address such challenge to the digital t/4 delay pll system. 
the propose vud adopt linear interpolation polynomial to approximate the fractional delay induce by the vary grid frequency in such a way that the control performance be enhance. 
the proposed vud have be demonstrate on a digitally control t/4 delay pll system. 
experimental result have confirm the effectiveness of the proposal. 
evaluation of winding arrangements in electric machinery for modular electric drives. 
this paper consider different winding connection configuration for a modular electric drive base on series parallel connected polyphase bridge converter. 
suitable stator wind connection configuration be identify to adapt to the converter topology consider. 
particular focus be put on the post fault performance. 
select winding layout be evaluate use 2d fem simulation. 
an improved image segmentation algorithm base on rough set. 
the main information of image focus in the target area and the rest part contain a large amount of redundancy. 
the image segmentation be an important technology in image processing. 
this paper present an improved rough set image segmentation algorithm which be base on the theory of fuzzy c mean clustering the human visual attention model and relative position. 
combination of fuzzy cluster result visual saliency map and relative position map it constitute the knowledge representation system and then obtain the relate decision rule through the attribute reduction. 
the experiment show that this algorithm have good segmentation effect compare with traditional method. 
a small size ultrawideband mimo antenna with triple band notched function and high isolation. 
in this paper a small size ultra wideband uwb multiple input multiple output mimo antenna with triple notch band and a high isolation be propose. 
its size be dramatically decrease to 30x26x0.8 mm(3 on a cost effective fr4 substrate. 
it consist of two rectangular print monopole pm element and a simple step ground stub to enhance wideband isolation. 
for two different reject band of the wireless local area network wlans cover 5.15 5.35 and 5.725 5.825 ghz four parasitic c shape split ring resonator pcsrr be place on either side of feed line. 
by etch two inverted u shape slot on the center of radiator the notched frequency at four ghz c band 3.7 4.2 ghz of satellite communication system be obtain. 
simulated and measure result prove a bandwidth of s 11 10db and s 12 21db at 3.1 11.2 ghz exclude three independently adjustable rejection band. 
hence the propose uwb mimo antenna have a very small size a simple structure a high isolation and three narrow notch band which effectively save more useful frequency. 
moreover it be a good candidate for wireless portable uwb mimo application. 
on the design of universal schemes for massive uncoordinated multiple access. 
future wireless access point may have to support sporadic transmission from a massive number of unattended machine. 
recently there have be a lot of interest in the design of massive uncoordinated multiple access scheme for such system base on clever enhancement to slot aloha. 
a close connection have be establish between the design of the multiple access scheme and the design of low density generator matrix code. 
base on this connection optimal multiple access scheme have be design base on slotted aloha and successive interference cancellation assume that the number of user in the network be know at the transmitter. 
in this paper we extend this work and consider the design of universal uncoordinated multiple access scheme that be agnostic to the number of user in the network. 
we design markov chain base transmission policy and numerical result show that substantial improvement to slot aloha be possible. 
consecutive switch codes. 
switch code first propose by wang et al be code that be design to increase the parallelism of datum writing and read process in network switch. 
a network switch consist of n input port k output port and m bank which store new arrive packet from the input port in each time slot call a generation. 
the objective be to store the packet in the bank such that every request of k packet by the output port which can be from previous generation can be handle by read at most one packet from every bank. 
in this paper we study a new type of switch code that can simultaneously deliver large symbol request and good code rate. 
these attractive feature be achieve by relax the request model to a natural sub class we call consecutive request. 
for this new request model we define a new type of code call consecutive switch code. 
these code be study in both the computational and combinatorial model correspond to whether the datum can be encode or not. 
we present several code construction and prove the optimality of one family of these code by provide the correspond low bind. 
lastly we introduce a construction of switch code for the case n k which improve upon the well know result for this case. 
throughput maximization in uncooperative spectrum sharing network. 
we consider an opportunistic communication system in which a secondary transmitter communicate over the unused time slot of a primary user. 
in particular we consider a system in which the primary user be uncooperative and transmit whenever its buffer be nonempty and the secondary user rely on feedback from its receiver in order to decide when to transmit. 
the objective of the secondary user be to maximize its own throughput without degrade the throughput of the primary user. 
we analyze the maximum achievable throughput of the secondary user by formulate the problem as a partially observable markov decision process. 
we derive bound on the optimal solution and find a channel access policy for the secondary user that be near optimal when the primary user s exogenous arrival rate be low. 
these result be then use to characterize the set of arrival rate to the primary and secondary user that may be stably support by the system. 
asynchronous decentralize algorithms for the noisy 20 questions problem. 
this paper study the problem of adaptively search for an unknown target use multiple agent connect through a time vary network topology. 
agent be equip with sensor capable of fast information processing and we propose an asynchronous decentralized algorithm for control their search base on noisy observation. 
we propose asynchronous decentralize algorithm for adaptive query base search that combine the bayesian bisection method and social learning. 
under standard assumption on the time vary network dynamic we prove convergence to correct consensus on the value of the parameter as the number of iteration grow. 
our result establish that stability and consistency can be maintain even with one way updating and randomized pairwise averaging thus provide a scalable low complexity alternative to the synchronous decentralized estimation algorithm study in previous work. 
we illustrate the effectiveness and robustness of our algorithm for random network topology. 
aimms system framework automatic dental pathologies recognition from dicom file. 
this paper be make within the context of the research uefiscdi project no. 
31/2014 aimms application for use image data mining and 3d modeling in dental screening. 
the project be interdisciplinary and want to build a system framework compose of several sub system dental pathology recognition part 3d printing part user interface part. 
the main emphasis of this article regard the pathology recognition part that be one of the core area of our framework. 
dental pathology can be detect automatically from cone beam computed tomography cbct datum extract from dicom file. 
dental cbct have a low dose of radiation compare to computerized tomography ct scan offer 3d information that sustain the diagnosis treatment planning and analysis of the patient oral cavity. 
our approach consist of novel procedure like semantically annotate the tomography which be facile to be process. 
the analyze oral pathology be edentation and dental cavity use our own adaptive threshold filter and edge detection algorithm. 
an important role be play by the knowledge base of the mouth cavity during the overall processing of the dicom input datum. 
the cost of our solution be low compare to the existent system on the market incorporate feature that sustain its synergistic property. 
ontology base multi system for sme knowledge worker. 
the objective of this paper one be to present a framework that help small and medium enterprise to exploit their available informational space. 
while large enterprise contain dedicated information management department and software the actual software framework implementation lack orientation towards small and medium company with few employee and small budget. 
we propose a framework implementation which couple with legacy datum system that be usually use by small and medium company. 
by the use of ontology this framework implementation add semantically enable information integration and will also provide for the employee a work process embed context sensitive information service. 
in this paper we focus on the framework s main architecture and present advance relate to the ontology generation framework. 
towards modelling of modelling in se. 
the engineering of complex system and system of system sos often lead to complex and very time consume modelling task mts. 
mt can be distribute in several autonomous and heterogeneous place a place be a set of stakeholder and their practice. 
an issue be to master mt while take into account the constraint of their large complex engineering environment lcee. 
a step toward the resolution of this issue be to deeply understand and model mt in lcee. 
in this paper we propose to characterize an lcee as a federation of place in order to keep the capability and autonomy of each involved place and to apply model base system principle to modelling of mt. 
the global goal be to design a formal holistic support for operation continuous analysis and improvement optimization of mt. 
system engineering analysis approach base on interoperability for reconfigurable manufacturing systems. 
in this paper we propose a system engineering approach for the analysis of reconfigurable manufacturing system. 
this work contribute in the implementation of the system engineering perception in industry 4.0 research framework. 
the approach be base on interoperability concept in order to correlate diverse requirement as input for the analysis and generate a result base on reconfigurability parameter. 
beside the approach itself this paper present an application on a reconfigurable machine tool that demonstrate the applicability of the develop method. 
model base engineering of autonomous systems use ontologies and metamodels. 
our research focus on engineering process for autonomous intelligent system construction with a life cycle holistic view by mean of a model base framework. 
the conceptual core of the framework be ontologically drive. 
our ontological approach consist of two element. 
the first one be a domain ontology for autonomous systems oasys to capture the autonomous system structure function and behaviour. 
the second element be an ontology drive engineering methodology odem to develop the target autonomous system. 
this methodology be base on model base systems engineering and produce model of the system as core asset. 
these model be use through the whole system life cycle from implementation or validation to operation and maintenance. 
on the application side the ontological framework have be use to develop a metacontrol engineering technology for autonomous system the om engineering process omep to improve their runtime adaptivity and resilience. 
omep have be apply to a mobile robot in the form of a metacontroller build on top of the robot s control architecture. 
it exploit a functional model of the robot tomasys model to reconfigure its control if require by the situation at runtime. 
the functional model be base on a metamodel about controller function and structure use concept form the ontology. 
the metacontroller be develop use the ontology drive methodology and a robot control reference architecture. 
a holacratic socio technical system architecture. 
a holacratic socio technical system architecture hstsa introduce holacratic engineering management hem a propose new system engineering and engineering management process model. 
the purpose of this research study be to determine if hem arise out of the agile software and agile system engineering discipline deliver on the promise of self  managing self organize adaptable resilient and more efficient organization. 
by answer the question what be the effect of holacratic engineering management architecture on socio technical systems performance the utility of hem be investigate. 
the holacratic business architecture measurement instrument hbami be apply to company in multiple industry group by standard industrial classification sic to determine hem architecture and organizational holacracy level. 
correlation analysis between the hbami index and dynamic organizational input structure be explore to evaluate value add work production. 
it be expect that more holacratic enterprise engineering architecture yield high revenue and intellectual property per employee. 
prediction of multi response parameters in material removal processes use soft computing a review. 
advance in soft computing reshape the manufacturing industry to develop an integrate self adjust manufacturing system into dynamically scalable and highly distribute cost efficient business model. 
due to presence of uncertainty and inaccuracy in manufacturing process the various soft computing algorithm neural network fuzzy set genetic algorithm ant colony optimization adaptive neural fuzzy inference system swarm optimization technique and simulated annealing have be apply for anticipate the performance of the metal cutting process and optimize they. 
the paper present the state of the art review on the soft computing technique apply for the prediction of multiresponse parameter in material removal process. 
load balancing in cloud data center use modified active monitoring load balancer. 
cloud computing be a hot topic of research for the researcher these day. 
with the rapid growth of internet technology cloud computing have become main source of compute for small as well big it company. 
in the cloud compute milieu the cloud datum center and the user of the cloud computing be globally situate therefore it be a big challenge for cloud datum center to efficiently handle the request which be come from million of user and service they in an efficient manner. 
load balance in this environment mean equal distribution of workload across all the node. 
load balancing provide a way of achieve the proper utilization of resource and well user satisfaction. 
hence use of an appropriate load balance algorithm be necessary for select the virtual machine or server. 
this paper focus on the load balance algorithm which distribute the incoming job among vm optimally in cloud datum center. 
the proposed algorithm in this paper have be implement use cloudanalyst simulator and the performance of the propose algorithm be compare with the three algorithm which be preexist on the basis of response time. 
the experiment carry out in the paper show that the propose algorithm perform well than the exist algorithm. 
min parent an effective approach to enhance resource utilization in cloud environment. 
with the rapid growth in online service and scarcity of professional under same domain there be a huge requirement for integaration of service with cloud computing cc. 
it be a late technological trend in present arena. 
it provide an efficient infrastructure well service over the internet. 
in cc environment scheduling of service be one of the major issue which can have significant impact on resource utilization and system performance. 
work flow scheduling be a problem of find the correct execution sequence for assign work flow task. 
it play a vital role in the work flow management. 
proper scheduling of work flow can have an efficient impact on performance of the system. 
this paper propose a scheduling algorithm for work flow. 
key parameter include parent child relationship task allocation to available virtual machines(vms for execution. 
propose algorithm mainly focus on increase the resource utilization and reduce the make span. 
in proposed algorithm we create a table that contain ready task and their correspond child in a work flow and occurrence of child have be count. 
far on the basis of child occurrence this parent child relationship table be sorted and then use for ready task schedule. 
the propose algorithm have be execute and validate by use simulation base analysis through workflowsim tool kit. 
the result of the propose scheduling algorithm significantly minimize overall execution time of work flow. 
implement a flexible failure detector that express the confidence in the system. 
traditional unreliable failure detector be per process oracle that provide a list of node suspect of having fail. 
in we introduce the impact failure detector that output a trust level value which be the degree of confidence in the system. 
an impact factor be assign to each node and an input threshold parameter define an impact factor limit value over which the confidence degree on the system be ensure. 
the impact factor indicate the relative importance of the process in the set s while the threshold offer a degree of flexibility for failure and false suspicion. 
we propose in this article two different algorithm base on query response message round that implement the impact fd whose conception be tailor to satisfy the impact fd s flexibility. 
the first one exploit the time free message pattern approach while the second one consider a set of bounded timely response. 
we also introduce the concept that a process can be ps accessible or lozenge ps accessible which guarantee that the system s will always or eventually always be trust by this process as well as two property pr(itps and pr(lozenge itps that characterize the stability condition which ensure the confidence or eventual confidence of process p on s. 
in both implementation if the process that monitor s be ps accessible or lozenge ps accessible at every query round it only wait or eventually only wait for a set of response that satisfy the threshold. 
a crucial facet of this set of process be that it be not fix the set of process can change at each round which be in accordance with the flexibility feature of the impact fd. 
an autonomic hierarchical reliable broadcast protocol for asynchronous distributed systems with failure detector. 
reliable broadcast protocol be a fundamental building block in fault tolerant distribute system. 
it consist of a basic primitive that provide agreement among process of the system on the delivery of each broadcast message either none or all correct process deliver the message despite failure of process. 
in this work we propose a reliable broadcast solution on top of the vcube assume that the system be asynchronous. 
the vcube be an autonomic monitoring layer that organize process on a hypercube overlay which provide several logarithmic property even in the presence of process failure. 
we consider that process fail by crash do not recover and fault be eventually detect you all correct process. 
the protocol tolerate false suspicion by send additional message to suspect process but logarithmic property of the algorithm be still keep. 
experiment machine learning techniques to predict vulnerability. 
software metric can be use as a indicator of the presence of software vulnerability. 
these metric have be use with machine learning to predict source code prone to contain vulnerability. 
although it be not possible to find the exact location of the flaw the model can show which component require more attention during inspection and testing. 
each new technique use his own evaluation dataset which many time have limited size and representativenes. 
in this experience report we use a large and representative dataset to evaluate several state of the art vulnerability prediction technique. 
this dataset be build with information of 2186 vulnerability from five widely use open source project. 
result show that the dataset can be use to distinguish which be the good technique. 
it be also show that some of the technique can predict you all of the vulnerability present in the dataset although with very low precision. 
finally accuracy precision and recall be not the most effective to characterize the effectiveness of this tool. 
a finite element post processing for skew effects in brushless doubly fed induction machines. 
brushless doubly feed induction machine have great potential as variable speed generator in wind turbine. 
undesired space harmonic exist because the special rotor need to couple both stator winding which with different pole pair number and different frequency. 
these undesired space harmonic lead to a big torque ripple compare with conventional induction machine. 
previously a 2d multi slice finite element fe method be apply to study the effect of rotor skew on torque response in brushless dfim. 
it result in a significant computing time because several 2d fe slice be couple and calculate simultaneously in one model. 
it be not efficient to use such a model to predict how much average torque and torque ripple would be reduce by apply skewed slot at the beginning of design. 
this paper make use of normal 2d fem result and apply skew factor in post processing to investigate the influence of rotor skew on the torque response. 
the propose method can give an approximate prediction of skew effect on torque response with limited computing time. 
an improved analytical model of eccentric synchronous reluctance machines consider the iron saturation and slotting effect. 
this paper deal with an improved analytical model of synchronous reluctance rel machine with eccentricity. 
this model consider the magnetic saturation occur in the different iron part of the stator and the rotor. 
this saturation result from the actual b h characteristic of the iron. 
in addition the slotting effect be consider in the analytical model. 
the unbalanced magnetic force umf on the rotor be accurately estimate. 
furthermore the impact on the estimated umf due to the slotting effect and the magnetic saturation be study. 
both static and dynamic eccentricity case be consider. 
as an example four pole 36 slot rel motor with three flux barrier per rotor pole be consider. 
fe analysis be carry out to confirm the result achieve by mean of the improve analytical model. 
an improved fractional slot concentrated wind for low poles induction machines. 
recent investigation on im with fscw show that due to the high mmf harmonic content of concentrated winding this machine type be characterize by low torque capability and quality as well as low efficiency and thermal problem. 
this paper present a new fundamental wave fscw with sinusoidal mmf waveform and a non overlapping winding arrangement. 
the propose winding solution consist of two different fscw type and a dual slot layer stator structure. 
the first winding be locate on the outer slot layer region while the second one be locate on the inner slot layer. 
additionally both winding be shift in space to each other for a specific angle. 
this winding configuration have several advantage like high quality mmf wave with low harmonic content short end wind length and applicability to low pole ims. 
obtain result from the analysis of different im show that the propose fscw provide high performance in different application area. 
characterization and validation of a large hydrogenerator under dynamic condition. 
in this paper the validation of a set of parameter of a 97mva 50hz 10.3kv hydro generator obtain both by simulation from finite element analysis and by experimentation from the no load curve and the short circuit test be investigate. 
as each parameter of the synchronous generator determination involve some inaccuracy due either to the method use or to the processing of the test datum a comparison have be make with actual experimental datum. 
robustness of the derive d q model be make by build a dynamic model of the synchronous generator in simpowersystem and compare successfully with measurement under dynamic condition. 
the methodology as well as the main hypothesis be establish for the simulation. 
the result of this study show that finite element analysis be a good alternative to the experimental measurement for the parameter determination of synchronous generator. 
influence of magnet imperfections on torque pulsation of pm machine have different pole and slot combinations. 
this paper investigate the influence of magnet imperfection on the torque pulsation of permanent magnet machine have different pole slot combination 2p ns include fractional slot as well as integer slot topology. 
the magnet imperfection result in change in the cog period which in turn might reduce the effectiveness of skewing and also introduce new harmonic order that could lead to more noise and vibration. 
it be find that such influence be reduce significantly with the number of structure cyclic symmetry which be equal to the great common divisor between the pole and slot number. 
hence the imperfection be more severe in machine have similar number of pole and slot 2p n s one follow by 2p n s two and the influence be relatively small in other fractional slot combination as well as integral slot machine. 
influence of magnetic saturation on rotor bar current waveform and performance in induction machines. 
this paper investigate the influence of magnetic saturation on the rotor bar current waveform and performance characteristic of a squirrel cage induction machine im. 
the level of iron saturation in different part include stator and rotor back iron tooth body and tooth tip etc be examine and their influence be investigate while the dominant part which cause the non sinusoidal rotor bar current waveform be identify. 
it have reveal that the magnetic saturation particularly in the rotor tooth have a significant effect on the bar current waveform and the phenomenon be explain in depth. 
modeling and estimation of slot harmonics in wound rotor induction machines. 
in this paper a novel method for modeling and simulation of a slot harmonic estimation model be present. 
this model calculate only the harmonic due to the slotting and therefore can be easily add to an exist model of a wound rotor induction machine. 
the approach present in this paper be also valid for develop a slot harmonic estimation model of a doubly feed induction machine since the slot harmonic frequency do not dependent on the rotor voltage. 
for the validation of the model an experimental set up consist of a 4.2 kw 220/380 v/50 hz/4 pole be use. 
the comparison between the experimental and simulated value confirm the validity of the approach. 
on load cog torque calculation use frozen permeability method and permeance network models. 
cog torque produce negative effect in permanent magnet synchronous machines pmsms such as vibration noise and position control inaccuracy. 
its impact can be bad due to magnetic saturation when the machine be load increase its amplitude and cause the magnet or stator slot skew to be ineffective. 
this paper deal with the study of these phenomenon combine a permeance network model pnm and the frozen permeability fp method. 
with this approach the actual cog torque amplitude can be accurately predict. 
furthermore the optimal skew angle which eliminate the on load cog torque can be correctly select. 
comparison between the maxwell stress tensor and the virtual work principle be also establish for the on load cog torque calculation. 
it be conclude that the virtual work principle must be employ when use fp technique in a pnm. 
parameterized dynamic model of cage induction machine. 
this paper give the detailed derivation of a parameterized cage induction machine dynamic model in the natural frame of reference. 
the model be suitable for the analysis of the impact of a different number of rotor bar on machine transient as well as steady state performance. 
after the initial induction machine design process for a predetermined number of stator slot and rotor bar the parameterized model mean that any different number of rotor bar could be choose result in different machine parameter. 
during this process the stator winding scheme as well as the rate power of the machine be invariant. 
the model of the machine be derive by mean of winding function. 
thus in the way describe a very powerful model be obtain that enable the analysis of a dozen of the different number of rotor bar in an hour. 
the advantage of this be self evident compare with model base on the finite element method. 
the power of the model be illustrate by an analysis of a specific machine with three different number of rotor bar. 
performance of a high torque density induction motor with an integrated magnetic gear. 
there have be a number of recent advancement in magnetic gear and pseudo direct drive permanent magnet pm machine with integrated magnetic gear. 
despite these advance there be a number of application where induction machine drive be preferable. 
this paper investigate the feasibility of a pseudo direct drive induction machine with an integrate magnetic gear and present some of the difficulty in the design process as compare to the design process for pm machine. 
the performance of an induction machine with an integrate magnetic gear be investigate. 
this paper present some of the loading characteristic of the propose machine. 
a prototype design at small scale be develop and simulation result demonstrate the potential for high torque density with good loading characteristic. 
time  and spatial harmonic content in electrical machines and its application in fourier base. 
model. 
an increase interest in both efficient electrical machine and more extensive control strategy demand evermore fast simulation tool. 
one of the modeling technique that meet this demand be fourier base modeling. 
however even fourier base model may encounter problem relate to cpu usage. 
to cope with these problem the author present three simple technique to reduce the computational time of fourier base model for synchronous machine. 
the technique be mainly base on a qualitative knowledge of which time and spatial harmonic order be present in the machine s magnetic field. 
the propose technique be validate and a benchmark test have be perform. 
the possible reduction in computational time show to be very large for the present benchmark case study up to a factor 5000. 
torque ripple modeling and minimization for pmsm drive with consideration of magnet temperature variation. 
the spatial harmonic of magnet flux be a major cause of torque ripple in permanent magnet synchronous machine pmsms and it be temperature dependent. 
thus this paper investigate torque ripple modeling and minimization for pmsm consider magnet temperature variation. 
firstly experimental study be conduct to demonstrate that the torque ripple be magnet temperature dependent. 
then base on extensive experimental test a novel linear model be propose to model the relationship between the de and harmonic component of magnet flux in the dq reference frame which provide a way to estimate the magnet flux harmonic. 
base on this model the torque ripple model consider magnet temperature variation be propose and validate with simulation. 
afterwards a novel adaptive current optimization approach be propose for torque ripple minimization which consist of two part the magnet flux harmonic estimation use the propose linear magnet flux model and the current optimization use the propose torque ripple model. 
in our approach the stator current be adaptively optimize with respect to the magnet temperature. 
however the propose approach be not necessary to run in real time because temperature variation have a large time constant. 
our approach be validate through both numerical and experimental study. 
transformation by rewinde a stator of a three phase induction machine with squirrel cage to a five phase induction machine. 
the electrical winding be the necessary centerpiece for create the rotate magnetic field. 
the winding be then a determine factor for the quality of dynamic performance of any electrical machine. 
this paper deal with the condition of transformation by re wind a static armature of a small power three phase squirrel cage induction machine to a five phase machine. 
only double layer winding be consider in this paper. 
by elsewhere a detailed description of the result distribution factor similarly the mmf distribution of both fractional and integral pitch five phase winding be accurately treat. 
analytical modeling of hybrid electromagnetic excited linear synchronous motor. 
improve analytical modeling of electrical machine can make the process of analysis design and optimization more accurate and time saving. 
in order to improve analytical modeling it be need to compute magnetic flux distribution more precisely. 
an accurate calculation of magnetic flux distribution lead to a fine estimation of electrical machine characteristic. 
in this paper a four layer model of hybrid excitation linear synchronous motor heelsm be implement and analytical magnetic flux distribution base on two d analysis be obtain by solve maxwell equation. 
the aim be to take into account all field harmonic produce by both dc and high temperature superconducting hts excitation coil on secondary. 
moreover thrust force and normal force be determine analytically. 
these result have be validate by a corresponding finite element analysis fea. 
comparison show a good agreement between analytical and fea result. 
demagnetization of modular surface mounted permanent magnet machines. 
this paper investigate the demagnetization issue in modular surface mount permanent magnet machine with flux gap in alternate stator tooth. 
the influence of flux gap on the d axis inductance and the potential peak short circuit current be analyse for different slot pole number combination. 
it be find that the flux gap will reduce short circuit current of machine with pole number small than slot number while they will increase short circuit current of machine with pole number high than slot number if the flux gap width be not carefully select. 
however opposite phenomenon can be observe for demagnetization withstand capability if short circuit current be assume to be constant. 
for machine have pole number small than slot number the flux gap tend to deteriorate this capability whilst for machine have pole number high than slot number this capability can be improve. 
other influence parameter such as magnet thickness temperature etc. 
have also be account for in the demagnetization analysis. 
test have be carry out to validate the prediction of inductance and short circuit current. 
direct electromagnetic actuation on high ratio gear. 
this document demonstrate a conceptual study design and development of unconventional electromagnetic actuator for application where a high torque over a limited part of a rotational turn be require. 
the unconventionality of the actuator be that the electromagnetic actuation be apply directly on a high ratio transmission gear such as a cycloid disc in a cycloid drive or a flex spline in a harmonic drive. 
furthermore normal force be intentionally use to displace and rotate a cycloid disc or deform a flex spline instead of tangential force which be typically use when integrate conventional rotate machine drive a high ratio gear transmission. 
the conceptual study be base on a number of finite element model where the idea be first present and follow by field and force analysis. 
a finite element static model be use to calculate the expect excitation versus the gear location. 
the gear location of the cycloid disc be define by an eccentric origin and rotation angle while the flex spline be define by a deformation and rotation angle. 
the analysis of the integrate normal force actuator inside the harmonic drive demonstrate the challenge strain gear action in term of elasticity and magnetic saturation. 
the challenge with the cycloid drive be the electromagnetic action force direction compare to the desire mechanic reaction force direction that cause unnecessary inner load or even lock the gear mechanism. 
a prototype machine with the maximized rotor eccentricity be use to characterize four different rolling and gear cycloid transmission. 
fractional slot pm assisted reluctance motors configuration comparison and optimization. 
this paper deal with the analysis of fractional slot pm assist synchronous reluctance motor. 
the configuration consider here refer to high torque low speed application so that a relatively high number of pole be adopt. 
as well know this be a drawback for synchronous reluctance motor. 
the aim of this paper be to illustrate how different design technique influence the performance of the machine. 
some typical combination of slot and pole number be adopt to the aim of have a more general result. 
influence of slot opening and flux gaps on the voltage distortion in spm machines. 
this paper comprehensively investigate the voltage distortion i.e. 
terminal voltage ripple mechanism in surface mount permanent magnet spm machine equip with a single layer fractional slot concentrate wind fscw. 
stator flux gap can be use in fscw machine to increase the pitch factor and hence the winding factor as well as to simplify the manufacturing process. 
furthermore they can also reduce wind magneto motive force mmf subharmonic which cause extra saturation in the stator lamination and lead to a high voltage distortion. 
this paper focus on investigate the influence of key parameter on the voltage distortion the slot opening the stator back iron thickness and the stator flux gap. 
it be find that flux gap may have a detrimental effect on the voltage distortion in machine with a large slot leakage inductance closed slot or small slot opening. 
however the flux gap can reduce the voltage distortion in machine with large slot opening where the voltage distortion be dominate by the armature reaction subharmonic. 
stator rotor slot and winding pole pair combinations of dc biased sinusoidal vernier reluctance machines. 
the recent novel dc bias sinusoidal current reluctance machine dc bias vrm be similar to switch reluctance machine srms in term of structure as they both adopt the doubly salient structure and concentrated winding. 
however the special characteristic of dc bias vrms be that their phase current have both dc current and ac current. 
therefore it can be infer that the vibration and noise can be much small than srms as the phase current waveform be smooth. 
besides compare with variable flux reluctance machine with specialized field winding dc bias vrm exhibit well performance such as few copper loss and high torque density. 
in this paper the stator rotor slot combination and armature wind configuration with different pole pair of the dc bias vrm be deeply investigate. 
firstly relationship among stator rotor slot and armature wind pole pair be give base on the work principle. 
then several feasible stator rotor slot combination be obtain and the electromagnetic performance be compare by the finite element analysis fea. 
the result show that the eight rotor slot five armature pole pair machine exhibit high torque in rate load but with high torque density the 10 rotor slot four armature pole pair machine show high torque in over load condition and the 12/11 and 12/13 machine present the minimum pulsation torque. 
synthesis of fractional slot vernier permanent magnet machines. 
vernier permanent magnet vpm machine have gain grow interest in recent year due to several advantage include high torque density and simple mechanical structure. 
this paper present a thorough investigation on the nature of fractional slot vernier permanent magnet fs vpm machine with regular stator topology. 
through analytical derivation the configuration and performance of two winding type fractional slot concentrate wind fscw and fs wind with two slot coil pitch be evaluate for vpm machine. 
the fs wind vpm machine with two slot coil pitch be newly propose and turn out a promising candidate in direct drive application with competitive torque density and improved power factor. 
all the electromagnetic performance be calculate and compare through finite element analysis fea. 
comparative study of current control methods of asymmetric pm synchronous machine. 
the current control of asymmetric pm synchronous machine be investigate systematically in this paper. 
the conventional proportional integral pi control in dq frame and three typical balanced current control method be investigate and their relationship be reveal. 
these three method include the proportional and resonant pr control in stationary alpha beta frame the dual current control and the proportional integral plus resonant pi r control in dq frame. 
those three method be functionally identical in suppress the negative sequence current and well know in previous literature but the relationship and difference between they have not be investigate systematically. 
it be find that there be resonant controller at the center frequency of twice fundamental frequency in their equivalent control in dq frame. 
therefore they can suppress second harmonic current in dq frame so that the negative sequence current can be suppress. 
it be also find that the pr control in alpha beta frame be equivalent to the dual current control in theory. 
elaborate experiment be conduct in an asymmetric pmsm system to validate their capability. 
current reference governor of permanent magnet synchronous machine. 
this paper present a control method for constrain control of a permanent magnet synchronous machine. 
the control system utilize field orient pi current control tune use linear control theory to obtain good steady state performance and a fast transient response. 
however the linear control theory do not consider constraint violation of which may lead to performance deterioration and even instability. 
in order to ensure constraint satisfaction an additional device call a reference governor be add to the exist control loop. 
the main advantage of such add on device be in its simplicity and its low computational burden which enable real time implementation. 
the real time feasibility of the propose method be show use a processor in the loop simulation implement on texas instruments f28335 150 mhz micro controller. 
efficiency and loss mapping of ac motors use advanced testing tool. 
the efficiency and loss map represent an important tool to evaluate an electrical motor drive. 
the efficiency map be usually compute use finite element analysis or equivalent circuit that take into account the motor loss. 
however these method need to be compare with efficiency map that must be experimentally obtain use calibrate instrument. 
the main problem be how to implement an automate procedure that must obtain the motor or drive efficiency for all operating point. 
this paper describe an efficiency and loss mapping procedure that have be apply for a 5.3 kw three phase internal permanent magnet machine prototype for traction application but it can be use for any ac machine with inverter supply. 
all measurement have be perform with an advanced data recorder instrument. 
the efficiency and loss map be calculate after the test with a post processing procedure that can provide all information regard the motor exploitation include current voltage and flux vector trajectory in d q rotor frame. 
monitoring of thermal degrade ac machine winding insulation by inverter pulse excitation. 
the demand for ac machine in traction application feed by voltage source inverter be increase. 
these highly efficient drive work near and even above their rate value be expect to operate for many year or even decade. 
thus condition monitoring be gain a more important role. 
with focus in this work on outage due to deteriorated machine wind insulation an online monitoring method be present to detect change in the insulation strength. 
with the propose method the insulation system state be assess before an actual short circuit occur without the need for additional equipment or disconnection of the drive. 
the inverter be use as a source of excitation by apply pulse sequence with different duration to enable high frequency excitation and analysis in a range suitable for the insulation condition monitoring. 
the evaluation of a change in the electrical strength of the insulation be make by analyze the transient current response measure with the build in sensor of the inverter. 
a new matlab and octave interface to a popular magnetics finite element code. 
femm finite element method magnetics be a free open source high quality 2d finite element modelling tool extremely popular in academia for both research and teaching particularly in the field of electrical machine design. 
however femm suffer from be tie to the microsoft windows platform and have a slow interface to external program. 
this paper present a successful project to extract the core algorithm from femm make they cross platform and compile they into a set of library and command line program. 
in addition the creation of a new matlab and octave interface with direct access to the library be describe with an example of its use. 
the library use only the c++ standard template library for maximum portability. 
for student and researcher the tool can be use without knowledge of c++ but for more advanced student and those who might want to add further improvement the code have also be substantially reorganise for clarity. 
the new c++ toolbox be refer to as xfemm and the interface mfemm. 
a new systematic method to design windings of polyphase rotating electrical machines and evaluation of their optimization potential. 
in this paper a new systematic design method for ac wind design be present which base on the star of slot and the table of slot. 
with this design method it be possible to design symmetrical single and double layer winding for polyphase system with a maximum fundamental winding factor especially for winding with z(1)/mt odd. 
because of the modular structure of the systematic design method the winding imbrication can be consider to influence the leakage factor or specific harmonic. 
the mathematical representation of the winding imbrication and consequently the introduction of a degree of imbrication make it possible to optimize winding automatically. 
a statistical solution to efficiently optimize the design of an inverter feed permanent magnet motor. 
this paper provide the fundamental of integrate motor drive system design knowledge which could be use as a basis to change the exist machine design approach from be a separate machine design tool to a more advanced engineering package. 
various user s preference include motor performance at transient rate and flux weakening operation along with the inverter quality be study by mean of a competent co simulation process which utilize fem matiab and simulink package to build the framework base on which magnetic electric and electronic device and quantity be model simulated and post process. 
a case study of an interior permanent magnet motor connect to a field orient control drive be investigate and the design process concept be develop by mean of a comprehensive statistical analysis. 
the initial goal be to reduce the search space of the optimal region. 
it be show that incorporate the inverter effect into the design process change the idea of an optimum motor design and not only the design parameter but also the expectation from motor performance have to be revise. 
in fact an integrate motor drive system design process regard the good motor operation in the transient rate and flux weakening mode be target as the ultimate goal. 
a set of practical solution be propose to fulfill any motor operation requirement while keep the inverter efficiency at the high possible level. 
a study of the effect of temperature on magnetic and copper losses in electrical machines. 
the magnetic property of ferromagnetic core and the resistance of conductor be severely affect by the high operating temperature in modern electrical machine. 
these temperature effect must be take into account in the electrical machine design process to optimize their performance. 
in this work we have propose a simple material model to predict the change in the single value b h relationship of non oriented electrical steel with respect to the temperature. 
the temperature dependent power loss curve have also be measure and be fit to a two term iron loss formula to compute the magnetic loss. 
the temperature dependent magnetic property b h relationship and power loss formula and the resistivity value of the conductor have then be incorporate into the finite element fe base computer simulation of a transformer core and an induction machine. 
the effect of temperature on different performance parameter such as magnetic and copper loss and supply current have be study. 
an optimal design of a 5mw afpmsm for wind turbine application use analytical model. 
in this paper an optimize design procedure for the axial flux permanent magnet synchronous machine afpmsms for large scale wind turbine be introduce. 
in this paper the design for a 5mw wind turbine afpmsm be introduce analyze and validate. 
in this design an efficient analytical model be use that be capable of obtain all the electromagnetic parameter in a very accurate way. 
the structural mass be the most dominant mass in large wind turbine. 
therefore inclusion of this mass in the design be do. 
the effect of use multi stage on the electromagnetic performance the cost and the the total mass of the machine be also introduce. 
two type of structural mass be introduce. 
one with solid disk structure and another machine with ring type structure. 
the comparison of both structure on the electromagnetic performance be study. 
moreover a comparison of different available market generator be propose. 
in this comparison the ring type afpmsm have prove great robustness in term of cost and mass to torque ratio. 
a complete 3d finite element fe validation have prove the robustness of the analytical model. 
analysis of radial magnetic forces in hydrogenerators with fractional slot winding. 
this paper investigate radial magnetic force in two hydrogenerator with fractional slot winding. 
use time step finite element analysis time and space distribution of the flux density in the airgap be compute. 
maxwell stress tensor be then employ to calculate the radial force analytically. 
spatial harmonic order of radial force density at one time instant and time vary mean value of radial force density be study. 
use simple structural equation stator deformation due to the zeroth and low non zero mode of vibration be calculate and compare. 
simulation result be discuss to identify the major cause of vibration in the hydrogenerator under investigation. 
analytical prediction of electromagnetic performances and unbalanced magnetic forces in fractional slot spoke type permanent magnet machines. 
this paper present an analytical method for the computation of electromagnetic performance and non intrinsic unbalanced magnetic force umf in fractional slot spoke type permanent magnet stpm machine. 
it be base on the two dimensional two d subdomain method in polar coordinate consider the drive current i sinusoidal and ii six step rectangular. 
it involve solution of laplace s and poisson s equation in the stator slot the air gap the bury tangential pms into rotor slot and the non magnetic region under pm. 
the result obtain with two d analytical model viz the electromagnetic performance and the non intrinsic umf be verify with those issue from finite element method fem. 
computationally efficient 3d rotor eddy current loss prediction in permanent magnet machines. 
this paper propose a computationally efficient method for accurate prediction of three dimensional 3d rotor eddy current loss in permanent magnet pm machine. 
2d time step finite element analysis fea be use to generate the information on radial and tangential time derivative of 2d magnetic field eddy current source in the magnet and the retain sleeve for application of the 3d imaging technique. 
the propose method be employ to evaluate the 3d magnet loss associate with surface mount pm spm machine interior pm ipm machine and also the eddy current loss in the retain sleeve. 
the method be validate by 3d time step finite element analysis fea for an eight pole 18 slot spm and ipm machine. 
design and optimisation of an ironless double rotor radial flux permanent magnet machine. 
this paper have to do with the multi objective optimisation of an ironless double rotor radial flux permanent magnet idrfpm machine. 
the optimisation objective be to improve efficiency torque and pm mass. 
only the electromagnetic aspect be consider. 
due to ease of implementation a weighted sum method wsm be implement to reduce the multi objective problem into a single objective problem. 
however for this study the specific weight value be not choose beforehand but rather an entire spectrum of weight be use in the optimisation process which subsequently generate a large variety of solution allow the decision maker to make a more informed design choice. 
furthermore this paper show that optimisation function evaluation can be do use either finite element modelling fem or the analytical subdomain analysis method sam and that the result correlate well. 
the work do to derive a sam model be also extremely summarise. 
with sam the optimisation process can be speed up significantly. 
the solution of the optimisation process be also briefly discuss. 
design of a high fill factor permanent magnet integrated starter generator with compressed stator windings. 
this paper focus on the improved thermal performance of electrical machine by increase the conductor fill factor. 
a comparative design study of integrated starter generator isg consider different pole slot combination and magnet topology be use as a case study to fix slot dimension. 
compressed stator winding couple with segmented stator structure be introduce to reduce copper loss of the optimize isg. 
by perform quasi static explicit dynamic simulation deformation of insulation have be investigate regard mechanical property of the magnet wire enamel. 
it be note that magnet wire at certain cross sectional area can be compress up to 0.72 fill factor without observe insulation failure. 
thermal conductivity enhancement of the stator winding at improved slot fill factor be demonstrate by perform steady state and transient finite element thermal simulation. 
design of a permanent magnetic excited transverse flux machine for robotic applications. 
this paper present the design and optimization process of a permanent magnetic excited transverse flux machine which shall be use as a shoulder joint motor in an articulate six axis robot arm in service robotic. 
start from give application specific requirement a parametrized model of the machine be present. 
for transverse flux machine the typically high number of design parameter lead to a large parameter space. 
a full factorial analysis simulate every possible parameter variation would lead to simulation time in the order of year. 
therefore a suitable classification of the parameter be propose which be use for an iterative optimization algorithm perform several parametric sweep in a three dimensional finite element simulation. 
result from the sensitivity analysis and the final optimization result be discuss. 
design construction and measurement of a permanent magnet axial flux machine. 
the result of the design the construction and first measurement of an axial flux permanent magnet afpm machine be summarize. 
the goal of this project be to build an axial flux machine with surface mount magnet in the simple possible way to use the machine as a demonstrator for small wheel hub drive with a reduce torque demand. 
therefore the machine be design as double sided motor with internal stator and tooth coil wind to enable a modular structure and two rotor disc. 
for the ease of a simple integration of the machine the outer diameter be limit to a certain value. 
therefore the design yield to a machine with 12 pole and 18 stator tooth number of slot per pole and phase q 1/2. 
3d electromagnetic and 3d thermal study with the finite element method fem software jmag be carry out. 
after the design of the active element the construction of the prototype be do. 
the machine be build up on a test bench and couple with a load machine to compare the simulation result with the measurement. 
the measurement show that the electromagnetic property torque efficiency fit with the simulation result but due to the open ventilation motor design the thermal behavior of the machine be well than assume for the simulation. 
with the result it be possible to estimate also the behavior of big wheel hub drive. 
electromagnetic design issues of high speed permanent magnet machine. 
this paper aim to provide some useful instruction to electromagnetic design of high speed permanent magnet machine. 
in this paper the electromagnetic design procedure be illustrate with a two pole 40,000 rpm prototype machine. 
in order to determine a rotor structure with good performance rotor design include rotor structure pole arc and magnetization direction of magnet be analyze respectively. 
on the other hand two machine with different stator core but same rotor be study. 
and a novel method of stator winding design be provide to have more option for the design by increase number of parallel branch. 
finally the influence of stator slot opening and number of segmentation in magnet to rotor eddy current loss be discuss. 
small stator slot opening would reduce the rotor eddy current loss but it bring some processing technic problem. 
and segmentation in magnet would reduce the eddy current loss in magnet only. 
experimentally calibrated thermal stator modelling of ac machines for short duty transient operation. 
this paper present an approach to the thermal design of an ac machine where the application require a low duty transient operation. 
to provide accurate temperature prediction the design process have be inform with experimental datum from test on a stator wind sector motorette. 
these have be show to be a time and cost effective mean of calibrate the thermal model of a full machine assembly prior to manufacture of the final design. 
such an approach be usually adopt in design analysis of machine with a concentrated winding topology. 
here the motorette testing have be extend to machine with distributed winding. 
in the interest of improve heat transfer from the winding body into the machine periphery several alternative slot liner and impregnating material have be compare. 
a total of nine stator section sample have be manufacture and evaluate. 
the performance trade off between the various combination be discuss in detail alongside their ability to satisfy the design requirement. 
base upon these experimental result three stator segment sample have be select for transient duty analysis. 
a lumped parameter thermal model have be use and calibrate to match the performance of the experimental sample. 
this be turn have be use to predict the transient thermal performance of the full machine assembly for the design specification. 
the most promising motorette variant have be select for machine prototype. 
fea base method for estimate pm demagnetization in electrical motor design development and experimental validation. 
this paper present a procedure base on finite element analysis fea to determine the maximum allow current of permanent magnet pm motor from a demagnetization point of view. 
the procedure have several fea stage include the identification of pm demagnetized region under load condition and the calculation of the back electromotive force bemf voltage waveform after the motor have be subject to potential demagnetizing current. 
ferrite pm s have be characterize use a hysteresisgraph for high accuracy and use as input for simulation. 
the model be validate at bad case condition compare the simulation and experimental result at control negative temperature. 
the result show a very good agreement among calculate and practical bemf waveform provide a reliable and inexpensive method for estimate the maximum allow current at early motor design stage. 
improved analytical estimation of rotor losses in high speed pm synchronous machines. 
this paper present a novel and more complete approach for study rotor loss in pmsm permanent magnet surface mounted synchronous machine. 
the prediction of rotor loss due to eddy current in either magnet or other rotor conductive part be of great concern for the machine design. 
particularly in high speed electrical machine the eddy current loss can be severe and seriously affect the machine performance in term of efficiency and thermal issue. 
therefore have a comprehensive tool able to predict in a fast as well as accurate way these loss can represent a useful mean for electrical machine design and analytical optimization. 
improvement of axial flux single rotor single stator induction machine performance by apply semi magnetic wedge. 
this research investigate an axial flux singlerotor single stator asynchronous motor afam with aluminum and copper cage winding. 
in order to avoid use die casting of the rotor cage wind an open rotor slot structure be implement. 
in future this technique allow use copper cage wind avoid critically high temperature treatment as in the die casting processing of copper material. 
however an open slot structure lead to a large equivalent air gap length. 
therefore semi magnetic wedge should be use to reduce the effect of open slot and consequently to improve the machine performance. 
the paper aim to investigate the feasibility of use open slot rotor structure for avoid die casting and impact of semi magnetic wedge to eliminate negative effect of open slot. 
the result be mainly obtain by 2d finite element method fem simulation. 
measurement result of mechanical performance of the prototype with aluminum cage winding give in the paper prove the simulated result. 
influence of local magnetic saturation on iron losses in interior permanent magnet machines. 
interior pm ipm machine can have severe local magnetic saturation especially in the rotor iron region above the pms and the stator tooth tip. 
in this paper the influence of local magnetic saturation on the iron loss be comprehensively investigate in ipm machine account for the influence of the slot pole number combination. 
due to local magnetic saturation the tooth tip have much high iron loss density than the other part of stator. 
the iron loss density of the rotor iron region above the pms be also high. 
also both the iron loss in the tooth tip and the rotor iron region above the pms remain high even when ipm machine be under deep flux weakening. 
it be find that fractional slot machine have high local magnetic saturation and iron loss than the integer slot machine. 
the ipm machine will exhibit high local magnetic saturation than the machine have the same slot number but low pole number. 
investigation of additional ac losses in tooth coil winding pmsm with high electrical frequency. 
stator winding structure and its manufacturing in permanent magnet synchronous machine pmsm be the vital part of the whole machine design. 
it be important to follow particular procedure in order to keep the winding loss at the acceptable level which include dc resistance loss and additional loss due to alternative magnetic flux within the area of the stator wind. 
the winding transposition or using of litz wire which be effective way of proximity loss suppression sometimes can not be implement due to challenge in assembling or cost aspect especially in low cost pmsm solution. 
in this case it be important to know consequence of use straight non twisting winding in pmsms with relatively high electrical frequency. 
this article study impact of the number of stator wind parallel strand on the additional ac loss distribution in the slot where this winding be locate. 
also thermal condition which impact the life time of the insulation of the winding be analyze with different number of parallel strand. 
current and temperature distribution in the slot conductor be attain by finite element method fem. 
the total loss cause by additional ac loss in the winding be compare with the measurement result. 
magnet losses in inverter fed two pole pm machine. 
this article deal with the estimation of magnet loss in a permanent magnet motor insert in a nut runner. 
this type of machine have interesting feature such as be two pole slot less and run at a high speed 30000 rpm. 
two analytical model be choose from the literature. 
a numerical estimation of the loss with 2d finite element method be carry out. 
a detailed investigation of the effect of simulation setting e.g. mesh size time step remanence flux density in the magnet superposition of the loss etc be perform. 
finally calculation of loss with 3d fem be also run in order to compare the calculated loss with both analytical and 2d fem result. 
the estimation of the loss focus on a range of frequency between 10 and 100 khz. 
model quasi static magnetic hysteresis a new implementation of the play model base on experimental asymmetrical b(h loop. 
this paper relate a new model of quasi static magnetic hysteresis base on the play model hysteron which build the magnetic field density b from the magnetic field h. 
in the original model h be discretize into temporal value h(t(m which be itself model by a hysteron chain of m sub value. 
b be then reconstruct from these sub value through a function experimentally determine by measure b(h center cycle use a constraint optimization method. 
the new propose method be to measure asymmetrical b(h loop which give additional equation lead to a fully determined linear square invertible system. 
the asymmetrical b(h loop be include in a big symmetrical loop with a magnetic flux density turnaround in order to be regulatable. 
on the neural network single phase induction motor efficiency estimation as a design tool. 
this paper present a modify design approach as well as a practical and effective neural network efficiency estimation procedure of a permanent capacitor single phase induction motor spim. 
the standard industrial motor frame size along with the current design trend of large length and small diameter be take into account which be not likely present in literature. 
in this context a computer aid design approach of a spim  base mainly on the classical output coefficient  be propose first. 
numerous simulation use finite elements method fem be conduct in order to verify the propose procedure and investigation regard the number of stator and rotor slot be perform. 
secondly base on the previous result a neural network nn scheme be propose in order to estimate the efficiency of spim with various stator rotor slot combination and different output power. 
it be see that the propose methodology be verify satisfactorily and could be of great use as an aid tool to industrial spim designer. 
on winding design of a high performance ferrite motor for traction application. 
design of low cost traction motor with ferrite magnet need to meet challenge such as minimize the risk of demagnetization and maximize the torque and power density via a suitable choice of rotor and stator winding topology and parameter. 
with regard to the stator distribute and concentrated winding may have both advantage and disadvantage when consider manufacturing cost slot fill factor the contribution factor of reluctance torque and parasitic effect. 
furthermore the trend toward high speed operation of the traction motor may increase the ac loss effect in the winding contribute to motor deficiency and risk of thermal failure. 
in this paper the performance of a high speed ferrite motor with a distribute and concentrated wound stator and with regard to torque and power performance as well ac loss effect be assess. 
the dynamic performance of a full scale prototype design base on a distribute aluminum wound stator be present. 
optimization of a spm machine use a non isotropic magnetic wedge with an analytical method for cog torque estimation. 
cog torque be a know disadvantage of surface permanent magnet spm machine especially if equip with open stator slot. 
a possible strategy to reduce the cog torque be to use suitably design non isotropic magnetic wedge. 
the design of such wedge for cog torque minimization require a genetic optimization approach. 
this have be do in previous work use finite element analysis fea simulation to predict the cog torque for each machine design be explore lead to a very time consume optimization process. 
in this paper the same optimization be perform use an analytical method to compute the cog torque. 
it be show that the optimization process base on the analytical formula for cog torque prediction lead to the same result as the fea base procedure but with a significant reduction in the computational burden. 
pm material selection guide for ipmsm. 
the aim of this paper be to provide a wellorganize design procedure for select the proper permanent magnet pm material to be use in construct the interior permanent magnet synchronous machine ipmsm. 
a simple and clear design flow chart be introduce to support the machine designer in each design step. 
the design start by select one of the propose pm grade as a base line material. 
the flow chart provide a guide to the machine designer in select the proper volume for the select material in order to provide the require power and torque. 
this be follow by optimize the pm volume of the base line material. 
finally a comprehensive comparison between different pm material grade in term of size cost and ability to withstand the demagnetization. 
a case study be introduce to compare between different neodymium iron boron ndfeb rare earth magnet grade and samarium cobalt smco magnet grade in order to describe and verify the propose procedure. 
apply the propose selection guidance on the case study have show fast and accept result. 
a 2d finite element simulation use motor cad software package drive by matlab use the activex have be script in the verification process for the case study. 
pros and cons of each material grade be discuss through the case study as well. 
thermal analysis for stator slot of permanent magnet machine. 
thermal management of an electric machine play a significant role in the improvement of machine performance. 
material selection of different component be one of the key stage in electric machine design for high efficiency and high torque density application. 
in the stator the slot liner between the copper wind and laminate be typically good as electrical insulation but poor in thermal conductivity. 
this affect the heat transfer from the winding to the stator significantly. 
this paper identify the key parameter in slot liner selection and the effect of these parameter in term of heat distribution in the stator of a 150kw motor by use a lumped parameter network. 
the simulation provide an insight and comparison between various air gap liner laminate condition different liner and impregnation material and the impact of manufacturing process evaluate under the same speed and load operating condition. 
thermal parameters evaluation of a fractional slot concentrated winding machine for home appliance applications. 
efficiency and reliability of electrical machine be considerably affect by their thermal performance therefore thermal simulation model have be develop to support the thermal design of electrical machine. 
however the adoption of reasonable value to represent the input thermal parameter require in such simulation be as important as the modeling strategy itself. 
this paper deal with the determination of thermal parameter concern a fractional slot concentrated winding fscw electrical machine properly design for home appliance application. 
equivalent thermal resistance and capacitance of the winding insulation system compose by winding impregnation and coil support be evaluate. 
in addition the equivalent thermal conductivity value have be assess use a novel approach suitable for fscw machine. 
a critical analysis of the obtain result have be conduct and it have show that the equivalent thermal conductivity of the fscw machine be up to two time high than the value obtainable for conventional distributed winding machine. 
topology optimisation of pmsm rotor for pump application. 
this paper propose a design optimization procedure of a pmsm rotor. 
in the process of optimization the shape and the size of the permanent magnet be consider constant while the distribution of electric steel and voids air in the rotor be variable contribute to the final objective. 
for the gradient search the method of moving asymptotes algorithm be apply to the rotor design of an internal permanent magnet synchronous motor for a circulation pump. 
the objective of the optimisation be to improve the torque of the machine with any give magnet placement or shape. 
the optimisation method take into account the inherent mesh dependency of the topology optimization process and dynamic constraint be apply ensure design with favourable cogging and ripple torque characteristic. 
the design method be carry out for various magnet size and placement show the ability of the algorithm to find valid solution in the search space. 
winding loss separation in thermal analysis of electromagnetic device. 
this paper investigate various winding loss separation approach applicable to the thermal analysis of electrical machine transformer and wound passive component. 
the accurate temperature prediction and identification of hot spot within such electromagnetic device be strongly dependent on the absolute power loss datum as well as the loss distribution within the subassemblie or region of the device. 
the loss within a device be often define as the average loss over a particular region for example the winding loss core loss or magnet loss. 
however such a loss definition might not yield the require fidelity or resolution particularly if localise power loss such as ac winding loss be present during device operation. 
to account for the inhomogeneous winding loss a more detailed loss separation be require. 
in this paper the winding subassembly be subdivide into a number of sub region account for both the active length and end wind. 
three dimensional 3d electromagnetic and thermal analysis be employ to give insight into the effect of the loss definition on the accuracy and validity of the temperature prediction. 
a hardware exemplar representative of a single layer open slot stator winding subassembly have be select for the analysis. 
the result suggest that detailed loss separation provide improved accuracy of the temperature prediction and hotspot identification when compare with the more common average loss definition. 
the theoretical finding have be validate with experimental datum show close correlation. 
application of infrared thermography to fault detection in industrial induction motor case story. 
infrared thermography have be extensively apply over decade to area such as maintenance of electrical installation. 
its use in electrical machine have be mainly circumscribe to the detection of fault in static machine such as power transformer. 
however with regard to the predictive maintenance of rotate electrical machine its use have be much more limited. 
in spite of this fact the potential of this tool together with the progressive decrease in the price of infrared camera make this technique a very interesting option to at least complement the diagnosis provide by other well know technique such as current or vibration datum analysis. 
in this context infrared thermography have recently show potential for the detection of motor fault include misalignment cool problem bear damage or connection defect. 
this work present several industrial case that help to illustrate the effectiveness of this technique for the detection of a wide range of fault in field induction motor. 
the datum obtain with this technique make it possible to detect the presence of fault of diverse nature electrical mechanical thermal and environmental these datum be very useful to either diagnose or to complement the diagnosis provide by other tool. 
comparison between the salient pole synchronous machine and the double fed induction machine with regard to electromagnetic parasitic forces and stator vibrations. 
pump storage hydro power plants have be mainly equip with fix speed salient pole synchronous machines spsm. 
however the upgrade from fix speed technology to variable speed technology use double fed induction machines dfim bring many benefit the control of the power in pump mode operation at the good efficiency point in turbine mode high stability in case of a perturbation. 
like the spsm the dfim face radial electromagnetic force due to the non sinusoidal airgap magnetic flux density. 
however these force be not necessarily the same as the one exist in the original spsm essentially because of the different magnetic circuit property. 
vibration problem due to match between exciting force and stator eigen mode may occur in the dfim although they do not exist in the original spsm. 
the risk be even more relevant consider that the dfim operate at different speed so that it lead to a shift in frequency in some force component. 
effect of magnetic wedge on electromagnetically induce acoustic noise and vibration of electrical machine. 
the article study the effect of stator magnetic wedge on the electromagnetically induce acoustic noise and vibration of a squirrel cage induction machine. 
firstly a review of previous study analyse the effect of magnetic wedge both on electromagnetic and vibro acoustic domain be do. 
then simulation be perform with manatee r software to quantify the reduction of noise and vibration due to maxwell force with the use of magnetic wedge in a squirrel cage induction machine present a strong resonance due to slotting effect. 
a sensitivity study be carry on the magnetic permeability of the wedge and it be show that the maximum sound pressure level and vibration reduction only reach two db with a relative magnetic wedge permeability of 20. 
emulate bear faults a novel approach. 
the relation between evolve mechanical fault in rotate electrical machine and their reflection in the machine electrical parameter still require a lot of research. 
this imply serious obstruction in the evolution of motor current signature analysis as a complete and reliable condition monitor technology. 
this paper present the translation of common bearing fault into specific rotor stator movement use finite element modeling. 
subsequently a novel method to elucidate the complex relation between rotor movement and the electrical parameter of an induction machine use an experimental test setup be describe dimension and simulate. 
replace one of the induction machine s bearing with an active magnetic bearing will give the opportunity to create specific rotor movement and consequently evaluate different programmable mechanical fault and their reflection in the stator current and/or voltage with high relevance and reproducibility. 
fbg sense for hot spot thermal monitoring in electric machinery random wound components. 
this paper investigate the application of fibre bragg grating sensor for thermal hot spot temperature monitoring of random wound electric coil. 
the paper first present the design installation and in situ characterisation detail of a thermal sensor use for enable thermal monitoring in the centre of the wound coil structure in close proximity to the thermal hot spot location. 
a number of thermal monitoring experiment be then undertake on a prototype current carry test coil under a range of control static and dynamic thermal condition. 
it be show that reliable improve fidelity information on the coil s thermal status can be obtain from embed fibre bragg grating thermal sensor when compare to conventional thermal sense solution. 
portable network analyzer and mobile app base small wind turbine condition monitoring. 
improve fault diagnostic technique in wind turbine be a field of grow interest give the negative impact that unexpected breakdown have on the profitability of wind farm. 
traditional and new diagnostic technique mainly base respectively on vibration and generator current monitoring can not be apply easily to small wind group due to the very restrictive cost limitation. 
this paper propose a fault diagnosis technique base on monitor generator voltage current and power suitable for small wind group base on permanent magnet synchronous generator which aim to offer an affordable solution that provide easy to understand information even for user lack technologic training help they decide when to ask for specialized assistance. 
this proposal be base on datum provide by a commercial monitoring system instal between the generator and the regenerative inverter and process and display in a mobile device smartphone or tablet pc app run either android or ios thus greatly contribute to a very cost effective solution. 
the actual performance of an off the shelf small wind group have be measure both off line and on line by the diagnosis app during the training stage with good agreement and confirm the suitability of the method to detect demagnetization fault. 
radial force and vibration in surface mounted permanent magnet vernier machines. 
this paper mainly deal with the radial force and vibration of the surface mount permanent magnet vernier machine spmvm with the integer slot distribute winding isdw and the fractional slot concentrated winding fscw. 
the harmonic order and frequency of the radial force in spmvm with the permanent magnet surface mount on rotor or stator tooth be detail discuss by the analytical and finite element analysis fea method. 
a prototype be build to validate the analysis of radial force and investigate the effect of the low order harmonic radial force on vibration in spmvm. 
webcam base tachometer for in field induction motor load estimation. 
rotational speed measurement be a key issue in most industry either for process control characterization or fault diagnosis. 
in electric motor drive system it can be use for example to estimate the motor load or pulley belt transmission slip. 
encoder and resolver be typically use for continuous speed monitoring require mechanical coupling with the rotate shaft part. 
if the speed be to be measure at a give instant or during a few moment noninvasive contactless optical tachometer can be use use optical reflection or stroboscopic principle. 
in most case stroboscopic tachometer require no reflective element strip in the rotate part. 
however if the user want to continuously measure the speed of a give rotate part during the audit characterization period with real time datum logging and without stick reflective strip or introduce shaft couple encoder resolver there be no low cost commercial solution to perform such task. 
for example if the user s aim be to continuously estimate the load variation of an induction motor over a day or week on the basis of the slip speed value it be not possible with conventional commercial low cost contactless equipment unless the user use expensive online operation equipment estimate the speed by mean of input voltage current. 
moreover in some rotate system part not directly drive by an electric motor the online equipment can not be use and it be not practical and in some case even impossible to couple an encoder resolver or stick some reflective strip. 
in this paper an innovative nonintrusive low cost webcam base tachometer be propose develop and experimentally test. 
it can be use to easily estimate and record the speed over time in for example electrical motor pulley shaft and wind turbine. 
a new single phase fefsm with segmental rotor for conventional fan. 
diverse topology of three phase and single phase field excitation flux switching machines fefsms that have be develop recently have several advantage such as variable flux capability and the single piece structure of rotor suitable for high speed application. 
however overlap winding between armature and field excitation coil fec have cause the problem of high end coil increase size of motor as well as high copper loss. 
therefore a new topology of single phase segment rotor fefsm with 12s 6p configuration be present with the advantage of non overlapping armature and fec winding less weight low copper loss and high efficiency. 
the performance include coil test back emf flux strengthening flux line and torque and power versus speed of machine be analyze by 2d finite element analysis fea. 
a 3d solidworks and computer numerical control cnc machine be use for motor prototype fabrication process and the performance be validate experimentally. 
the fundamental back emf generate at 500rpm and 3000rpm be 2.75v and 16.3v respectively which be close to the simulation result while the predict torque show a good agreement between simulation and experiment. 
as conclusion the propose fefsm have be able to be apply for conventional fan. 
analytical modeling of a flux switch permanent magnet machines. 
flux switch permanent magnet machine have attract considerable attention due to their simple and robust structure easy heat dissipation high torque density and suitability for high speed operation. 
to enhance these propriety we present in this paper an analytical model for prediction of the magnetic field for a three phase 12 stator slot and 10 rotor tooth 12/10 flux switch permanent magnet machine. 
the propose model be base on an two dimensional analytical solution of maxwell equation in low permeability region use the variable separation method. 
the global quantity can be derive from the local magnetic field expression. 
the computation provide exact result in relatively short resolution time. 
finally the accuracy of the model be validate by compare the analytical result with those obtain with a finite element analysis. 
investigation of field to armature slot area ratio on torque ripple in hefs machine. 
in order to adjust the airgap fix flux density cause by permanent magnet the hybrid excited flux switch machine be propose by use both pm and dc wind excitation on stator structure. 
in e core hybrid excited flux switch machine both the armature winding and excitation wind be locate in stator slot. 
in fix current density and fix copper loss field to armature slot area ratio will affect on machine develop electromagnetic torque. 
in this paper the effect of variation of this ratio on the develop torque and torque ripple be investigate for a prototype fspm machine employ finite element analysis method by modeling of the motor with various field to armature slot area ratio. 
design guidelines of bearingless pmsm with two separate poly phase winding. 
this document provide design guideline for bearingless permanent magnet synchronous motors pmsm which generate torque and lateral suspension force via two separate poly phase winding. 
the step by step bearingless motor development process be accompany by explicit analytical formula use in the dimensioning of the magnetic circuit and in the calculation of magnetic field quantity like flux density in the air gap electromagnetic torque and levitation force. 
the design procedure be exemplify on a prototype with a rate mechanical power of 40 kw reach at 40 000 rpm and have a hybrid five axis levitation system compose of a bearingless unit and a combined axial radial magnetic bearing. 
radial force control of multi sector permanent magnet machines. 
the paper presentsn alternative radial force control technique for a multi sector permanent magnet machine mspm. 
radial force control have be widely investigate for a variety of bearingless machine and can be also apply to conventional pmsm aim the reduction of the mechanical stress on the bearing as well as reduce the overall vibration. 
traditional bearingless motor rely on two independent set of winding dedicate to torque and suspension respectively. 
the work present in this paper take advantage of the spatial distribution of the winding set within the stator structure towards achieve a controllable net radial force. 
in this paper the alpha beta axis model for the mspm and the theoretical investigation of the force production principle be present. 
a novel force control methodology base on the single value decomposition svd technique be describe. 
the predict performance of the mspm have be validate use finite element simulation and benchmarke against state of the art control technique. 
short term duty electrical machines. 
this paper present a design of a short term duty electrical machine work in an extreme environment consist of 80 degree c ambient temperature and altitude of over 30,000 m. 
high power density be a key factor in the design wherein the machine s operation be require only for a short duty. 
the requirement of high power to weight and power to volume lead to a permanent magnet pm machine design which be then optimize. 
different slot and pole combination with both concentrated and distribute winding arrangement be consider. 
for the optimization a genetic algorithm ga be use where analytical electromagnetic and thermal model be adopt together with finite element fe method. 
it be show that the adopt thermal model provide sufficient accuracy when predict temperature rise within the wind. 
it be also show that the design be thermally limited where the pole number be limit by volt amp draw from the converter. 
the design consist of a high slot number allow for improve the heat dissipation from the machine and thus the weight can be minimize for the give torque production. 
performance comparison of different concentrated wind configuration for five phase pmsg in normal and faulty mode in flux weakening operation for fixed pitch tidal turbine. 
this paper aim to evaluate some configuration of winding for low speed high power five phase permanent magnet synchronous generator pmsg associate to fix pitch tidal turbine. 
several fractional slot concentrated windings have be consider and compare for these specification. 
the propose structure be compare in term of torque vs speed characteristic include flux weakening operation in healthy and faulty mode. 
in fault mode the failure of one and two phase be consider. 
the result show that concentrated winding can be particularly useful for these particular specification. 
square current space vector signature analysis for rotor fault detection in wound rotor induction machine. 
fault detection in induction machine be commonly realize through motor current signature analysis. 
in case of wound rotor induction machine rotor fault the amplitude of the inverse sequence harmonic component  sf of the rotor current space vector be monitor in order to sense its variation. 
however motor current signature analysis be limit by some drawback. 
in fact under transient operating condition an efficient fast fourier transform can not be make since slip or frequency vary and so the amplitude of the harmonic component  sf. 
in this paper a new technique base on the square current space vector signature analysis scssa be propose for rotor fault detection in wound rotor induction machines operate under time vary condition. 
the performance of the propose approach be confirm by simulation and experimental result. 
the propose technique can be easily embed in the digital control system for modern wind power plant. 
aspect concern verification method and rigidity increment of complex technological system. 
any technological process and technology aim a quality and precise product something almost impossible without high rigidity machine tool equipment and component. 
therefore from the design phase it be very important to create structure and machine with high stiffness characteristic. 
at the same time increase the stiffness should not raise the material cost. 
search this midpoint between high rigidity and minimum expense lead to investigation and check in structural component through various method and technique and sometimes quite advanced method. 
in order to highlight some aspect concern the significance of the mechanical equipment rigidity the finite element method and an analytical method base on the use mathcad software be use by take into consideration a subassembly of a grind machine. 
graphical representation be elaborate offer a more complete image about the stress and deformation able to affect the consider mechanical subassembly. 
hydraulic cushion type overload protection devices usable in mechanical presses. 
a patent \study. 
the possible consequence of machine tool overload be well know. 
in order to prevent such machine tool be equip with various overload protection device. 
mechanical press intensively strain machine tool be typically equip with three protection system against accidental access to the work area during machine deployment against torque overload and force overload. 
force overload protection system include either destructible part and be use in small to medium nominal force mechanical press or non destructible one use mostly in medium to large nominal force h frame press. 
a particular class of force overload protection system without destructible part be hydraulic cushion type device. 
while such system do not necessarily cause the machine to stop the slide s stroke do not reach the initial dead centre and consequently can not exert the design technological force on the workpiece. 
by a patent study reference 19 relevant patent the paper capture both the diversity of the constrictive solution of hydraulic cushion type protection device and their positioning modality within the structure of a mechanical press. 
an important aim of the study be to highlight the reserve of creativity exist in this field at least from the viewpoint of the hydraulic cushion positioning as well as to emphasize the essential requirement of a relative motion between the mobile and the fix part of the tool a motion of opposite sense to that of the slide crank mechanism. 
decision method for optimal selection of warehouse material handling strategy by production company. 
adequate establishment and operation of warehouse logistic determine the company competitiveness significantly because it effect greatly the quality and the selling price of the good that the production company produce. 
in order to implement and manage an adequate warehouse system adequate warehouse position stock management model warehouse technology motivated work force commit to process improvement and material handling strategy be necessary. 
in practical life company have pay small attantion to select the warehouse strategy properly. 
although it have a major influence on the production in the case of material warehouse and on smooth costumer service in the case of finish good warehouse because this can happen with a huge loss in material handling. 
due to the dynamically change production structure frequent reorganization of warehouse activity be need on what the majority of the company react basically with no reaction. 
this work present a simulation test system frame for eligible warehouse material handling strategy selection and also the decision method for selection. 
artificial immune algorithm implementation for optimize multi axis sculptured surface cnc machining. 
this paper present the result obtain by the implementation of an artificial immune algorithm to optimize standard multi axis tool path apply to machine free form surface. 
the investigation for its applicability be base on a full factorial experimental design address the two additional axis for tool inclination as independent variable whilst a multi objective response be formulate by take into consideration surface deviation and tool path time objective assess directly from computer aid manufacturing environment a standard sculpture part be develop by scratch consider its benchmark specification and a cut edge surface machine tool path be apply to study the effect of the pattern formulate when dynamically incline a toroidal end mill and guide it towards the feed direction under fix lead and tilt inclination angle. 
the result obtain form the series of the experiment be use for the fitness function creation the algorithm be about to sequentially evaluate. 
it be find that the artificial immune algorithm employ have the ability of attain optimal value for inclination angle facilitate thus the complexity of such manufacturing process and ensure full potential in multi axis machining modelling operation for produce enhance cnc manufacturing program. 
result suggest that the propose algorithm implementation may reduce the mean experimental objective value to 51.5. 
ring tool profiling graphical method in catia base on generating trajectory theorem. 
machining of thread have high dimension and multiple start by turn be a challenging problem. 
an alternative possibility be to machine they by mill. 
the most productive milling solution be when use tool with inner active surface namely ring tool. 
in the case of thread with multiple start the reciprocal enwrap profile of the ring tool be considerably different to the shape of the thread axial normal section. 
in this paper we suggest a methodology to profile the generator ring tool base on a complementary theorem from enwrap surface field. 
at the same time a graphical algorithm aim to find the ring tool profile develop in catia graphical environment have be apply in the concrete case of a trapezoidal thread. 
the graphical profiling solution be present in comparison to an analytical solution in order to test the result precision. 
the graphical profiling method prove to be rigorous easy to apply and highly intuitive. 
the influence of machined surface microgeometry on mechanical hydraulic removal mechanism at ultrasonically aid edm finishing. 
the paper deal with finite element method fem of mechanical hydraulic component of material removal mechanism at electrical discharge machining aid by ultrasonic edm+us finishing. 
the influence of two type of crater shape produce by command and relaxation pulse be analyze. 
base on fem result the ratio between depth and crater diameter be correlate with the consumed power on ultrasonic chain in order to minimize the edmed surface roughness. 
increase productivity and cost optimization in cnc manufacturing. 
the advantage of the technological assist design consist in easy modification of the machining technology for obtain machine alternation tool change work parameter variation or the modification of load to which the tool be subject. 
by determine tool movement inside machining and by use tool related move speed need for both positioning and manufacturing we be able to compute the required machining time for each component of the machining operation in progress. 
the present study describe a cost optimization model for machine operation which use the follow component machine and its operator relate cost set up and adjustment unproductive cost idle state direct and indirect cost. 
by use manufacturing technology assist design procedure we may obtain various variant for the technological model by modify the machining strategy tooling working regime or the machine tool that be use. 
simulate those variant allow we to compare and establish the optimal manufacturing variant as well as the most productive one. 
investigation regard the evaluation of specific intellectual property production risk within quality management system. 
this paper be a theoretical research concern method for risk assessment of specific intellectual property production risk that be identify in the product achievement stage within the quality management system. 
in order to realize this we will start by identify the specific intellectual property production risk and by propose some new calculate formula for minimalize their negative effect. 
the theoretical model propose assessment of specific intellectual property production risk will be realize base on three hypothetical situation. 
this study intend to reduce the intellectual property risk identify in the production process of commercial society that have an industrial profile. 
the use of statistical process control to improve the accuracy of turn. 
the present work deal with the turning process improvement use mean of statistical process control. 
the approach on improvement be relate to the fact that several method be use in order to achieve quality define by technical specification. 
the experimental datum be collect during identical and successive manufacturing process of turning of an electrical motor shaft. 
the initial process present some difficulty because many machined part be nonconforme as a consequence of reduce precision of turn. 
the article be use datum collect in turning process present through histogram and control chart to improve the accuracy in order to reduce scrap. 
finite time stabilization for discontinuous interconnected delayed systems via interval type two t s fuzzy model approach. 
this paper investigate the finite time stabilization for a class of interconnect system with nonlinear discontinuous interconnection in which the time vary delay be consider. 
by utilize the universal approximation ability of the fuzzy model a unified interval type two it2 takagi sugeno t s fuzzy model base interconnect delay system be provide. 
then in order to solve the existence of solution for the concerned system with discontinuous right hand side the filippov solution be define base on differential inclusion theory and set value analysis. 
furthermore by the it2 t s fuzzy model approach a delay state feedback controller equip with discontinuous term and time vary delay term be propose. 
accord to the classical finite time stability theory and generalize lyapunov approach finite time stabilization for the discontinuous interconnect delay system be achieve and the estimate of settle time be give. 
moreover when the detailed information of time vary delay be unknown the finite time stabilization be also realize via another improved controller which only depend upon the upper bound of time vary delay. 
finally the propose methodology be illustrate by a numerical example. 
consensus building with individual consistency control in group decision make. 
the individual consistency and the consensus degree be two basic measure to conduct group decision make with reciprocal preference relation. 
the exist framework to manage individual consistency and consensus degree have be investigate intensively and follow a common resolution scheme compose by the two phase the consistency improve process and the consensus reach process. 
but in these framework the individual consistency will often be destroy in the consensus reach process lead to repeat the consistency improve process which be time consume. 
in order to avoid repeat the consistency improve process a consensus reach process with individual consistency control be propose in this paper. 
this novel consensus approach be base on the design of an optimization base consensus rule which can be use to determine the adjustment range of each preference value guarantee the individual consistency across the process. 
finally theoretical and numerical analysis be both use to justify the validity of our proposal. 
fuzzy rule base domain adaptation in homogeneous and heterogeneous space. 
domain adaptation aim to leverage knowledge acquire from a related domain call a source domain to improve the efficiency of complete a prediction task classification or regression in the current domain call the target domain which have a different probability distribution fromthe source domain. 
although domain adaptation have be widely study most exist research have focus on homogeneous domain adaptation where both domain have identical feature space. 
recently a new challenge propose in this area be heterogeneous domain adaptation where both the probability distribution and the feature space be different. 
moreover in both homogeneous and heterogeneous domain adaptation the great effort and major achievement have be make with classification task while successful solution for tackle regression problem be limited. 
this paper propose two innovative fuzzy rule base method to deal with regression problem. 
the first method call fuzzy homogeneous domain adaptation handle homogeneous space while the second method call fuzzy heterogeneous domain adaptation handle heterogeneous space. 
fuzzy rule be first generate from the source domain through a learning process these rule also know as knowledge be then transfer to the target domain by establish a latent feature space to minimize the gap between the feature space of the two domain. 
through experiment on synthetic dataset we demonstrate the effectiveness of both method and discuss the impact of some of the significant parameter that affect performance. 
experiment on real world dataset also show that the propose method improve the performance of the target model over an exist source model or a model build use a small amount of target datum. 
a novel asynchronous control for artificial delay markovian jump systems via output feedback slide mode approach. 
a novel asynchronous control for a class of markovian jump system mjss via output feedback slide mode approach with an artificial time delay be propose. 
the asynchronous control strategy be adopt owe to the nonsynchronization between the control system and the controller. 
in some practical application the state variable be often difficult to be measure directly from the outside of the system which make the implementation of state feedback technique more complex. 
however the output information be always accessible to the system. 
therefore an asynchronous output feedback slide controller where an artificial time delay be introduce in the synthesis of the slide surface for mjs be design to guarantee the slide mode dynamic satisfy the reach condition and a sufficient condition be derive to ensure the resultant system exponentially stable. 
besides a program of optimization be give to optimize the artificial delay time. 
finally a numerical simulation and a practical application be give to validate the effectiveness of the propose technique. 
exponential stability passivity and dissipativity analysis of generalized neural networks with mixed time varying delay. 
in this paper we analyze the exponential stability passivity and d g r) gamma dissipativity of generalize neural network gnns include mixed time vary delay in state vector. 
novel exponential stability passivity and d g r) gamma dissipativity criterion be develop in the form of linear matrix inequality for continuous time gnn by construct an appropriate lyapunov krasovskii functional lkf and apply a new weight integral inequality for handle integral term in the time derivative of the establish lkf for both single and double integral. 
some special case be also discuss. 
the superiority of employ the method present in this paper over some exist method be verify by numerical example. 
time dependent genetic algorithm and its application to quadruped s locomotion. 
genetic algorithm gas be widely use in machine learning and optimization. 
this paper propose a time dependent genetic algorithm tdga base on real code genetic algorithm rcga to improve the convergence performance of function over time such as a foot trajectory. 
tdga have several distinguish feature when compare with traditional rcga. 
first individual be arrange over time and then the individual be optimize in sequence. 
second search space of design variable be newly comprise of process of reduction for search space. 
third the search space for crossover operation be expand to avoid local minima trap that can occur in new search space up to the previous search space before perform any reduction of search space and boundary mutation operation be perform to the new search space. 
computer simulation be implement to verify the convergence performance of the robot locomotion optimize by tdga. 
then tdga optimize the desire foot trajectory of quadrupe robot that climb up a slope and the impedance parameter of admittance control so that quadrupe robot can trot stably over irregular terrain. 
simulation result clearly represent that the convergence performance be improve by tdga which also show that tdga could be broadly use in robot locomotion research. 
c 2018 elsevier b.v. 
all right reserve. 
a context aware model for autonomous agent stochastic planning. 
markov decision processes mdp be not able to make use of domain information effectively due to their representational limitation. 
the lacking of element which enable the model be aware of context lead to unstructured representation of that problem such as raw probability matrix or list. 
this cause these tool significantly less efficient at determine a useful policy as the state space of a task grow which be the case for more realistic problem having localize dependency between state and action. 
in this paper we present a new state machine call context aware markov decision process ca mdp base on mdp for the purpose of represent markovian sequential decision make problem in a more structured manner. 
ca mdp change and augment mdp facility by integrate causal relationship between action and state thereby enable structural hence compact if possible representation of the task. 
to show the expressive power of ca mdp we give the theoretical bound for complexity of conversion between mdp and ca mdp to demonstrate the expressive power of ca mdp. 
next to generate an optimal policy from ca mdp encoding by exploit those newly define facility we devise a new solver algorithm base on value iteration vi call context aware value iteration ca vi. 
although regular dynamic programming dp base algorithm be successful at effectively determine optimal policy they do not scale well with respect to state action space make both the mdp encoding and related solver mechanism practically unusable for real life problem. 
our solver algorithm get the power of overcome the scalability problem by integrate the structural information provide in ca mdp. 
first we give theoretical analysis of ca vi by examine the expect number of bellman update be perform on arbitrary task. 
finally we present our conduct experiment on numerous problem with important remark and discussion on certain aspect of ca vi and ca mdp to justify our theoretical analysis empirically and to assess the real performance of ca vi with ca mdp formulation by analyse the execution time by check how close it get to the practical minimum runtime bind with respect to vi performance with mdp encoding of the same task. 
c 2018 elsevier b.v. 
all right reserve. 
mean centre clustering improve melody classification use time  and frequency domain supervised clustering. 
this paper report a new approach for cluster melody in audio music collection of both western as well as indian background and its application to genre classification. 
a simple yet effective new classification technique call mean centre clustering mcc be discuss. 
the propose technique maximize the distance between different cluster and reduce the spread of datum in individual cluster. 
the use of mcc as a preprocessing technique for conventional classifier like artificial neural network ann and support vector machine svm be also demonstrate. 
it be observe that the mcc base classifier outperform the classifier base on conventional technique such as principal component analysis pca and discrete cosine transform dct. 
extensive simulation result obtain on different data set of western genre ismir and classical indian ragas be use to validate the efficiency of propose mcc base cluster algorithm and ann svm classifier base on mcc. 
as an additional endeavour the performance of mcc on preprocesse datum from pca and dct be study. 
base on simulation result it be conclude that the application of mcc on dct coefficient result in the high overall classification success rate over different architecture of the classifier. 
multi objective optimization for design under uncertainty problem through surrogate modeling in augmented input space. 
multi objective design under uncertainty problem that adopt probabilistic quantity as performance objective and consider their estimation through stochastic simulation be examine in this paper focus on development of a surrogate modeling framework to reduce computational burden for the numerical optimization. 
the surrogate model be formulate to approximate the system response with respect to both the design variable and the uncertain model parameter so that it can simultaneously support both the uncertainty propagation and the identification of the pareto optimal solution. 
krige be choose as the metamodel and its probabilistic nature its ability to offer a local estimate of the prediction error be leverage within different aspect of the framework. 
to reduce the number of simulation for the expensive system model an iterative approach be establish with adaptive characteristic for control the metamodel accuracy. 
at each iteration a new metamodel be develop utilize all available training point. 
a new pareto front be then identify utilize this surrogate model and be compare for assess stop criterion to the front that be identify in the previous iteration. 
this comparison utilize explicitly the potential error associate with the metamodel prediction. 
if stop criterion be not achieve a set of refinement experiment new training point be identify and process proceed to the next iteration. 
a hybrid design of experiment be consider for this refinement with a dual goal of global coverage and local exploitation of region of interest separately identify for the design variable and the uncertain model parameter. 
topology optimization of channel cool structure consider thermomechanical behavior. 
a topology optimization method be present to design straight channel cool structure for efficient heat transfer and load carry capability. 
the optimization be perform on the structural cross section that consist of solid void and fluid coolant. 
a simplified convective heat transfer model be use to simulate the flow characteristic in the channel with a low computational cost. 
besides a continuous design dependent surface base penalty approach be propose to ensure a meaningful inlet fluid temperature during the continuous process of the fluid topology alteration. 
couple thermomechanical problem be solve to account for the engineering requirement on the uniformity of temperature and structural deformation tolerance. 
furthermore a phase interface constraint be implement to prevent unrealistic boundary that adjoin the liquid to the void or to the outer boundary of a design domain. 
numerical example of design a lightweight cool support frame and a hot stamp tool structure subject to uniform or non uniform thermomechanical load be give to demonstrate its applicability. 
verification result of 3d structure by a full blow turbulent fluid simulation show that the propose approach be effective in yield channel cool structure with optimize heat transfer capability and well control structural deformation. 
distribute event trigger control for global consensus of multi agent system with input saturation. 
the global consensus problem for first order continuous time multi agent system with input saturation be consider. 
in order to reduce the overall need of communication and system update we propose an event trigger consensus protocol and a trigger law which do not require any a priori knowledge of global network parameter. 
it be show that zeno behavior be exclude for these system and that the underlie direct graph have a direct span tree be a necessary and sufficient condition for global consensus. 
we use a new lyapunov function to show the sufficient condition and it inspire the trigger law. 
numerical simulation be provide to illustrate the effectiveness of the theoretical result. 
c 2018 elsevier ltd. 
all right reserve. 
on line detection of qualitative dynamical change in nonlinear system the resting oscillation case. 
motivate by neuroscience application we introduce the concept of qualitative detection that is the problem of determine on line the current qualitative dynamical behavior e.g. resting oscillating bursting spike etc of a nonlinear system. 
the approach be think for system characterize by i large parameter variability and redundancy ii a small number of possible robust qualitatively different dynamical behavior and iii the presence of sharply different characteristic timescale. 
these property be omnipresent in neuroscience and hamper quantitative modeling and fitting of experimental datum. 
as a result novel control theoretical strategy be need to face neuroscience challenge like on line epileptic seizure detection. 
the propose approach aim at detect the current dynamical behavior of the system and whether a qualitative change be likely to occur without quantitatively fit any model nor asymptotically estimate any parameter. 
we talk of qualitative detection. 
we rely on the qualitative property of the system dynamic extract via singularity and singular perturbation theory to design low dimensional qualitative detector. 
we introduce this concept on a general class of singularly perturb system and then solve the problem for an analytically tractable class of two dimensional system with a single unknown sigmoidal nonlinearity and two sharply separate timescale. 
numerical result be provide to show the performance of the design qualitative detector. 
c 2018 elsevier ltd. 
all right reserve. 
mean field production output control with sticky price nash and social solution. 
this paper present an application of mean field control to dynamic production optimization with sticky price and adjustment cost. 
both noncooperative and cooperative solution be consider. 
by solve auxiliary limit optimal control problem subject to consistent mean field approximation two set of decentralize strategy be obtain and far show to asymptotically attain nash equilibrium and social optima respectively. 
a numerical example be give to compare market price firm output and cost under the two solution framework. 
c 2018 elsevier ltd. 
all right reserve. 
distribute stabilization of korteweg de vries burgers equation in the presence of input delay. 
we consider distribute stabilization of one d korteweg de vries burgers kdvb equation in the presence of constant input delay. 
the delay may be uncertain but bound by a know upper bound. 
on the basis of spatially distribute either point or average measurement we design a regionally stabilize controller apply through distribute in space shape function. 
the exist lyapunov krasovskii functional for heat equation that depend on the state derivative be not applicable to kdvb equation because of the third order partial derivative. 
we suggest a new lyapunov krasovskii functional that lead to regional stability condition of the closed loop system in term of linear matrix inequality lmis. 
by solve these lmi an upper bound on the delay that preserve regional stability can be find together with an estimate on the set of initial condition start from which the state trajectory of the system be exponentially converge to zero. 
this estimate include a priori lyapunov base bound on the solution of the open loop system on the initial time interval of the length of delay. 
numerical example illustrate the efficiency of the method. 
c 2018 elsevier ltd. 
all right reserve. 
free finite horizon lqr a bilevel perspective and its application to model predictive control. 
we consider linear quadratic optimal control problem with free final time and terminal state constraint and propose a solution procedure that be particularly useful for online feedback control in a model predictive control mpc framework. 
the procedure avoid the standard time transformation which transform the problem into an equivalent but non convex optimal control problem on a fix time horizon. 
the transformed problem typically suffer from many local minima which might cause instability in online optimization task like lqr or model predictive control. 
to avoid this drawback of the time transformation we develop a method from the viewpoint of bilevel optimal control which be beneficial especially in online control task. 
the novelty of the approach be the optimal final time tracking procedure for which we exploit a property of the hamiltonian function. 
to this end we show that within the continuous time closed loop control system the optimal final time linearly decrease in time as one could intuitively expect. 
finally numerical experiment support the effectiveness of the propose algorithm. 
c 2018 elsevier ltd. 
all right reserve. 
port hamiltonian base optimal power flow algorithm for multi terminal dc network. 
in this paper an algorithm for solve the optimal power flow problem for multi terminal dc network base on the gradient method be propose. 
the aim be seek the optimal point subject to voltage current and power constraint. 
the algorithm be describe by a continuous time port hamiltonian model and the inequality constrain be include by the use of barrier function. 
the dynamic of the algorithm be study and stability condition be obtain. 
finally the method be use for the offshore wind integration grid in the north sea and the interconnection with the network dynamic be test by mean of numerical simulation. 
evolve behavior for bound flow tracking control of second order dynamical system. 
a two stage methodology for the development of nonlinear analytical controller for track control in second order dynamical system subject to flow variable constraint be propose. 
it extend the concept of behavior base control to describe the system as the summation of its unforced force and learn behavior. 
while the unforced behavior be characterize by its analytical dynamical model the forced and learn behavior be introduce in the system by mean of a control theory base controller and an evolutionary learning process base in the genetic programming paradigm. 
the integration of both approach in a unified framework allow the system to exhibit a good tracking performance while keep the flow variable bound to a desire value parametrize as a boundary interval. 
a set of 180993 learned behavior which preserve asymptotic convergence to the desire behavior while achieve a bound flow variable be discover by the evolutionary process. 
simulation result show the effectiveness of the find nonlinear tracking controller with the high fitness value as well as the one with the low structural complexity. 
a performance comparison between numerical simulation and real time experiment for a mechatronic prototype be also provide to illustrate the feasibility of the propose method in real world application. 
job shop schedule with consideration of float breaking time under uncertainty. 
there be several practical case in where the attendance of operator during performance of operation be mandatory. 
in such case during the resting time the operator can not leave the job until the relevant operation be finish. 
on the other hand usually some fix time frame be assign to rest purpose during a work day and therefore the operation must be schedule in such a manner that the operator could have enough time to rest in the arrange time frame. 
moreover the processing time be under uncertainty in real condition. 
the present paper intend to deal with a new variant job shop scheduling problem. 
for this reason a mathematical model be present and the robust modification be discuss. 
next a branch and bind algorithm and two heuristic algorithm base on the beam search bs and particle swarm optimization pso which be well adjusted to scheduling problem be employ to solve the practical case. 
the effectiveness of the propose algorithm be then validate by compare with optimum solution use small and medium size instance and simulate anneal algorithm as the most common one for scheduling problem and a strong lower bind use medium and large size instance. 
a surrogate optimization base mechanism for resource allocation and routing in network with strategic agents. 
we consider a mechanism design problem for the joint flow control and multipath route in informationally decentralize network with strategic agent. 
base on a surrogate optimization approach we propose an incentive mechanism that strongly implement the social welfare maximizing outcome in nash equilibrium. 
this mechanism possess several other desirable property include individual rationality and budget balance at equilibrium. 
more importantly in contrast to the exist literature on the network resource allocation mechanism the propose mechanism be dynamically stable mean that the nash equilibrium ne of the game induce by the mechanism can be learn by the agent in a decentralized manner. 
to establish dynamic stability we propose a decentralized iterative process that always converge to a ne of the game induce by the mechanism provide that all strategic agent follow the process. 
to the good of our knowledge this be the first incentive mechanism that simultaneously possess all the above mention property. 
a regularize variable projection algorithm for separable nonlinear least square problem. 
separable nonlinear least square snlls problem arise frequently in many research field such as system identification and machine learning. 
the variable projection vp method be a very powerful tool for solve such problem. 
in this paper we consider the regularization of ill condition snlls problem base on the vp method. 
select an appropriate regularization parameter be difficult because of the nonlinear optimization procedure. 
we propose to determine the regularization parameter use the weighted generalize cross validation method at every iteration. 
this make the original objective function change during the optimization procedure. 
to circumvent this problem we use an inequation to produce a consistent demand of decrease at successive iteration. 
the approximation of the jacobian of the regularize problem be also discuss. 
the propose regularize vp algorithm be test by the parameter estimation problem of several statistical model. 
numerical result demonstrate the effectiveness of the propose algorithm. 
the polynomial approach to the lq non gaussian regulator problem through output injection. 
in this paper an improved approach for the solution of the regulator problem for linear discrete time dynamical system with non gaussian disturbance and quadratic cost functional be propose. 
it be know that a suboptimal recursive control can be derive from the classical linear quadratic gaussian lqg solution by substitute the linear filter part with a quadratic or in general polynomial filter. 
however we show that when the system be not asymptotically stable the polynomial control do not improve over the classical lqg solution due to the lack of the internal stability of the polynomial filter. 
in order to enlarge the class of system that can be control we propose a new method base on a suitable rewriting of the system by mean of an output injection term. 
we show that this allow we to overcome the problem and to design a polynomial optimal controller also for non asymptotically stable system. 
numerical result show the effectiveness of the method. 
newton type alternating minimization algorithm for convex optimization. 
we propose a newton type alternate minimization algorithm nama for solve structured nonsmooth convex optimization problem where the sum of two function be to be minimize one be strongly convex and the other compose with a linear mapping. 
the proposed algorithm be a line search method over a continuous real value exact penalty function for the correspond dual problem which be compute by evaluate the augment lagrangian at the primal point obtain by alternate minimization. 
as a consequence nama rely on exactly the same computation as the classical alternate minimization algorithm ama also know as the dual proximal gradient method. 
under standard assumption the propose algorithm converge with global sublinear and local linear rate while under mild additional assumption the asymptotic convergence be superlinear provide that the search direction be choose accord to quasi newton formula. 
due to its simplicity the propose method be well suited for embed application and large scale problem. 
experiment show that use limited memory direction in nama greatly improve the convergence speed over ama and its accelerate variant. 
singular arcs in optimal control of continuous time bimodal switch linear systems. 
this paper consider a singular problem in optimal control of continuous time bimodal switch linear system. 
a relaxed switch system with a continuous value switching signal be consider and the representation of singular control and singular arc be derive. 
the similarity in the structure between the singular control and a stabilize switch law be reveal and an approximation of the singular control by a well define switching signal be address. 
the result be demonstrate by numerical simulation. 
exploit machine learning against on chip power analysis attacks tradeoffs and design considerations. 
modern power analysis attack paa and exist countermeasure pose unique challenge on the design of simultaneously secure power efficient and high performance ic. 
in a typical paa power information be collect with a monitoring circuit connect to the compromise device. 
the non typical voltage variation induce on a power distribution network pdn by such a malicious probing be sense with on chip sensor and exploit in this paper for detect paa in real time use statistical analysis. 
a closed form expression for the voltage variation cause by malicious probing be provide. 
guideline with respect to the pdn characteristic and number of sensor be propose for secure power delivery. 
the paa detection system be design in a 45 nm standard cmos process. 
base on the simulation result a paa on an ibm benchmarke microprocessor be detect with the accuracy of 88 with 30 on chip sensor. 
power overhead of 0.34 and 14.3 be demonstrate in respectively the ibm microprocessor and a typical advanced encryption standard system. 
in a practical cryptographic device security sensitive pdn region can be identify significantly reduce the number of the on chip sensor. 
reduced order observer base sliding mode control for singular markovian jump system with time vary transition rate. 
this paper present a stabilisation problem for singular markovian jump system with time vary transition rate base on a reduce order observer. 
to design the reduce order observer a canonical equivalent form for singular markovian jump system be give. 
by the output variable of the equivalent form of singular markovian jump system and the state of the reduce order observer an integral slide surface be design. 
then the sufficient condition for the stochastic admissibility of slide motion be give in which the time vary transition rate be handle by the quantize method. 
furthermore a slide mode controller be develop such that the system can be drive to the slide surface in finite time. 
finally the effectiveness and superiority of the obtain result be illustrate by two example a numerical example and a practical example of dc motor model respectively. 
consensus of discrete time multiagent systems with input delay by truncated pseudo predictor feedback. 
the consensus problem for multiagent system mass describe by discrete time linear system with multiple input delay be investigate. 
under two reasonable assumption a truncate pseudo predictor feedback tppf approach be establish to solve the consensus problem. 
the propose tppf protocol allow arbitrarily large yet bound delay and be easy to implement in practice since they be finite dimensional and only use the relative current state information of neighboring agent. 
moreover the propose protocol can also achieve semi global consensus of mass if the actuator be subject to saturation. 
a numerical example be give to illustrate the effectiveness of the propose approach. 
hough forest with optimize leaves for global hand pose estimation with arbitrary posture. 
vision base hand pose estimation be important in human computer interaction. 
while many recent work focus on full degree of freedom hand pose estimation robust estimation of global hand pose remain a challenging problem. 
this paper present a novel algorithm to optimize the leaf weight in a hough forest to assist global hand pose estimation with a single depth camera. 
different from traditional hough forest we propose to learn the vote weight store at the leaf node of a forest in a principled way to minimize average pose prediction error so that ambiguous vote be largely suppress during prediction fusion. 
experiment show that the propose method largely improve pose estimation accuracy with optimize leaf weight on both synthesis and real dataset and perform favorably compare to state of the art convolutional neural network base method. 
on real world depth video the propose method demonstrate improve robustness compare to several other recent hand tracking system from both industry and academy. 
moreover we utilize the propose method to build virtual augment reality application to allow user to manipulate and examine virtual object with bare hand. 
a control theoretic assessment of interventions during drinking event. 
this paper employ control theoretic tool to provide guideline for in situ intervention aim at reduce high risk alcohol consumption at drinking event. 
a dynamical direct network model of a drinking event with external intervention suitable for mathematical analysis and parameter estimation use field datum be propose with insight from pharmacokinetic and psychology. 
later a characterization of a bind on blood alcohol content bac trajectory be obtain via lyapunov stability analysis and structural controllability guarantee be obtain via a graph theoretic method. 
we use the degree of controllability give to be the trace of the system s controllability gramian as a metric to compare the viability of network node for intervention base on theoretic and heuristic centrality measure. 
result of numerical example of bar and party inform by field datum and the stability and controllability result suggest that intervene in the environment in wet bar while target influential individual with high alcohol consumption motivation in private party efficiently yield low peak bac level in individual at the drinking event. 
quasi synchronization of delayed chaotic memristive neural networks. 
we study the problem of master slave synchronization of two delay memristive neural network mnn. 
different from most previous paper memristor be regard as uncertain continuous time vary parameter and mnn be model by neural network nns with continuous time vary parameter and polytopic uncertainty. 
thus synchronization of two delay mnn be convert into synchronization of delay nn with uncertain parameter mismatch. 
quasi synchronization criterion be derive by lyapunov function and inequality technique. 
it be show that give a predetermine error bind quasi synchronization of two delay chaotic mnn can be achieve provide that the pin strength be large than a threshold. 
in the end a numerical example be provide to illustrate the effectiveness of the derive result. 
optimization of distributions difference for classification. 
in this paper we introduce a new classification algorithm call the optimization of distribution difference odd. 
the algorithm aim to find a transformation from the feature space to a new space where the instance in the same class be as close as possible to one another whereas the gravity center of these class be as far as possible from one another. 
this aim be formulate as a multiobjective optimization problem that be solve by a hybrid of an evolutionary strategy and the quasi newton method. 
the choice of the transformation function be flexible and could be any continuous space function. 
we experiment with a linear and a nonlinear transformation in this paper. 
we show that the algorithm can outperform eight other classification method namely naive bayes support vector machine linear discriminant analysis multilayer perceptron decision tree and k near neighbor and two recently propose classification method in 12 standard classification datum set. 
our result show that the method be less sensitive to the imbalanced number of instance compare with these method. 
we also show that odd maintain its performance well than other classification method in these data set and hence offer a well generalization ability. 
deep convolutional identifier for dynamic modeling and adaptive control of unmanned helicopter. 
helicopter be complex high order and timevarye nonlinear system strongly couple with aerodynamic force engine dynamic and other phenomenon. 
therefore it be a great challenge to investigate system identification for dynamic modeling and adaptive control for helicopter. 
in this paper we address the system identification problem as dynamic regression and propose to represent the uncertainty and the hidden state in the system dynamic model with a deep convolutional neural network. 
particularly the parameter of the network be directly learn from the real flight datum of aerobatic helicopter. 
since the deep convolutional model have a good performance for describe the dynamic behavior of the hidden state and uncertainty in the flight process the propose identifier manifest strong robustness and high accuracy even for untrained aerobatic maneuver. 
the effectiveness of the propose method be verify by various experiment with the real world flight datum from the stanford autonomous helicopter project. 
consequently an adaptive flight control scheme include a deep convolutional identifier and a backstepping base controller be present. 
the stability of the flight control scheme be rigorously prove by the lyapunov theory. 
it reveal that the tracking error for both the position and attitude of unmanned helicopter asymptotic converge to a small neighborhood of the origin. 
distribute proximal minimization algorithm for constrained convex optimization over strongly connected network. 
this paper propose a novel distribute proximal minimization algorithm for constrain optimization problem over fix strongly connect network. 
at each iteration each agent update its own state by evaluate a proximal operator of its objective function under a constraint set and compensate the unbalancing due to unidirectional communication. 
we show that the state of all agent asymptotically converge to one of the optimal solution. 
numerical result be show to confirm the validity of the propose method. 
predictive pinning control with communication delays for consensus of multi agent systems. 
in this paper base on the policy of model predictive control a new method of predictive pin control be propose for the consensus problem of multi agent system. 
pin control be a method that the external control input be add to some agent pin node leader. 
by the external control input consensus to a certain target value not the average of the initial state and fast consensus be achieve. 
in the propose method the external control input be calculate by the controller node connect to only pin node. 
since the state of all agent be require in calculation of the external control input communication delay must be consider. 
the propose algorithm include not only calculation of the external control input but also delay compensation. 
the effectiveness of the propose method be present by a numerical example. 
computationally efficient model predictive control for multi agent surveillance systems. 
in this paper a surveillance system by multiple agent which be call a multi agent surveillance system be study. 
a surveillance area be give by an undirected connected graph. 
then the optimal control problem for multi agent surveillance system the optimal surveillance problem be to find trajectory of multiple agent that travel each node as evenly as possible. 
in our previous work this problem be reduce to a mixed integer linear programming problem. 
however the computation time for solve it exponentially grow with the number of agent. 
to overcome this technical issue a new model predictive control method for multi agent surveillance system be propose. 
first a procedure of individual optimization which be a kind of approximate solution method be propose. 
next a method to improve the control performance be propose. 
in addition an event trigger condition be also propose. 
the effectiveness of the propose method be present by a numerical example. 
flash crowd absorber for p2p video streaming. 
this paper propose a method to absorb flash crowd in p2p video streaming system. 
the idea of the propose method be to reduce the time before a newly arrive node become an uploader by explicitly construct a group of newly arrive node call flash crowd absorber fca. 
fca grow continuously while serve a video stream to the member of the group and it be explicitly control so that the upload capacity of the node be fully utilize and it attain a nearly optimal latency of the stream during a flash crowd. 
a numerical comparison with a naive tree base scheme be also give. 
multi layer contribution propagation analysis for fault diagnosis. 
the recent development of feature extraction algorithm with multiple layer in machine learning and pattern recognition have inspire many application in multivariate statistical process monitoring. 
in this work two exist multilayer linear approach in fault detection be review and a new one with extra layer be propose in analogy. 
to provide a general framework for fault diagnosis in succession this work also propose the contribution propagation analysis which extend the original definition of contribution of variable in multivariate statistical process monitoring. 
in fault diagnosis stage the propose contribution propagation analysis for multilayer linear feature extraction algorithm be compare with the fault diagnosis result of original contribution plot associate with single layer feature extraction approach. 
plot of variable contribution obtain by the aforementioned approach on the datum set collect from a simulated benchmark case study tennessee eastman process as well as an industrial scale multiphase flow facility be present as a demonstration of the usage and performance of the contribution propagation analysis on multilayer linear algorithm. 
a survey of the research status of pedestrian dead reckoning systems base on inertial sensors. 
with the development of micro electromechanical system mems miniaturized low power and low cost inertial measurement unit imus have be widely integrate into mobile terminal and smart wearable device. 
this provide the prospect of a broad application for the inertial sensor base pedestrian dead reckon ipdr system. 
especially for indoor navigation and indoor positioning the ipdr system have many unique advantage that other method do not have. 
at present a large number of technology and method for ipdr system be propose. 
in this paper we have analyze and outline the ipdr system base on about 80 document in the field of ipdr in recent year. 
the article be structure in the form of an introduction elucidation conclusion framework. 
first we propose a general framework to explore the structure of an ipdr system. 
then accord to this framework the ipdr system be divide into six relatively independent subproblem which be discuss and summarize separately. 
finally we propose a graph structure of ipdr system and a sub directed graph form by select a combined path from the start node to the end node skillfully constitute a technical route of one specific ipdr system. 
at the end of the article we summarize some key issue that need to be resolve before the ipdr system be widely use. 
iterative selection of gob pole in the context of system modeling. 
this paper be concern with the problem of system identification use expansion on generalize orthonormal basis gob. 
three algorithm be propose to optimize the pole of such a basis. 
the first two algorithm determine a gob with optimal real pole while the third one determine a gob with optimal real and complex pole. 
these algorithm be base on the estimation of the dominant mode associate with a residual signal obtain by iteratively filter the output of the process to be model. 
these algorithm be iterative and base on the quadratic error between the linear process output and the gob base model output. 
they present the advantage to be very simple to implement. 
no numerical optimization technique be need and in consequence there be no problem of local minima as be the case for other algorithm in the literature. 
the convergence of the propose algorithm be prove by demonstrate that the modeling quadratic error between the process output and the gob base model be decrease at each iteration of the algorithm. 
the performance of the propose pole selection algorithm be base on the quadratic error criterion and illustrate by mean of simulation result. 
special spectral approach to solutions of siso lti h optimization problem. 
the paper be devoted to h optimization problem for linear time invariant lti system with scalar control external disturbance and measurement noise. 
all these problem can be numerically solve with the help of the well know universal approach base on riccati equation linear matrix inequality lmi or maximum entropy technique. 
nevertheless in our opinion there exist a possibility to increase the computational efficiency of synthesis use a special spectral approach to the above mention problem in frequency domain. 
some relevant detail be discuss and efficient numerical algorithm be propose for the practical implementation of spectral approach. 
one of its virtue be a possibility to present optimal solution in a specific form which be convenient for investigation. 
ensure good e waste recycling practice in develop country an australian example. 
the waste electrical and electronic equipment e waste management be one of the great challenge face in the twenty first century due to the steep e waste increase worldwide and their potential to be both a source of valuable material and a hazardous source of contamination. 
in this study the management of e waste be discuss have the australian recycling scheme as an example. 
the investigation on the actual recycling process and the associated cost analysis reveal important outcome for the decision make process of determine which equipment or material will be export and which will be recycle domestically. 
it be show that scrap computer be the only equipment with enough intrinsic value to justify the domestic recycling without require any external subsidy. 
furthermore the importance of such subsidy of regulation and monitoring be discuss principally for e waste with an intrinsic value small than computer. 
the result indicate that labor account for more than 90 of the cost of first stage recycling in australia which can be extrapolate to country where labor be expensive. 
finally in the interest of achieve a well waste management worldwide this study provide argument to encourage a well monitoring of the recycling process undertake internationally and/or the promotion of downstream recycling process in develop country. 
c 2018 elsevier ltd. 
all right reserve. 
numerical simulation and experimental analysis of an lcpv t system under real operating condition. 
in this study the performance evaluation of a low concentration photovoltaic thermal lcpv t module under different operating condition fix flow outlet temperature be carry out numerically and experimentally. 
in addition the influence of individual parameter on module performance be also study. 
all experiment show that both the electrical and thermal output first increase and then decrease with time. 
the maximum experimental value be 470 w and 1916 w respectively. 
the electrical and thermal efficiency however first decrease and then increase with time. 
the maximum respective experimental value be 17.28 and 59.84. 
the result also indicate that in general there be error of 10% 20 between the theoretical and experimental value. 
therefore modification co efficient be determined to correct the theoretical model. 
the result show that the relative error between the modify theoretical value and the experimental value be stable within five. 
c 2018 elsevier ltd. 
all right reserve. 
safety information cognition a new methodology of safety science in urgent need to be establish. 
in order to explain safety and environment protection from the aspect of information cognition it be imperative to establish new safety theory by explore accident and environmental pollution mechanism from the upstream level. 
in recent year safety relate information or cognition study have become new extension point in safety science. 
the researcher do not make any breakthrough in the mechanism analysis of safety information science because the essential process be not understand by researcher. 
obviously establish safety information science be irreversible and critical. 
therefore it be theoretically and practically significant to establish and discuss the foundation of safety information science. 
firstly the safety system should follow three level scale decomposition dimension decomposition and research field. 
then from the perspective of spatial order a systematic cognitive sequence of safety information and a five areas four belts spatial order model be establish. 
thirdly the meaning and basic connotation of safety information be clarify. 
in addition from the view of the combination between safety information dissemination and behavior cognition the safety information cognition model be construct accord to the general model of safety information cognition and principle of system decomposition. 
besides the accident mechanism of five layer distortion and four time delay as well as the general procedure of injury accident be propose. 
finally the worth of safety science model research for the future development be summarize. 
this paper contain a series of achievement include system decomposition method safety information cognition process and the cause mechanism and prevention strategy of accident or pollution information. 
the conclusion show that the information communication theory the cognitive model and the safety information law can deepen the understanding of the safety and environment system and provide new way for the further study of the safety and clean production. 
it can also far consolidate the essential principle of safety and environmental system and supply new prevention of accident and pollution for example the control and elimination of harmful factor identification and analyze safety information science of dangerous and harmful factor risk evaluation prevention monitoring and early warning measure et al. 
c 2018 elsevier ltd. 
all right reserve. 
diagnostic of mechanical and electrical fault in induction motor use wavelet base feature of vibration and current through support vector machine algorithm for various operating condition. 
fault diagnosis of induction motor ims be always a challenging task in the practical industrial field and it be even more challenging in the case of inadequate information of im working condition. 
in this paper a new methodology for fault detection have be propose for im to detect various electrical and mechanical fault as well as their severity where the datum be unavailable at required operating condition i.e. speed and load base on wavelet and support vector machine svm. 
for this the radial axial and tangential vibration and three phase current signal be acquire from im have different fault. 
the acquire time domain signal be then transform to time frequency signal use continuous wavelet transform cwt. 
ten different base wavelet be use to investigate the impact of different wavelet function on the fault diagnosis of im. 
statistical feature be extract base on the cwt and then appropriate feature(s be select use the wrapper model. 
these feature be feed to the svm to detect whether a defect have occur. 
the fault detection be perform for identical speed and load case use a number of mother wavelet. 
to analyze the robustness of the present system diagnosis be attempt for various operational condition of im. 
the result show that the feature(s select use the shannon wavelet diagnose the fault category of im more accurately as compare to other wavelet and remarkably find to be robust at all work condition of im. 
the work be finally extend to perform the fault diagnosis when limited information be available for the training. 
from the result it be observe that the propose methodology do not only take care of the practical problem of unavailability of datum at different operating condition but also show good performance and take low computation time which be vital requirement of a condition monitoring and diagnostic system. 
optimization of sequential grinding process in a fuzzy environment use genetic algorithm. 
the paper present the methodology of optimization of the sequential grinding process with the application of fuzzy logic for the definition of objective and constraint impose on the machining process. 
the present method include the succession of several subsequent operation and the dimensional and shape inaccuracy between they. 
the use of the fuzzy set theory enable the definition of not only the space of expectable solution but also the space of acceptable solution for which the goal and limit impose on the grind process be partially meet. 
the present methodology be use to optimize the process of sequential grinding of small ceramic element corundum ceramic with al2o3 content of 92 99 the definition of fuzzy objective and constraint in the process of sequential grinding of small ceramic element be propose. 
the influence of the speed of the rotary grind table and the machining allowance on the deviation of the flatness and height of the grind element and the value of the component of the normal grind force be determine. 
use the develop relationship the definition of fuzzy objective and constraint define in the process output parameter space be transfer to the process parameter set space. 
in such a define space the optimization process be carry out use the genetic algorithm. 
the analysis of the impact of the apply t norm function use for aggregation of the fuzzy objective and constraint on the obtain result be perform. 
it be show that in the case of sequential grinding of small ceramic element the use of minimum t norm for an aggregation of grind objective and constraint allow to achieve the high process efficiency. 
experimental investigation of tool wear in cryogenically treat insert during end milling of hard ti alloy. 
the present study aim to investigate the tool wear mechanism of tialn /nbn coat tungsten carbide insert during end milling of hard ti alloy under cryogenic treatment at 24h and 48h. 
the output response be examine by look at the flank wear tool wear mechanism elemental composition analysis cut force and vibration acceleration signal. 
a 12 23 and four 11 reduction in the flank wear be note at 48 h and 24 h cryogenically treat insert cti when compare with untreated insert. 
the reduction in the cut force and vibration be also observe in the cti when compare with untreated insert. 
the result show well machinability and enhance tool life for cti which be well than untreated insert under the same set of working condition. 
influence of edge preparation of coat carbide tool on mill aluminum alloy 211z. 
edge preparation can improve tool life cut process stability and quality of the machine surface. 
the coated tool must be edge prepare after grind to ensure enough bonding area to improve tool life. 
the influence of edge preparation on milling of aluminum alloy 211z use the coated carbide tool be investigate via deform simulation and correspond cut experiment. 
in this paper the influence of edge radius type of coating tin ticn tialn tisin ticrn cut speed feed axial depth and radial depth on cut force surface roughness and temperature be reveal. 
the result provide a basis for determine the effect of edge preparation. 
moreover theoretical value be use to reveal basic law govern the cutting process which may have practical significance. 
extraction method for signal effective component base on extreme point symmetric mode decomposition and kullback leibler divergence. 
datum processing be widely use to extract effective component from original signal which be essential in mechanical condition monitoring and fault diagnosis. 
in order to solve the invalid component and non stationary feature in the measure signal the extraction method for effective signal component be propose base on extreme point symmetric mode decomposition esmd and kullback leibler k l divergence. 
this method fully integrate the characteristic of esmd in self adaptive decomposition and the advantage of k l divergence in measure the distance between different signal. 
the effective and invalid component of non stationary signal be automatically separate by esmd and the effective component be far identify through k l divergence calculation. 
some analysis of simulated datum and experimental datum be investigate. 
and the effect of the propose method in effective component extraction be emphatically explore. 
research result indicate that the propose method can adaptively acquire effective signal component with high accuracy. 
moreover compare with the classic method it be more efficient in the extraction of effective component from complex signal. 
in addition this research solve the interference problem of invalid signal and accurately reconstruct the desire useful signal. 
time predictable synchronization support with a share scratchpad memory. 
multicore processor need to communicate when work on share task. 
in classical system this be perform via share object protect by lock which be implement with atomic operation on the main memory. 
however access to share main memory be already a bottleneck for multicore processor. 
furthermore the access time to a share memory be often hard to predict and therefore problematic for real time system. 
this paper present a share on chip memory that be use for communication and support atomic operation to implement lock. 
access to the shared memory be arbitrate with time division multiplexing provide time predictable access. 
the share memory support extend time slot so that a processor can execute more than one memory operation atomically. 
this allow for the implementation of locking and other synchronization primitive. 
we evaluate this share scratchpad memory with synchronization support on a nine core version of the t crest multicore platform. 
bad case access latency to the share scratchpad be 13 clock cycle. 
access to the atomic section under full contention when every processor core want access to acquire a lock be 135 clock cycle. 
c 2018 elsevier b.v. 
all right reserve. 
a novel approach to quantized matrix completion use huber loss measure. 
in this paper we introduce a novel and robust approach to quantize matrix completion. 
first we propose a rank minimization problem with constraint induce by quantization bound. 
next we form an unconstrained optimization problem by regularize the rank function with huber loss. 
huber loss be leveraged to control the violation from quantization bound due to two property first it be differentiable and second it be less sensitive to outlier than the quadratic lass. 
a smooth rank approximation be utilize to endorse low rank on the genuine data matrix. 
thus an unconstrained optimization problem with differentiable objective function be obtain allow we to advantage from gradient descent technique. 
novel and firm theoretical analysis of the problem model and convergence of our algorithm to the global solution be provide. 
another contribution of this letter be that our method do not require projection or initial rank estimation unlike the state of the art. 
in the numerical experiments section the noticeable outperformance of our propose method in learn accuracy and computational complexity compare to those of the state of the art literature method be illustrate as the main contribution. 
formal analysis of galois field arithmetic circuits parallel verification and reverse engineering. 
galois field gf arithmetic circuit find numerous application in communication signal processing and security engineering. 
formal verification technique of gf circuit be scarce and limit to circuit with know bit position of the primary input and output. 
they also require knowledge of the irreducible polynomial p(x which affect final hardware implementation. 
this paper present a computer algebra technique that perform verification and reverse engineering of gf(2(m multiplier directly from the gate level implementation. 
the approach be base on extract a unique irreducible polynomial in a parallel fashion and proceed in three step one determine the bit position of the output bit two determine the bit position of the input bit and three extract the irreducible polynomial use in the design. 
we demonstrate that this method be able to reverse engineer gf(2(m multiplier in m thread. 
experiment perform on synthesized mastrovito and montgomery multiplier with different p(x include nist recommend polynomial demonstrate high efficiency of the propose method. 
numerical study on fire hazard of elevator evacuation in supertall building. 
long evacuation time be a key fire safety concern for crowded supertall building. 
elevator evacuation appear to be the only choice but fire safety provision be not specially design for the use of elevator. 
a fire safe elevator system be propose early for supertall building by provide elevator accessible on each floor level and pass through the refuge place. 
the fire hazard associate with this design have be study numerically through an example building in this paper. 
smoke spread to the elevator system be consider in the study. 
the effect of ventilation of the shaft stack effect and wind effect on smoke movement be study by empirical equation in fire engineering and justify by computational fluid dynamic. 
different design of smoke extraction with pressurization system be evaluate by analyse the smoke dispersion and pressure distribution. 
the effect of fire at different height on smoke spread be also investigate. 
result show that the smoke extraction system can only delay smoke spread to the elevator shaft near the fire source for a short time. 
the four floor approach pressurization system can confine the smoke in the area of fire floor for a sufficiently long time period for safe evacuation. 
commix automate evaluation and exploitation of command injection vulnerability in web application. 
despite the prevalence and the high impact of command injection attack little attention have be give by the research community to this type of code injection. 
although there be many software tool to detect and exploit other type of code injection such as sql injection or cross site scripting there be no dedicated and specialized software that detect and exploit automatically command injection vulnerability. 
this paper propose an open source tool that automate the process of detect and exploit command injection flaw on web application name as command injection exploiter commix. 
we present and elaborate on the software architecture and detection engine of commix as well its extra functionality that greatly facilitate penetration tester and security researcher in the detection and exploitation of command injection vulnerability. 
moreover base on the knowledge and the practical experience gain from the development of commix we propose and analyze new identify technique that perform side channel exploitation for command injection allow an attacker to indirectly deduce the output of the execute command i.e. also know as blind command injection. 
furthermore we evaluate the detection capability of commix by perform experiment against various application. 
the experimental result show that commix present high detection accuracy while at the same time false positive be eliminate. 
finally and more importantly we analyze several zero day command injection vulnerability that commix detect in real world application. 
despite its short release time commix have be embrace by the security community and come preinstalle in many security orient operating system include the well know kali linux. 
a cut sequence optimization method base on tabu search algorithm for complex part machining. 
define the cutting sequence of each cutter scientifically in the process of remove the allowance have an important influence on the machining efficiency for complex part which have multiple machining feature. 
in order to satisfy the need of high efficiency for rough machining after determine the tool path of the machining region a cut sequence optimization method base on the tabu search algorithm be present to define the cutting order in rough machining of complex part. 
first a cut sequence optimization mathematical model be establish which relate to the short total length of the tool path. 
second through the problem analysis the cut sequence optimization model be convert into an open and constrain travel salesman problem. 
and then the optimization model be solve by deal with an open and constrain travel salesman problem use the tabu search algorithm. 
finally the optimal cutting sequence of machine a casing part be calculate and a simulation and experiment be carry out. 
the result show that the optimization approach present in this article can optimize the cutting sequence and cutter position of advance and retract. 
compare with the non optimized cut sequence method the total length of tool path be reduce by 16.7 the cutter lifting time be reduce to 26 and the efficiency be increase by 21.62. 
effect of slotted electrode on improvement in machine performance of large scale electrical discharge machining. 
under special condition electrical discharge machining be prone to experience poor machining removal rate. 
this create debris deposit that lead to decrease machining efficiency and poor machine quality in the machining workpiece during machine operation. 
thus the present study investigate the use of slotted electrode to improve machine debris removal and compare the machining capability of such electrode with that of cylindrical nonslotted electrode. 
concurrently oscilloscope be use to measure the machining voltage and current signal during the machining process in which waveform be analyze to gain insight into the electrical discharge condition of the electrical discharge machining. 
compare with general cylindrical nonslotted electrode the deep slotted electrode improve the material removal rate on large scale and hemisphere electrical discharge machining result by 91 and 116.7 respectively. 
the experiment result also show that slot electrode be inapplicable to finish operation. 
therefore during rough operation slot electrode should be use to lower machining time during finish operation cylindrical nonslotted electrode should be use to adjust machine precision. 
adaptive on line compensation model on position error of ball screw feed drive system use in computerized numerical control machine tool. 
the positioning error of ball screw feed system be mainly cause by thermal elongation of the screw shaft in machine tool. 
in this article an adaptive on line compensation method of position error for the ball screw shaft be establish. 
in order to explore the thermal solid mechanism of ball screw feed drive system the experiment be carry out. 
an exponential fitting equation be present to obtain the temperature relationship between the temperature sensitive point and its center of each heat source base on the finite element method of the feed drive system. 
consequently base on time and position exponential distribution function a variable separation model of heat transfer be establish. 
furthermore base on the heat transfer model of multiple vary and move heat source an adaptive on line analytical compensation model of positioning error be present. 
finally the effect of the adaptive on line analytical compensation model of positioning error be verify through the experiment. 
and this model have self adaptive ability and robustness. 
therefore this adaptive on line analytical compensation model base on the heat transfer theory can be apply in real time compensation of position error. 
parallel acceleration deceleration feedrate scheduling for computer numerical control machine tool base on bi directional scan technique. 
the acceleration deceleration feedrate scheduling be one of the most important technique in computer numerical control system. 
along with this technique the bi directional scan technique be always employ. 
the bi directional scan technique consist of a backward scan process follow by a forward scan process. 
the two scan process in the conventional method be execute in a serial manner by scan through all the scheduling block one by one. 
consequently the feedrate scheduling will suffer from a heavy computational burden when there be massive block to be scan which deteriorate its real time performance for computer numerical control machining. 
to alleviate the computational burden a parallel acceleration deceleration feedrate scheduling approach be propose in this article. 
with this method the scheduling block be splitte into several scheduling unit and the feedrate for each of they be schedule simultaneously. 
the feasibility of the propose approach be validate through the feedrate scheduling for two widely use butterfly and helix path. 
for a construct example of feedrate scheduling a significant acceleration ratio about 3.7 on a personal computer with a quad core central processing unit be achieve. 
state entropy base fluctuation analysis mechanism for quality state stability in data drive manufacturing process. 
intelligent quality state analysis be a promising tool to deal with manufacture big datum due to its ability in efficiently process state signal and provide accurate warning result. 
inspire by the idea that use the change of entropy flow to characterize the quality state change this article propose a fluctuation analysis mechanism for quality stability base on state entropy in data drive manufacturing process. 
first the multidimensional space cloud model with a three tuple feature be construct to describe quality state fluctuation in which the digital feature of entropy and hyper entropy represent the fluctuation uncertainty of quality state. 
furthermore in order to quantitatively analyze the fluctuation degree of process state the entropy change mechanism be introduce into the manufacture quality state to calculate the state fluctuation degree. 
the propose method be validate by a fan blade machining process dataset and the result show that the approach could well monitor the quality state fluctuation and show good effect for process stability analysis which will provide theoretical evidence for the real time warning and evaluation for abnormal quality state in manufacturing process. 
a comprehensive study of the effect of hone pattern on twin land oil control ring friction use both a numerical model and a float liner engine. 
engine bore be finish with a multi stage honing process and the finished surface roughness contribute significantly to the piston ring hydrodynamic pressure generation especially for twin land oil control ring whose land profile be parallel to the liner surface. 
in this paper five different hone pattern on a cast iron liner and one on a spray coat aluminum liner be study with a float liner engine and numerical model. 
the liner temperature and engine speed be varied such that all the lubrication regime namely boundary mixed and fully hydrodynamic be present. 
it be find that the model base on deterministic approach with a patch of carefully measure liner roughness can match the trend of the stribeck curve for different liner finish observe in the experiment. 
furthermore the result show that the roughness height and structure of the honing affect the twin land oil control ring lubrication differently. 
with the same honing structure although rough liner experience mixed and boundary lubrication in large range of gumbel hersey number it render less friction than the smooth one in the hydrodynamic regime. 
with the same plateau roughness height a more continuous plateau can provide more flow resistance and thus generate high hydrodynamic pressure at the ring liner interface and less friction. 
influence of granularity of grind stone on grind force and material removal in the rail grind process. 
the objective of this study be to explore the influence of grind stone granularity on the grind force and rail material removal behavior use a rail grind friction machine. 
the result indicate that with the increase in granularity the grind force and friction coefficient in the grind interface obviously increase which bring about a rise in the hardness and grind temperature rise of rail specimen. 
the increase in the grind stone granularity cause a fall in the grind volume and surface roughness of rail material and bring about strong vibration in the grind interface owe to different material removal mechanism. 
in view of the experimental result the optimization of grind stone granularity be significant for improve the rail grind efficiency and surface quality. 
a novel neural network base adaptive control scheme for output constrained stochastic switch nonlinear systems. 
in this paper a novel neural network nn) based adaptive track controller design method be present for the single input single output nonlinear stochastic switch system in low triangular structure with an output constraint. 
first a well design nonlinear mapping be introduce to transform the switch stochastic system to a new system without constraint which imply the controller design of the transformed system be equivalent to that of the stochastic switch system. 
then radial basis function nn be apply to model the unknown nonlinearitie and the adaptive backstepping technique be employ to construct two class of adaptive neural controller under different adaptive law. 
it be prove that both controller can assure all the signal in the closed loop remain bound in probability and the tracking error finally converge to a neighborhood of the origin without violate the constraint. 
furthermore the use of the nonlinear mapping to deal with the asymmetric output constraint be also study as a generalization result. 
two illustrative example with numerical datum and simulation result be give to show the validity and performance of the propose control scheme. 
explore biases between human and machine generated designs. 
the objective of this work be to explore the possible bias that individual may have toward the perceive functionality of machine generate design compare to human created design. 
toward this end 1187 participant be recruit via amazon mechanical turk amt to analyze the perceive functional characteristic of both human create two dimensional 2d sketch and sketch generate by a deep learn generative model. 
in addition a computer simulation be use to test the capability of the sketch idea to perform their intended function and explore the validity of participant response. 
the result reveal that both participant and computer simulation evaluation be in agreement indicate that sketch generate via the deep generative design model be more likely to perform their intended function compare to human create sketch use to train the model. 
the result also reveal that participant be subject to bias while evaluate the sketch and their age and domain knowledge be positively correlate with their perceive functionality of sketch. 
the result provide evidence that support the capability of deep learn generative design tool to generate functional idea and their potential to assist designer in creative task such as ideation. 
data driven platform design patent data and function network analysis. 
a properly design product system platform seek to reduce the cost and lead time for design and development of the product system family. 
a key goal be to achieve a tradeoff between economy of scope from product variety and economy of scale from platform sharing. 
traditionally product platform planning use heuristic and manual approach and rely almost solely on expertise and intuition. 
in this paper we propose a data drive method to draw the boundary of a platform system complement the other platform design approach and assist designer in the architecting process. 
the method generate a network of function through relationship of their co occurrence in prior design of a product or system domain and use a network analysis algorithm to identify an optimal core periphery structure. 
function identify in the network core co occur cohesively and frequently with one another in prior design and thus be suggest for inclusion in the potential platform to be share across a variety of product system with peripheral function. 
we apply the method to identify the platform function for the application domain of spherical rolling robot srrs base on patent datum. 
efficient design for test approach for network on chip. 
to achieve high reliability in on chip network it be necessary to test the network continuously with build in self tests bist so that the fault can be detect quickly and the number of affect packet can be minimize. 
however bistcause significant performance loss due to data dependency. 
we propose esytest a comprehensive test strategy with minimized influence on system performance. 
esytest test the datum path and the control path separately. 
the datum path test start periodically but the actual test perform in the free time slot to avoid deactivate the router for testing. 
a reconfigurable router architecture and an adaptive fault tolerant route algorithm be propose to guarantee the access to the processing core when the associated router be under test. 
during the whole test procedure of the network all processing core be accessible and thus the system performance be maintain during the test. 
at the same time esytest provide a full test coverage for the noc and a well hardware compatibility compare with the exist test strategy. 
under the parsec benchmark and different test frequency the execution time increase less than five percent at the cost of 9.9 percent more area and 4.6 percent more power in comparison with the execution where no test procedure be apply. 
a probabilistic multivariate copula base technique for faulty node diagnosis in wireless sensor network. 
wireless sensor network wsns find extensive application in various sensitive domain such as tracking monitoring environmental datum collection and border surveillance. 
in these case the collected datum be consider as a critical resource and use to detect any anomaly or abnormal behavior provide information about an occur event or a node failure. 
an outlier detection process must be set up to ensure the proper functioning of the monitoring system. 
the exist approach be limit by assumption on a specific distribution or a predefine data range of the collected datum. 
often these assumption do not hold in practice the data distribution be not know or determine reliable upper and low bound for the set of datum be not possible. 
to overcome this we propose a new copula base probabilistic multivariate outlier detection method for faulty node detection in wireless sensor network wsns. 
the joint probability density function of the copula be construct consider dependency among the capture n sensed measure without make any assumption on the distribution of the collected datum. 
the sample have probability violate a predetermine control limit be classify to be faulty. 
the performance of the propose technique be observe to be well than the exist statistical method. 
tool wear and surface roughness analysis in mill with ceramic tool of waspaloy a comparison of machine performance with different cool method. 
ceramic cutting tool be widely use particularly in high speed machining of difficult to machine material. 
however use cut fluid with these ceramic tool significantly reduce tool life. 
therefore the inclusion of a cool lubrication method into the process to improve the machining performance of ceramic tool will make machining efficiency much more effective. 
the aim of this study be to analyze the effect of cut parameter and cool lubricate condition on tool wear and surface roughness in the milling of nickel base waspaloy with ceramic tool. 
the cut tool select for the study be ti[c n] mixed alumina insert cc650 sic whisker reinforce alumina insert cc670 and alumina and sialon ceramic insert cc6060. 
the machining parameter comprise three different cooling lubricate method dry wet and mql three different cutting speed 500 600 and700m min and three different feed rate 0.02 0.04 and 0.06mm rev. 
analysis of variance be use to determine the effect of the machining parameter on tool wear and surface roughness. 
in addition a regression analysis be conduct to identify the relationship between the dependent and independent variable. 
accord to the experimental result the minimum quantity lubrication method be identify as the good cool method for minimum tool wear and surface roughness. 
in term of ceramic grade the sialon insert provide well result in all experimental trial. 
the dominant wear type observe in all cut tool be flank wear and notch wear. 
an inverse identification base finite element simulation of orthogonal cutting tungsten carbide. 
modeling and simulation use finite element method fem be a powerful estimation tool and have be greatly helpful to study the metal cutting process such as investigation of cut mechanism optimization of cut parameter and design of cut tool. 
thereinto an effective material model and its parameter be still key problem in the fem modeling of metal cutting. 
in this paper a 2d fe model for simulate the orthogonal cutting of tungsten carbide wc 17.5co be develop in which an inverse identification approach be use to identify the parameter of material model base on orthogonal cutting experiment. 
the commercially available software deform v11.0 be utilize to develop the fe model whereas the johnson cook model and brozzo model be select as the constitutive model and the fracture model of the work material respectively. 
continuous serrate chip formation be obtain in experiment as well as in fe simulation. 
the simulated chip morphology cut force and specific cut force be compare with the experimental result to identify the parameter of the material model. 
it be find that the chip morphology be more difficult to be use to identify inversely the material model parameter than the cut force and specific cut force. 
the material model parameter be derive and the verification test show that there be a close agreement between the simulated and experimental result through comparison of cut force and specific cut force. 
it indicate that the inversely identify parameter of the johnson cook model and the brozzo model can be use to describe the mechanical property of tungsten carbide. 
supergraph search in graph databases via hierarchical feature tree. 
supergraph search be a fundamental problem in graph database that be widely apply in many application scenario. 
give a graph database and a query graph supergraph search retrieve all data graphs contain in the query graph from the graph database. 
most exist solution for supergraph search follow the pruning and verification framework which prune false answer base on feature in the pruning phase and perform subgraph isomorphism testing on the remain graph in the verification phase. 
however they be not scalable to handle large sized data graphs and query graphs due to three drawback. 
first they rely on a frequent subgraph mining algorithm to select feature which be expensive and can not generate large feature. 
second they require a costly verification phase. 
third they process feature in a fix order without consider their relationship to the query graph. 
in this paper we address the three drawback and propose new indexing and query processing algorithm. 
in indexing we select feature directly from the data graph without expensive frequent subgraph mining. 
the feature form a feature tree that contain all sized feature and both the cost sharing and pruning power of the feature be consider. 
in query processing we propose a new algorithm where the order to process feature be query dependent by consider both the cost sharing and the pruning power. 
we explore two optimization strategy to far improve the algorithm efficiency. 
the first strategy apply a lightweight graph compression technique and the second strategy optimize the inclusion of answer. 
we far introduce how to efficiently maintain the index incrementally when the graph database be update dynamically. 
moreover we propose an approximation approach to significantly reduce the computational cost for large data graph and/or query graph while preserve a high result quality. 
finally we conduct extensive performance study on two real large dataset to demonstrate the efficiency and effectiveness of our algorithm. 
dynamic structure embed online multiple output regression for streaming data. 
online multiple output regression be an important machine learning technique for modeling predict and compress multi dimensional correlate datum stream. 
in this paper we propose a novel online multiple output regression method call mores for stream datum. 
mores can dynamically learn the structure of the regression coefficient to facilitate the model s continuous refinement. 
consider that limited expressive ability of regression model often lead to residual error be dependent mores intend to dynamically learn and leverage the structure of the residual error to improve the prediction accuracy. 
moreover we introduce three modify covariance matrix to extract necessary information from all the see datum for training and set different weight on sample so as to track the data stream evolve characteristic. 
furthermore an efficient algorithm be design to optimize the propose objective function and an efficient online eigen value decomposition algorithm be develop for the modify covariance matrix. 
finally we analyze the convergence of mores in certain ideal condition. 
experiment on two synthetic dataset and three real world dataset validate the effectiveness and efficiency of mores. 
in addition mores can process at least 2,000 instance per second include training and testing on the three real world dataset more than 12 time fast than the state of the art online learn algorithm. 
discrete adjoint method for the sensitivity analysis of flexible multibody systems. 
the gradient base design optimization of mechanical system require robust and efficient sensitivity analysis tool. 
the adjoint method be regard as the most efficient semi analytical method to evaluate sensitivity derivative for problem involve numerous design parameter and relatively few objective function. 
this paper present a discrete version of the adjoint method base on the generalize alpha time integration scheme which be apply to the dynamic simulation of flexible multibody system. 
rather than use an ad hoc backward integration solver the propose approach lead to a straightforward algebraic procedure that provide design sensitivity evaluate to machine accuracy. 
the approach be base on an intrinsic representation of motion that do not require a global parameterization of rotation. 
design parameter associate with rigid body kinematic joint and beam sectional property be consider. 
rigid and flexible mechanical system be investigate to validate the propose approach and demonstrate its accuracy efficiency and robustness. 
design and folding unfold dynamics of an over constrained airplane s landing gear with four side stay. 
this paper introduce the design of a specific landing gear retraction system present a mechanism with four redundant side stay and examine its dynamic behavior during the folding and unfold process. 
first a concept design of a four side stay landing gear retraction system be present. 
to get the particular motion during folding and unfolding the main kinematic parameter be give. 
then the influence of the side stay s kinematic redundancy on the mechanism parameter be examine. 
because the mechanism be over constrain the allowable parameter belong to a specific region of the space call feasible region. 
finally a dynamic analysis of the over constrain system be execute by use the newton euler approach and compliant equation. 
numerical simulation indicate that this kind of landing gear retraction system equitably share the load between different side stay and therefore the total load at one side stay be greatly reduce. 
analysis of reservoir computing focus on the spectrum of bistable delay dynamical system. 
reservoir computing rc be a machine learn paradigm that be capable to process empirical time series datum. 
this paradigm be base on a neural network with a fix hidden layer have a high dimensional state space call a reservoir. 
reservoir include time delay be consider to be good candidate for practical application because they make hardware realization of the high dimensional reservoir simple. 
performance of the well train rcs depend both on dynamical property of attractor of the reservoir and task they solve. 
therefore in the conventional monostable rcs there arise task wise optimization problem of the reservoir which have be solve base on trial and error approach. 
in this study we analyze the relationship between the dynamical property of the time delay reservoir and the performance in term of the spectra of the delay dynamical system which might facilitate the development of the unified systematic optimization technique for the time delay reservoir. 
in addition we propose a novel rc framework that perform well on distinct task without the task wise optimization use bistable reservoir dynamic which can reduce complicated hardware management of the reservoir. 
rapid method to determine accuracy and repeatability of positioning of numerically control axis. 
machine tool testing and accuracy analysis be an important task in evaluation of machine s capability. 
currently quasi static time consuming technique be propose by standard. 
this paper propose a new method for evaluation of accuracy and repeatability of machine tool positioning under dynamic condition on the fly. 
in this method displacement be capture by a laser interferometer during continuous motion of the analyze axis. 
the method be capable of analyze accuracy and repeatability of axis positioning without synchronization of the laser interferometer with the machine position transducer. 
transformation of time domain measurement into nominal position domain be perform use a novel curve fitting approach. 
the drawback of perform the test during machine motion be the potential contribution of the measure system vibration to the register signal. 
in this paper permissible range of vibration frequency for lens commonly use in optical metrology system for axis positioning of computer numerically control machine tool be experimentally determine. 
application of the propose method on a typical computer numerically control lathe lathe for non circular turning and mill machine be undertake. 
result of the test carry out at various feed rate be compare to quasi static result. 
pose dependent tool tip dynamic prediction use transfer learn. 
machining chatter have a great influence on the produce efficiency and surface quality. 
frequency response function at the tool tip be a crucial input for construct accurate mill stability model. 
however the tool tip dynamic usually change with the continuously vary posture of the machine tool axis during the whole machining process. 
how to predict the pose dependent tool tip dynamic precisely have become one of the most challenging task in chatter suppression in both research and industry. 
compare to traditional finite element analysis or kinematic modeling base method this paper propose a data drive method use transfer learn to predict the pose dependent tool tip dynamic for different tool holder assembly. 
firstly a tool holder assembly be select as the source tool and its pose dependent tool tip dynamic be obtain as the source datum by sufficient impact test. 
for a new tool holder assembly namely the target tool only few impact test be require to measure the tool tip dynamic as the target datum. 
then both the target and source datum be use to train a regression model for predict the target pose dependent tool tip dynamic base on transfer learn by integrate domain adaptation and adaptive weighting. 
furthermore a detailed experimental validation with a five axis machine tool be carry out to verify the accuracy and efficiency of the propose method. 
identification of corrosive substances and types of corrosion through electrochemical noise use signal processing and machine learning. 
several system in industry be subject to the effect of corrosion such as machine structure and a lot of equipment. 
as consequence the corrosion can damage structure and equipment cause financial loss and accident. 
among the most common type be the localize corrosion and it be present in most industrial process and be the most difficult to detect. 
such consequence can be reduce considerably with the use of method of detection analysis and monitoring of corrosion in hazardous area which can provide useful information to maintenance planning and accident prevention. 
in this work we analyze some feature extract from electrochemical noise for the classification of different type of localize corrosion. 
furthermore we use some technique to identify corrosive substance that may cause corrosion in material. 
for both task we apply signal processing and machine learning technique. 
experimental result show that the feature obtain use wavelet transform and recurrence quantification analysis be effective to solve both task the corrosion identification and the classification of substance. 
almost all evaluate machine learning technique achieve an average accuracy above 90. 
a hybrid modeling approach for characterization and simulation of cryogenic machining of ti 6al 4v alloy. 
a hybrid modeling approach base on computational fluid dynamic ced and finite element method fem be present to simulate and study cryogenic machining cm of ti 6al 4v alloy. 
cfd analysis be carry out to study the characteristic of the fluid flow and heat transfer process of liquid nitrogen ln2 jet use as a coolant in turn operation. 
the velocity turbulence gas volume fraction and temperature of the impingement jet be investigate. 
base on the analysis result the coefficient of heat transfer cht between the ln2 and cut toollinsert be obtain and use in the fem analysis to model the heat transfer process between the ln2 and the tool chip workpiece. 
a three dimensional 3d finite element fe model be develop to simulate a real cm operation. 
cm test be carry out to validate the 3d fe model by compare cut force and chip temperature. 
to evaluate ln2 cool effect on tool temperature and tool wear a two dimensional 2d fe model be develop for steady state thermal analysis of cryogenic and dry machining. 
base on the predict temperature the tool wear be estimate show that ln2 cooling can significantly improve tool life. 
a framework for the capture and analysis of product usage data for continuous product improvement. 
product improvement usually through change in design and functionality be rely more and more on the continuous analysis of large amount of datum. 
product datum can come from many source with vary effort in obtain the datum condition monitoring and maintenance datum. 
intelligent product also know as product embed information device peid be already equip with sensor and onboard compute capability and therefore able to generate valuable datum such as the number of user interaction during the use phase. 
the internet of thing iot make data transfer possible at any time to close the loop for the product lifecycle datum and method like machine learning promote new use of those datum. 
this paper propose a methodology to capture the most relevant datum on product use and human product interaction automatically and utilize it as part of data drive product improvement. 
product engineer and designer will gain insight into the use phase and can derive design change and quality improvement. 
the methodology guide the user through research on product use dimension base on the principle of user center design ucd. 
the finding be apply to define what usage element such as specific action and context need to be available from the use phase. 
during system development machine learning be suggest to fuse sensor datum to efficiently capture the usage element. 
after product deployment use datum be retrieve and analyze to identify the improvement potential. 
this research be a first step on the long way to self optimize product. 
software project management in high maturity a systematic literature mapping. 
high maturity in software development involve statistically control the performance of critical sub process and use the predictability thus gain to manage project with well planning precision and monitor control. 
maturity model such as cmmi mention statistical and other quantitative method technique and tool support high maturity project management but do not provide detail about they their use or their available type. 
thus knowledge be lack on how to support software process improvement initiative to select and apply statistical and other quantitative method technique and tool in this context. 
the goal of this study be to identify various method technique and tool which can assist in high maturity software project management. 
by conduct a systematic literature mapping we identify 108 paper describe 153 contribution. 
we describe the contribution identify classify they by their type their software technology maturation phase the method by which they be evaluate the development method and characteristic which they support and the process indicator area to which they be apply. 
we hope this work can help fill the knowledge gap on the statistical and other quantitative method technique and tool actually be propose evaluate experiment with and adopt by organization to support quantitative high maturity software project management. 
c 2018 publish by elsevier inc.. 
quality of input datum in emergency department simulation framework and assessment technique. 
operation research technique be widely use to analyse and optimise emergency department operation. 
the complex and stochastic nature of an emergency department make simulation a suitable and frequently use technique. 
simulation can provide valuable insight to hospital manager on how to improve the efficiency of an emergency department. 
however the output of the simulation study be only as reliable as the input datum use as basis for simulation modelling. 
as a result high quality input datum be essential for the construction of a realistic simulation model. 
this paper provide a data quality framework that categorise possible datum quality problem in electronic healthcare record of emergency department. 
electronic healthcare record be a common source of input datum for emergency department simulation but often suffer from datum quality issue. 
for the datum quality problem identify in the framework datum quality assessment technique be describe. 
these technique enable researcher and practitioner to identify and quantify the potential datum quality issue present in input datum. 
in order to facilitate datum quality assessment an implementation to automate this process be develop and apply to a real life case study. 
this case study demonstrate the need for thorough and structure datum quality assessment. 
possible way to deal with identify datum quality problem be also describe. 
steady state thermal modeling of a power module an n layer fourier approach. 
the steady state thermal modeling of a rectangular n layer structure with an arbitrary number of heat source on the top surface be obtain by a fourier series solution. 
as the structure of power module can be closely approximate as a rectangular n layer structure this model may be use to accurately estimate the temperature field occur in such module. 
various simplified structure be analyze to understand the effect of structural approximation on the temperature field. 
the fourier base method develop in this work be compare with the finite element method simulation and an excellent matching approximately 0.27 temperature error be find in the center of the semiconductor die. 
experimental temperature measurement take at the surface of a commercial sic power module be also present demonstrate agreement in the center of the die to within 3.5. 
an online monitoring method of circuit parameters for variable on time control in crm boost pfc converters. 
this paper propose an improved zero current detection for critical conduction mode crm control which can compensate the input current distortion cause by the signal propagation delay and the existence of the negative resonance current. 
a unified variable on time calculation method be also propose to unify the formula under the zero voltage switch condition and the valley switch condition. 
since these two method be dependent on the boost inductance and device junction capacitance which may be different from the nominal value effort be need to compensate the deviation on these two parameter. 
in this paper an online monitoring method be propose to compensate the numerical deviation. 
the propose method only need to sense the input voltage output voltage and the reverse flow time of the inductor current lead to a high power quality in the entire input and load condition. 
the experimental result of the propose method be demonstrate on a 200 w gan base crm boost power factor correction prototype. 
with the propose method the input current total harmonic distortion be only 0.78 at 110 vac input with full load and 2.1 at 220 vac input with full load. 
a novel voltage stabilization and power sharing control method base on virtual complex impedance for an off grid microgrid. 
microgrid mg usually operate in medium lowvoltage system where the line impedance parameter be mainly resistive and traditional p f q u droop control be no long applicable. 
when the virtual complex impedance method be adopt the resistance component of line impedance can be counteract by a virtual negative resistance. 
unfortunately the improper design of the virtual negative resistance will result in an unstable system due to the problem of line impedance parameter drift and estimation error. 
accord to the line parameter characteristic of the off grid mg with medium low voltage the p u q f droop control be adopt in this study where the virtual complex impedance compose of a virtual negative inductance and a virtual resistance be introduce in the control loop. 
the virtual negative inductance be use to reduce the power coupling cause by the inductive component of the system impedance. 
the virtual resistance be implement to enhance the resistive component and adjust the impedance matching degree for raise the accuracy of power sharing. 
however the power sharing be still affect by the system hardware parameter meanwhile the voltage deviation cause by the droop control and the virtual impedance exist. 
in this study a novel voltage stabilization and power sharing control method base on the virtual complex impedance be investigate to achieve accurate power sharing without the impact of hardware parameter variation and to improve the voltage quality. 
moreover the small signal model of the inverter base off grid mg with the propose controller be establish which can be utilize to analyze the stability and dynamic performance of the system. 
meanwhile the control parameter can be sequentially determine. 
analysis show that the strategy be robust against the line impedance parameter drift and the estimation error and have a large stability margin and fast dynamic response speed. 
finally numerical simulation and experimental result be provide to verify the effectiveness of the propose control method in comparison with traditional framework. 
challenge and recommend practice for software architecte in global software development. 
context global software development gsd although now a norm in the software industry carry with it enormous challenge mostly regard communication and coordination. 
aforementioned challenge be highlight when there be a need to transfer knowledge between site particularly when software artifact assign to different site depend on each other. 
the design of the software architecture and associated task dependency play a major role in reduce some of these challenge. 
objective the current literature do not provide a cohesive picture of how the distribute nature of software development be take into account during the design phase what to avoid and what work in practice. 
the objective of this paper be to gain an understanding of software architecte in the context of gsd in order to develop a framework of challenge and solution that can be apply in both research and practice. 
method we conduct a systematic literature review slr that synthesise i challenge which gsd impose on software architecture design and ii recommend practice to alleviate these challenge. 
result we produce a comprehensive set of guideline for perform software architecture design in gsd base on 55 select study. 
our framework comprise nine key challenge with 28 relate concern and nine recommend practice with 22 relate concern for software architecture design in gsd. 
these challenge and practice be map to a thematic conceptual model with the following concept organization structure and resources way of working architecture knowledge management change management and quality management design practices modularity and task allocation. 
conclusion the synthesis of finding result in a thematic conceptual model of the problem area a mapping of the key challenge to practice and a concern framework provide concrete question to aid the design process in a distributed setting. 
this be a first step in create more concrete architecture design practice and guideline. 
adaptive state feedback control for lipschitz nonlinear system in reciprocal state space design and experimental result. 
this article propose a design of an adaptive control for nonlinear system which satisfy the lipschitz condition. 
the objective be the use of the new reformulation of reciprocal state space form in adaptive control design. 
the present controller be compose of a state derivative feedback approach with adaptive gain base on the lyapunov stability theorem. 
the first control approach deal with the case of system stabilization. 
the second be an extension to the tracking problem. 
high performance be show through real time implementation with digital signal processing device arduino uno r3 and mega 2560. 
reshore and environmental sustainability an unexplored relationship. 
offshore manufacturing activity to low cost country have be an industry mantra for decade. 
some company have start to re think this supply chain configuration choice bring production back home. 
reshore or backshore production have see increase interest. 
this evolution pose a major question for sustainable supply chain management scholar what be the relationship between reshoring or global supply chain reconfiguration and environmental sustainability at firm country and global level in this paper we propose a set of potential research direction face this question. 
main aspect of reshoring include motivation implementation and impact be all discuss in this context. 
a modular bilateral haptic control framework for teleoperation of robot. 
this paper present a novel approach to implement bilateral control loop between local haptic device and remote industrial manipulator use a layer of simulation and virtual reality. 
the remote scene of manipulation have be visualize in an open source software environment where forward and inverse kinematic of the manipulator can be compute. 
therefore the explicit knowledge of mathematical model of the robot be not require for the implementation of the propose bilateral control scheme. 
a haptic coupling have be design between the human operator and the task in the remote environment. 
virtually introduce force feedback have contribute to the performance of the propose bilateral loop by facilitate the adaptation of unexperienced human operator. 
teleoperation of one remote manipulator have be experimentally demonstrate with the propose controller. 
structural modularity of the bilateral haptic control scheme make they directly extendable for the teleoperation of multiple collaborative robot. 
stability and transparency of the propose bilateral haptic controller have be theoretically and experimentally investigate. 
online condition monitoring of mv cable feeder use rogowski coil sensor for pd measurement. 
condition monitoring be a highly effective prognostic tool for incipient insulation degradation to avoid sudden failure of electrical component and to keep the power network in operation. 
improve operational performance of the sensor and effective measurement technique could enable the development of a robust monitoring system. 
this paper address two main aspect of condition monitoring an enhance design of an induction sensor that have the capability of measure partial discharge pd signal emerge simultaneously from medium voltage cable and transformer and an integrated monitoring system that enable the monitoring of a wide part of the cable feeder. 
having describe the conventional practice along with the author own experience and research on non intrusive solution this paper propose an optimum design of a rogowski coil that can measure the pd signal from medium voltage cable its accessory and the distribution transformer. 
the propose pd monitoring scheme be implement use the directional sensitivity capability of rogowski coil and a suitable sensor installation scheme that lead to the development of an integrate monitoring model for the component of a mv cable feeder. 
furthermore the paper present forethought regard huge amount of pd datum from various sensor use a simplified and practical approach. 
in the perspective of today s change grid the present idea of integrated monitoring practice provide a concept towards automate condition monitoring. 
pmu base model free method for transient instability prediction and emergency generator shed control. 
use pmu measurement this paper propose a model free method to predict post fault transient instability and develop emergency generator shed control. 
first the multi machine system be convert to an equivalent one machine infinite bus omib system base on online generator clustering and then the stability criterion be derive to judge the transient stability use the omib rotor speed omib omega trajectory. 
next a new trajectory prediction algorithm base on ensemble online sequential learning machine e os elm)is propose to predict the omib omega trajectory with an adaptive prediction window. 
the post fault transient instability status can be detect in advance on basis of the predict omega trajectory and the derive stability criterion. 
lastly when the system be foresee to lose stability an analytical generator shed control algorithm be present and the relationship between the generator shed amount and the time delay be illustrate. 
case study on the new england 39 bus system the npcc 140 bus system and a realistic province power system in china be present to show the propose methodology can detect the instability status early and help the system maintain synchronism. 
a pilot base distance protection scheme for mesh distribution system with distribute generation. 
this paper propose a pilot base distance protection scheme for mesh distribution system with a high penetration of distribute generation. 
the propose scheme assume distance relay instal at the opponent end of each main line segment. 
a forward distance element be enable in each relay to protect the main line segment while a reverse distance element be enable in each relay for protect adjacent bus and lateral. 
the relay protect a main line segment or a bus lateral communicate in a permissive logic ensure protection sensitivity and security at the same time. 
the scheme provide efficient primary and backup protection against fault of any type even with a considerable fault resistance and under weak infeed condition. 
it be also appropriate for both the grid connect and the islanded mode of system operation. 
coordination of the distance protection scheme with the lateral protection mean be also address. 
exist numerical distance relay technology be consider to enhance the applicability of the propose scheme. 
offline setting of the distance relay be require which have to be perform once. 
only one set group be ultimately extract for each relay suitable for different fault system condition avoid the need for adaptive protection technique. 
the propose scheme be apply to a test mesh distribution system and conclusion be draw. 
comparison with directional over current and differential protection show the advantage of the design distance base protection scheme. 
conduction radiation combine heat transfer with contact resistance for application to vacuum insulation. 
combine heat transfer of conduction and radiation be investigate with thermal contact resistance boundary condition to scrutinize the effect on heat transfer and to evaluate the thermal performance of vacuum insulation panel vips. 
numerical analysis show that introduction of contact resistance flattens temperature profile and reduce both the conductive and the radiative heat transfer. 
in vip if interstitial material be purely absorb emit and well contact the radiation shield center of panel thermal conductivity can be more than twice large than that estimate by separate analysis of conduction and radiation especially when the optical thickness of the layer be moderate and the wall emissivity be low. 
on the other hand this error decrease with increase scatter albedo and reduce conduction radiation interaction. 
in any case use of low emissivity shield greatly improve the insulation performance. 
far contact resistance between the interstitial material and the shield reduce the heat transfer substantially. 
thus insulation performance of vip with artificial core structure can be greatly improve by employ rough or emboss and highly reflect shield. 
c 2018 elsevier ltd. 
all right reserve. 
estimation of temperature dependent thermal conductivity and specific heat capacity for char ablator. 
the accurate assessment of thermal property be crucial for char material simulation and design. 
in this work a new inversion method for estimate temperature dependent thermal conductivity and specific heat capacity from temperature datum be present for char ablator. 
firstly a one dimensional thermal response model with surface recession be develop to simulate the thermal behavior of char ablator. 
then base on the developed model sensitivity analysis be conduct to investigate the correlation between thermal parameter and temperature for determine inversion sequence and find that virgin thermal conductivity have the big influence on temperature which should be estimate at first. 
finally the temperature dependent thermal conductivity and specific heat capacity be obtain by the inversion method from temperature datum. 
the inversion value from simulation temperature datum coincide with the reference value which the average inversion error of thermal conductivity be 4.3 and the average inversion error of specific heat capacity be 3.1. 
and the calculated thermal response temperature employ the inversion thermal property show a good agreement with the arc jet test datum which the average error be 8.5. 
this inversion method can accurately determine unknown temperature dependent thermal property such as thermal conductivity and specific heat capacity which provide an insight into the analysis and design of thermal protection material for spacecraft. 
c 2018 elsevier ltd. 
all right reserve. 
effect of pulse parameter on drop transfer dynamic and heat transfer behavior in pulse gas metal arc weld. 
the effect of pulse parameter on the metal and heat transfer behavior in pulse gas metal arc welding be investigate by a numerical model base on the solution of the magnetohydrodynamic equation within the framework of phase field method. 
five set of current waveform use different peak current and duration i.e. 
300 a 2.30 ms 350 a 1.80 ms 400 a 1.45 ms 450 a 1.20 ms and 500 a 1.00 ms but maintain an identical average current i.e. 
170 a be consider and compare. 
the pulse use high current but short duration result in more elongate shape of the pendent drop early detachment and significantly high velocity of the detached drop. 
unlike the drop velocity high peak current merely lead to a slight increase in the average temperature of the detached drop. 
the reason for this slight increase be that only the joule heating increase with the peak current while the sheath heating and arc heating be govern by the average current and keep almost constant use different pulse parameter. 
the simulation result be compare with the high speed photo and exhibit good agreement. 
c 2018 elsevier ltd. 
all right reserve. 
the effect of different hitran database on the accuracy of the snb and snbck calculation. 
the statistical narrow band snb and the statistical narrow band correlate k snbck model be use with hitran2008 hitran2012 and hitran2016 database in order to demonstrate the effect that the different hitran database version have on the accuracy of the snb and snbck calculation. 
the line by line lbl calculation be base on the hitemp datum. 
eight case be calculate use the lbl the snb and the snbck model in a one dimensional enclosure between two parallel plate fill with co2 h2o or a mixture of both. 
the result demonstrate that the radiant flux and the source of the snb and snbck model base on the hitran2012 and hitran2016 database be in good agreement. 
this be not true in the 0.1 m short path. 
the improvement in accuracy from the hitran2016 to the hitran2012 database be not as accurate as the improvement from the hitran2012 database to the hitran2008 database. 
the result calculate use the same hitran database by the snb model be more accurate than those obtain with the snbck model. 
and the lack of contribution of the hot line in the three hitran database lead to the relative error value of more than 20 on the radiant flux. 
this indicate that the hitran database be not suitable for engineering calculation at a high temperature. 
c 2018 elsevier ltd. 
all right reserve. 
a discrepancy analysis methodology for roll element bear diagnostic under variable speed condition. 
perform condition monitoring on critical machine such as gearbox be essential to ensure that the machine operate reliably. 
however many gearbox be expose to variable operating condition which impede the condition inference task. 
rolling element bear component failure be important cause of gearbox failure and therefore robust bear diagnostic technique be require. 
in this paper a roll element bear diagnostic methodology base on novelty detection be propose for machine operate under variable speed condition. 
the methodology use the wavelet packet transform order tracking and a feature modelling approach to generate a diagnostic metric in the form of a discrepancy measure. 
the probability distribution of the diagnostic metric statistically condition on the correspond operating condition be estimate whereafter the condition of the rolling bearing element be infer. 
the roll element bear diagnostic methodology be validate on datum from a phenomenological gearbox model and two experimental dataset. 
c 2018 elsevier ltd. 
all right reserve. 
array processing for the localisation of noise source in hot flow. 
this paper investigate the problem of localize a sound source in a heated flow use a microphone array. 
application be find in study deal with the identification of sound source in hot turbulent jet or with the sound radiation from installed turbofan. 
two configuration have be investigate a shear layer flow wind tunnel type and a jet flow. 
in the present study acoustic datum be generate use a simulation base on the linearized euler equations. 
for heated flow refraction by temperature gradient be superimpose with refraction by velocity gradient and the objective of this study be to assess whether this effect be important and how it can be account for in different source localisation method. 
for this purpose a time reversal base imaging method have be compare with a beamforming base method in which the time delay be compute base on ray trace. 
for the shear flow the result show that for high subsonic mach number and steep thermal gradient the thermal stratification must be take into account to ensure a satisfactory precision of localisation for both method. 
however include the gradient of velocity and temperature be less crucial for image sound source in the jet flow. 
the result indicate also that the localisation error be low with the beamforming and ray trace technique than with the time reversal technique the latter be more sensitive to the limited array aperture. 
c 2018 elsevier ltd. 
all right reserve. 
a review of stochastic resonance in rotate machine fault detection. 
condition base monitoring and machine fault detection play important role in industry as they can ensure safety and reduce breakdown loss. 
weak signal detection be an essential stage in many signal processing base machine fault detection method because the acquire machine signal be always corrupt by heavy background noise. 
stochastic resonance sr be a nonlinear phenomenon in which the weak signal can be enhance with the assistance of proper noise. 
due to this distinct merit sr have be extensively investigate in rotate machine fault detection. 
give this the present study be commit to provide a comprehensive review of sr from history to state of the art method and finally to research prospect along with the application in rotate machine fault detection. 
first the classical sr theory include the history merit and limitation be introduce and discuss and the basic research progress of sr be review. 
second the modify sr method design for process the rotate machine signal be review and summarize. 
third application of sr for analyze different kind of rotate machine fault signal be introduce. 
finally the open problem challenge and research prospect of sr in rotate machine fault detection be discuss. 
c 2018 elsevier ltd. 
all right reserve. 
combination of input shaping and radial spring damper to reduce tridirectional vibration of crane payload. 
the input shaping technique alter the human operator command to reduce the payload oscillation. 
a single radial spring damper can simultaneously produce three damping to suppress the tridirectional vibration of a crane payload. 
combination of input shaping and radial spring damper can be a sensorless approach to reduce the vibration induce by both operator command and external disturbance. 
a numerical simulation of a boom crane be carry out to clarify the effectiveness of each component in the combination. 
an experiment of a laboratory boom crane be present to show the effect of radial spring damper. 
c 2018 elsevier ltd. 
all right reserve. 
extraction of the large amplitude impact transient for diagnose roll element defect in bearing. 
this paper present a method base on the extraction of the large amplitude impact transient elait for diagnose the rolling element defect in bearing. 
as a defected roll element cause two large amplitude impact transient laits during a spin period when the element pass the load zone centre laits be separate for each rolling element accord to the kinematic of the bearing operation. 
by apply band pass filtering demodulation low pass filtering and ensemble averaging to these lait an enhanced signature name envelope ensemble average eea be obtain for each rolling element which allow a reliable indication of the defect element. 
the robustness of the method be evaluate by investigate the localise fault model of rolling bearing with the inclusion of phase error cause by rotational speed oscillation and rolling element slippage along with additive white noise. 
evaluation result show that eea signature be very sensitive to element defect and give an accurate indication of the most probably defect element and the elait method be robust to rotational speed oscillation and slippage. 
the same performance be also achieve when the method be validate with experimental signal from a test rig of machinery fault simulation show effectiveness and robustness in detect roll element defect in an operate bearing. 
besides the propose method can be easily implement online as it do not need a tachometer and be implement at low computation cost. 
c 2018 elsevier ltd. 
all right reserve. 
modeling and dynamic characterization of nonlinear non smooth aeroviscoelastic system. 
in this work viscoelastic material be adopt for handle aeroelastic feature of typical section model with three degree of freedom which present non smooth free play type nonlinearitie in their control surface. 
a rotational viscoelastic damper be add to the resilient element associate to the control surface motion of the typical section. 
equation of motion be derive account for the viscoelastic damper dependence on frequency and temperature. 
for this a fractional derivative base viscoelasticity constitutive law be consider. 
aerodynamic force be introduce base on linear potential unsteady aerodynamic account for arbitrary airfoil motion. 
the aeroelastic behavior be investigate through time domain simulation from which bifurcation diagram be construct. 
numerical result show that the addition of viscoelastic damping can increase the flutter speed noticeably and reduce the amplitude of limit cycle oscillation for the system under consideration. 
another observed benefit provide by the viscoelastic damper be that undesirable subcritical behavior for the bifurcation onset can be eliminate or modify to have a supercritical character. 
the influence of temperature on the aeroviscoelastic behavior be also investigate. 
use the propose strategy nonlinear instability can be control improve the safety margin of aeroelastic system. 
c 2018 elsevier ltd. 
all right reserve. 
extraction and imaging of aerodynamically generate sound field of rotor blade in the wind tunnel test. 
the acoustic beamforming have be widely apply in the imaging of flow induce aeroacoustic sound source. 
however the measure signal of the rotor blade often accompany with the unwanted interference from other component of the experimental setup in the wind tunnel test for example the rotor shaft and the stand which result in the undistinguished source in the beamforming result. 
in this paper the signal of rotor blade be define first as the cyclostationary process base on the ffowcs williams hawkings fw h equation in the form of wold cramer decomposition which connect the statistical definition of rotor blade signal with the wave propagation model of move source. 
then the develop cyclostationary signal processing tool of a second order specifically the reduce rank cyclic wiener filter can be apply in the wind tunnel test of rotor blade. 
the rotor blade signal can be extract from the noisy measurement with other interference which aide to purify the image result of beamforme in the final experiment of wind tunnel test. 
c 2018 elsevier ltd. 
all right reserve. 
static structural behaviour of wire bearing under axial load comparison with conventional bearing and study of design and operational parameter. 
in wire bearing the rolling process occur on raceway machine on steel wire and the ring be make of light material such as aluminium. 
this particular architecture provide both weight and inertia saving but also significantly different behaviour with respect to conventional bearing. 
for this reason specific design and analysis tool must be develop as a first step this work use finite element model to study the influence of different parameter on the static structural response of wire bearing. 
thus bear stiffness load capacity and contact status contact force and angle and ellipse truncation have be evaluate for several combination of conformity friction coefficient and boundary condition. 
the result have be compare with an equivalent conventional bearing shed light on the main structural feature of wire bearing. 
c 2018 elsevier ltd. 
all right reserve. 
spm slam simultaneous localization and mapping with squared planar marker. 
slam be generally address use natural landmark such as keypoint or texture but it pose some limitation such as the need for enough textured environment and high computational demand. 
in some case it be preferable sacrifice the flexibility of such method for an increase in speed and robustness by use artificial landmark. 
the recent work propose an off line method to obtain a map of squared planar marker in large indoor environment. 
by freely distribute a set of marker print on a piece of paper the method estimate the marker pose from a set of image give that at least two marker be visible in each image. 
afterwards camera localization can be do in the correct scale. 
however an off line process have several limitation. 
first error can not be detect until the whole process be finish an insufficient number of marker in the scene or marker not properly spot in the capture stage. 
second the method be not incremental so in case of require the expansion of the map it be necessary to repeat the whole process from start. 
finally the method can not be employ in real time system with limited computational resource such as mobile robot or uav. 
to solve these limitation this work propose a real time solution to the problem of simultaneously localize the camera and build a map of planar marker. 
this paper contribute with a number of solution to the problem arise when solve slam from square planar marker coin the term spm slam. 
the experiment carry out show that our method can be more robust precise and fast than visual slam method base on keypoint or texture. 
c 2018 elsevier ltd. 
all right reserve. 
shall deep learning be the mandatory future of document analysis problem. 
as the use of deep method become widespread in the scientific community cause major change in system architecture and position in term of knowledge acquisition we report here our insight about how document analysis system be build. 
where do the expertise really lie in the feature in the decision make step in the system design in the datum illustrate the problem to be solve the examination of the practice of researcher in this field and their evolution allow we to conclude that the tool that be use and related issue have become more and more complex over time. 
nevertheless human skill be need to activate these tool and to imagine new one. 
c 2018 elsevier ltd. 
all right reserve. 
stiffness base pose optimization of an industrial robot for five axis milling. 
industrial robot provide an optimistic alternative of traditional cnc machine tool due to its advantage of large workspace low cost and great flexibility. 
however the low posture dependent stiffness deteriorate the machining accuracy in robotic milling task. 
to increase the stiffness this paper introduce a pose optimization method for the mill robot when convert a five axis cnc tool path to a commercial six axis industrial robot trajectory take advantage of a redundant degree of freedom. 
first consider the displacement of at least three point on the end effector of the robot a new frame invariant performance index be propose to evaluate the stiffness of the robot at a certain posture. 
then by maximize this index a one dimensional posture optimization problem be formulate in consideration of the constraint of joint limit singularity avoidance and trajectory smoothness. 
the problem be solve by a simple discretization search algorithm. 
finally the performance index and the robot trajectory optimization algorithm be validate by simulation and experiment on an industrial robot show that the machining accuracy can be efficiently improve by the propose method. 
data science framework for variable selection metrology prediction and process control in tft lcd manufacturing. 
tft lcd panel manufacturer rely on experimental design and engineering experience for process monitoring and quality control throughout the production line. 
to shorten production and reduce the cost of labor resource this study propose a three phase data science framework embed with several datum mining and machine learning technique which can identify the variable affect yield predict the metrology result of photo spacer process and suggest the process control in the color filter manufacturing process. 
an empirical study of taiwan s lead tft lcd manufacturer be conduct to validate the propose framework. 
the result indicate that the propose framework effectively and quickly select the important variable predict the metrology result with high performance and identify the main effect and interaction effect of the select variable for yield improvement. 
simpm upper level ontology for manufacturing process plan network generation. 
distribute computer integrated manufacturing be increasingly adopt cloud computing software as a service saas and multi agent system as step towards design anywhere build anywhere strategy. 
in this scenario ontologie not only serve as common message exchange structure among distribute agent but also provide reasoning capability to extract implicit knowledge from explicit information already store in the knowledge base. 
foundation ontology upper level comprise of most general concept of a domain provide a common semantic structure to the domain level ontology which capture detail of multi disciplinary manufacturing knowledge. 
in this paper novel upper level ontology call simpm semantically integrated manufacturing planning model be propose in order to model three fundamental constraint of manufacturing process planning variety time and aggregation. 
the philosophical underpinning of the propose ontology present as owl dl axiom be derive from a three dimensional planning model develop during our past research on computer aid process planning. 
as part of the evaluation of simpm ontology we first expound on the interoperability issue with other upper level manufacturing ontology. 
next we present a case study on process planning for prismatic part design. 
in this way we demonstrate how the generic set of propose axiom may be use to address various manufacturing process planning concern such as alternative manufacturing resource the temporal order among operation and granularity in the detail of a process plan. 
deep learning for print document source identification. 
due to the rapid development of the information technology and wide use of the internet information be easily to be obtain in the form of digital format. 
digital content can be freely print into document since the convenience and accessibility of the printer. 
on the other hand print document can be illegally manipulate by some criminal issue such as forge document counterfeit currency copyright infringement and so on. 
therefore how to develop an efficient and appropriate safety testing tool to identify the source of print document be an important task in the meantime. 
currently the forensic system use the statistical method and support vector machine technology have be able to identify the source printer for the text and the image document. 
such an approach belong to the category of shallow machine learning with human interaction during the stage of feature extraction feature selection and data pre process. 
in this paper a deep learning system to solve the complex image classification problem be develop by convolutional neural networks cnns of deep learning which can learn the feature automatically. 
systematic experiment have be perform for both system. 
for microscopic document feature base svm system outperform the deep learning system with limited gap. 
for scanned document both system can achieve equally well with high accuracy. 
both system should be constantly evaluate and compare for the good interest in universal utilization. 
ensemble sw image steganalysis a low dimension method for lsbr detection. 
blind steganalysis examine digital medium for the likely existence of hide message without prior knowledge of the steganographic algorithm that may have be use to hide such message. 
this paper put forward a novel learning base blind image steganalysis method for tackle spatial domain least significant bit lsb flipping. 
its key steganalytic feature be the correlation between message length and the regression of the quantity of intensity identical pixel and channel. 
a specially design support vector machine svm kernel be train to analyze each pixel as an individual analysis unit with the combined result of the analysis determine the ultimate steganalysis decision. 
this method make a number of innovative contribution to the field of blind steganalysis. 
first it offer a novel steganalytic feature for measure similarity between the weight of pixel and channel. 
second it involve pixel in the steganalytic process accord to the degree of their detect membership thus avoid neutral pixel influence the process. 
third it extract reference statistical behavior from cover and stego pixel thereby enhance the sensitivity of the steganalyzer. 
fourth its svm kernel enhance sensitivity use statistical function combine with trapezoidal fuzzy membership. 
finally with all these innovation it be capable of achieve a sensitivity of 99.626 for 0.25 bpp stego image through only two analysis dimension. 
tribo design of lubricant for power loss reduction in the oil film bearing of a process industry machine modelling and experimental test. 
this paper address the optimization of the tribological characteristic of lubricate oil use in the process industry. 
in many case the machine be organize in several stand to form line and be equip by spindle support by oil film journal bearing that be feed by the same oil. 
the modelling of a steel roll form line be present by use a thermo elasto hydro dynamic model for the calculation of the power dissipate in each journal bear. 
the optimal lubricate oil characteristic be define by mean of a multivariate optimization on the parameter of viscosity temperature and thickness of the oil film. 
the result of the experimental test be show for the oil use in the real plant and the new oil formulate by simulation. 
development of an interactive friction model to predict aluminum transfer in a pin on disc slide system. 
in aluminum form process it be observe that the coefficient of friction increase and a transfer layer be form on the tool surface. 
in the current paper this phenomenon be study via pin on disc dry slide test with aluminum alloy 6082 slide against cast iron g3500. 
the result show that the aluminum transfer layer generate at the slide interface be identify as the origin of this behaviour that affect both friction and wear. 
to model this phenomenon an interactive friction model be develop enable the prediction of friction and the evolution of the transfer layer from the running in to the steady state. 
this mechanism base model can be use for represent friction variation and material transfer in slide system. 
field validation of gap type overhead conductor creep. 
gap type overhead conductor sag tension calculation base on experimental conductor creep test be base on stress strain and metallurgical creep test. 
although for bi metallic conductor these test be carry out for both the core and the full conductor for gap type overhead conductor the aluminum metallurgical creep be usually neglect and the full conductor metallurgical creep be not carry out. 
the purpose of the present study be the validation of these calculation method. 
for this purpose field measurement have be obtain in a pilot line in operation. 
the gap type conductor installation process have be measure and the conductor creep have be monitor during three year of line operation. 
in order to model relevant event such as the pre sag and sag step during the installation and ice and wind event during the operation a flexible sag tension calculation method have be use. 
besides the widely use graphical sag tension method have also be evaluate obtain similar result as the flexible method. 
the tension decrease be use as the indicator of the creep. 
the calculated and measure tension decrease value be close. 
therefore it be conclude that the sag tension calculation base on experimental conductor creep test be valid to represent the actual creep of the conductor in operation. 
stiffness performance index base posture and feed orientation optimization in robotic milling process. 
industrial robot be promise and competitive alternative for perform machining operation. 
a relatively low stiffness be the major constraint for the widespread use of industrial robot in machining application. 
in this study the stiffness property of an industrial robot be analyze to improve the machining accuracy of robotic milling and optimization method for the robot posture and tool feed orientation be establish. 
first base on the relationship between the external force and deformation of the robot end effector ee the normal stiffness performance index nspi of the surface which be derive from the comprehensive stiffness performance index cspi be propose to evaluate the robot stiffness performance for a give posture. 
the nspi be prove to be independent of the magnitude of the external force and dependent on the direction of these force. 
a distribution rule be then propose for the nspi with respect to any direction in the cartesian space for a give posture which clearly reveal the anisotropic property of the robot stiffness. 
by maximize the nspi an optimization model be establish to optimize the posture of a six degree of freedom dof industrial robot in a mill application. 
use the nspi the optimize tool feed orientation for robot planar milling be obtain. 
finally the result of the robot milling experiment be discuss to illustrate the feasibility and effectiveness of the propose optimization method. 
interpreting and extend the guided filter via cyclic coordinate descent. 
the guide filter gf be a widely use smoothing tool in computer vision and image processing. 
however to the good of our knowledge few paper investigate the mathematical connection between this filter and the least square optimization. 
in this paper we first interpret the guide filter as the cyclic coordinate descent ccd solver of a least square objective function. 
this discovery imply an extension approach to generalize the guide filter since we can change the least square objective function and define new filter as the first pass iteration of the ccd solver of modified objective function. 
in addition refer to the iterative minimize procedure of the ccd we can derive new roll filter scheme. 
so we be reasonable to say that our discovery not only reveal an approach to design new gf like filter adapt to specific requirement of application but also offer thorough explanation for two roll filter scheme of the guide filter as well as the method to extend they. 
experiment prove our new propose filter and roll filter scheme could produce state of the art result. 
normal contact stiffness of rough surface consider oblique asperity contact. 
the contact stiffness of the machine surface have an important effect on the performance of the complex mechanical product. 
a modify fractal model base on oblique asperity contact be propose in this research. 
first the contact radius and the critical contact area be analyze base on oblique contact condition. 
the normal contact stiffness and elastic plastic force be calculate. 
the ratio of the actual contact area and a new parameter relate to the current contact angle be introduce. 
second numerical simulation indicate the difference. 
the result show that the stiffness of the oblique contact be small and with the increment of the fractal dimension the extent of the stiffness reduction be large. 
in contrast the uniform distribution have the low proportion of the elastic force in the total normal contact force. 
finally experiment include speciman surface observation and load deformation measurement be utilize to obtain contact stiffness of the machine surface. 
to some extent the modify fractal stiffness model be more reasonable and accurate from the result. 
an ipv6 base framework for fog assist healthcare monitoring. 
the new generation healthcare monitoring system combine technology of wireless body sensor network cloud computing and bigdata and there be still limitation in protocol security response delay and prediction of potential severity disease. 
in response to the above situation an internet protocol version six ipv6) base framework for fog assist healthcare monitoring be propose. 
this framework be composite of body sense layer fog layer and cloud layer. 
the body sense layer generate physiological datum and fog compute node in fog layer collect and analyse time sensitive datum. 
fog layer send physiological datum to cloud compute node in cloud layer for further processing. 
mobile intelligent device connect fog compute node and help individual to predict the potential disease with its level of severity. 
the propose framework use advanced technique such as ipv6 base network architecture cloud fog resource scheduling algorithm base on time threshold and classification model of chronic disease base on cascade deep learning and so on. 
in order to determine the validity of the framework health datum be systematically generate from 45 patient for 30 day. 
result depict that the propose classification model of chronic disease have high accuracy in determine the level of severity of potential disease. 
moreover response delay be much low than internet protocol version four ipv4) base cloud assist environment. 
inspiration from games and entertainment artifact a rising paradigm for designing mechanisms and algorithms in robotic. 
game and toy have be serve as entertainment tool to human for a long period of time. 
while except for entertainment they can also trigger inspiration and enhance productivity in many other domain such as healthcare and general workplace. 
the concept of the game be refer to a series of structure procedure e.g. card game and virtual program. 
the entertainment artifact could be a toy or even a handicraft such as origami and kirigami for entertainment purpose in a broad sense. 
recently the design of robot and relevant application in robotic have be emerge in take inspiration from games and entertainment artifacts gea. 
however there be a lack of systematic and general process for implement a gea inspire design for develop robot relate application. 
in this article we put forward a design paradigm base on the inspiration of game and entertainment artifact which be a systematic design approach. 
the design paradigm could follow two different process which be drive by problem and solution respectively use analogy of game and entertainment artifact to build robotic solution for solve real problem. 
the problem drive process start with an exist real world problem which follow the sequence of robotic problem search robotic problem identification gea solution search gea solution identification gea principle extraction and the principle implementation. 
reversely the solution drive process follow the sequence of gea solution search gea solution identification gea principle extraction robotic problem search robotic problem identification and principle implementation. 
we demonstrate the application of the design paradigm use the case study of a new type of reconfigurable floor cleaning robot and its path plan algorithm. 
wake behavior and control comparison of les simulation and wind tunnel measurement. 
this paper apply a large eddy actuator line approach to the simulation of wind turbine wake. 
in addition to normal operating condition a specific focus of the paper be on wake manipulation which be perform here by derating yaw misalignment and cyclic pitching of the blade. 
with the purpose of clarify the ability of les method to represent condition that be relevant for wind farm control numerical simulation be compare to experimental observation obtain in a boundary layer wind tunnel with scale wind turbine model. 
result indicate a good overall matching of simulation with experiment. 
low turbulence test case appear to be more challenging than moderate  and high turbulence one due to the need for denser grid to limit numerical diffusion and accurately resolve tip shed vortex in the near wake region. 
noise add selection method for location base service use differential privacy in internet of thing. 
with the development of internet of thing many application need to use people s location information result in a large amount of datum need to be process call big datum. 
in recent year people propose many method to protect privacy in the location base service aspect. 
however exist technology have poor performance in big datum area. 
for instance sensor equipment such as smart phone with location record function may submit location information anytime and anywhere which may lead to privacy disclosure. 
attacker can leverage huge datum to achieve useful information. 
in this article we propose noise add selection algorithm a location privacy protection method that satisfie differential privacy to prevent the datum from privacy disclosure by attacker with arbitrary background knowledge. 
in view of internet of thing we maximize the availability of datum and algorithm when protect the information. 
in detail we filter real time location distribution information use our selection mechanism for comparison and analysis to determine privacy protect region and then perform differential privacy on they. 
as show in the theoretical analysis and the experimental result the propose method can achieve significant improvement in security privacy and complete a perfect balance between privacy protection level and datum availability. 
accelerate apache spark with fpga. 
apache spark have become one of the most popular engine for big datum processing. 
spark provide a platform independent high abstraction programming paradigm for large scale datum processing by leverage the java framework. 
though it provide software portability across various machine java also limit the performance of distribute environment such as spark. 
while it may be unrealistic to rewrite platform like spark in a fast language a more viable approach to mitigate its poor performance be to accelerate the computation while still work within the java base framework. 
this paper demonstrate the feasibility of incorporate field programmable gate array fpga acceleration into spark and present the performance benefit and bottleneck of our fpga accelerate spark environment use a mapreduce implementation of the k mean clustering algorithm to show that acceleration be possible even when use a hardware platform that be not well optimize for performance. 
an important feature of our approach be that the use of fpga be completely transparent to the user through the use of library function which be a common way by which user access function provide by spark. 
power user can far develop other computation use high level synthesis. 
deep bayesian network architecture for big data mining. 
classical datamining method be face various challenge in the era of big data. 
between the need of fast knowledge extraction and the high flow of datum acquire in small slot of time these method become shift. 
the variability and the veracity of the big data perplex the machine learning process. 
the high volume of big data yield to a congested learning because the classic method be design for small set of feature. 
deep learning have recently emerge in the aim of handle voluminous datum. 
the concept of the deep induce the conversion of the feature into a new abstract representation in order to optimize an objective. 
although the deep learning method be experimentally promising their parameterization be exhaustive and empirical. 
to tackle these problem we utilize the causality and the uncertainty of the bayesian network in order to propose a new deep bayesian network architecture. 
we provide a new learning algorithm for this multi layered bayesian network with latent variable. 
we evaluate the propose architecture and learn algorithm over benchmark dataset. 
we use high dimensional datum in order to simulate the big data challenge which be impose by the volume and veracity aspect. 
we demonstrate the effectiveness of our contribution under these constraint. 
efficient routing and reconfiguration in virtualized hpc environment with vswitch enable lossless network. 
to meet the demand of communication intensive workload in the cloud virtual machine vm should utilize low overhead network communication paradigm. 
in general such paradigm enable vm to directly communicate with the hardware by mean of a passthrough technology like single root i o virtualization sr iov. 
however when passthrough base virtualization be couple with lossless interconnection network live migration introduce scalability challenge due to the substantial network reconfiguration overhead. 
with these challenge in mind we propose a virtual switch vswitch sr iov architecture for infiniband in our previous work title towards the infiniband sr iov vswitch architecture. 
in this paper we first suggest solution to rectify the space domain scalability issue that be present in vswitch enable subnet as a result of the vm use dedicated layer two address. 
then we discuss route strategy for virtualized environment use vswitche and present a route algorithm for fat trees. 
we also present a reconfiguration method that minimize impose reconfiguration overhead on fat tree. 
we perform an extensive evaluation of our prototype algorithm and as vswitch enable hardware do not yet exist we deduce from empirical observation by emulate vswitche with exist hardware as well as large scale simulation. 
our result show significant reduction in the reconfiguration time as route recalculation can be eliminate and for certain scenario the number of reconfiguration subnet management packet send to switch be reduce from several hundred thousand down to a single one without degrade the route quality. 
intelligent control for accurate position tracking of electrohydraulic actuator. 
a novel intelligent control scheme be present for accurate position tracking of electrohydraulic servo actuator. 
the propose control law be design by mean of a non linear control approach and include an adaptive neural network to provide the basic intelligent feature. 
online learning instead of off line supervised training be propose to update the weight vector of the neural network. 
moreover the adoption of a composite error signal as the only input to the neural network allow a significant reduction in the computational complexity of the algorithm. 
rigorous proof for the boundedness and convergence property of the closed loop signal be provide. 
experimental result obtain with an electrohydraulic system demonstrate the efficacy of the propose controller even consider the highly non linear and uncertain plant dynamic. 
dynamic hierarchical load balancing model for cloud datum centre network. 
today s datum centre need efficient traffic management to improve resource utilisation in their network. 
it help to solve the load imbalance problem of each processor. 
this letter present a dynamic hierarchical load balance approach for high traffic scalability. 
the method select the most favourable host satisfy the multi dimensional resource constraint in term of compute capability and its performance. 
the propose method achieve significant traffic scalability improvement upto 66 over sequential and random virtual machine placement heuristic. 
simple finite time slide mode control approach for jerk system. 
this article describe an easy way to apply active control upon all jerk system for which the linear part of the third order differential jerk equation strongly depend on acceleration and velocity. 
the kernel of that methodology be to rewrite the jerk equation as a single implicit first order differential equation escort with a slide variable. 
it be show that for such a jerk class the fast terminal slide convergence base on lyapunov stability be achieve with a first order sigmoid slide surface. 
various numerical simulation have be conduct on sprott simple jerk class as well as on the single op amp jerk system. 
for experiment we synchronize two sprott circuit with nonlinearity be the absolute value of position. 
experimental result match well with numerical simulation. 
analysis of the characteristic of electromechanical hydraulic model of multi source drive transmission system base on periodic excitation. 
multi source drive system with the feature of compact small size and other advantage be widely use in large engineering machinery such as shield machine wind turbine and shearer. 
in this article a reasonable power transmission form be design and the electromechanical hydraulic coupling model of the multi source drive system include the hydraulic pump motor lump parameter model and gear system dynamic model be establish base on the co simulation of matlab and amesim. 
take the pump flow pulsation and the time vary meshing stiffness as the external and internal excitation of the multi source drive system respectively the vibration and the dynamic characteristic of the multi source drive system and the transfer characteristic of the dynamic excitation be analyze. 
result show that the flow speed pulsation and the pressure torque pulsation be gradually reduce along the direction of the transmission chain. 
as the external and internal excitation the flow pulsation and the time vary meshing stiffness will cause complex influence on the vibration and the dynamic characteristic of the multi source transmission system. 
the finding provide a reference basis for the design of the multi source drive system. 
insulation condition assessment of high voltage rotate machine use hybrid technique. 
the endure life span of the machine insulation will be decide base on degradation level in motor and generator stator winding. 
the non destructive diagnostic tool like dielectric loss and capacitance test and partial discharge pd analysis recognize to access the deterioration in the insulation system of rotate machine. 
the experiment reveal various characteristic parameter such as leakage current dielectric dissipation factor the capacitance value and pd magnitude. 
the integrity of the rotate machine can be find out by analyze these parameter. 
this research study show the hybrid method for prediction of insulation condition in the stator wind by utilize the artificial neural network ann with gravitational search algorithm in comparison with ann and ann genetic algorithm. 
the advent of expert system ensure the quality assurance and service life assessment of the high voltage asset. 
it offer a predictive maintenance solution to personnel deal with power utility thereby increase the uptime reliability and productivity which in turn reduce the operating cost downtime and unplanned outage. 
for testing and predict the insulation status several 11 kv machine be consider. 
the predicted result use hybrid technique extend a close agreement with reference to the datum obtain from the experiment perform. 
the propose method indicate the competent and trustworthy by the present test result. 
opinion mining from social medium short text do collective intelligence beat deep learning. 
the era of big datum have among other three characteristic the huge amount of datum create every day and in every form by everyday people artificial intelligence tool to mine information from those datum and effective algorithm that allow this datum mining in real or close to real time. 
on the other hand opinion mining in social medium be nowadays an important parameter of social medium marketing. 
digital media giant such as google and facebook develop and employ their own tool for that purpose. 
these tool be base on publicly available software library and tool such as word2vec or doc2vec and fasttext which emphasize topic modeling and extract low level feature use deep learning approach. 
so far researcher have focus their effort on opinion mining and especially on sentiment analysis of tweet. 
this trend reflect the availability of the twitter api that simplify automatic datum tweet collection and testing of the propose algorithm in real situation. 
however if we be really interested in realistic opinion mining we should consider mining opinion from social medium platform such as facebook and instagram which be far more popular among everyday people. 
the basic purpose of this paper be to compare various kind of low level feature include those extract through deep learning as in fasttext and doc2vec and keyword suggest by the crowd call crowd lexicon herein through a crowdsourcing platform. 
the application target be sentiment analysis of tweet and facebook comment on commercial product. 
we also compare several machine learning method for the creation of sentiment analysis model and conclude that even in the era of big datum allow people to annotate a small portion of datum would allow effective artificial intelligence tool to be develop use the learning by example paradigm. 
emulation of auto reclosing scheme with adaptive dead time control for protection of series compensated transmission line. 
series compensation play an important role in smart power grid to improve power transfer capacity and voltage profile. 
majority of fault occur in grid be transient in nature. 
however discrimination between transient fault and permanent fault be contemporary problem in the field of distance protection of transmission line. 
auto reclosure be one of the foremost solution for the same. 
this paper demonstrate implementation of auto reclose scheme use modify full cycle discrete fourier transform with adaptive dead time control. 
the fault detection logic be base on monitor impedance trajectory in the r x diagram of distance relay. 
the reclose instance be identify by examine differential voltage across the contact of circuit breaker. 
during transient fault condition base on the time by which the breaker voltage retard to normal value below preset threshold be use to set adaptive dead time of reclosure. 
software validation have be perform with the variation in fault location fault resistance and fault location with vary line compensation level. 
real time validation be also perform use digital signal controller on laboratory prototype. 
the outcome of simulation and emulation indicate substantial reduction in dead time indicate effectiveness of the develop scheme. 
investigation of the fluctuation of the static axial rigidity for double nut preloade ball screw. 
this article aim to investigate the fluctuation of the static rigidity for preloaded ball screw. 
base on the correlation between preload and friction torque a new model to calculate the contact rigidity by friction torque be propose. 
meanwhile a novel test bench be construct to measure the static stiffness at different position. 
the experimental result agree well with the theoretical value which prove the validity of the model. 
furthermore it be find that the screw shaft rigidity have the great influence on the system stiffness fluctuation compare to the bearing rigidity and the torsional rigidity. 
for the feed system increase the bearing rigidity which be the low stiffness of the whole system be an effective method to increase the system stiffness. 
the study provide an accurate method to obtain the stiffness fluctuation in the effective travel of ball screw which be significant for improve the positioning accuracy of ball screw and computer numerical control machine tool. 
irradiation target cooling use circular slot air jet. 
to study the effect of irradiation on material sample coupon be irradiate in cyclotron facility. 
during the irradiation process these sample produce significant heat. 
this heat need to be continuously remove from the sample in order to avoid melting of the sample as well as to keep the sample at a particular temperature during irradiation. 
the area available for heat transfer be limit due to small size of the sample. 
to increase the heat transfer rate jet cooling be use as it provide large heat transfer co efficient. 
to understand the heat transfer characteristic of jet cooling under these condition experiment have be carry out. 
two inclined jet hit on both side of the target plate give maximum cooling and uniform temperature distribution. 
this paper give the detail of the numerical and experimental study carry out and the discussion about the result obtain. 
generalized quality control parameter for heterogenous recycle concrete aggregate a pilot scale case study. 
although recycled concrete aggregates rca derive from concrete waste represent a potential sustainable solution for the structural concrete production their heterogeneous composition be a feature that still prevent their large scale use in the construction you all around the world. 
in order to find a possible exist relationship between the source of residue and the result rca characteristic a pilot scale case study be carry out in which approximately 20 ton of concrete waste derive from different origin be process to obtain granulometric fraction from coarse aggregate to powder. 
the rca fraction obtain use a control processing procedure be then thoroughly characterize to establish quality control parameter that could lead to a classification of different type of recycled aggregate generate. 
the result show that the source of concrete waste strongly influence the amount of each aggregate fraction produce during processing and aggregate property be dependent on the waste origin. 
despite this the present analysis demonstrate that by evaluate a fundamental parameter such as the attached paste mortar within the rca a generalize quality control classification can be propose for the industrial upscaling of rca characterization. 
it be believe that such a classification could promote the integral and rational re use of these secondary raw material in different cement base product of the construction sector. 
c 2018 elsevier ltd. 
all right reserve. 
influence of ball burnish process on surface topography parameters and tribological properties of hardened steel. 
the ball burnish process be a particular finishing treatment that can improve select property of different material. 
in the present study the ball burnish technique be use to investigate the effect of input parameter of process on select surface layer feature like surface roughness and residual stress of the 42crmo4 steel surface. 
the burnishing process be conduct on haas cnc vertical mill center vf three use a tool with tungsten carbide tip. 
a further objective of our research be to improve tribological property of the aforementioned steel by the ball burnishing process. 
the result of the investigation show that it be possible to reduce the root mean square height of the surface sq from 0.522 mu m to 0.051 mu m and to increase wear resistance compare to ground sample. 
generation of a continuous free gait for quadrupe robot over rough terrain. 
generate a robust gait be one of the most important factor to improve the adaptability of quadrupe robot on rough terrain. 
this paper present a new continuous free gait generation method for quadrupe robot capable of walk on the rough terrain characterize by the uneven ground and forbid area. 
when walk with the propose gait the robot can effectively maintain its stability by use the center of gravity cog trajectory planning method. 
after analyze the point cloud of rough terrain the forbid area of the terrain can be obtain. 
base on this analysis an optimal foothold search strategy be present to help quadrupe robot to determine the optimum foothold for the swing foot automatically. 
in addition the foot sequence determine method be propose to improve the performance of robot. 
with the free gait propose in this paper quadrupe robot can walk through the rough terrain automatically and successfully. 
the correctness and effectiveness of the propose method be verify via simulation. 
impact of 3d printing technologies on the transformation of industrial production in the arctic zone. 
today the process of transition to a new technological order have become evident to everyone especially in develop country. 
one of the most urgent area for ensure the long term competitiveness of industrial enterprise be the development of the arctic zone. 
this region have many economic and logistical difficulty the solution of which may lie in the use of advanced technology of the new technological order for example 3d print technology. 
the aim of the article be to study the transformation of the cost structure of industrial product as a result of integration of 3d print technology into the production process of industrial enterprise operate in the arctic zone. 
it be find that the structure of the main cost element vary greatly due to the ambiguity of replace computer numerical control cnc or other classical shaping technology with 3d print technology as well as the specific of supply chain which be quite urgent for the arctic region. 
the result of empirical study necessitate the development of tool for predict the economic viability of integrate 3d print technology into the technological process of industrial enterprise operate in the arctic zone. 
within the article the author substantiate and develop a fuzzy multiple model for assess the level of investment attractiveness of integration of 3d print technology into the production process of an industrial enterprise operate the arctic zone. 
one of the aim of this model be to answer the question of whether an enterprise should invest in a technological transition to 3d print technology. 
systematic review of research relate to heavy duty machine tool foundation system. 
the quality of heavy duty machine tool foundation can drastically affect the operate life and working precision of the tool and the high cost of manufacture have draw a lot of attention. 
this article summarize the research status of the relevant literature on the characteristic vibration isolation foundation optimization and quality inspection of heavy duty machine tool foundation system induce the influence law of the influence factor of the system review the highlight and achievement in the research of heavy machine tool foundation system at present and put forward some problem and development direction exist in the research of heavy machine tool foundation system. 
it lay a foundation for realize the judgment of the concrete foundation quality and improve the processing precision and the maintenance of the heavy machine tool. 
experimental analysis of the wear coefficient for the rolling linear guide. 
with the development of roll linear guide manufacturing improvement of performance and reliability of roll linear guide product have become the critical technical challenge. 
one of the key point lie in the analysis of wear process in which the crucial step depend on the computation of the wear coefficient. 
however little attention have be devote to the wear coefficient of roll linear guide. 
therefore in this article to reflect the actual work condition of roll linear guide a novel calculation model for the wear coefficient of rolling linear guide be establish first through theoretical analysis. 
and then base on a novel loading bench and a friction measure device the wear process and wear coefficient of a rolling linear guide da45cl be obtain and analyze. 
further analysis show that the wear coefficient obtain in this article which be several order of magnitude less than the previous empirical value be more reasonable for the wear analysis of roll linear guide. 
the current work provide a new theoretical and experimental method to investigate the wear coefficient for roll linear guide which be meaningful for the study of the wear process of roll linear guide and other rolling component of computer numerical control cnc machine tool. 
on the impact of unknown signals on delay doppler amplitude and phase parameter estimation. 
the estimation of time delay doppler shift amplitude and phase be an important fundamental tool in signal processing which have receive extensive study for case with know transmit signal but little study for unknown transmit signal. 
we derive the closed form cramer rao bind crb expression for joint or separate estimation of time delay doppler shift amplitude and phase with unknown signal with possibly know structure and possible multiple look at direct path and reflect path observation. 
the present result generalize previous result for know transmit signal and showhowmany look from the direct path and the reflected path we need to derive an accurate estimation of time delay doppler shift amplitude and phase. 
the advantage of the know signal format with unknown parameter over totally unknown signal be illustrate. 
after analysis under a simple white clutter plus noise model extension to the case with dependent clutter plus noise be discuss. 
numerical result show very similar behavior. 
numerical calculation of the mean square error from maximum likelihood estimation be provide to support the utility of the unknown signal crb and the know signal format crb. 
real time three dimensional vibration monitoring of rotate shaft use constant density sinusoidal fringe pattern as tri axial sensor. 
the radial and axial vibration signal of a rotate machine be crucial information to understand the machine operation and to diagnose potential fault. 
instead of use three single sensor to measure the horizontal vertical and axial displacement of rotate shaft a novel non projection vision base system be propose to realize simultaneous measurement of the radial and axial displacement with high accuracy and good reliability use an tailored artificial constant density sinusoidal fringe pattern cdsfp which be paste around the shaft surface and work as a tri axial i.e. 
the horizontal vertical and axial displacement sensor. 
the measurement principle and setup of the propose measurement system be well establish. 
the horizontal displacement could be correctly obtain from the fringe period density change of the cdsfp image sequence record by a high speed camera. 
simultaneously the vertical displacement could be acquire by track the centerline of shaft whilst the axial displacement could be obtain by locate the peak of the cross correlation sequence of the fringe intensity. 
a sub pixel method be employ to improve the displacement resolution of the develop system. 
the performance of the propose system be demonstrate by the comparison of the experiment use eddy current sensor. 
it show that the propose method be an effective and accurate technique for real time tri axial vibration monitoring of rotate shaft. 
experimental result verify the feasibility effectiveness and good robustness of the propose methodology which demonstrate that the propose system be capable of achieve accurate tri axial vibration displacement of rotate shaft compare to the commercial eddy current sensor which could only measure one dimensional displacement at each measurement. 
therefore the vision base tri axial vibration monitoring system could be recommend for real engineering application in condition monitoring of rotate shaft. 
c 2018 elsevier ltd. 
all right reserve. 
a generic tool wear model and its application to force modeling and wear monitoring in high speed mill. 
tool wear be an important factor that influence machining precision and part quality in high speed milling and it be essential to seek a convenient method to monitor and predict tool condition. 
a generic wear model with adjustable coefficient be propose and validate in this study. 
in this model three wear zone of an entire tool life be divide by critical time consider the nature of different wear stage. 
additionally the intrinsic amplitude and growth frequency in early and later mill stage be explicate and elaborate to determine the tool flank wear over whole milling process. 
the relationship between mill force against tool flank wear be study and identify which provide a technical foundation for online force modeling and wear monitoring. 
it be show that with inclusion of the wear factor the mill force can be predict accurately with 98.5 agreement with the instantaneous force model. 
in addition tool life can be predict conveniently base on the wear model. 
due to adjustability of coefficient in the model it can be generalize to various machining type and condition. 
c 2018 elsevier ltd. 
all right reserve. 
deep learning and its application to machine health monitoring. 
since 2006 deep learning dl have become a rapidly grow research direction redefine state of the art performance in a wide range of area such as object recognition image segmentation speech recognition and machine translation. 
in modern manufacturing system data drive machine health monitoring be gain in popularity due to the widespread deployment of low cost sensor and their connection to the internet. 
meanwhile deep learning provide useful tool for processing and analyze these big machinery datum. 
the main purpose of this paper be to review and summarize the emerge research work of deep learning on machine health monitoring. 
after the brief introduction of deep learning technique the application of deep learning in machine health monitoring system be review mainly from the following aspect auto encoder ae and its variant restricted boltzmann machines and its variant include deep belief network dbn and deep boltzmann machines dbm convolutional neural networks cnn and recurrent neural networks rnn. 
in addition an experimental study on the performance of these approach have be conduct in which the datum and code have be online. 
finally some new trend of dl base machine health monitoring method be discuss. 
c 2018 elsevier ltd. 
all right reserve. 
early chatter identification base on an optimize variational mode decomposition. 
in the milling process chatter which result in poor surface quality dimensional error and reduce cutter and machine life be one of the main limitation on performance. 
consequently a reliable real time detection method be desire to recognize chatter while it be develop. 
this study develop a novel method of online chatter identification for mill process. 
in this method optimize variational mode decomposition ovmd be use to decompose cut force measurement and the sub component contain chatter information be extract use a simulated annealing sa algorithm. 
the approximate entropy and the sample entropy be use to detect the onset of chatter. 
to evaluate the effectiveness of the propose method mill operation be perform and force measurement be collect for five type of operating condition. 
the result show that the propose method be suitable for detect both continuous and intermittent chatter. 
rather than establish an absolute threshold for chatter detection the onset of chatter be identify from relative change in the entropy with time that occur under the various cutting condition. 
the propose method be show to have great sensitivity and stability than empirical mode decomposition emd. 
c 2018 elsevier ltd. 
all right reserve. 
hybrid sequential fault estimation for multi mode diagnosis of gas turbine engine. 
health condition monitoring of gas turbine engine gte component be key for predictive maintenance planning. 
the task be challenge as the gas path component be mostly inaccessible for direct measurement while at the same time hide incipient fault must be diagnose use the available measurement. 
the presence of multiple fault with similar symptom add to the complexity of the diagnostic process. 
in previous research work a data drive multi mode fault parameter estimation scheme be introduce for real time multimode diagnosis of gtes under diverse operating condition and fault scenario. 
in this work a hybrid diagnostic framework be develop that fuse the result from a measurement base fault parameter estimation strategy together with a fault propagation model. 
the hybrid framework use a novel particle filter pf structure with redundant measurement that facilitate update the particle weight while reduce the dimensionality of the measurement likelihood. 
apply the developed framework on gte gas path datum with four different gradually worsen fault the result show the diagnostic accuracy increase up to ten time compare to the previously develop fault parameter estimation scheme. 
c 2018 elsevier ltd. 
all right reserve. 
identification and analysis of nonlinear dynamic of inertial actuator. 
this paper present an experimental study of the nonlinear dynamic of electrodynamic proof mass actuator. 
when inertial actuator be use in velocity feedback controller their nonlinear dynamic can affect the stability margin of the feedback loop. 
thus it be crucial to identify the nonlinearity source and to build reliable model that can be implement in the stability analysis. 
firstly the underlying linear model parameter of an inertial actuator be identify for small excitation signal. 
the inductance loss at high frequency due to eddy current have also be include in the electrical impedance model. 
secondly the nonlinear model of the inertial actuator be determine use the detection characterisation and identification process. 
finally a numerical analysis be carry out to highlight the implication of nonlinear dynamic of inertial actuator. 
the propose methodology be apply to several electromagnetic proof mass actuator include when the proof mass be not accessible to be directly instrumented. 
c 2018 elsevier ltd. 
all right reserve. 
hybrid interval and random analysis for structural acoustic system include periodical composite and multi scale bound hybrid uncertain parameter. 
for the response analysis of periodical composite structural acoustic system with multi scale uncertain but bound parameter a bound hybrid uncertain model be introduce in which the interval variable and the bound random variable exist simultaneously. 
in the periodical composite structural acoustic system the equivalent macro constitutive matrix and average mass density of the microstructure be calculate through the homogenization method. 
on the basis of the conventional first order taylor series expansion a homogenization base hybrid stochastic interval perturbation method hhsipm be develop for the prediction of periodical composite structural acoustic system with multi scale bound hybrid uncertain parameter. 
by incorporate the gegenbauer polynomial approximation theory into the homogenization base finite element method a homogenization base gegenbauer polynomial expansion method hgpem be also propose to calculate the bound of expectation and variance of the sound pressure response. 
numerical example of a hexahedral box and an automobile passenger compartment be give to investigate the effectiveness of the hhsipm and hgpem for the prediction of periodical composite structural acoustic system with multi scale bound hybrid uncertain parameter. 
c 2018 elsevier ltd. 
all right reserve. 
gear fault diagnosis base on a new wavelet adaptive threshold de noise method. 
purpose this paper aim to explore a new wavelet adaptive threshold de noising method to resolve the shortcoming of wavelet hard threshold method and wavelet soft threshold method which be usually use in gear fault diagnosis. 
design methodology approach a new threshold function and a new determined method of threshold for each layer be propose. 
the principle and the implementation of the algorithm be give. 
the simulated signal and the measure gear fault signal be analyze and the obtain result be compare with those from wavelet soft threshold method wavelet hard threshold method and wavelet modulus maximum method. 
findings the present wavelet adaptive threshold method overcome the defect of the traditional wavelet threshold method and it can effectively eliminate the noise hide in the gear fault signal at different decomposition scale. 
it provide more accurate information for the further fault diagnosis. 
originality value a new threshold function be adopt and the multi resolution unbiased risk estimation be use to determine the adaptive threshold which overcome the defect of the traditional wavelet method. 
simulation and experiment on pressure field characteristic of hydrostatic hydrodynamic hybrid thrust bearing. 
purpose this paper aim to improve the bearing capacity of hydrostatic thrust bear under work condition of high speed and heavy load a new wedge shape structure open on an edge of oil seal be put forward the loss and insufficiency for hydrostatic bearing capacity be make up by use dynamic pressure and then hydrostatic hydrodynamic lubrication be realize. 
design methodology approach oil film three dimensional model of unidirectional and bi directional hydrostatic hydrodynamic oil pad be establish by use ug. 
the oil film pressure field of two kind of oil pad be simulate by use ansys icem cfd and ansys cfx the pressure field distribution characteristic be obtain and the effect of workbench rotary speed and bear weight on pressure field be analyze. 
also the experimental verification be make. 
findings the result demonstrate that with an increase in workbench rotary speed the oil film pressure of two kind of hybrid oil pad increase gradually and the maximum pressure of the bi directional one account for 95 per cent of the unidirectional one when the load be constant. 
with an increase in load the oil film pressure of two kind of hybrid oil pad increase gradually the difference between they be 9.4 per cent under the condition of load of 25 t when the rotary speed be constant. 
originality value the paper can provide theoretical basis for a structure design of hybrid thrust bear under different rotary speed and load condition and compensate the shortage of static pressure bearing capacity by use dynamic pressure improve the stability of vertical cnc machining equipment. 
hot oil carry characteristic about hydrostatic bear oil film of heavy vertical lathe in high speed. 
purpose to investigate the effect of hot oil carry hoc the purpose of this paper be to present a new calculation method of oil film temperature which take the effect into account and define the factor of hoc. 
design methodology approach base on finite volume method the paper study the temperature characteristic in high speed and the condition of variable viscosity from the temperature field and flow field of the film and the thermal rule of hoc be reveal. 
the theoretical value be in good agreement with the experimental result. 
findings the result show that for this structure of hydrostatic bearing the phenomenon of hoc do not occur until the work speed be more than 10 r min under any load condition. 
and it always happen in the total range of load from zero to 320 kn when the speed be over 60 r min. 
moreover the film temperature increase sharply when the phenomenon happen in high speed and the influence of the speed be great than the effect of load on the temperature rise. 
originality value the result would help to increase the speed of cnc machine tool and the design on structure of the bearing in engineering practice. 
resource efficient piston ring cylinder liner pair. 
purpose the purpose of this paper be to investigate the influence of different finish process on the surface integrity and tribological behaviour of cylinder running surface for internal combustion engine. 
design methodology approach the cut force during finishing and the result surface topography be measure for a variety of cylinder running surface make of en gjl 250 en gjv 400 and thermal spray aluminium alloy. 
a separate conditioning tool be develop and test. 
different analysis method sem edx sims and fib for the characterisation of the boundary condition be use. 
by an oscillate friction wear test and a single cylinder float liner engine the running in and frictional behaviour be rate. 
finding it be show that hone with low cut force and silicon carbide cut material decrease the friction in operation. 
the characteristic of the boundary layer after running in depend on the finish machining process. 
a preconditioning with a separate tool can adjust the boundary layer and running in behaviour. 
base on the experimental result a multi body and computational fluid dynamic simulation be develop for the float liner engine. 
originality value the result demonstrate the potential of finish with low process force to reduce friction and the need for a complete consideration of the tribological system piston ring cylinder liner surface. 
a stable proportional proportional integral tracking controller with self organize fuzzy tuned gain for parallel robot. 
parallel robot be nowadays use in many high precision task. 
the dynamic of parallel robot be naturally more complex than the dynamic of serial robot due to their kinematic structure compose by closed chain. 
in addition their current high precision application demand the innovation of more effective and robust motion controller. 
this have motivate researcher to propose novel and more robust controller that can perform the motion control task of these manipulator. 
in this article a two loop proportional proportional integral controller for trajectory tracking control of parallel robot be propose. 
in the propose scheme the gain of the proportional integral control loop be constant while the gain of the proportional control loop be online tune by a novel self organize fuzzy algorithm. 
this algorithm generate a performance index of the overall controller base on the past and the current tracking error. 
such a performance index be then use to modify some parameter of fuzzy membership function which be part of a fuzzy inference engine. 
this fuzzy engine receive in turn the tracking error as input and produce an increment positive or negative to the current gain. 
the stability analysis of the closed loop system of the propose controller apply to the model of a parallel manipulator be carry on which result in the uniform ultimate boundedness of the solution of the closed loop system. 
moreover the stability analysis develop for proportional proportional integral variable gain scheme be valid not only when use a self organize fuzzy algorithm for gain tuning but also with other gain tuning algorithm only provide that the produce gain meet the criterion for boundedness of the solution. 
furthermore the superior performance of the propose controller be validate by numerical simulation of its application to the model of a planar three degree of freedom parallel robot. 
the result of numerical simulation of a proportional integral derivative controller and a fuzzy tune proportional derivative controller apply to the model of the robot be also obtain for comparison purpose. 
parlami a multimodal approach for programming intelligent environments dagger. 
the proliferation of internet of things iot device and service and their integration in intelligent environment create the need for a simple yet effective way of control and communicate with they. 
towards such a direction this work present parlami a conversational framework feature a multimodal chatbot that permit user to create simple if then rule to define the behavior of an intelligent environment. 
parlami deliver a disembodied conversational agent in the form of a messaging application name mai and an embody conversational agent name naomi employ the programmable humanoid robot nao. 
this paper describe the requirement and architecture of parlami the infrastructure of the intelligent home in which parlami be deploy the characteristic and functionality of both mai and naomi and finally present the finding of a user experience evaluation that be conduct with the participation of sixteen user. 
air quality planning and the minimization of negative externalities. 
the minimization of negative externality be a key aspect in the development of a circular and sustainable economic model. 
at the local scale especially in urban area externality be generate by the adverse impact of air pollution on human health. 
local air quality policy and plan often lack of consideration and instrument for the quantification and evaluation of external health cost. 
support for decision maker be need in particular during the implementation stage of air quality plan. 
modelling tool base on the impact pathway approach can provide such support. 
in this paper the implementation of health impact and externality analysis in air quality planning be evaluate. 
the state of the art in european member state be report consider whether and how health effect have be include in the planning scheme. 
the air quality plan of the piemonte region in italy be then consider. 
a case study be analyze to evaluate a plan action the development of the district heating system in the city of turin. 
the diati dipartimento di ingegneria dell ambiente del territorio e delle infrastrutture dispersion and externalities model didem model be apply to detect the scenario with the high external cost reduction. 
this methodology result be extensible and adaptable to other action and measure as well as other local policy in europe. 
the use of health externality should be encourage and integrate into the present methodology support air quality planning. 
effort should be address to quantify and minimize the overall uncertainty of the process. 
acceptability study of a3 k3 robotic architecture for a neurorobotics painting. 
in this paper author present a novel architecture for control an industrial robot via brain computer interface. 
the robot use be a series 2000 kr 210 two. 
the robotic arm be fit with di drawing device that clamp hold and manipulate various artistic medium like brush pencil pen. 
user select a high level task for instance a shape or movement use a human machine interface and the translation in robot movement be entirely demand to the robot control architecture define a plan to accomplish user s task. 
the architecture be compose by a human machine interface base on p300 brain computer interface and a robotic architecture compose by a deliberative layer and a reactive layer to translate user s high level command in a stream of movement for robot joint. 
to create a real case scenario the architecture be present at ars electronica festival where the a3 k3 architecture have be use for paint. 
visitor complete a survey to address four self assess different dimension relate to human robot interaction the technology knowledge the personal attitude the innovativeness and the satisfaction. 
the obtain result have lead to far explore the border of human robot interaction highlight the possibility of human expression in the interaction process with a machine to create art. 
adaptive security monitoring for next generation router. 
in today s internet modern router rely on high performance reliable general purpose multi core packet processing system in order to support the flexibility and the plethora of protocol operation and application. 
these processing system be programmable and have replace the traditional fix logic asic in the datum path of such router. 
hence lot of vulnerability and fault be introduce as the result of such programmability make the system susceptible to attack and failure. 
particularly it be a difficult task to detect whether a processing core behave correctly or it have a failure result from error or attack. 
in this paper we address this problem by propose a novel approach to verify the correct operation of the network processor. 
we propose a secure fault tolerant and reliable monitoring subsystem which function in parallel with the processing core of the router and aid in the detection of attack change the processing behavior of the processor. 
we prove experimentally that our system have the ability to detect the malicious activity and securely restore the router s operation to a different but functionally equivalent state. 
we also show experimentally that our approach have a well efficiency when compare with other exist work. 
bandwidth tunable filter balun base on compact 3d configuration. 
for the first time a novel bandwidth tunable filter balun base on compact 3d configuration be present. 
the overall design be basically compose of a two layer horizontal feeding plane a three layer vertically mount plane and the transmission line circuit dispose on both. 
implement the ring resonator in vertical double sided parallel strip line the complete horizontal ground and frequency independent phase difference be subtly combine. 
connect the shunt varactor diode with the insert vertical ground the desirable filter property and flexible bandwidth tunability be splendidly fulfil. 
a prototype balun centre at 1.53 ghz be fabricate. 
the measured operating bandwidth be dynamically tune from 0.87 to 1.23 ghz with a return loss 10 db forcefully validate the design concept. 
image processing procedure to quantify the internal structure of porous asphalt concrete. 
purpose in order to fully understand the property of porous asphalt investigation should be conduct from different point of view. 
this be from the fact that porous asphalt mixture design with the same aggregate gradation and air void content can give different infiltration rate due to the different formation of the internal structure. 
therefore the purpose of this paper be to investigate the micro structural property and functional performance of porous asphalt simultaneously. 
design methodology approach the aim be to develop image technique to process and analyze the internal structure of porous asphalt mixture. 
a few parameter be establish to analyze the air void property and aggregate interlock within the gyratory compact sample capture use a non destructive scan technique of x ray compute tomography ct throughout the sample. 
the result be then compare with the functional performance in term of permeability. 
four aggregate gradation use in different country malaysia australia the usa and singapore. 
the sample be test for resilient modulus and permeability. 
quantitative analysis of the microstructure be use to establish the relationship between the air void property and aggregate interlock and the resilient modulus and permeability. 
findings base on the result it be find that the micro structural property investigate have successfully describe the internal structure formation and they reflect the result of resilient modulus and permeability. 
in addition the imaging technique which include the image processing and image analysis for internal structure quantification seem to be very useful and perform well with the x ray ct image base on the reliable result obtain from the analysis. 
research limitation implication in this study attention be limit to the study of internal structure of porous asphalt sample prepare in the laboratory use x ray ct but can also be use to assess the quality of finished asphalt pavement by take core sample for quantitative and qualitative analysis. 
the use of ct for material characterization present a lot of possibility in the future of asphalt concrete mix design. 
originality value base on the validation process which include comparison between the value obtain from the image analysis and those from the performance test and it be find that the developed procedure satisfactorily assess the air voids distribution and the aggregate interlock for this reason it can be use. 
reusability analytic tool for end of life assessment of building material in a circular economy. 
purpose in a circular economy the goal be to keep material value in the economy for as long as possible. 
for the construction industry to support the goal of the circular economy there be the need for material reuse. 
however there be little or no information about the amount and quality of reusable material obtainable when building be deconstruct. 
the purpose of this paper therefore be to develop a reusability analytic tool for assess end of life status of building material. 
design methodology approach a review of the extant literature be carry out to identify the good approach to model end of life reusability assessment tool. 
the reliability analysis principle and material property be use to develop the predictive mathematical model for assess building material performance. 
the model be test use the case study of a building design and material take off quantity as specify in the bill of quantity of the building design. 
findings the result of analytic show that the quality of the building material vary with the building component. 
for example from the case study at the 80th year of the building the quality of the obtainable concrete from the building be 0.9865 0.9835 0.9728 and 0.9799 respectively from the foundation first floor frame and stair component of the building. 
originality value as a contribution to the concept of circular economy in the build environment the tool provide a foundation for estimate the quality of obtainable building material at the end of life base on the life expectancy of the building material. 
cognitive processes of the construction engineer planning and decision making in production and safety. 
in recent year in the construction industry face the limitation of behavioral approach the approach to cognitive aspect have be consider an alternative to improve production and safety. 
the goal of this article be to understand the cognitive process of the construction engineer that allow they to anticipate problem in several levels of anticipation of the construction process planning and decision make in production and safety. 
to achieve this goal we use interact with the ethnographic study the methodology of activity analysis and in particular what be call approach of the course of action. 
thus the case present make it possible to understand how the construction engineer use information available in the levels of anticipation of the construction process manipulate resource personal tacit and explicit knowledge skill etc material design and social relationship with his team) when he perceive problem. 
by understand their fortis we can well foment their cognitive process. 
thus the theory be relevant and contribute to describe and explain the process of human problem solve decision making and plan. 
longitudinal torsional ultrasonic vibration assist side milling process. 
in this paper a longitudinal torsional ultrasonic vibration assist side milling be investigate. 
different from the continuous cutting process in conventional side milling the longitudinal torsional ultrasonic vibration milling process be high frequency intermittent. 
the intermittent cutting process be cause by the helical trajectory of the cutting edge. 
a mathematical model be establish to simulate the trajectory and then the high frequency intermittent cutting process be analyze base on the model. 
spindle speed helix angle of mill tool and ultrasonic vibration amplitude be find to be the factor that be responsible for the ultrasonic cutting effect. 
when the spindle speed be 1500 r min and the helical angle of mill tool be 30 degree ultrasonic vibration milling experiment have show that the cut force can be reduce by 45.8 in the x direction at the most 27.6 in the y direction and 48 in the z direction compare to conventional milling. 
the experimental result also show that the decrement of the cut force decrease along with the increasing of the cut speed and helical angle of mill tool due to the decrease of the uncutting time. 
however the increasing of the vibration amplitude can increase the decrement. 
real time monitoring of event apply to syndromic surveillance. 
this article focus on monitor plan aim at the early detection of the increase in the frequency of event. 
the literature recommend either monitor the time between event tbe if event be rare or count the number of event per unit non overlapping time interval otherwise. 
some author advocate use the bernoulli model for rare event apply presence or absence of event within non overlapping and exhaustive time interval. 
this bernoulli model do improve the real time monitoring assessment of these event compare to count event over a large interval make they less rare. 
however this approach become inefficient if more than one event start occur within the interval. 
monitor tbe be the real time option for outbreak detection because outbreak information be accumulate when an event occur. 
this be prefer to wait for the end of a period to count event. 
if the tbe reduce significantly then the incidence of these event increase significantly. 
this article explore this tbe option relative to use the monitoring of count when the tbe be either exponentially gamma or weibull distribute for moderately low count scenario. 
the article will discuss and compare the approach of use an exponentially weighted moving average ewma statistic for the tbe to the ewma of count. 
several robust option will be consider when the future change in event frequency be unknown. 
our goal be to have a robust monitoring plan which be able to efficiently detect many different level of shift. 
these robust plan be compare to the more traditional event monitoring plan for both small and large change in the event frequency. 
discussion on real time monitoring of event apply to syndromic surveillance. 
i discuss the article real time monitoring of event apply to syndromic surveillance by spark and collaborator. 
this discussion focus on how statistical network modeling and inference can be use to augment the analysis do in their paper. 
in particular i describe what network model can be use to characterize the dynamic and interaction of twitter user and more broadly how network analysis can be use to benefit statistical process monitoring. 
i hope to not only provide reader a new perspective on how to approach statistical process monitor in the context of social interaction but also to motivate future research that address the unique challenge face quality engineer. 
stabilization of ode with hyperbolic equation actuator subject to boundary control match disturbance. 
in this paper we consider stabilisation for a cascade of ode and first order hyperbolic equation with external disturbance flow to the control end. 
the active disturbance rejection control adrc and slide mode control smc approach be adopt in investigation. 
by adrc approach the disturbance be estimate through a disturbance estimator with both time vary high gain and constant high gain and the disturbance be cancel online in the feedback loop. 
it be show that the result closed loop system with time vary high gain be asymptotically stable and be practically stable with constant high gain. 
by smc approach the existence and uniqueness of the solution for the closed loop via smc be prove and the monotonicity of the reach condition be present. 
the result closed loop system be show to be exponentially stable. 
the numerical experiment be carry out to illustrate effectiveness of the propose control law. 
parabolic pde base multi agent formation control on a cylindrical surface. 
this paper consider the modelling and control design of the multi agent system in the three d space. 
the communication graph of the agent be a mesh grid two d cylindrical surface. 
different from most exist literature where the agent be model by ordinary differential equation ode we treat the agent as a continuum in this paper. 
more specifically we model the collective dynamic of the agent by two reaction advection diffusion two d partial differential equation pde. 
the pde state represent the agent position and the equilibrium correspond to possible formation manifold. 
these pde can be open loop unstable and the boundary stabilisation problem of the pde on the cylindrical surface be solve use the backstepping method. 
an all explicit observer base output control scheme be construct which be distribute in the sense that each agent only need local information. 
closed loop exponential stability in the l two h one and h two space be prove for the controller design. 
numerical simulation illustrate the effectiveness of our propose approach. 
finite dimensional approximation for a class of infinite dimensional time optimal control problem. 
in this work we study the numerical approximation of the solution of a class of abstract parabolic time optimal control problem with unbounded control operator. 
our main result assert that provide that the target be a closed ball center at the origin and of positive radius the optimal time and the optimal control of the approximate time optimal problem converge in appropriate norm to the optimal time and to the optimal control of the original problem. 
in order to prove our main theorem we provide a nonsmooth datum error estimate for abstract parabolic system. 
identification and management of the near field knowledge of industrial design for innovative product shape. 
industrial design be a complex process that contain multifarious product knowledge system which play different role at different stage of product development. 
base on the research of different theory and method of knowledge classification the article propose a new method which divide industrial design knowledge into knowledge in the field near field knowledge and far field knowledge and establish a corresponding frame of the design knowledge. 
in order to differentiate the near field knowledge which be more innovative in design from considerable knowledge to facilitate an efficient design process mechanism of similarity search be use. 
if 0.3 s w similarity 0.6 then define the case as the near field product case and the relative knowledge as near field knowledge. 
the core knowledge can be retrieve to drive innovative modeling. 
furthermore the process of a laptop design be take as an example and validate use this method. 
trade association as corporate social responsibility actor an institutional theory analysis of animal welfare in tourism. 
most travel trade association ignore their responsibility towards sustainable development broadly and animal welfare in particular. 
we analyse the development and implementation of animal welfare standard across 62 national and international association use interview survey content analysis of publish material and website. 
only 21 association mention sustainability in their website and only six refer to animal welfare. 
of these three association have well develop animal welfare activity abta anvr and gstc aq1 and only one lightly monitor its member sustainability and animal welfare standard anvr. 
abta s animal welfare guidelines be the de facto industry standard despite be design for information not auditing purpose and lack enforcement mechanism. 
we examine jolt that prompt some association to respond to external pressure and the institutional entrepreneurship process that trigger a process of reflexivity theorisation and diffusion of a broad sense of responsibility. 
we examine the field level condition that lead to mostly mimetic pressure on large european tour operator that compel they to act due to reputational risk management with minimal normative pressure that would diffuse animal welfare practice across other association member. 
change be not divergent and the resource allocate to animal welfare protect trade association member from criticism without bind they to implementation. 
collaborative processes and collective impact in tourist rural villages insights from a comparative analysis between argentinian and italian case. 
multi case study research conduct in some rural village of argentina and italy be intend to propose a model of analysis and monitoring of the collaborative process which stand behind the tourist enhancement of local asset. 
base on the definition of collective impact three main issue be analyze one the shortage of social capital typical of some contemporary rural area as a social problem two the commitment of actor from different sector to the common agenda of tourist development three the structured form of coordination drive by extra local organization and program aim at foster sustainable tourism in rural village. 
these issue be develop into key concept use for the comparative description and analysis of the case and for the definition of a common model of measurement and monitoring of the ongoing development process. 
the main result be synthesize into a bidimensional plot where the x axis represent the integration dimension and the y axis the coordination. 
each village be then represent as a point of the cartesian plan. 
the final idea be to use the model to monitor the process within each different rural village and to measure the change over time. 
reduce the risk during the purchase of five axis cnc machining centers use ahp method and fuzzy systems. 
nowadays company be in the process of renew their manufacturing line by equip they with modern five axis cnc computer numerical control machining center. 
the decision to select between different five axis cnc machining center with similar technological capability be a difficult process so the main goal of this work be to develop a method for assist it. 
the propose approach rely on seven technical criterion four quantitative one traverse speed thrust spindle power and spindle speed which can be express by crisp numerical value while the other three flexibility operation easiness and setup time be qualitative one. 
the analytic hierarchy process ahp be use for order four variant of five axis cnc mill machining center. 
the qualitative criterion be process use fuzzy system to be express by crisp numerical value suitable for ahp. 
finally the four variant of five axis cnc mill machining center be hierarchize and the good one be choose. 
a sensitivity analysis be also unfold to certify the robustness of the ahp. 
a hybrid process to address uncertainty and change climate risk in coastal areas use dynamic adaptive pathways planning multi criteria decision analysis real options analysis a new zealand application. 
decision maker face challenge in coastal area about how to address the effect of ongoing and uncertain sea level rise. 
dynamic adaptive pathway plan dapp and real options analysis roa can support decision maker to address irreducible uncertainty in coastal area. 
this paper set out what we learn by complement multi criteria decision analysis with dapp and roa when develop a 100 year coastal adaptation strategy in hawke s bay new zealand. 
lesson include the value of collaborative community and decision maker process for increase understanding about the change risk over time and the need to take early action that enable a shift in pathway before those action become ineffective. 
modification to the method highlight the importance of use several plausible scenario for stress testing option consider cost and consent ability early to avoid the perception that hard protection will last which criterion be appropriate for community to assess and make many pathway visible for future decision maker. 
we learn about the difficulty shift think from short term protection action to long term anticipatory strategy. 
we find that a pathway system will require ongoing political leadership and governance with monitoring system that can manage the adaptive process over long timeframe by government and their constituent community. 
optimal joint production and emissions reduction strategy consider consumers environmental preferences a manufacturer s perspective. 
carbon cap and trade mechanism be a government mandate market base scheme to reduce emission which have a significant effect on manufacturer operation decision. 
base on the cap and trade mechanism this paper study the joint production and emission reduction problem of a manufacturer. 
the manufacturer face emission sensitive demand impact by consumer environmental preference cep. 
an extended newsvendor model be use to find the optimal production quantity and emission reduction quantity. 
we explore the impact of market price of carbon credit emission reduction investment coefficient and cep on the optimal strategy. 
numerical example be provide to illustrate the theoretical result and orthogonal experimental design technique be apply to find robust system parameter. 
it be conclude that among all parameter emission cap have the great impact on the expect profit which be follow by than the market price of carbon credit. 
this mean that the government play a major role in economic development. 
the total carbon emission be mainly affect by the carbon trading price and the product s sale price which indicate the carbon trading market and product market play a large role in control environmental benefit. 
several valuable managerial insight on help government and industry understand how market condition change and make well long term decision be far conclude. 
solve the screw compressor rotor form grind wheel use the edge detection method base on the graphic method. 
as a complex grinding wheel for special use the screw compressor rotor form grind wheel need to be design accord to the specific profile of the workpiece. 
the design process be complicated and difficult to grasp and various design issue be likely to occur. 
this study be base on the design theory of helical rotor form grind wheel. 
here disc shape form grind wheel for machine a helical surface be study with discrete point workpiece cros section as example. 
matlab be use as the development tool and the unigraphics motion simulation function be apply to establish a 3d model of screw rotor and design the form grinding wheel for machine the helical surface. 
additionally the edge shape of the grind wheel obtain with the analytical method and the edge shape obtain with the edge detection method base on the graphic method and the alpha shape algorithm be compare. 
the result of this comparison show that the edge shape of the grind wheel obtain by the edge detection method have high precision and be easy to solve. 
this method can also be use for the design of other similar conjugate product such as gear worm and grind wheel. 
the research finding provide important reference value for the design and machining of screw rotor and grind wheel. 
pressure characteristic of a novel double rotor hydraulic transformer. 
the hydraulic transformer be the core component when it work with the common pressure rail system which integrate the function of the pump and the motor and thus possess sensitive pressure characteristic. 
the rotate speed have significant influence on the pressure characteristic of a hydraulic transformer while it have not be consider previously. 
in this study aim at improve the work performance a novel double rotor hydraulic transformer be propose and a comprehensive mathematical model consider the dynamic characteristic of the cylinder block be establish. 
at the same time a prototype be make and the experiment be conduct. 
the test result show that the robust rotor structure enable a large pressure range and the numerical result exhibit a good match with the test result. 
the parameter sensitivity study show that the delivery pressure be mainly subject to the valve plate control angle delta and under the effect of the resistance torque pressure loss will occur especially under a large control angle and a high rotate speed. 
the magnitude of the instantaneous angular velocity fluctuation increase sharply when the speed be low than 400 r min which be the main reason for the serious pressure pulsation at a low speed. 
as a result of the improve low speed stability and output flow uniformity the pressure pulsation rate of the double rotor hydraulic transformer be greatly reduce. 
however the pulsation rate be still high at an extremely low speed. 
in addition when the rotate speed exceed the capability of the damp groove the pressure undershoot become serious at the a t transition region around the control angle of  30 degree. 
consequently from the perspective of pressure characteristic the limitation on the rotate speed under small control angle be suggest for the design of the double rotor hydraulic transformer controller. 
an improved sag detection approach base on modify goertzel algorithm. 
power quality be one of the key feature in develop electric network. 
it have be notice because of its impact on economy and reliability of electrical network. 
there be several power quality phenomenon which be categorise in recent standard and literature. 
among they voltage sag be more common and destructive for electric network and consumer. 
this article present a new detection method to monitor voltage sag in different electric network condition. 
goertzel algorithm be show to be effective and simple for sag measurement compare to available sag detection method. 
in order to increase the detection speed and response time the goertzel algorithm be modify. 
this modification will add to the speed of sag detection. 
the feasibility of the propose method be justify through a measurement set up develop use the dspace r1104 digital signal processor platform. 
the experimental result prove that sag measurement speed be improve by twice use the propose modify goertzel algorithm in comparison with the original method and some establish method. 
the result also verify that the sag detection of the propose method be not affect by harmonic distortion of the voltage waveform. 
re think monitoring services for five g network challenge and perspective. 
the five g promise of accelerate datum transmission low latency wide coverage and reliability enable new use case such as mission critical and enhance mobile broadband embb service. 
for accelerate massive growth the cloud native transformation result in process and workflow that fully take advantage of the five g platform. 
hence with the new requirement new scenario and massive technology transformation the monitoring service for the five g should be re design. 
this paper identify the new challenge for define monitoring service in five g network and present 10 design principle to meet the monitoring need. 
then by follow the analysis of these new monitoring challenge for the five g we review seven open source monitor tool with the propose design principle and present our perspective. 
deadpool performance deadline based frequency pooling and thermal management agent in dvfs enable mpsocs. 
high operating temperature and frequent thermal cycle in a multi processor system on chip which be now popularly utilize in mobile edge device harm the overall lifespan and reliability of such device. 
in this paper we propose an intelligent software agent that work alongside other resource mapping and partition mechanism in order to monitor and reduce the operate temperature of the system by regulate the operate frequency of the cpu core while cater for performance constraint at the same time. 
our propose approach deadpool thermal management agent be able to reduce the overall operating temperature of the system by 24.21 and reduce thermal cycle by 67.42 at the most when compare to the state of the art method. 
data cleaning optimization for grain big data processing use task merging. 
data quality have exert important influence over the application of grain big datum so datum cleaning be necessary and important work. 
in mapreduce frame we can use parallel technique to execute datum cleaning in high scalability mode but due to the lack of effective design there be amount of compute redundancy in the process of datum cleaning which result in low performance. 
in this research we find some task often be carry out multiple time on same input file or require same operation result in the process of datum cleaning. 
for this problem we propose a new optimization technique that be base on task merge. 
by merge simple or redundancy computation on same input file the number of the tool computation in mapreduce can be reduce greatly. 
thy experiment show by this mean the overall system runtime be significantly reduce which prove that the process of datum cleaning be optimize. 
in this paper we optimize several module of datum clean such as entity identification inconsistent data restoration and miss value fill. 
experimental result show that the propose method in this paper can increase efficiency for grain bid datum cleaning. 
design of human machine interactive system base on hand gesture recognition. 
due to the wide application of human computer interaction gesture recognition technology have receive more and more attention in recent year. 
at present the most common human computer interaction system often do not have hand gesture interaction function. 
therefore on the basis of the traditional interactive system function this paper add a depth image capture device to make the system interactive function with bare hand reality. 
the whole interactive system mainly consist of three module preprocessing hand gesture detection and recognition tracking and interaction. 
the preprocesse module be mainly responsible for detect and locate the interaction area. 
the gesture detection and recognition module be mainly responsible for detect and identify gesture appear in the interaction area. 
the tracking and interaction module perform tracking of user gesture through kalman tracking and operate virtual hardware accord to the gesture recognition result to realize human computer interaction function. 
the system have be test in complex environment show robustness to light change and complex background. 
by use cpu gpu parallel computing the average processing speed be achieve more than 50 fps. 
the propose system use kinect camera and use python open source tool for image and video processing. 
this paper establish a gesture interaction system with kinect camera and control the virtual hardware through gesture to realize real time human computer interaction in complex background. 
hydropower generation forecasting via deep neural network. 
with the advance of deep learning its application in our daily life have attract considerable attention from both academic and industry. 
however most of the exist work focus on computer vision and natural language processing while few study in the real industrial manufacture. 
the main reason be that the datum resource be difficult to obtain and the relationship between industrial datum be too complex to be model. 
in this paper we propose a deep neural network base approach for hydroelectric power generation prediction which to our knowledge be the first attempt model power generation datum with the combination of residual neural network and recurrent neural network. 
furthermore we consider different grain of the hydropower generation by divide the datum into four level recent daily weekly and time series sequence which can greatly improve the prediction performance. 
to this end we employ a multi information fusion method to fuse the four component i.e. 
closeness period trend long period predict result among which different component be learn with different weight to determine their influence on final hydropower prediction. 
experiment conduct on the real hydropow generation prove the effectiveness of the propose model which significantly outperform the baseline. 
we hope this research will open a new perspective of improve data usage in the industry especially in power generation area. 
research on network attack detection technology base on reverse detection and protocol analysis. 
with the rapid development of information technology the security of internet information system have become an urgent problem to be consider in the process of internet development. 
in order to prevent the computer information system vulnerability which may lead to hacker attack or virus attack an active defense idea be propose. 
that be to do not open source code and network protocol trojan horse program vulnerability mining and paralysis attack. 
there be also many method to detect network attack. 
this paper introduce the research on network attack detection technology base on reverse detection and protocol analysis. 
by monitor the network attack packet in the big data environment of power system the attack packet be restore and analyze to quickly diagnose and locate the network attack. 
the experimental result show that the method propose in this paper can quickly and accurately locate the network attack analyze the attack process in detail and find out the specific attack path and attack behavior effectively ensure the safe and stable operation of the company s information system network. 
a fault early warning and health status rating method for ensure safe operation of rotate equipment. 
rotate equipment safe operation require to recognize the current health state and forecast their future health state. 
in the field of rotate equipment research into the modeling of early failure warning and health status rating of equipment be still immature. 
therefore it be important to carry out research in this area. 
base on learn information from train fault case sample and expert opinion from condition monitor diagnosis analysis and health degree statistical classification from engineering case study the cross correlation function the spectral distance function the coherence function health evaluation model and the equipment health status rating criterion have be construct. 
combine with the early warning threshold self learn theory health status rating and the l1 trend filter algorithm a kind of health evaluation method have be propose in this paper. 
the fault case of the rotor imbalance of a centrifugal compressor and a laboratory bearing be use to verify the propose method. 
the result show that this approach can be use to evaluate the health status of rotate equipment or a part and can be use to guide the decision make process for equipment operation and maintenance to ensure the safe operation of rotate equipment. 
innovative design of multi process fixture for process the spoke. 
accord to the characteristic of spoke manufacturing process exist problem of spoke process with the traditional clamping of spoke be analyze one kind of multiprocess fixture for process the automobile spoke be design by innovation which have a simple efficient and high precision feature. 
the spoke be position by use the bolt hole surface and the internal plane and clamp fast by use the clamp pin in the bolt hole by mean of simultaneous center clamping the outside diameter surface. 
the end face he center hole surface and the external surface of the automobile speak be process by the way of one time clamp at the same time the 3d model of the spoke be import into abaqus software for deformation analysis. 
through check the result its easily deform place be obtain then the fixture structure be optimize after the optimization of the fixture the maximum displacement and the maximum equivalent stress of the deformable position be significantly reduce which improve the quality of the spoke. 
in the actual production use effect also show that the multiprocess fixture have an advantage of the simple structure reasonable design accurate positioning reliable clamping and convenient operation. 
it improve the machining accuracy of the spoke and create good economic benefit. 
on an improved sinusoidal square curve acceleration and deceleration algorithms in motion control. 
consider that the traditional linear or the exponential acceleration and deceleration control algorithm do not have continuous acceleration curve s curve motion control algorithm do not have continuous jerk some scholar have propose a sinusoidal square curve acceleration and deceleration algorithm in which the displacement velocity acceleration and jerk be all continuous. 
but the jerk curve in this algorithm be not smooth enough which will cause the vibration and the tracking error of the system. 
an improved sinusoidal square curve acceleration and deceleration algorithm be propose in this paper. 
in consideration that the curve of derivable function will become smooth when its order be increase a new second order sine square jerk function be propose and the relevant algorithm model be give. 
the simulation result show that the curve of improve algorithm be smooth than those of the original algorithm which meet the requirement of modern high precision cnc system. 
automatic and intelligent line inspection use uav base on beidou navigation system. 
in this paper the beidou high precision positioning technology the autonomous inspection technology of the uav and the communication technology of the uav be use to construct the inspection architecture of the uav autonomous inspection. 
the inspection architecture include uav inspection path standard planning and acquisition verification uav autonomous flight control system uav and application platform communication control uav inspection result identification and management. 
base on high precision positioning technology we design the architecture of the uav autonomous inspection system the uav autonomous inspection security strategy and transaction processing mechanism the uav s real time video and position transmission system. 
then we successfully develop the uav autonomous inspection system. 
after testing base on high precision positioning technology the accuracy of the uav autonomous inspection repeat flight can reach five cm ew six cm ns seven cm h and the stop point heading angle be 56 on average which can indicate that under the guarantee of this system the uav can carry an important role in inspection work safely and effectively. 
detection of weak signal to noise ratio signal while drilling base on duffing chaotic oscillator. 
in the process of drilling the strong vibration and rapid rotation of bottom drilling tool lead to multi frequency and high amplitude interference signal in attitude measurement signal. 
the problem of weak original signal amplitude and very low signal to noise ratio be always the technical difficulty in the field of while drilling measurement to solve this problem a duffing chaotic system detection method suitable for weak signal recognition while drilling be propose in this paper. 
firstly the frequency reconstruction of downhole measurement signal be realize by scale transformation and a weak signal detection model base on variable scale duffing oscillator be establish so that the measure signal meet the restriction of frequency parameter of this method then in order to solve the influence of initial phase of measure signal on the accuracy of detection model different periodic driving force be introduce the duffing equation be solve to get the detection model of all phase coverage measurement signal. 
finally the simulation result of the laboratory vibration platform system show that the signal to noise ratio of weak signal detect by this method can be as low as  20db which provide a new solution for the detection of strong vibration weak signal while drill. 
nighttime depression episodes classification use a formal method knowledge discovery in database. 
depression be a disease that affect 7.5 percent of global disability. 
depression be now day a common disorder that affect the state of mind and produce sleep disorder. 
around 50 of depressive patient suffer from sleep disturbance. 
in this work a datum mining process to classified depressive and not depressive episode during nighttime be carry out base on a formal method of data mining call knowledge discovery in databases kdd. 
this process guide the process of datum mining with stage well establish pre kdd selection pre processing transformation data mining evaluation and postkdd. 
the dataset use for this paper be depresjon dataset which contain the motor activity of 23 unipolar and bipolar depressed patient and 32 healthy control. 
the classification of depressive and not depressive episode be deploy with the random forest method and a model construct of eight feature. 
result on specificity be equal to 0.9927 and sensitivity equal to 0.9991. 
a survey on artificial intelligence techniques in cognitive radio network. 
cognitive radio cr be the solution for the current spectral underutilize problem context awareness and environment awareness be the key function of cr nowadays. 
a software radio with reconfiguration capacity will become cognitive radio by impart intelligence to sdr use artificial intelligence techniques. 
there be process in cr such as spectrum sensing monitoring and management involve the use of ai technique. 
artificial intelligence ai be direct along with cognitive function for well learning and classification. 
recently deep learning involve more self learn algorithm without any supervision. 
hence it be important to discuss the various ai technique for well resource optimization in cr network. 
optimization parameter be different for different technique depend upon the radio environment. 
the type of ai technique for a particular application be random. 
makespan efficient task scheduling in cloud computing. 
cloud computing be an emerge technology in modern era of online processing of customizable resource gather commonly for several remote server access through on demand access. 
cloud service provider csp render cloud compute infrastructure in pay per use scheme in various format. 
thus csp provide a major role in optimization of task scheduling ts in trade off with cost afford by the end user. 
in propose scheme to create efficient utilization of resource and balanced cost of render service to end user modified fuzzy clustering mean algorithm mfcm along with modified ant colony optimization maco technique be use thereby minimize the cost of use a cloud computing structure and with reduce makespan along with load balancing capability. 
propose strategy provide well result than exist strategy of various modification on aco alone that concentrate on optimize lineup of virtual machine vm. 
a dynamic resource allocation strategy to minimize the operational cost in cloud. 
cloud computing have gain momentum in the recent time due to the feature it provide like rapid elasticity and on demand service. 
it involve the interaction between the user and a resource broker. 
the resource broker accept the user job along with the requirement and provide the result and the status of the job back to the user. 
the user job can be datum intensive or computational intensive. 
the resource be allocate accord to the type of the user job. 
the propose particle swarm optimization technique with migration optimize the allocation process use computation and network base parameter. 
migration efficiently eliminate the problem of over utilization of resource. 
the clustering of virtual machine have also be explore in two dimension namely resource cluster and idle clustering to increase the utilization of resource. 
a hybrid approach to improve recommendation system in e tourism. 
recommendation systems help user search large amount of digital content and identify more effectively the item product or service that be likely to be more attractive or useful. 
as such it can be characterize as tool that help people make decision make a choice across a vast set of alternative. 
this research work have explore decision make process in the wide application domain of online service specifically hotel booking. 
this research work be a combination of collaborative filtering item base recommendation and knowledge base recommendation system. 
in which collaborative filter recommendation will work for user searching and knowledge base recommendation will work as default recommendation system. 
in knowledge base recommendation system it read the user profile along with his activity of certain last time period as our main knowledge base where this work define the fact of user s activity. 
then this research work apply sort and count algorithm. 
contextual datum be temporarily store in the knowledge base as the time user stay log in. 
each login will take an update contextual database. 
in search use item base k near neighbor algorithm for prediction by collaborative filtering. 
this work propose a new rating system which base on hotel performance. 
lightweight hardware transactional memory profiling. 
program that use hardware transactional memory htm demand sophisticated performance analysis tool when they suffer from performance loss. 
we have develop txsampler a lightweight profiler for program that use htm. 
txsampler measure performance via sample and provide a structure performance analysis to guide intuitive optimization with a novel decision tree model. 
txsampler compute metric that drive the investigation process in a systematic way. 
it not only pinpoint hot transaction with time quantification of transactional and fallback path but also identify cause of transaction abort such as data contention capacity overflow false sharing and problematic instruction. 
txsampler associate metric with full call path that be even deeply embed inside transaction and map they to the program s source code. 
our evaluation of more than 30 htm benchmark and application show that txsampler incur similar to four runtime overhead and negligible memory overhead for its insightful analysis. 
guide by txsampler we be able to optimize several htm program and obtain nontrivial speedup. 
a pattern based algorithmic autotuner for graph processing on gpu. 
this paper propose gswitch a pattern base algorithmic auto tune system that dynamically switch between optimization variant with negligible overhead. 
its novelty lie in a small set of algorithmic pattern that allow for the configurable assembly of variant of the algorithm. 
the fast transition of gswitch be base on a machine learning model train use 644 real graph. 
moreover gswitch provide a simple programming interface that conceal low level tune detail from the user. 
we evaluate gswitch on typical graph algorithm bfs cc pr sssp and bc use nvidia kepler and pascal gpu. 
the result show that gswitch run up to 10x fast than the good configuration of the state ofthe art programmable gpu base graph processing library on 10 representative graph. 
gswitch outperform gunrock on 92.4 case of 644 graph which be the large dataset evaluation report to date. 
poster high throughput image alignment for connectomics use frugal snap judgments. 
accurate and computationally efficient image alignment be a vital step in scientific effort to understand the structure of the brain through electron microscopy image of neurological tissue. 
connectomic be an emerge area of neurobiology that use cut edge machine learning and image processing algorithm to extract brain connectivity graph from electron microscopy image. 
this poster abstract describe a high throughput image alignment system that be design to run on commodity multicore machine. 
we achieve alignment that differ by no more than two pixel from state of the art alignment pipeline while achieve 40x additional throughput. 
the tool employ to achieve this performance boost include application specific optimization and the use of frugal snap judgment a general purpose technique for optimize computation that have strict accuracy performance trade off. 
high performance distribute deep learning a beginner s guide. 
the current wave of advance in deep learning dl have lead to many exciting challenge and opportunity for computer science and artificial intelligence researcher alike. 
modern dl framework like caffe2 tensorflow cognitive toolkit cntk pytorch and several other have emerge that offer ease of use and flexibility to describe train and deploy various type of deep neural networks dnn. 
in this tutorial we will provide an overview of interesting trend in dnn design and how cut edge hardware architecture be play a key role in move the field forward. 
we will also present an overview of different dnn architecture and dl framework. 
most dl framework start with a singlenode single gpu design. 
however approach to parallelize the process of dnn training be also be actively explore. 
the dl community have move along different distribute training design that exploit communication runtime like grpc mpi and nccl. 
in this context we will highlight new challenge and opportunity for communication runtime to efficiently support distribute dnn training. 
we also highlight some of our co design effort to utilize cuda aware mpi for large scale dnn training on modern gpu cluster. 
finally we include hand on exercise in this tutorial to enable the attendee to gain first hand experience of run distribute dnn training experiment on a modern gpu cluster. 
connotation on a quadratic stability criterion for arbitrary switch linear system. 
the work be place within the area of qualitative analysis of arbitrary switch linear system focus on the existence of quadratic lyapunov function for discrete  or continuous time dynamic. 
our investigation express a series of connotation on the utilization of a criterion amply cite in the control engineering literature which characterize the mode dependent quadratic lyapunov function in the discrete time case. 
these connotation be formulate as two distinct theorem for discrete time and continuous time system respectively both theorem provide algebraic condition that ensure the existence of time independent quadratic lyapunov function together with the associate set invariant relative to system trajectory. 
in the discrete time case our algebraic condition include as a particular form the algebraic condition use by the exist criterion mention above. 
our theorem be accompany by remark that create a deep insight into the dichotomy time independence vs. 
time dependence for quadratic lyapunov function. 
a numerical example address by the help of the sedumi solver with the yalmip interface illustrate the key theoretical point discuss for continuous time arbitrary switching system. 
channel hop in wireless process control. 
most of the application in the industrial area use wireless for process monitoring where traditional wired sensor can not be instal like for example hazardous or explosive environment. 
the use of wireless communication for process control have often be see as troublesome with a lack of robustness and determinism range problem and interference. 
possible solution include redundancy for robustness channel hop for interference and a high transmit power for range problem. 
this paper aim to cover the interference issue by propose a possible solution with channel hop pattern implement on a low power arm base micro controller pair with an ieee 802.15.4 sub ghz transceiver. 
real time stock analysis for blend recipe in industrial plant. 
many company use excel spreadsheet to keep stock record and to calculate process specific datum. 
these spreadsheet be often hard to understand and track. 
and if the user do not protect they there be a risk that the user randomly change or erase formula. 
the paper focus on the stock of product use in a blending process with a know recipe. 
develop an application that can bring this datum in a centralized form and that can assist the operator in decide be a necessity. 
when a programmer implement an application that use datum from plant he need to consider one fundamental aspect as read real time datum from the process. 
the real time stock analysis application take into account all the above element. 
the application be easy to use by an operator in the command room of installation because of the planning algorithm integrate into it. 
the algorithm propose and implement in this paper have well define goal identify the ingredient need to achieve the blending process for required quantity determine the quantity of the finished product that can be make with the exist ingredient and determine the optimum quantity of the finished product. 
the application implement in c intensively use these algorithm and give the user the ability to build the result step by step. 
an iterative method for computing stable manifolds and applications to optimal control. 
in this paper we propose a new iterative method for compute a local stable manifold of a hamiltonian system associate with an infinite horizon optimal control problem. 
for any sufficiently small state variable x the method yield a costate variable p(x such that the tuple x p(x be in the local stable manifold of the hamiltonian system. 
we also propose a numerical discretization scheme for the propose iterative method use a polynomial interpolation technique. 
the effectiveness of the propose method be verify through design an optimal controller of a simple inverted pendulum. 
a hierarchical learning control framework for track task base on model free principle. 
a hierarchical tracking learning framework be propose in this work by which an optimally learn tracking behavior be extrapolate to new unseen trajectory without the need for relearn. 
this intelligent behavior use learn reference input control output pair call primitive over a feedback control system cs. 
learning be base on model free iterative learning control under linearity assumption of the underlying cs. 
the cs linearity be indirectly ensure at low level through an output reference model orm track neural network state feedback controller learn with an iterative model free approximate value iteration as a representative reinforcement learning approach. 
learning use a large amount of input output process datum collect with an underperforming linear controller but design from few input output datum in a model free vrft approach. 
the high level primitive base learning be validate on a couple highly dimensional nonlinear aerodynamic positioning system. 
it prove that the optimal tracking behavior be extendable to new unseen trajectory without relearn. 
estimation based control strategies for an alcoholic fermentation process with unknown input. 
the present paper focus on estimation and advanced control structure for an alcoholic fermentation process afp exploit for the ethanol production. 
take into account the inhibition problem the control aim consist in the preservation of the so call process inhibitory compound at a prescribed reduce level in spite of large variation of the influent pollutant concentration and of the load have as a result a large production of alcohol. 
use a strongly nonlinear and uncertain model and realistic operating condition novel estimation and advanced control scheme be propose. 
more precisely adaptive control law design via novel nonlinear estimation algorithm for unknown input and kinetic be develop. 
to illustrate that the control goal be fulfil various test perform by computer simulation under realistic condition be include. 
two factor authentication framework for private cloud. 
authorize access to the public cloud have evolve over the last few year from simple user authentication and password authentication to two factor authentication totp with the addition of an additional field for enter a unique code. 
today it be use by almost all major website such as facebook microsoft apple and be a frequently use solution for banking website. 
on the other side the private cloud solution like openstack cloudstack or eucalyptus doesn t offer this security improvement. 
this article be present the advantage of this new type of authentication and synthetize the totp authentication form use by major cloud provider. 
furthermore the article be propose to solve this challenge by present a practical solution for add two factor authentication for openstack cloud. 
for this purpose the web authentication form have be modify and a new authentication module have be develop. 
the present document cover as well the entire process of add a totp user generate and send the secret code in qr form to the user. 
the study conclude with openstack tool use for simplify the entire process present above. 
time average model base regulator in a weakly nonlinear control system with high frequency perturbation. 
the paper deal with the construction of a stabilize regulator for a class of weakly nonlinear system with high frequency disturbance in coefficient. 
the close loop control design be base on time averaging and solution of matrix state dependent riccati equation sdre. 
a theorem on the asymptotic stability of the closed loop system be formulate. 
numerical experiment show the effectiveness of method be carry out. 
design a pi controller use state feedback algorithm for a cnc machine. 
a multiple proportional integrative pi controller for a multi input multi output system represent a computer numerical controlled machine be present. 
the pi controller gain be obtain base on pole placement state feedback algorithm apply on the augmented state space equation model. 
the augmented model be obtain by add extra integrator on the plant model and also by add extra state variable. 
an autonomous trajectory generation algorithm for swarm of quadcopter drones. 
this paper present a control algorithm for a nonlinear mathematical model of a quad copter. 
under the propose control law the machine follow polynomial trajectory with zero stationary error. 
an original method for the autonomous generation of trajectory be present along with a stability result concern the swarm form by agent follow this algorithm. 
the same algorithm be then slightly modify to provide an elegant solution to the obstacle navigation problem. 
simulation and numerical result be present. 
design of h infinity discrete time controllers for multivariable systems via give engineering performance indices. 
for a linear mimo control plant affect by unknown bound external disturbance a design method of discrete output controller that provide give or achievable performance index such as control error settle time and stability margin radii for each control loop be propose. 
the approach be base on the standard procedure of h infinity optimization form in a special way. 
the robust property of the design system in term of the nyquist plot for the separate control loop break at the plant input be study their connection with the absolute stability property of the system be find. 
a numerical example illustrate the effectiveness of the propose approach. 
deploy on demand cloud services to support process in robotic applications and manufacturing control systems. 
company try nowadays to get the most technological advantage in order to be successful on the market. 
one of the tool they use be cloud computing many company be not only use a cloud infrastructure or service but more it be estimate that until 2021 more than 90 of the company will use multi cloud system and service that mean more than five cloud system or service. 
this trend be affect also the manufacture company the challenge in this context be to manage these complex system and service. 
the cloud system and service be public private or hybrid be offer by different provider ibm redhat azure amazon web services aws and so on. 
the paper present a comparison for two cloud solution which offer service for robotic and manufacturing. 
the paper also discuss the term cloud manufacturing and cloud robotic which many time be wrongly interpret. 
finally a solution for cloud robotic manufacturing be propose and test for two variant of cloud solution use container and virtual machine. 
development of model prototype to investigate closer running autonomous train operation seamless interchangeability. 
this paper be prompt by the fact that the current united kingdom uk railway infrastructure be unable to support the increase usage. 
it be consider that autonomous train at operation will offer significant benefit to the uk railway network increase the railway network capacity. 
the significant benefit stem from ats be able to use move block signal thus potentially mean ats can operate much close together. 
a further possibility be to operate the railway network without the use of move block signal fully autonomous. 
the aim of the paper be to investigate the implementation of close running of ats through the use of a model base prototype for the potential future concept of seamless interchangeability si operation coupling and uncoupling of train on the move. 
the si operation to be explore use the prototype will assume that two at be within close proximity to one another. 
it be assume that global positioning satellite gps technology be use in normal at operation when they be not in close proximity. 
accuracy issue with gps mean that further sensor be need when at be in close proximity of one another. 
thus various sensor be investigate and the most suitable be integrate within a feedback proportional integral and derivative pid control system. 
the feedback pid control system be place on the follow at and its role be to maintain a desire short separation distance from the lead train. 
space debries decay estimation software use open source libraries. 
after more than 50 year of satellite and exploration spacecraft launch the region above earth between 100 and 2000 km also know as the leo region have become crowded with object. 
inevitably due to earth s gravity force and atmosphere all those object will fall back to the ground. 
a large part of the object will burn into the atmosphere but some part might reach the surface. 
while this be not a problem for the control object which can be guide to land in uninhabited area the uncontrolled object can land anywhere. 
the exact prediction of the impact point for those object be extremely difficult as it depend on several variable and be usually perform by the space agencies use in house software. 
however the prediction of the short term trajectory and the time interval when the object fly over some region can be compute with a fair accuracy. 
this paper present a software that use open source library to estimate short term trajectory for the orbital object which pose an imminent risk of deorbitation and define the time interval when they be fly over area of interest. 
an optimal control approach to public investment for unemployment reduction. 
the paper deal with the modelling and the control of a job market dynamic which consider unemployed individual and two class of job a temporary one characterise by a low quality of economical treatment and/or long duration assurance for the worker and a regular one more stable and economically more satisfactory. 
for each of the two class the active worker as well as the vacancy be consider. 
control action be introduce represent different government effort devote to the quantity and the quality improvement of the work. 
choice in the model be discuss and compare with literature. 
the numerical result of some simulation be report to well put in evidence the result obtain. 
an in depth comparison of compilers for deep neural networks on hardware. 
deep neural network dnn be currently the foundation for many artificial intelligence task. 
the difficulty of map nn model to high performance hardware implementation arise from factor range from the computation complexity of multiple operation to different hardware feature such as memory hierarchy and parallelism. 
in this article we present a generic compiler process flow and make an in depth comparison of compiler framework regard their domain specific language dsl intermediate representation irs optimization strategy and autoscheduling method. 
we reimplement typical nn model base on these compiler framework and evaluate the result performance. 
we also review our previous work(deep neural network virtual machine dnnvm on compiler framework and optimization for a custom fpga base accelerator to gain inspiration regard the difference between compiler design for general purpose processor and that of fpga base accelerator. 
a semi automate generation of entity relationship diagram base on morphosyntactic tagging from the requirements write in a serbian natural language. 
an entity relationship e r diagram be a graphical representation of interest in a specific domain of knowledge about any information system. 
it be a data modeling technique that can help define business process and play a central role in software engineering process. 
extract conceptual model from natural language requirement can help identify dependency redundancy and conflict between requirement generate from lengthy textual specification. 
the automatic generation of different software diagram from natural language requirement such as english be highly challenging with advancement in artificial intelligence. 
in this paper a semi automated approach for the design of e r model from the short requirement write in a serbian natural language use morphological analysis be present. 
present rule be heuristic and be found suitable for conceptual model creation in the phase of requirement analysis. 
at the end example obtain by use basic learning resource be present. 
modeling and mitigation of xpath injection attacks for web services use modular neural network. 
injection attack be consider to impact the most widespread vulnerability in web application by open web application security project owasp. 
xml be use as an alternative technology to database system to store datum in xml format which can be query to produce the desire result. 
xpath be a query language for xml which have injection issue similar to sql. 
xpath can be use by the attacker to exploit the vulnerability in web application by inject malicious xpath query. 
if the web service be inject with malicious xml code then it affect all the application which integrate the infected web service. 
in this paper we propose a solution which use count base validation technique and long short term memory lstm modular neural network to identify and classify atypical behavior in user input. 
once the atypical user input be identify the attacker be redirect to sham resource to protect the critical datum. 
our experiment result in over 90 accuracy in classification of input vector. 
our result also show that use of modular neural network result in improved response time of the web application compare to single neural network. 
detecting android security vulnerability use machine learning and system call analysis. 
android operating system have become a prime target for cyber attacker due to security vulnerability in the underlie operate system and application design. 
recently anomaly detection technique be widely study for security vulnerability detection and classification. 
however the ability of the attacker to create new variant of exist malware use various masking technique make it hard to deploy these technique effectively. 
in this research we present a robust and effective vulnerability detection approach base on anomaly detection in a system call of benign and malicious android application. 
the anomaly in our study be type frequency and sequence of system call that represent a vulnerability. 
our system monitor the process of benign and malicious application and detect security vulnerability base on the combination of parameter and metric type frequency and sequence of system call to classify the process behavior as benign or malign. 
the detection algorithm detect the anomaly base on the define scoring function f and threshold p. 
the system refine the detection process by apply machine learn technique to find a combination of system call metric and explore the relationship between security bug and the pattern of system call detect. 
the experiment result show the detection rate of the propose algorithm base on precision recall and f score for different machine learning algorithm. 
random test generation from regular expressions for graphical user interface gui testing. 
generation of test sequence that is user input expect system output be an important task of testing of graphical user interface gui. 
this work propose an approach to randomly generate test sequence that might he use for comparison with exist gui testing technique to evaluate their efficiency. 
the propose approach first model cui under test by a finite state machine fsm and then convert it to a regular expression re. 
a tool base on a special technique we develop analyze the re to fulfill miss context information such as the position of a symbol in the re. 
the result be a context table represent the re. 
the propose approach traverse the context table to generate the test sequence. 
to do this the approach repeatedly select a symbol in the table start from the initial symbol in a random manner until reach a special finalize symbol for construct a test sequence. 
thus the approach use a symbol coverage criterion to assess the adequacy of the test generation. 
to evaluate the approach mutation testing be use. 
the propose technique be to a great extent implement and be available as a tool call pq ran test pq analysis base random test generation. 
a case study demonstrate the propose approach and analyze its effectiveness by mutation testing. 
raise the quality of bug reports by predict software defect indicator. 
the descriptive quality of bug report be one of the essential part of defect management. 
sometimes they provide inadequate or incorrect datum about software problem which can lead to incomplete defect fixing or omission of serious defect. 
therefore it be vital to evaluate and improve the quality of hug report. 
this paper propose an approach that help to resolve this problem by predict various indicator. 
the value of these indicator allow qa engineer to evaluate the quality of defect description and correct it in a suitable way. 
this paper also introduce nostradamus a new open source tool build to implement the approach. 
the tool use machine learn technique to analyze the datum store in software defect repository and evaluate the interdependence of defect attribute include such a crucial element as a defect description. 
this paper describe the approach the tool that be base on it and the typical use case. 
b sefi a binary level soft error fault injection tool. 
soft error be become more prominent in modern computing system due to the increase integration of chip. 
these fault pose a major challenge for memory and logic circuit in high performance microprocessor. 
in this paper a tool base on pin be design to simulate soft error which can implement hardware fault injection at the machine code level. 
our tool be base on binary instrumentation that support an accurate and low cost fault injection. 
we apply the tool to five classic machine learning program and analyze the program weakness to soft error by simulate bit flip. 
we investigate the soft fault effect on performance and accuracy accord to experimental result. 
our study reveal that these program be highly sensitive to soft error therefore the tool provide a new effective approach for future resiliency research. 
complicated causality discovering and present base on enterprise knowledge management. 
at present knowledge management be an important mean for enterprise to gain competitive advantage. 
face with a large amount of datum generate in the process of enterprise operation current datum analysis machine learning and other technology be not enough to effectively discover and express the complex uncertain causality between datum. 
therefore from the perspective of knowledge management combine with the characteristic of datum use the method of conceptual modeling and qualitative analysis this paper propose a new idea to find and express the complex causality between datum. 
the need for unified testbed management across multiple teams and stakeholders in a large scale telecom integration context. 
the quality assurance of large scale integrative system often require complex testbe environment and simulation that allow to test the overall functionality and enable various experiment towards systematically verify the realization of the identify user and system requirement. 
thereby an integration setup and result activity lead to another level of quality assurance whereby the integrator deal with the quality examination of the single component and their integrative interplay accord to a set of overall system and user requirement. 
in such context it be often the case that the testing activity be conduct by various partner e.g. 
single company and legal entity with complement know how require for specific sub task pki chip card special network protocol firewall security architecture and penetration testing. 
this lead to the emergence of a large number of proprietary testbed focus on specific aspect result in the lack of a unify testbed configuration versioning and technological foundation e.g. 
operating system network stack implementation hypervisor technology. 
in this paper we present our experience draft from a large scale industrial project with 600 700 requirement relate to a critical ehealth infrastructure within a telecom provider context. 
thereby various sub contractor have to be unify in their approach to testbe management in order to achieve reproducible and traceable with respect to system requirement test result base on a test architecture accommodate various quality assurance activity unit testing development test component testing integration testing security testing. 
we gradually analyze the project situation with respect to testbe management and argue on the need for unified testbe management across multiple team and stakeholder in a large scale telecom integration setup. 
subsequently we propose possible solution and conduct a series of experiment highlight the advantage of the propose approach and belonging solution. 
research on security detection and data analysis for industrial internet. 
industrial internet platform need to solve a series of problem such as access of multi type industrial equipment multi source industrial datum integration massive datum management and processing industrial internet security and so on. 
this paper build industrial big datum analysis algorithm library base on domain knowledge modeling and big datum analysis of industrial datum. 
through the analysis of the behavior characteristic of industrial internet network traffic datum this paper study the method of select traffic characteristic of event in the industrial internet establish the propagation and evolution model of security event in the industrial internet and build a traceability map of security event propagation this study combine the characteristic of large datum volume and centralized control of future industrial internet to reduce the complexity of security event detection and analysis. 
it have reference value for industrial internet controller to formulate node routing strategy. 
entrack a data driven maximum entropy approach to fiber tractography. 
the combined effort of brain anatomy expert and computerized method have continuously improve the quality of available gold standard tractogram for diffusion weight mri. 
these prototypical tractogram contain information that can be utilize by other brain mapping application. 
however this transfer require data drive tractography algorithm which learn from example tractogram to deliver the obtain knowledge to other diffusion weight mri datum. 
the value of these data drive method would be greatly enhance if they could also estimate and control the uncertainty of their prediction. 
these reason lead we to propose a generic machine learning method for probabilistic tractography. 
we demonstrate the general approach with a basic fisher von mises distribution to model local fiber direction. 
the distributional parameter be infer from diffusion datum by a neural network. 
for train the neural network we derive an analytic entropy regularize cost function which allow to control model uncertainty in accordance with the level of noise in the datum. 
we highlight the ability of our method to quantify the probability of a give fiber which make it a useful tool for outlier detection. 
the tracking performance of the model be evaluate on the ismrm 2015 tractography challenge. 
smartkt a search framework to assist program comprehension use smart knowledge transfer. 
regardless of attempt to extract knowledge from code basis to aid in program comprehension there be an absence of a framework to extract and integrate knowledge to provide a near complete multifaceted understanding of a program. 
to bridge this gap we propose smartkt smart knowledge transfer to extract and transfer knowledge relate to software development and application specific characteristic and their interrelationship in form of a knowledge graph. 
for an application the knowledge graph provide an overall understanding of the design and implementation and can be use by an intelligent natural language query system to convert the process of knowledge transfer into a developer friendly google like search. 
for validation we develop an analyzer to discover concurrency relate design aspect from runtime trace in a machine learning framework and obtain a precision and recall of around 97 and 95 respectively. 
we extract application specific knowledge from code comment and obtain 72 match against human annotate ground truth. 
fault detection in timed fsm with timeout by sat solving. 
fault in safety critical real time system be not only logical but they can correspond to violation of timing constraint. 
they must be detect to avoid system failure with adverse consequence. 
develop efficient fault detection technique for variety of system model be still challenge. 
in this paper we deal with fault detection for timed finite state machine with timeout tfsms t. 
tfsm t be an extension of fsm to model timing constraint in safety critical real time system. 
we lift a fault detection approach develop for fsm to generate test detect both logical fault and violation of time constraint in tfsms t. 
the approach be base on constraint solve and use mutation machine to represent domain of faulty implementation mutant of a specification tfsms t. 
it also avoid enumerate the implementation one by one. 
we develop a prototype tool and we conduct experiment to evaluate the scalability of the propose method. 
competitive feature extraction for activity recognition base on wavelet transforms and adaptive pooling. 
any application of machine learning require feature extraction whereupon the source datum be process to yield representation that be germane to obtain the desire output. 
traditional approach to feature extraction include the estimation of statistical and structural property of the datum the choice of which be mainly influence by domain knowledge. 
however deep learning have make it possible to learn the good feature directly from the datum itself when sufficient datum be available. 
for domain such as activity recognition where such plentiful datum may be lack the application of deep learning may be limit. 
therefore method which can yield deep learning like performance without the need for massive amount of datum remain of interest. 
in this work we present a novel approach to feature extraction for sensor generate activity recognition datum. 
we first process the datum use wavelet transform and subsequently use an adaptive pooling operator on the generate decomposition to obtain a compact fix length representation of the datum. 
our experiment on seven different activity recognition dataset yield result comparable to those obtain from a deep neural network for all the consider dataset without the need for large amount of datum or any training overhead. 
modified state observer base two way etnac design for uncertain linear systems. 
in this study a neural network nn base two way event trigger controller etc design be present for uncertain linear system. 
dynamic triggering condition be develop for both state and control datum transmission. 
these triggering condition be base on real performance parameter include estimation tracking error which make control execution more relevant instead of the extended time sample as see in most etc literature. 
the other unique feature of this etnac scheme be the online uncertainty approximation even during inter event time which make control robust and efficient. 
a modified state observer mso use in this study to replicate the system to estimate the system uncertainty. 
in this way it not only save datum communication over network but also reduce computational effort. 
system stability and event trigger condition be establish use lyapunov analysis. 
a benchmark numerical example be use to illustrate the effectiveness of the propose method. 
infinite gaussian fisher vector to support video base human action recognition. 
human action recognition har be a computer vision task that attempt to monitor understand and characterize human in video. 
here we introduce an extension to the conventional fisher vector encoding technique to support this task. 
the methodology base on the infinite gaussian mixture model igmm seek to reveal a set of discriminant local spatio temporal feature for enable the precise codification of visual information. 
specifically it be much simple to handle the infinite limit from the igmm than work with traditional gaussian mixture models gmm with unknown size that will require extensive cross validation. 
under this premise we develop a fully automatic encoding methodology that avoid heuristically specify the number of component in the mixture model. 
this parameter be know to greatly affect the recognition performance and its inference with conventional method imply a high computational burden. 
moreover the markov chain monte carlo implementation of the hierarchical igmm effectively avoid local minima which tend to plague mixture train by optimization base method. 
attain result on the ucf50 and hmdb51 database demonstrate that our proposal outperform state of the art encoding approach concern the trade off between recognition performance and computational complexity as it drastically reduce both number of operation and memory requirement. 
a visual analytics approach for analyzing technological trends in technology and innovation management. 
visual analytics provide with a combination of automate technique and interactive visualization huge analysis possibility in technology and innovation management. 
thereby not only the use of machine learn datum mining method play an important role. 
due to the high interaction capability it provide a more user center approach where user be able to manipulate the entire analysis process and get the most valuable information. 
exist visual analytics system for trend analytics and technology and innovation management do not really make use of this unique feature and almost neglect the human in the analysis process. 
outcomes from research in information search information visualization and technology management can lead to more sophisticated visual analytics system that involve the human in the entire analysis process. 
we propose in this paper a new interaction approach for visual analytics in technology and innovation management with a special focus on technological trend analytic. 
a novel design of a respiratory rate monitoring system use a push switch circuit and arduino micocontroller. 
respiratory rate be one of the vital indicator of person s health sign. 
it be the rate of a person s breathe when at rest and measure in breath per minute. 
respiratory rate rr may vary from infant to adult and also respiratory rate vary for a person when ill. 
the propose respiratory rate monitor be base on an electronic circuit with a push switch. 
the circuit be instal in a chest belt. 
due to the chest movement of the breathing process the switch in the circuit will be push and the breath rate of the patient will be count and display in a bluetooth application. 
the propose respiratory rate monitoring system have be test and compare with other respiratory rate monitor belt system and the result be satisfactory. 
development process for intelligent user interface an initial approach. 
the human computer interaction hci be a research field that support the user interface development. 
furthermore hci influence the intelligent user interface iui area. 
iui be a user interface that use intelligent technology to reach the communication between human and machine. 
the construction of iui be not easy and require the knowledge of different method technique and technology from many domain such as hci artificial intelligence ergonomic software engineering etc. 
in this way the existence of a process be an important tool for iui developer. 
the literature present design process and framework for user interface but most of they do not offer any knowledge regard the method technique and technology that can be use to support the activity involve. 
thus this work propose a development process for iui which offer recommendation about method technique and technology. 
we hope that this process will help analyst and designer who work in iui area. 
use machine learning technique for effort estimation in software development. 
estimate in software project aim to help practitioner predict more realistic value on software development impact the quality of software process activity regard planning and execution. 
however software company have difficulty when carry out estimation that represent adequately the real effort need to execute the software project activity. 
although the literature present technique to estimate effort this activity remain complex. 
recently machine learning ml technique be be apply to solve this problem. 
through ml technique it be possible to use database of finished project dataset to help get more precisely estimation. 
this research aim to propose a methodology to estimate effort use a ml technique base on decision tree xgboost. 
to evaluate our methodology we conduct test with four dataset use two metric mean magnitude relative error and prediction(25. 
the preliminary result show consistent result for this methodology for software effort estimation base on the employ metric which indicate that our methodology be promise. 
as further work new dataset must be analyze use our methodology and also an approach use synthetic datum to improve the ml training. 
uni repm scs a safety maturity model for requirements engineering process. 
context software be an important part in safety critical system scs development since it be become a major source of hazard. 
software have be responsible to implement innovative and complex function and to send instruction to the hardware. 
requirement relate hazard have be associate with many accident and safety incident. 
requirement issue tend to be mitigate in company with high process maturity level since they adopt good practice from software engineering in a systematic consistent and proactive way. 
however requirement engineer need systematic guidance to consider safety concern early in the development process. 
objective this thesis investigate which safety practice action be suitable to be use in the requirements engineering process of scs as well as to propose a safety maturity model to this area. 
method a set of empirical study be use in this work. 
the datum collection be do through systematic literature review and case study. 
we follow the design science methodology to propose uni repm scs a safety module for unified requirements engineering process maturity model uni repm and the technology transfer framework to perform the safety module validation. 
besides comprehensive literature review be also conduct to provide background and support for the empirical study. 
result the safety module have seven main process 14 sub  processe and 148 safety action describe principle and practice that form the basis of safety process maturity. 
moreover we describe its usage through a tool. 
we conduct a static validation with two practitioner and nine academic expert to evaluate its coverage correctness usefulness and applicability. 
furthermore we perform a dynamic validation with seven industry practitioner to evaluate the safety maturity level of seven industry project. 
conclusion the validation indicate a good coverage of practice and good receptivity by the expert. 
finally the module can help company in evaluate their current practice as well as offer a step wise improvement strategy to reach high maturity. 
mcp a security testing tool driven by requirement. 
we present mcp a tool for automatically generate executable security test case from misuse case specification in natural language i.e. use case specification capture the behavior of malicious user. 
mcp rely on natural language processing nlp a restricted form of misuse case specification and a test driver api implement basic utility function for security testing. 
nlp be use to identify the activity perform by the malicious user and the control flow of misuse case specification. 
mcp match the malicious user s activity to the method of the provide test driver api in order to generate executable security test case that perform the activity describe in the misuse case specification. 
mcp have be successfully evaluate on an industrial case study. 
feedback in scrum data inform retrospective. 
improve the way that team work together by reflect and improve the execute process be at the heart of agile process. 
the idea of iterative process improvement take various form in different agile development methodology scrum retrospective. 
however these method do not prescribe how improvement step should be conduct in detail. 
in this research we investigate how agile software team can use their development datum such as commit or ticket create during regular development activity to drive and track process improvement step. 
our previous research focus on data inform process improvement in the context of student team where control circumstance and deep domain knowledge allow creation and usage of specific process measure. 
encourage by positive result in this area we investigate the process improvement approach employ in industry team. 
research how the vital mechanism of process improvement be implement and how development datum be already be use in practice in modern software development lead to a more complete picture of agile process improvement. 
it be the first step in enable a data inform feedback and improvement process tailor to a team s context and base on the development datum of individual team. 
function and aesthetics of a product in segmentation of the sketch. 
understand the central characteristic of product design before study the sketch of product be an essential task. 
it be well establish in design research that sketch be the most important communication tool in the conceptual stage of the design process. 
however recent study have show that the interaction between functionality and aesthetics influence the customer s emotional connection with the product. 
furthermore sketch segmentation have be consider a fundamental step towards the understanding of sketch and this problem have never be tackle from a design perspective. 
this paper present a novel perspective on the problem of product sketch segmentation by propose two different segmentation procedure. 
first a low level segmentation procedure be propose in which gestalt theory be apply to group the sketch element into large component base only on their visual arrangement and no prior knowledge be require on the product. 
second a high level segmentation process be propose consider the prior knowledge of the functional aspect of the product representation on the grouping of the sketch element. 
result of the two procedure apply to the same sketch indicate that the low level segmentation procedure which require less cognitive burden can lead to component with specific well define function as obtain through the high level segmentation procedure. 
stability and security analysis with identification of attack on industrial networked control system an overview. 
a networked control system ncs be sensitive to the different type of attack and it be essential to secure and stabilize it. 
in this manuscript to represent the impact on the stability of the control system an industrial ncs be consider. 
the process noise and measurement noise alongside certain attack be assume to be affect the performance of this system. 
it be also assume that the agent may inject false datum to disrupt the performance of the control system. 
an overview of recent work do for stabilization of ncs in such scenario be present here. 
kalman filter along with some control system stability condition be use to mitigate the effect of noise and attack on ncs. 
a numerical example be present here to exemplify the performance of the kalman filter and linear quadratic gaussian lqg controller along with pid controller on system state estimation. 
it be show that kalman filter estimate the state optimally which indict by the eigenvalue of  4.87 1.77 12. 
the simulation and sample timea be 20 and 10ms respectively. 
development of direct time study technology for advanced work measurement. 
in a work system standard time be a parameter to measure or analyze the performance of worker also use to improve flow process efficiency and determination of production target. 
standard time be obtain by work measurement. 
work measurement be the evaluation of the time require to complete a job use the stopwatch and other method. 
it enable the organization to promote productivity and measure direct time study. 
however there be several challenge associate with its implementation such as the continuous analysis of worker from start to finish by an observer. 
this lead to the inability of the observer to carry out other activity worker tend to work inadequately under supervision and limited timeframe. 
these challenge lead to the development of a technology that measure work take more measurement and produce accurate and real time cycle without the presence of observer. 
therefore the purpose of this research be to develop a technology with the ability to automatically measure work directly use the vision sensor technology. 
the design equipment measure the movement of worker base on color which be convert into work time and far process into standard time use an application program. 
the result of this study be vision sensor technology which be an integration of hardware pixy cmucam5 and arduino uno rev three component with at mega 328p and application program visual studio 2015 programming. 
furthermore base on usability testing the result have show that parameter be able to function accurately and in real time and base on the mean of standard time it be see that the difference in measurement of time use technology and stopwatch be only 7.8. 
feasibility analysis of blockchain for donation base crowdfunding of ethical projects. 
donation be a necessary social tool that be plague by many inherent shortcoming. 
a novel model in the form of a decentralized app be design in the ethereum blockchain to solve the challenge present and optimize the process of zakaah donation. 
load and stress test on the prototype of the smart contract in the public testnet of ethereum be analyze to gauge the feasibility of mass usage. 
similar test be do in hyperledger to conclude on the optimum blockchain platform for zakaah. 
an anomaly be detect during the testing phase of the decentralized app in the public testnet of ethereum and it be exploit to propose a novel strategy to enhance the throughput of ethereum. 
the testing be a pioneer in evaluate the throughput and feasibility of a blockchain base financial product and provide a benchmark to validate the business and technical hypothesis of other similar financial product and service. 
open platform for network functions virtualization in the digital era. 
network functions virtualization nfv be a network architecture philosophy which offer a new way to design deploy and manage networking service. 
nfv enable a new level of service agility and manageability while also allow well asset utilization. 
to achieve these and other goal nfv can be use in combination with software defined networking another technology that use network abstraction. 
this article analyse open platform for nfv opnfv an open source project and its significance in provide for an open source reference platform to validate multivendor interoperable nfv solution. 
the opnfv platform architecture and some of the component integrate into opnfv from upstream project to build the nfv infrastructure be also cover in the article. 
opnfv be a carrier grade platform aim at accelerate the deployment of new nfv product and service that meet the industry s need by introduce specific technology component base on their use case and deployment architecture. 
to ensure consistency performance and interoperability among virtualized network infrastructure opnfv encourage an open ecosystem of participant and enable broad industry collaboration. 
simplify over temperature protection circuit structure for wsn iot device power management. 
this paper present a modify structure of the over temperature protective circuit integrate into the power management converter design for wireless sensor node device. 
the design be focus on realize a simplified circuit structure that be continuable with standard cmos technology structure and evaluate the over temperature threshold to assure need accuracy. 
hspice simulation use monte carlo analysiv for the bandgap voltage reference be use to get a well estimation process variation and reliability the target design temperature threshold be obtain at approximately 150 degree c which be the standard chip testing value at bad temperature consideration. 
post layout simulation of the propose circuit design structure be carry out use 6.5 nm 1p9 m cmos 1.2v/2.5f logic cmos technology. 
and it be co integrated in the power management circuit design for the system on chip wireless sensor node device. 
dynamic balance testing system for micro roller base on mems. 
in order to address the problem such as heavy weight high cost and poor sensitivity relate to the swing frame of the exist roller test system a micro roller dynamic balance test system base on micro electro mechanical systems mems acceleration sensor be propose. 
the mems accelerometer be symmetrically embed act as the support of the swing frame to measure the vibration acceleration. 
the circuit board with perforated processing be directly use as the support of the swing frame. 
two wire be use to connect the sensor and the datum acquisition system to avoid the interference of cable elasticity on the vibration characteristic of the swing frame. 
the datum obtain from this test system have be process. 
the influence of various interference signal in the system on the vibration measurement be identify. 
vibration signal generate by imbalance be extract from complex measurement signal. 
the test datum show that the optimize swing frame design have small weight low cost high sensitivity simple operation and much broad application range. 
a planar inductive based oil debris sensor plug. 
online monitoring of debris in hydraulic and lubrication oil be an effective method to enable preventive maintenance of the associated machinery. 
the debris particle generate by the machinery due to wear and tear be carry by the work or lubrication fluid. 
this paper present a new online magneto inductive sensor plug. 
the new sensor plug consist of a permanent magnet pm and a spiral shape planar sensor coil. 
the static magnetic field of the pm be utilize to attract the ferrous wear debris particle that reach the oil tank reservoir to the sensor coil. 
the inductance of the sensor coil place close to the pm will change as a function of the presence of magnetic conductive debris. 
the change in inductance be measure use a high resolution inductance to digital converter. 
the prototype of the propose sensor unit be test in an experimental setup similar to an industrial hydraulic system. 
the sensor response for different size and quantity of debris particle be record after inject they into the hydraulic circuit. 
the particle that be attract towards the sensor plug be retain in the plug itself. 
hence its recirculation in the machinery be avoid. 
differential pressure transmitter base on programmable system on chip psoc. 
differential pressure be an important technological parameter one urgent task of which be control and measurement. 
to date the lion s share of research in this area have focus on the development and improvement of differential pressure transmitter. 
this study build on the literature in its aim to develop a differential pressure transmitter with improved operational and metrological characteristic. 
the measure unit of the develop pressure transmitter be base on two strain gauge sensor. 
to achieve the state aim modern method and technology be use in the development of the electronic unit of the pressure transmitter. 
the programmable system on chip psoc technology be use to develop the electronic unit. 
due to the use of psoc technology it be possible to increase the noise immunity of the develop differential pressure transmitter as well as provide an unparalleled combination of flexibility integration analog and digital functionality. 
point cloud annotation method for 3d deep learning. 
the domain of 3d deep learning be grow rapidly as 3d sensor cost plunge and the perception capabilitie these sensor can provide be continuously be extend. 
dataset creation and annotation be a huge bottleneck in this field of work however particularly in 3d segmentation task where every point in 3d space must be label accurately. 
this paper will review some creative way of improve the datum annotation process in term of efficiency accuracy and automatability. 
the review be comprise of two half firstly annotation tool which have improve the user interface for pointcloud annotation be present include work which use technology such as virtual reality. 
secondly automation scheme which delegate as much of the work as possible to a machine while still give the user insight and control over the process will be review. 
software architecture as a thinging machine a case study of monthly salary system. 
software architecture be concern with the study of a software system s high level structure and involve the design and production of such structure. 
accord to expert n the field software team struggle to communicate software architecture. 
to communicate the software architecture of a software system developer use diagram that tend to be a confused mess of box and feature unstable notation ununiform name unlabeled relationship generic terminology miss technology decision mixed abstraction etc. 
this paper propose a new diagrammatic representation call a thinge machine tm as a methodology in software architecture. 
we show that a tm can express situation that arise in practice and be therefore an alternative to tool currently in use. 
the general aim be to provide alternative representation that may be use to develop more refined tool in this field of study. 
align decision analytics with business goal the case of incident management. 
solve the problem of modelling decision performance can be facilitate with develop a more comprehensive framework base on an application of the requirement engineering principle to business alignment of decision analytic. 
the author apply these principle in exist ppinot framework base on incident management s case. 
with the propose framework base on manager requirement it can be anticipate specific decision model and notation standard dmn extension for decision performance measure purpose or for development of new analytic monitoring tool. 
a traditional data mining algorithm be apply to a decision dpi and process ppi performance measure in order to fulfill some of the decision analytic requirement identify within the framework. 
a new approach towards develop a prescriptive analytical logic model for software application error analysis. 
software application be heavily be use by today s business operation. 
however as of the fact it be no software application in the market can guarantee that it have no software defect escape during the release. 
whenever software application error arise it can be the cause happen either within the software application layer or any other factor outside the software application layer. 
the root cause analysis activity become more complex in such situation as the analysis activity involve multiple layer. 
time consuming be increase to identify the valid error. 
it lead to the entire analysis duration which can be easily prolong. 
this arise the problem statement that the duration of root cause analysis on software application error carry crucial impact to the service restoration. 
the objective be to create a logic model to conduct decision making process. 
this process include the identification of the root cause in a more accurate manner and shorten the duration of root cause analysis activity. 
the design of analytic hierarchy process ahp hierarchy will depend on the software application error and other involved error find from different layer. 
these error become the participant. 
the participant can be group far base on the error category. 
once the hierarchy be construct the participant analyze it through a series of pairwise comparison that derive numerical scale of measurement for the node. 
then the priority be associate with the node and the node carry weight of the criterion or alternative. 
base on the priority the valid error and the prefer resolution can be decide. 
many past research in ahp have be conduct however there be a knowledge gap of ahp in software application error analysis. 
therefore a prescriptive analytical logic model pal incorporate with ahp into the propose algorithm be suggest. 
this logic model would contribute a new knowledge in the area of log file analysis to shorten the total time spend on root cause analysis activity. 
natural language search and associative ontology matching algorithms base on graph representation of texts. 
the ability to freely publish any information content be cause rapid growth of unstructured duplicate and unreliable information volume with irregular dynamic. 
this significantly complicate timely access to actual reliable information especially in the task of the specific scientific topic monitor or when it be necessary to get quick insight of adjacent scientific field of interest. 
the paper contain the description of the technology of text representation as a semantic graph. 
the algorithmic implementation of propose technology in the task of fuzzy and exploratory information search be develop. 
the problem of current search technology be consider. 
the propose ontology associative graph matching approach to post full text search system development be capable of solve the problem of document search under condition of insufficient initial datum for correct query formation. 
the propose graph representation of text allow restrict usable ontology which in turn give the benefit of thematic localization of the search region in the field of knowledge. 
it technologies and automation as factor in increase labor productivity at industrial enterprises. 
the fact that increase business efficiency be currently important and intrinsically mean that company be force to search out reserve relate to labor productivity growth and be primarily focus on industrial automation cost reduction introduction of information system intend to monitor change in parameter and carry out their detailed analysis. 
these issue be particularly important for industrial enterprise that come very close to the depletion of traditional reserve relate to labor productivity growth. 
as business volume grow the effect of such change also tend to increase. 
use the example of several large russian company this article describe the potential of labor productivity growth by introduce it technology that for example enable enterprise to manage labor resource more effectively. 
this area of activity can be implement within hr analytic. 
there be a hypothesis that the increase application of it technology to analyze datum within the company and make management decision will lead to include all necessary datum not only about human resource but also about people directly or indirectly associate with the company in these process. 
the fact that the recommendation in question be rather simple make it possible to use their potential for other organization as well irrespective of their sectorial affiliation and business volume. 
face recognition in automotive application. 
already available advanced driver assistance system technology like lane departure cruse control blind spot detection etc. 
be construct a model of the external environment help to increase the security in traffic. 
with the advance of the autonomous driving the car maker be shift the focus also into the interior of the car. 
face recognition recognize a person base on a picture which be highly available on social platforms(e.g. 
facebook pose a challenge when it have to be implement in an automotive system due to small computational power and low memory currently available in such system. 
this paper explore the possibility to implement a face recognition on an automotive embed system. 
the system be compose from a infrared camera 1mpixel resolution and an image processing unit base on tda3x. 
a tool for fake news detection. 
the word post truth be consider by oxford dictionaries word of the year 2016. 
the word be an adjective relating to or denote circumstance in which objective fact be less influential in shape public opinion than appeal to emotion and personal belief. 
this lead to misinformation and problem in society. 
hence it be important to make effort to detect these fact and prevent they from spread. 
in this paper we propose machine learning technique in particular supervised learning for fake news detection. 
more precisely we use a dataset of fake and real news to train a machine learning model use scikit learn library in python. 
we extract feature from the dataset use text representation model like bag of word term frequency inverse document frequency tf idf and bi gram frequency. 
we test two classification approach namely probabilistic classification and linear classification on the title and the content check if it be clickbait nonclickbait respectively fake real. 
the outcome of our experiment be that the linear classification work the good with the tf idf model in the process of content classification. 
the bi gram frequency model give the low accuracy for title classification in comparison with bag of words and tf idf. 
increase protection against internet attacks through contextual feature pairing. 
cyberattack have evolve from infect computer use floppy disk or usb drive to the point where internet through malicious url or spear phishing have become the main infection vector. 
in order for these attack to succeed and avoid detection an attacker must often change the location where the malicious content be host. 
the short life span of a malicious url have force many security vendor to search for different proactive method for detection. 
therefore machine learning algorithm have become a powerful tool against this kind of attack vector. 
the paper present multiple approach to combine feature obtain from url body and from its content in order to increase the detection rate for internet attack take into consideration the short life span of malicious url and the high importance of keep the false positive rate to a minimum. 
the josephson balanced comparator and its gray zone measurement. 
the josephson balanced comparator be the key component of single flux quantum logic device because it be the decision make element. 
it be form by two josephson junction jjs connect in series from a clocking perspective and in parallel for the current to be measure. 
its noise property be crucial for the performance of logic device. 
the balanced comparator can also be use to monitor the fab process and design implementation as an indicator of excess noise overheat linearity dynamic effect etc. 
we design several test structure to measure the comparator gray zone at different fabrication process node at mit ll. 
we use digital circuitry to measure comparator characteristic at low frequency. 
an analog testbe be use to perform high frequency characterization. 
experimental result for different current density sheet resistance damp and clock frequency be present. 
automatic generation of multi precision multi arithmetic cnn accelerators for fpga. 
modern deep convolutional neural networks cnns be computationally demand yet real application often require high throughput and low latency. 
to help tackle these problem we propose tomato a framework design to automate the process of generate efficient cnn accelerator. 
the generate design be pipeline and each convolution layer use different arithmetic at various precision. 
use tomato we showcase state of the art multi precision multi arithmetic network include mobilenet v1 run on fpga. 
to our knowledge this be the first multi precision multi arithmetic auto generation framework for cnn. 
in software tomato fine tune pretraine network to use a mixture of short power of two and fix point weight with a minimal loss in classification accuracy. 
the fine tune parameter be combine with the template hardware design to automatically produce efficient inference circuit in fpga. 
we demonstrate how our approach significantly reduce model size and computation complexity and permit we to pack a complete imagenet network onto a single fpga without access off chip memory for the first time. 
furthermore we show how tomato produce implementation of network with various size run on single or multiple fpga. 
to the good of our knowledge our automatically generate accelerator outperform close fpga base competitor by at least two 4 x for lantency and throughput the generate accelerator run imagenet classification at a rate of more than 3000 frame per second. 
design and development of a pressure sensitive shoe platform for nao h25. 
this paper introduce a smart pressure sensitive platform design in a modular manner similar to the shape of the foot of the nao h25 v5 humanoid robot hence any h25 nao can easily wear it like a shoe. 
the main purpose of the develop shoe system be to accurately estimate and monitor ground reactive force and the plantar pressure distribution of the foot of the nao in real time. 
in order to measure these force a unique pressure sense element be design and develop and four sense element have be place at the bottom of the shoe. 
since the sense element should be in direct contact with the ground a soft pressure sense element should be utilize it should be flexible enough and also can withstand the weight of the robot. 
the present sense element consist of a barometric pressure sensor and a silicone coating. 
it have be design in a way that can withstand extreme burst pressure without be damage and it have a linearity of up to 300 n. 
all the necessary electrical component such as battery and wireless module be build in inside the shoe in order to make a standalone wireless enable platform that seamlessly integrate with nao without any complication. 
the present shoe platform can measure the center of pressure across the plantar surface of the foot in real time. 
these parameter can help form a comprehensive balance controller for nao which can have significant value in a variety of application. 
the calculated parameter and sensor reading have be preliminarily validate and the estimate center of pressure be comparable with similar study. 
a nonlinear controller base on the convolutional neural network. 
this paper focus on develop a nonlinear controller base on the convolutional neural network to control different plant. 
it be assume that the prior knowledge about the plant be very limited and there be only sensory input output data history of they. 
the neural network be train in supervised learning method without have a target controller. 
as manipulate datum be not picture frame they be preprocesse and concatenate to form adequate frame require by the convolutional neural network. 
a convolutional neural network with a simple structure be propose for the problem. 
the train controller be apply to six different linear and nonlinear plant one of which be inherently unstable and different from the plant utilize in the training process. 
furthermore an important parameter of this unstable plant be considerably change and the controller performance be analyze. 
the simulation result show that the propose controller can properly control all plant. 
resilient consensus in double integrator systems with switch network face smart attack. 
in this paper an algorithm be consider for the double integrator multi agent system to achieve consensus resiliently. 
consider the stable control of the system in presence of malicious attack be call resilient control. 
the network graph be vary in this paper and the malicious node be smart as mean that its position be change between the minimum and maximum value. 
it be presume that we know how many malicious node be in vicinity of each node and its number be limited. 
the smart node which want to damage network oscillate between the minimum and maximum value of the position so w msr algorithm on the position be not able to determine malicious node and isolate it. 
this paper utilize velocity instead of use position so the modify version of w msr call mw msr be propose. 
finally it be provide some numerical simulation to show the performance and efficiency of the theoretical result. 
optimal sensor configuration for activity recognition during whole body exercise. 
advance in wearable device with inertial measurement unit imus for the detection of different motor activity and monitor training task have important application in tele rehabilitation. 
these technology can play an effective role in improve the quality of life for people with progressive movement disorder such as parkinson s disease pd. 
consider cost simplicity and practicality a small and more efficient number of imu that can accurately recognize the type of movement be preferable. 
the purpose of the current study be to design an affordable and accurate wearable device with imus to detect thirty four different motor activity in a customize training program call lsvt big(1 which be usually use for people with pd. 
nine neurologically healthy individual perform all 34 task. 
the collected datum be process in window of 2.5 second. 
eight feature in time and frequency domain and discrete wavelet transform be calculate. 
dimension reduction be perform use the pca(2 algorithm. 
nm3 rbf4 svm5 and knn(6 classifier be then train and use to recognize the activity. 
a genetic algorithm be utilize to decide which sensor and signal take part in the classification to produce the good accuracy. 
our result show that the four sensor instal on the left shank right thigh leave forearm and right arm provide the optimal number and arrangement to achieve a precision of 94.3 and sensitivity of 93.4 use nm classification. 
also an adaptation algorithm be utilize in order to maintain the quality of recognition for new user. 
robust fuzzy nonlinear control of microbeams vibration with piezoelectric actuator and electrostatic force. 
in this paper transverse vibration control of a microbeam with nonlinear govern equation be investigate. 
the non classical modified strain gradient theory be use to derive the govern differential equation of motion. 
the dynamic model consider the electrostatic force and the nonlinear effect of mid plane stretching. 
piezoelectric layer be laminate on the beam and the piezoelectric voltage be define as the actuate control signal. 
because of the existence of nonlinear term due to mid plane stretching and electrostatic force the govern partial differential equation be nonlinear. 
the control aim be to stabilize microbeam s transverse vibration. 
in the present study the govern partial differential equation be simplify use the galerkin method. 
a robust nonlinear slide mode controller be design and implement to compensate for the effect of high mode in the closed loop system. 
to prevent the chatter phenomenon near the slide surface a fuzzy logic controller be mix with the slide mode controller. 
the closed loop response of the system be investigate in the presence of disturbance and uncertainty through numerical simulation. 
the innovation in this research include use the effect of electrostatic force mid plane stretch and the effect of piezoelectric all together in a model provide exact mode shape for galerkin method use taylor s third order expansion for electrostatic force that improve accuracy and design terminal slide mode and fuzzy terminal slide mode controller. 
effort prediction in agile software development with bayesian network. 
the success rate of software project have be increase since agile methodology be adopt by many company. 
due their flexibility and continuous communication with client the main reason for the failure have shift from the formulation and understanding of the requirement to inaccurate effort estimation. 
in recent year several researcher and practitioner have propose different estimation technique. 
however some project be still fail because the budget and/or schedule be not accurately estimate since there still be numerous uncertain variable in software development process. 
previous team collaboration expertise and experience of team member frequency of change requirement or priority be just a few example. 
to improve the accuracy of effort estimation this research propose a model for agile software development project prediction use bayesian network. 
base on literature review and practitioner knowledge we identify two major category of factor that influence effort need teamwork quality and user story characteristic. 
we identify the sub factor for each category and inter dependency between they. 
in our model these factor be the node of the direct acyclic graph. 
the model can help agile team to obtain a well software effort estimation. 
approach for variability management of legal rights in human resources software product line. 
this work concern software product line spl it come from the experience gain collaborate with berger levrault a french society leader in human resources system. 
this enterprise serve many french and european territorial community. 
they have a variability problem associate to the difference of applicable legal right in different country or territory and this activity be perform manually at a high cost. 
on the other hand functionality be common and mandatory and do not very much. 
the crucial issue in spl development and practice be to manage the correct selection of variant. 
however no standard method have be develop yet and industry build spl use on the market or in house technique and method aware of the benefit a product line can provide nevertheless this development must return the investment and this be not always the case. 
in this work an approach to variability management in case of legal right applicability to different entity be propose. 
this architecture centric and quality base approach use a reference architecture that have be build with a bottom up strategy. 
variability be incorporate to the reference architecture at abstract level consider non functional property. 
a production plan to reduce the gap between abstraction and implementation level be define. 
mcmf max criticality max feasibility method for cloud task scheduling. 
task scheduling be one of the key challenge in cloud computing and deadline be one of the most important criterion for prioritize task when schedule on resource which provide useful information for the scheduler about the priority of task. 
this paper present a method call mcmf for scheduling task base on priority in the cloud environment. 
in addition to scheduling deadline sensitive task the mcmf also attempt to balance the load of virtual machine at the time of allocation. 
the propose method be simulate in cloudsim toolkit and the simulation result show that the reject rate and the system throughput be improve. 
also makespan and resource utilization have be improve with regard to the prioritization technique of virtual machine in the propose method compare to recent study. 
control strategies for an octopus like soft manipulator. 
we investigate a reachability control problem for a soft manipulator inspire to an octopus arm. 
case model mechanical breakdown of the actuator be treat in detail we explicitly characterize the equilibrium and we provide numerical simulation of optimal control strategy. 
improve the convergence of the periodic qz algorithm. 
the periodic qz algorithm involve in the structure preserve skew hamiltonian hamiltonian algorithm be investigate. 
these be key algorithm for many application in diverse theoretical and practical domain such as periodic system robust optimal control and characterization of dynamical system. 
although in use for several year few example of skew hamiltonian hamiltonian eigenproblem have be discover for which the periodic qz algorithm either do not converge or require too many iteration to reach the solution. 
this paper investigate this rare bad convergence behavior and propose some modification of the periodic qz and skew hamiltonian hamiltonian solver to avoid nonconvergence failure and improve the convergence speed. 
the result obtain on a generate set of one million skew hamiltonian hamiltonian eigenproblem of order 80 show no failure and a significant reduction sometimes of over 240 time of the number of iteration. 
parada control support system for parade. 
the parade of festas in honor of nossa senhora d agonia which be celebrate every year in the city of viana do castelo it be one of the highlight of the traditional festival that gather hundred of people in one giant parade throughout the city street this event attract thousand of spectator. 
due to its big dimension it present some difficulty regard its organization. 
the lack of cohesion of the parade during its course be one of the issue observe that originate several and large empty space which end up to discredit the parade. 
this paper present the study the issue relate with the parade s organization planning by propose a solution base on low cost technology. 
in this work we intend to study the problem of empty space propose a solution base on low cost technology and evaluate the performance of this solution with its potential user. 
in this way a process of collect information be initiate through the observation of the parade an interview with the organization and an inquiry of the collaborator and another one for the driver. 
base on the collected information it be propose a solution that use smartphone to interconnect through a mobile application and also a web management application in order to monitor the parade and help in suppress empty space. 
the proposal be evaluate to its potential user through a functional prototype. 
usability and user experience test be perform and the result be promise. 
it be intend to validate the propose solution in the field and extend the proposal to other parade. 
leverage cloud base tools to talk with robot. 
although there have be significant advance in human machine interaction system in recent year cloud base advance be not easily integrate in autonomous machine. 
here we describe a toolkit that support interactive avatar animation and modeling for human computer interaction. 
the avatar toolkit utilize cloud base speech to text software that provide active listening by detect sound and reduce noise a cloud base ai to generate appropriate textual response to user query and a cloud base text to speech generation engine to generate utterance for this text. 
this output be combine with a cloud base 3d avatar animation synchronize to the spoken response. 
generate text response be embed within an xml structure that allow for tune the nature of the avatar animation to simulate different emotional state. 
an expression package control the avatar s facial expression. 
latency be minimize and obscure through parallel processing in the cloud and an idle loop process that animate the avatar between utterance. 
asynchronous control design of continuous time markovian jump systems with bounded time vary transition rates. 
the asynchronous control design of continuous time markovian jump system with bound time vary transition rate be address in this paper. 
accord to the framework of parameterized linear matrix inequality plmis essential stabilization condition be establish with consideration on dissipativity performance and then transform to solvable set of linear matrix inequality lmis under our propose method. 
especially our technique be derive from not only time vary system mode but also asynchronous control mode transition rate. 
the effectiveness of our method be then illustrate through our numerical example. 
wavelet analysis base stability conditions of a prediction model. 
prediction model find a wide application in advanced control system intelligent system of information decision support play a significant role in any activity concern with signal processing procedure involve detect failure of different technological process. 
method base on the wavelet analysis be characterize by a unique ability of detailed frequency analysis in the time. 
the paper present stability condition of a prediction model which be develop on the basis of the multi scale wavelet transform as well an example of the prediction model apply in the oil refining process. 
neural network contour error prediction of a bi axial linear motor positioning system. 
in the article a method of predict contour error use artificial neural network for a bi axial positioning system be present. 
the machine consist of two linear stage with permanent magnet linear motors control by servo drive. 
the drive be control from a pc with real time operating system via ethercat fieldbus. 
a randomly generate non uniform rational b spline nurbs trajectory be use to train offline a narx type artificial neural network for each axis. 
these network allow prediction of follow error and contour error of the motion trajectory. 
experimental result be present that validate the viability of the neural network base contour error prediction. 
the present contour error predictor will be use in predictive control and velocity optimization algorithm of linear motor base cnc machine. 
requet real time qoe detection for encrypted youtube traffic. 
as video traffic dominate the internet it be important for operator to detect video quality of experience qoe in order to ensure adequate support for video traffic. 
with wide deployment of end to end encryption traditional deep packet inspection base traffic monitoring approach be become ineffective. 
this pose a challenge for network operator to monitor user qoe and improve upon their experience. 
to resolve this issue we develop and present a system for real time quality of experience metric detection for encrypted traffic requet. 
requet use a detection algorithm we develop to identify video and audio chunk from the ip header of encrypted traffic. 
feature extract from the chunk statistic be use as input to a machine learning ml algorithm to predict qoe metric specifically buffer warning low buffer high buffer video state buffer increase buffer decay steady stall and video resolution. 
we collect a large youtube dataset consist of diverse video asset deliver over various wifi network condition to evaluate the performance. 
we compare requet with a baseline system base on previous work and show that requet outperform the baseline system in accuracy of predict buffer low warning video state and video resolution by 1.12x 1.53x and 3.14x respectively. 
a comparative study of video annotation tools for scene understanding yet not another annotation tool. 
computer be powerful tool capable of solve a great variety of ever so complex problem yet train they to interpret even the simple video scene can prove more challenging than one might imagine. 
still be one of the major problem in computer vision this issue recently be address by utilize promise deep learning approach in order to recognize object and their semantic. 
for achieve this goal huge artificial network be feed with many human create annotation use more or less sophisticated tool for speed up the otherwise time consume task of manual annotation. 
purposefully refrain from design yet another of these annotation tool in this work we strive for evaluate what make existing one great or not we aim at determine effectiveness and efficiency of state of the art object annotation tool when employ for annotate different kind of video content. 
our finding in a user study evaluate three comparable tool on three video of distinct domain indicate a significant difference in annotation effort from a video perspective yet no significance regard utilize tool. 
far we determine a significant correlation between annotation time and accuracy. 
a simple exploratory power loss modelling of the flyback smps. 
the power loss of the main semiconductor of the flyback smps be dissipate in the figure of heat which should be keep by the permissible temperature rise in the switch device for the reliable operation life expectancy and burning hour. 
it be significantly important that the power loss optimize for optimal heat flow cope up with the heating and cool technique of the semiconductor by the convection conduction and radiation process to administer the power loss of the power converter as most important power loss modeling and reliable issue of the paper. 
decentralize fractional order controller for a granulation process. 
this paper develop a decentralized fractional control scheme for a widely use granulation process to enhance the closed loop performance. 
a fractional filter pi controller be design for the granulator transfer function matrix. 
the control scheme be so design to have an impact of fractionality in improve the closed loop performance yet preserve the simplicity of the proportional integral pi controller. 
the propose controller be a fractional filter couple with an integer order pi controller. 
stability and robustness assessment of the propose controller be also carry out. 
then relative normalize gain array rnga be employ to achieve the desire control loop pair for the decentralized scheme. 
finally the fractional filter pi control be effectuate to the granulator control problem for test the efficacy of the propose method. 
numerical simulation of the paper confirm the superiority of the closed loop performance result from the propose controller of the paper in contrast to the conventional controller. 
a deep learning approach to detect drowsy driver in real time. 
fatigue and microsleep be the reason behind many severe road accident. 
these can be avoid if the symptom of fatigue be detect on time. 
this paper describe a realtime system for monitor driver vigilance. 
driver drowsiness detection algorithm in the past have prove to work in control environment but have not be implement on a wide scale as of yet. 
algorithm in the past suggest calculate a scalar value know as eye aspect ratio ear and detect drowsiness by compare its instantaneous value with a previously configure value. 
we propose a generalise approach use convolution neural networks cnn in this paper. 
our algorithm track the driver s eye and feed it into a pre train that predict the state of the eye. 
once the prediction be obtain we would be able to detect if the driver be drowsy or not. 
the main component of our system include a camera for real time image acquisition a processor for run algorithm to process the acquire image and an alarm system to warn the driver when the symptom be detect in order to avoid potential accident. 
dda distributed data acquisition system use wireless sensor network. 
wireless sensor networks wsn and embedded systems can be combine to have an efficient real time factory monitoring system in term of cost power and scalability. 
in this paper a distributed data acquisition system ddas be develop use wsn for monitor machine health production line and factory s environmental condition. 
it provide factory relate alert to authority during critical situation. 
the system sense the real time datum from different sensor node incorporate at different section of the factory and relay it to a central node. 
a test bed implementation and experimentation of ddas show that the sensor node be power efficient accurate and scalable. 
portable fluorescence reader for point of care molecular diagnostic device. 
polymerase chain reaction pcr be routinely use as a diagnostic tool for detection of genetic material of pathogen to confirm whether an individual be infect or not. 
the readout for quantifying pcr amplicon be still a bottleneck for development of field deployable portable system to perform pcr test in low resource setting. 
herein we present a portable fluorescence readout system for pcr amplicon readout with high accuracy and sensitivity that can detect as low as 18ng mu l of dsdna a concentration 10 time low than those usually encounter in pcr amplicon. 
it utilize a single board computer sbc with integrated wireless connectivity that enable a user friendly and robust system. 
an optimize system implementation assure a low one watt power consumption enable battery powered usage. 
we demonstrate the use and efficacy of the develop system as a proof of concept by perform a quantitative analysis of a pcr amplify functional gene belong to mycobacterium tuberculosis. 
an effective web service anti pattern prediction model use smote. 
an anti pattern be a common response to a recur problem that be usually ineffective and risk be highly counterproductive. 
in this work we empirically investigate the association between the occurrence of four different type of anti pattern and source code metric. 
smote be be use for datum sample as the dataset consider be imbalance. 
principle component analysis and rough set analysis be apply for feature extraction and selection. 
the feature select from this two technique along with the significant features(sigf be consider as input for build the predictive model for the detection of anti pattern. 
the effectiveness of these technique be evaluate use logistic regression(logr decision tree(dt and least square support vector machine(lssvm with three different kernel linear(lsvvml polynomial(lssvmp and radbas(lssvmr. 
experimental result reveal that the model develop use smote be yield well result when compare to the model develop with the original dataset. 
furthermore we also observe that the predictive model develop use lssvm with linear and polynomial be more effective than the model develop use other classifier technique. 
performance prediction method for embedded systems products. 
in this paper state human center design hcd method it predict and quantifie performance characteristic such as time performance and the probability of human error for embedded systems products. 
the propose method be base on functional structure theory fst of man machine systems mms and generalized structural method gsm of a.gubinsky. 
synthesis the structure of the technological cutting process. 
one of the direction of technological process tp improvement of processing by cut operation be the development of application for automate the synthesis of tp machining and the synthesis be carry out in two stage the first be the structural optimization of tp in the form of tp operation sequence the second be the parametric optimization of tp where the search for optimal mode of operation be carry out. 
a decision of support system for the structural optimization of the tp cut metal processing that be use for the high precision product of aviation equipment which make a rational choice of the set of tp component in the form of a set of part surface work piece equipment fixture tool lubricate and cool technological environment be use in the enterprise and possible operation be propose in the paper. 
the solution be form on the basis of the develop heuristic rule for the selection of tp component that take into account technical and technological datum on tp component the requirement of standard regulatory and industry metalworking document accumulate knowledge in the field of the theory of mechanical machining and the experience of process expert. 
with this approach the problem have a finite set of solution form as a set of alternative tp. 
the final decision on the tp structure be form after determine the optimal mode of operation cut speed and feed accord to the specify objective function. 
to solve the problem which be formalize in the form of a decision tree a method of sequential hierarchical synthesis and method of artificial intelligence namely production rule implement use the logic programming language be apply. 
the testing make on the example of tp process a specific product. 
a model for the calculation of the thrust force and torque during bone tissue drilling. 
an improved model to calculate the force characteristic i.e. 
axial thrust force and torque of the bone tissue drilling process be present. 
the model make use of theoretical and experimental datum and be base upon the cut work concept. 
it take into account the heterogeneity of the bone material and the effect of contact indentation and delay bone chip evacuation on the axial force and torque during bone drilling. 
the propose model have show to accurately predict the force characteristic in all stage of the drilling process. 
method of artificial neural network synthesis for use in integrated cad. 
the factuality of the problem of automate classification and code with the use of modern information technology be explain by its complexity. 
one solution be to automate part classification procedure in integrated cad system use artificial neural network. 
this article be devoted to solve the problem of neural network synthesis by modify genetic algorithm. 
combinatorial optimization problems solving base on evolutionary approach. 
an evolutionary method for solve the travel salesman problem in the field of pharmacy business by optimize the work of the drug delivery device be propose in this paper. 
modification of three method of initialization of the initial population of the genetic algorithm be develop. 
the software base on the propose evolutionary method be create. 
it allow change the initial parameter of the genetic algorithm observe the process of solve the salesman problem graphically obtain a result in text and graphic form. 
modeling and design of the industrial production control unit. 
in the article the industrial production of polypropylene filter element be consider. 
one of the main problem of the of fibrous polypropylene filter element production control be the technological process management. 
the main object in the technological process be a circular heater the schematic design of which be give in the work. 
base on the model of the heater the main characteristic for control and tuning be select. 
heater tuning process have be make and it be determined that for this object the pb controller be well suit. 
development of cad cam cae systems of designing spatial frame for technological and machine tool equipment. 
the paper analyze the elastic stressed state of the technological equipment frame layout for the strategy selection of the second order surface process with the minimum deviation from the plan trajectory. 
the analysis of the parallel structure mechanism behavior within relation of use typical processing strategy by the line of develop specialized software product be conduct. 
possibility of choose the second order surface processing strategy accord to the calculated accuracy criterion be present as technical mean for design. 
the calculation of the predict behavioral quality of equipment with mechanism of parallel structure be show. 
specialized computer system control the technological parameters of the drilling rig. 
systematize and research characteristic of quasi stationary oil and gas object complex on the example of industrial drilling plant. 
as a result requirement for the implementation of algorithm and special processor for perform diagnostic function of quasi stationary object be form. 
the algorithm of identification of state of quasi stationary object on the basis of special code be develop. 
the technique be propose besides the compact coding of a set of technological parameter of drill state in the form of structure code that carry information about the number time and plan economic datum on the example of drilling process. 
analysis of reliability survivability and telemetry datum of on board equipment of small satellite. 
in paper we present the solution of relevant problem of estimation analysis and forecast the indicator of reliability and survivability of the onboard equipment of small satellite. 
the solution of the problem of intelligent datum analysis of telemetry onboard equipment of small satellite in order to detect the state of its operation and do operability analysis. 
a set of software tool and technique for the evaluation and analysis of reliability survivability and telemetry of small satellite onboard equipment be develop. 
the develop software tool and technique be base on the method and algorithm of reliability theory probability theory and mathematical statistic boolean algebra machine learning and image processing. 
the suggested software tool set be implement in desktop and web version and have a flexible service orient architecture. 
synthesis of neurocontroller for intellectualization tasks of process control systems. 
the paper deal with the development of a basic neurocontroller for intellectualization of process control system. 
a vertical tabular algorithmic method for calculate the scalar product by use two and more table of macropartial product allow a computation time to be reduce through parallel datum processing be improve. 
maintenance support and software be develop for the basic modular base neurocontroller that ensure rapid improvement in a product be design. 
the neurocontroller s structure and model be develop to manage an intelligent greenhouse that rely on an artificial neural network. 
combine onthologies and behavior base control for aware navigation in challenging off road environment. 
autonomous navigation in off road environment be a challenging task for mobile robot. 
recent success in artificial intelligence research demonstrate the suitability and relevance of neural network and learn approach for image classification and off road robotic. 
nonetheless meaningful decision make process require semantic knowledge to enable complex scene understanding on a high abstraction level than pure image datum. 
a promising approach to incooperate semantic knowledge be ontology. 
especially in the off road domain scene object correlation heavily influence the navigation outcome and misinterpretation may lead to the loss of the robot environmental or even personal damage. 
in the past behavior base control system have prove to robustly handle such uncertain environment. 
this paper combine both approach to achieve a situation aware navigation in off road environment. 
hereby the robot s navigation be improve use high level off road background knowledge in form of ontology along with a reactive and modular behavior network. 
the feasibility of the approach be demonstrate within different simulation scenario. 
integration of open source arduino with labview base scada through opc for application in industry 4.0 and smart grid scenario. 
modern innovative concept around digital information and communication technologies dict like industry 4.0 the internet of things or smart grids be impact the scientific and technological world and hence in control and automation arena. 
these trend involve networked interconnection and continuous data flow between a number of hardware and software actor. 
in parallel open source technology have gain increase attention from last year especially due to the widespread presence of the open source hardware arduino microcontroller. 
focus on industrial advanced framework supervisory control and data acquisition scada system be require to exchange datum with new smart device sensor and/or actuator. 
arduino board be commonly use as development platform for such smart device. 
therefore communication solution must be design towards the convergence of open source hardware and widely use traditional scada devoted software. 
this paper present a system that seamlessly integrate arduino board into a labview base scada system through ethernet connection. 
the open connectivity provide by the open platform communications opc protocol enable such integration. 
the propose framework be a novelty in scientific literature. 
the development of the system be report and initial result be provide to demonstrate the feasibility of the proposal. 
an iot framework for assembly tracking and scheduling in manufacturing sme. 
a universal rfid platform be present which be mean to be use as a building component of iot integrate collaboration platform for manufacturing application. 
the core element of the system be base on affordable raspberry pi module run on an iot operating system. 
the main goal of this paper be to demonstrate an affordable iot solution for manufacture sme to improve productivity by measure and adapt the assembly process for a give product. 
to track the production chain each part in the supply chain be equip with an rfid tag which will be record during its travel through the facility. 
in addition each worker have his own rfid tag to localize himself and record the perform activity. 
the workstation be equip with rfid scanner use to record activity and product flow through the station. 
all the gather datum be collect on a server and the real time status of the assembly line be process and display to the dispatch agent. 
upon this datum analysis the dispatcher can take action update the manufacturing setup and ultimately increase productivity. 
modular and domain guide multi robot planning for assembly processes. 
smart factory of the future will be equip with dynamic and task specific team of robot in order to manufacture custom tailor product. 
for this it be necessary to facilitate the planning of appropriate task sequence for cooperate robot. 
in this paper we introduce a modular and domain guide planning approach for multiple robot. 
due to its modularity the approach can be adapt to different assembly problem. 
moreover domain knowledge be use to guide the planning towards feasible solution. 
we evaluate the approach with different example from the block world domain i. 
e. 
lego r duplo r. 
this evaluation show that this domain guide approach outperform classical planning base on state space search such as a. 
software 2.0 for scrap metal classification. 
software 2.0 and its approach to the processing of multi spectral image help to perform an automatic classification of metal scrap be the subject of this research. 
the use of machine learning and deep learning tool contribute to the development of intelligent system allow to achieve relevant result in the classification of image particularly of metal scrap. 
in this research test will be perform with a multi spectral chamber to obtain image of aluminum iron copper brass stainless steel simulate an environment of metal scrap. 
the aim be to obtain the classification of these metal through the development of software and to perform a multi spectral analysis of the obtain image. 
preliminary test be make in a control environment with a small sample of these material. 
study to implement a prototype in a brazilian steel industry will follow. 
real time network intrusion detection system base on deep learning. 
computer network be vulnerable to hacker computer virus and other malicious attack. 
as an active defense technology intrusion detection play an important role in the field of network security. 
traditional intrusion detection technology face problem such as low accuracy low detection efficiency high false positive rate and inability to cope with new type of intrusion. 
to solve these problem we propose a real time network intrusion detection system base on deep learning which use big datum technology natural language processing technology and deep learning technology. 
our main contribution be as follow one use flume as the agent for log collection to realize real time massive log collection use flink as real time computation engine. 
two aim at the high dimensional problem of traffic datum a self encoder base intrusion detection dimension reduction method be propose and the intrusion detection datum be preprocesse include datum cleaning coding extraction and integration and normalization. 
three propos a deep learning base intrusion detection model ae alexnet which use auto encoder alexnet neural network. 
the experimental result of the intrusion detection datum set kdd 99 show that the accuracy of the ae alexnet model be as high as 94.32. 
a monitor method base on adaptive frequency for self adaptive software. 
self adaptive systems sass be require to adapt to the complex change with different characteristic by frequent monitor. 
the problem with gathering and update change information frequently at runtime be that it may cause computing and communication overhead which affect the real time of sas. 
however if the frequency be reduce it be difficult to ensure the accuracy of change identify. 
so it be necessary to solve the trade off between the accuracy and expensive overhead. 
exist method base on data processing improve accuracy by reduce potential uncertainty. 
other method base on adaptive frequency lack quantification and be difficult to ensure accuracy. 
we expect to combine they and break through the latter. 
to this purpose this paper propose a method base on adaptive frequency for sas. 
the method can ensure the accuracy of adaptive adjustment by comprehensively analyze the influence factor of monitor frequency and can quantify the monitoring frequency in real time by calculate these factor accord to the monitoring datum. 
finally we exemplify these method with an e commerce system. 
a retransmission control scheme with adjustment factor for hierarchical secondary users in crn. 
in our work for the purpose of control the retransmission behavior of secondary user sus in cognitive radio network crns with hierarchical su we set a feedback probability for the interrupted low priority sus su2. 
whether an interrupted su2 packet leave the system depend on this feedback probability. 
this feedback probability be a system parameter associate with the amount of packet in the system. 
an adjustment factor be introduce to control the impact of the amount of packet on the feedback probability. 
by establish a markov chain model we obtain some expression of relate performance metric. 
finally by operate numerical experiment we analyze the impact of the adjustment factor on different performance indicator of su2. 
design and research of edge layer service platform base on flexible service architecture. 
with the advent of the future generation networks(5 g high bandwidth high density and low latency will become the mainstream feature of network service. 
if we continue to adopt single cloud computing mode speed delay or stability can not be guarantee at all. 
the edge calculation propose in recent year can properly solve this problem. 
edge computing be a network architecture that provide user with the service and cloud computing function on the wireless side. 
at the same time the emergence of virtualization technology enable the traditional server resource to be more fully utilize. 
platform and application virtualization now be rapidly move to the edge of the cloud. 
an edge computing platform be build by integrate docker technology and kubernetes technology in this paper. 
in addition network service experiment on the platform be perform. 
through the comparison of experiment result on the edge layer and the cloud layer conclusion be obtain that the edge computing layer can satisfy the low latency and stable demand of service. 
an approximate ctl model checking approach. 
the state space explosion be the main bottleneck of computational tree logic ctl model checking. 
in the framework of traditional model checking technique this problem be difficult to be solve completely. 
to this end a method be propose for predict the result for ctl model checking use several machine learning ml algorithm. 
first the datum set with a number of kripke structure ctl formula and their model checking result be obtain use the exist ctl model check tool. 
second random forest rf boosted trees bt decision trees dt and logistic regression lr algorithm be employ to train the datum set. 
on the basis of it the four ml model be obtain to predict the result of ctl model checking. 
the experiment show that the good accuracy of the new method be same as the exist ctl model checking method and its average efficiency be 378 time high than that of the exist method if the length of each of ctl formula equal to 500. 
unmatche observer base controller design for t s time delay systems. 
in this paper the problem of stabilization for imperfect premise matching be study in which the t s fuzzy observer model with time delay and the fuzzy controller do not share the same membership function. 
a sufficient condition for the stabilization via observer base state feedback under imperfect premise matching be present and an unmatche observer base state feedback controller be also construct. 
the propose control scheme enhance the design flexibility as the membership function of the observer base controller can be arbitrarily select. 
a numerical example be give to illustrate the conservative of the propose design method. 
learn to plan with logical automata. 
this paper introduce the logic base value iteration network lvin framework which combine imitation learning and logical automata to enable agent to learn complex behavior from demonstration. 
we address two problem with learn from expert knowledge one how to generalize learn policy for a task to large class of task and two how to account for erroneous demonstration. 
our lvin model solve finite gridworld environment by instantiate a recurrent convolutional neural network as a value iteration procedure over a learn markov decision process mdp that factor into two mdp a small finite state automaton fsa correspond to logical rule and a large mdp correspond to motion in the environment. 
the parameter of lvin value function reward map fsa transition large mdp transition be approximately learn from expert trajectory. 
since the model represent the learn rule as an fsa the model be interpretable since the fsa be integrate into planning the behavior of the agent can be manipulate by modify the fsa transition. 
we demonstrate these ability in several domain of interest include a lunch boxpacking manipulation task and a drive domain. 
asymptotically optimal planning for non myopic multi robot information gathering. 
this paper propose a novel highly scalable sampling base planning algorithm for multi robot active information acquisition task in complex environment. 
active information gather scenario include target localization and tracking active slam surveillance environmental monitoring and other. 
the objective be to compute control policy for sense robot which minimize the accumulate uncertainty of a dynamic hide state over an a priori unknown horizon. 
to address this problem we propose a new sampling base algorithm that simultaneously explore both the robot motion space and the reachable information space. 
unlike relevant sampling base approach we show that the propose algorithm be probabilistically complete asymptotically optimal and be support by convergence rate bound. 
moreover we demonstrate that by introduce bias in the sampling process towards informative area the propose method can quickly compute sensor policy that achieve desire level of uncertainty in large scale estimation task that may involve large sensor team workspace and dimension of the hide state. 
we provide extensive simulation result that corroborate the theoretical analysis and show that the propose algorithm can address large scale estimation task which be previously infeasible. 
equivalence of the projected forward dynamics and the dynamically consistent inverse solution. 
the analysis design and motion planning of robotic system often rely on its forward and inverse dynamic model. 
when execute a task involve interaction with the environment both the task and the environment impose constraint on the robot s motion. 
for model such system we need to incorporate these constraint in the robot s dynamic model. 
in this paper we define the class of task base constraints tbc to prove that the forward dynamic model of a constrain system obtain through the projection base dynamics pbd and the operational space formulation osf be equivalent. 
in order to establish such equivalence we first generalize the osf to a rank deficient jacobian. 
this generalization allow we to numerically handle redundant constraint and singular configuration without have to use different controller in the vicinity of such configuration. 
we then reformulate the pbd constraint inertia matrix generalize all its previous distinct algebraic variation. 
we also analyse the condition number of different constraint inertia matrix which affect the numerical stability of its inversion. 
furthermore we show that we can recover the operational space control with constraint from a multiple task base constraint abstraction. 
online incremental learning of the terrain traversal cost in autonomous exploration. 
in this paper we address motion efficiency in autonomous robot exploration with multi legged walking robot that can traverse rough terrain at the cost of low efficiency and great body vibration. 
we propose a robotic system for online and incremental learning of the terrain traversal cost that be immediately utilize to reason about next navigational goal in build spatial model of the robot surround. 
the traversal cost experience by the robot be characterize by incrementally construct gaussian processes use bayesian committee machine. 
during the exploration the robot build the spatial terrain model mark untraversable area and leverage the gaussian process predictive variance to decide whether to improve the spatial model or decrease the uncertainty of the terrain traversal cost. 
the feasibility of the propose approach have be experimentally verify in a fully autonomous deployment with a hexapod walking robot. 
reduced order vs. 
discretized lumped system models with absolute and relative states for continuum manipulators. 
a reliable accurate and yet simple dynamic model be important to analyze design and control continuum manipulator. 
such model should be fast as simple as possible and user friendly to be widely accept by the ever grow robotic research community. 
in this study we introduce two new modeling method for continuum manipulator a general reduce order model rom and a discretized model with absolute state and euler bernoulli beam segment eba. 
additionally a new formulation be present for a recently introduce discretized model base on euler bernoulli beam segment and relative state ebr. 
the model be validate in comparison to experimental result for dynamic of a stiff flop continuum appendage. 
our comparison show high simulation accuracy eight 14 normalize error and numerical robustness of the rom model for a system with small number of state and computational efficiency of the eba model with near real time performance that make it suitable for large system. 
the challenge with design control and observation scenario be briefly discuss in the end. 
conditional neural movement primitives. 
conditional neural movement primitives cnmps be a learning from demonstration framework that be design as a robotic movement learning and generation system build on top of a recent deep neural architecture namely conditional neural processes cnps. 
base on cnp cnmp extract the prior knowledge directly from the training datum by sample observation from it and use it to predict a conditional distribution over any other target point. 
cnmps specifically learn complex temporal multi modal sensorimotor relation in connection with external parameter and goal produce movement trajectory in joint or task space and execute these trajectory through a high level feedback control loop. 
condition with an external goal that be encode in the sensorimotor space of the robot predict sensorimotor trajectory that be expect to be observe during the successful execution of the task be generate by the cnmp and the correspond motor command be execute. 
in order to detect and react to unexpected event during action execution cnmp be far condition with the actual sensor reading in each time step. 
through simulation and real robot experiment we show that cnmps can learn the non linear relation between low dimensional parameter space and complex movement trajectory from few demonstration and they can also model the association between high dimensional sensorimotor space and complex motion use large number of demonstration. 
the experiment far show that even the task parameter be not explicitly provide to the system the robot could learn their influence by associate the learn sensorimotor representation with the movement trajectory. 
the robot for example learn the influence of object weight and shape through exploit its sensorimotor space that include proprioception and force measurement and be able to change the movement trajectory on the fly when one of these factor be change through external intervention. 
transformer incipient fault diagnosis use machine learning classifier. 
power transformer be important equipment in the electric grid. 
the availability loss of the transformer be a high impact event for various stakeholder in the power system network. 
hence transformer health monitoring have garner much significance. 
dissolved gas analysis be by far the most prevalent condition monitoring technique among utility. 
however identify the condition of the transformer from the dga observation be a difficult task. 
machine learning algorithm base on the principle of probability and decision make theory be now gain momentum in this area. 
in this study the performance of svm k nn and ensemble method algorithm be compare in interpret dga datum. 
datum transformation be perform on raw datum to improve its quality. 
the dga test dataset be generally skew which hamper the performance of the classifier. 
datum random sampling be employ to balance the datum. 
the effect of the datum transformation and datum imbalance have be study. 
the result obtain show that the ensemble method algorithm perform the good in most case. 
also the performance of the classifier algorithm have be find to increase through datum pre processing and datum balancing. 
development of fault diagnosis unit for induction motor use digital signal processor and mems accelerometer. 
this work present an attempt in develop a non electrical contact and non invasive type portable fault diagnosis unit for induction motor im use omap digital signal processor and micro electro mechanical systems mems accelerometer. 
the novelty of the work lie in the fact that several electrical and mechanical fault can be successfully detect in order to deal with challenge in the continuous condition monitoring of incipient fault in im. 
the methodology include capture of vibration signal by accelerometer conversion of vibration signal to voltage signal and take the fft of the signal in digital signal processor to carry out the spectral analysis. 
the experimental result have be validate by compare with the result of tektronix fft analyzer and simulation. 
far the develop system be examine on im at milk processing dairy industry and ply wood manufacturing industry to validate the system performance. 
design of a modify radar sensor for liquid level measurement and monitoring. 
a modify non contact type radar level sensor have be design for liquid level measurement in a highly aggressive process environment. 
this paper describe detail of various component of this sensor set up and its optimize design result achieve after iteration. 
reinforcement of generator stator end winding structure by modal analysis approach. 
stator end wind of turbine generator experience high vibration at resonance frequency in operation which result into basket loosening insulation failure and ultimately end with no power from machine. 
modal analysis be a powerful tool of vibration test to visualize vibration characteristics viz. 
natural frequency amplitude and mode shape of dynamic structure. 
this article elucidate the vibration behavior of stator end wind structure in a 150 mva 16 kv 50 hz turbine generator of decennial period. 
natural frequency test nft be conduct on it in off line condition. 
an impact hammer and an accelerometer be jointly use for excitation force and respond vibration respectively. 
modal parameter be extract from the frequency response function through fft analyzer. 
natural frequency and vibration magnitude have be obtain. 
overhang be reinforce base on the test result. 
efficacy of the rectification work be endorse by post modal analysis. 
vibration amplitude have be bring down to low value in the resonance band width of 95 to 110 hz. 
finite element base vibration signature analysis of electrical propeller drive system for condition monitoring. 
any defect in the form of an axial crack or a circular defect in the propeller induce additional component in the centrifugal force and thereby produce an additional vibration characteristic in the propeller. 
the objective of this paper be to determine the translation of vibration to the permanent magnet synchronous machine pmsm which drive the propeller and in turn a triaxial accelerometer be use to detect the fault. 
a finite element base model be create consist of the propeller shaft bearing and pmsm. 
the fea modal analysis be perform to determine the natural frequency of the system and a harmonic response analysis be perform to determine the vibration harmonic at the natural frequency of the system. 
a comparison of the natural frequency of the healthy system and the defective system be obtain along with vibration characteristic for the different profile and the load dependency of the vibration characteristic. 
it be observe that the x axis and z axis vibration increase significantly for the defective propeller and it increase with load. 
prediction of feasible operating point for a dbd reactor base on decomposition rate constant. 
strict emission regulation be be implement worldwide to tackle the issue of air pollution these year. 
it be important that suitable technological solution have to be introduce in addition to the conventional pollution control method. 
non thermal plasma reactor be prove to be effective in tackle several pollutant if properly tune. 
one dimensional numerical model and mathematical model of a dielectric barrier discharge reactor be simulate in this work. 
the solution of these model be couple to obtain the good operating condition of the reactor under specific emission condition of oxide of nitrogen. 
the importance of power deposit and decomposition rate constant be analyze. 
it be infer that careful tuning of operating parameter can improve the efficiency of dbd reactor. 
design and simulation of mems base piezoelectric acoustic sensor. 
a mems base acoustic sensor that combine high sensitivity wide frequency range and low cost batch process miniaturized silicon component to build self powered system be present in this paper. 
it also throw light on an effective method to monitor health of a machine which be by use an piezoelectric mems microphone. 
the propose acoustic sensor consist of a sputter piezoelectric zno layer that transform the mechanical deflection of a thin etch si diaphragm into a piezoelectric charge. 
this zno layer be sandwich between bottom al electrode and top al electrode. 
the simulation of the propose acoustic sensor be carry out for two design i the piezoelectric material be place at the four corner of the silicon substrate and ii the piezoelectric material be place at centre of the silicon substrate. 
the thickness of the layer be choose so as to withstand the dynamic sound pressure of 96 106db and it produce maximum of eight mu v pa. 
the simulation be do by comsol multiphysic and coventorware. 
a novel autonomous technique for early fault detection on overhead power line. 
provide uninterrupted reliable and high quality power supply to consumer have be very challenging for power utility around the world. 
the utility spend a considerable amount for the maintenance inspection testing and monitoring of power infrastructure to achieve the above. 
the overhead power line be the main power carrier for the delivery of electricity to the consumer. 
these overhead power line be prone to risk of fire and fault cause by vegetation encroachment and touch on the power corridor result in damage to the conductor power blackout and catastrophic event such as wildfire or bushfire. 
therefore utility have to regularly inspect and monitor powerline for the prevention of damage. 
utility have be adopt foot patrol aerial inspection and more recently lidar technology to inspect the overhead power line on regular basis. 
however these approach only give point of time information and be time consume and costly. 
this paper present a novel technique which use directional antenna mount on pole carry overhead conductor to detect the partial discharge pd signal generate by incipient fault in an experimental set up and also field testing. 
these pd signal be process by fpga signal processing unit for peak detection and filtering and digest of the signal be deliver to a secure cloud server for post data processing such as trend analysis pattern recognition and localisation. 
this paper demonstrate the effectiveness of this early fault detection efd technique to accurately locate vegetation encroachment and partial discharge originate from broken insulator defective gas switch and transformer. 
this technology have be successfully employ at various location on distribution feeder in australia and the result be very encouraging. 
resolve the asymmetry of on exit versus on entry in executable models of behaviour. 
for the uml state chart be by far the most use modelling tool both to communicate behaviour and to produce executable model. 
we investigate the inherent asymmetry of on entry and on exit actions in uml statechart. 
we show first that the apparently simple and symmetric rule for handle the sequencing of on entry and on exit action be hard to fully comprehend and apply effectively by software developer. 
second define a semantic that result in executable model for application such as reactive system and real time system be very delicate. 
third formal verification can be hamper because the semantic result in a combinatorial explosion of state. 
we evaluate the understandability of the semantic by take out experiment with various task comprise sample uml statechart and logic label finite state machine llfsms. 
several experiment with software developer enable we to dissect how issue of understandability of state diagram relate to nesting or event drive vs logic label. 
since logic label finite state machine achieve model composition through a subsumption architecture suspend restart resume we propose a specific alternative semantic for logic label finite state machine that be suitable for robotic and embed system. 
modular construction of context specific test case migration methods. 
migration of test case have a twofold benefit in software migration project reuse of valuable knowledge as well as time and cost saving. 
the diversity of software migration project contexts require a flexible and modular construction method to address several aspect like different system and test environment or the impact of the system change on the test case. 
when an inappropriate migration method be use it may increase the effort and the cost and also decrease the overall software quality. 
therefore a critical task in test case migration be to provide a transformation method which fit the context. 
to address this problem in this paper we present a framework that enable a modular construction of context specific migration method for test case by assemble predefine building block. 
our approach build upon an exist framework for modular construction of software transformation method and consist of a method base and a method engineering process. 
method fragment be the atomic building block of a migration method whereas method pattern encode specific migration strategy. 
the guidance on development and enactment of migration method be provide by the method engineering process. 
we evaluate our approach in an industrial case study where a part of the eclipse modeling framework be migrate from java to c. 
numerical analysis of the eutectic melting and relocation of the b4c control rod materials by the mpfi mps method. 
eutectic melting and subsequent relocation of the boron carbide b4c control rod material be simulate by a particle method. 
in the past it be difficult to simulate the eutectic melting by a particle method because the melting start at the interface between two different material which lead to the instability of the particle motion due to the small amount of fluid particle and lack of the thermodynamic consistency of the particle system. 
thus the move particle full implicit mpfi) moving particle semi  implicit mps method be develop and introduce in the current study. 
specifically the mpfi method be introduce for the momentum transfer calculation and the mps method be introduce for the heat and mass transfer calculation. 
the mpfi mps method realize the simulation of the eutectic melting and subsequent relocation behaviour. 
a dynamically frequency tunable perfect microwave absorber use graphene. 
in this paper a graphene base really dynamically frequency tunable absorber be propose for the first time the center frequency of which can be tune in x band while maintain a large absorption coefficient close to unity. 
the propose absorber consist of a layer of pattern graphene sandwich(gss and a layer of substrate back with ground and print with periodical patch print on the top. 
we fabricate and measure some sample to experimentally verify the dynamical tunability of absorber. 
a good agreement between simulation and measurement be obtain. 
resonant frequency modeling of coplanar waveguide dual frequency antenna base on prior knowledge gaussian process. 
aim at the problem of gaussian process machine learn to solve the problem of low efficiency cause by too many sample in the process of antenna modeling a gaussian process modeling method base on prior knowledge be propose. 
the input sample of the model be the size parameter of the antenna and the output sample be the difference of the electromagnetic simulation calculation result and the prior knowledge thus establish the gaussian process model. 
this modeling method be use to model the resonant frequency of the coplanar waveguide feed dual frequency microstrip antenna and the error result be ideal. 
it be show that the gaussian process model base on prior knowledge can replace the electromagnetic simulation software improve the modeling speed and prove the feasibility of the method. 
design of dual band bandstop filter use microstrip and dgs resonator. 
in this paper we present a dual band bandstop filter(dbbsf design use quarter wavelength resonator and defect ground structures(dgss. 
the quarter wavelength resonator on the upper plane contribute the low stop band and the open loop dgs resonator on the ground plane introduce the high stop band. 
and a reasonable tuning method be adopt to tune the two stop band with smooth response. 
the design strategy and the equivalent circuit be introduce in detail. 
a third order dual band bsf with center frequency of 0.55ghz and 1.05ghz be design and fabricate. 
the attenuation of the filter great than 20db for the two stop band. 
good agreement be achieve between the experimental result and the simulation result. 
mutual coupling reduction between high density broadband dual polarize cross dipole use composite isolator. 
this paper present a composite isolator for mutual coupling reduction between high density broadband dual polarize cross dipole. 
the composite isolator be compose of periodic strip and a metallic wall which be etch on the both side of a dielectric slab with low profile 0.16 lambda(0 and ultra thin thickness 0.0045 lambda(0 and vertically place above the ground plane. 
two 45 degree dual polarize cross dipole element with impedance bandwidth of 45 range from 1.7 to 2.7ghz be build with center to center distance of 0.45 lambda(0 lambda(0 correspond to free space wavelength at 1.7ghz to verify decouple effect of composite isolator. 
reconstruction of isolated object by pso base inverse scattering method. 
inverse scattering problem be ill pose and usually be transform into optimization problem. 
conventionally the search direction in these optimization process be calculate by certain gradient base deterministic algorithm. 
in the absence of a priori knowledge there be a great risk of obtain a local extremum result. 
in this work a customize particle swarm optimization(pso method be utilize to search the globally optimal solution of inverse problem. 
the introduction of random factor can help inversion optimization evade local extrema. 
a numerical example be include to demonstrate the effectiveness of the propose method for inverse problem. 
towards a new adaptation engine for self adaptation of bpmn processes instances. 
in this paper we introduce an adaptation engine support self adaptation of run bpmn process instance. 
this adaptation engine implement the mape k monitor analyze plan execute knowledge approach from autonomic computing for self adaptation. 
the mape control loop aim at identify the adaptation need and define and execute the operation require to deal with these need while the k be the knowledge need for the mape control loop. 
more precisely the paper present the architecture of the adaptation engine it detail how autonomic manager responsible for self adaptation of process instance implement the mape control loop. 
compare testing and runtime verification of iot systems a preliminary evaluation base on a case study. 
assure the quality of internet of things iot system be of paramount importance and guarantee their reliability and compliance with the requirement be mandatory but few attempt have be make so far. 
in previous work we propose two approach for acceptance testing and runtime verification of iot system. 
both work rely on a uml state machine to specify the system expect behaviour. 
in the acceptance testing approach the interesting path to exercise be identify and translate into executable test script. 
in the runtime verification approach the relevant event during the system execution be monitor and compare against a formal specification derive from the uml state machine. 
in this paper we compare the effectiveness of our two approach by apply they to a mobile health iot system for the management of diabetic patient employ over 100 mutate version of the original system and analyse more than 1000 different execution. 
result show that both approach be effective in different way in detect bug. 
while the acceptance testing approach be more effective to detect the bug affect the user interface the runtime verification approach track well the subtle deviation from the system expect behaviour in particular those concern network issue. 
a software tools catalogue to support the statistical process control on the software context. 
statistical process control spc be apply to the software context in process analysis and improvement in high level maturity organization. 
there be some study that talk about the spc in the context of software however these do not yet describe in depth the approach relate to it. 
the main goal of this study be to present the result of a systematic review of literature aim to identify the spc relate approach in this work approach be understand as technique framework method and tool to support the implementation of a process which be put together in the form of a catalog. 
in this study only the tool that implement the spc will be present describe its characteristic example of use availability and ownership. 
with this study researcher will obtain valuable information for the possible future application of these tool in their development context. 
extract core elements of tfm functional characteristics from stanford corenlp application outcomes. 
stanford corenlp be the natural language processing nlp pipeline that allow analyse text at paragraph sentence and word level. 
its outcome can be use for extract core element of functional characteristic of the topological functioning model tfm. 
the tfm element form the core of the knowledge model keep in the knowledge base. 
the knowledge model ought to be the core source for further model transformation up to source code. 
this paper present research on main step of process stanford corenlp application result to extract action object result and executor of the functional characteristic. 
the obtain result illustrate that such processing can be useful however require text with rigour and even uniform structure of sentence as well as attention to the possible parse error. 
the analysis of key technologies for advanced intelligent quadruped robot. 
as boston dynamics announce more and more technical detail of its quadrupe robot to the world and eth successfully apply artificial intelligence to anymal the quadrupe robot have attract more and more attention of the researcher on robot and artificial intelligence all over the world. 
take the famous quadrupe robot in the world as the research object this paper analyze the key technology of advanced intelligent quadrupe robot. 
the integration of function and structure be introduce for the dexterous mechanism the typical gait and jumping motion be introduce for the advanced mobile ability perceptual and navigation be introduce for the autonomous walking. 
by analyze the key technology of advanced intelligent quadrupe robot the paper could provide abundant theoretical reference for the technical development of the legged robot. 
a computer aid method for sleep stage scoring employing single channel electroencephalogram signal. 
an automatic sleep monitoring system be a prime requirement in order to minimize analyst workload of visually inspect large scale datum for sleep scoring and to improve the accuracy at large range. 
this research introduce a robust precise single channel eeg base automate classification scheme for sleep state base on variational mode decomposition vmd. 
after pre processing and decomposition various feature be obtain from the decompose mode and the pre processed eeg signal. 
this propose method aim to use vmd for the first time in eeg base sleep scoring to the good of our knowledge. 
our model achieve its good performance use 10 fold cross validation in rf classifier after enormous experimentation. 
our model yield promise classification performance of 98.1894 95.4183 93.2352 92.0181 and 90.8283 overall accuracy for two state to six state classification respectively. 
this scheme also show a high or comparable detection accuracy for awake s1 s2 s3 and rem stage of five stage sleep scoring. 
behavior of napt middleware in an sdn environment. 
software defined networking sdn be a novel concept that aim to achieve flexibility and scalability by decouple control and datum plane and imbue centralized control while leverage route overlay and connection orient technology. 
another concept network function virtualization nfv focus on virtualization of network device that allow implementation of virtual middleware such as intrusion detection system ids network address and port translation napt load balancer etc. 
in this project our goal be to examine the performance of an sdn base network where it be integrate with a middleware napt. 
the napt be implement use the click modular router within a virtual platform mininet. 
a pox controller be use for nfv and sdn integration and this simulated client server network s performance be evaluate for different bandwidth of udp datagram. 
our test show that the inclusion of a middleware result delay packet delivery period and incurred deterioration in packet delivery ratio. 
optimization of sleep stage classification use single channel eeg signal. 
classification of various stage of sleep be mandatory for the diagnosis and treatment of sleep disorder. 
manual scoring be a time consume and tedious task as well as it require sleep specialist. 
therefore automatic sleep stage classification be necessary. 
in this paper we have utilize state of the art signal processing and machine learning technique for sleep stage classification use single channel eeg signal. 
three case of sleep classification have be do use support vector classifier svc decision tree dt random forest rf and xgboost xgb. 
the feature extract from pre procesed eeg have be apply to spectral regression dimensionality reduction technique to reduce the model complexity. 
the bayesian optimization bo technique be apply to optimize the hyper parameter of the classifier. 
our propose classification technique provide the minimum error of 25.52 14.03 and 4.93 for case i case ii and case iii respectively. 
word sense disambiguation by context detection. 
word sense disambiguation wsd refer to the process of find the appropriate sense of an ambiguous word a word with multiple sense. 
it be an important problem in natural language processing that enable a machine to disambiguate and understand human natural language. 
in this paper a method for wsd be propose base on the context of the word use wordnet as a knowledge base. 
first the input paragraph be preprocesse before disambiguate operation start. 
the disambiguation process determine the appropriate sense of the ambiguous word use context information of each word in the paragraph. 
the radix tree datum structure use to store context information for efficient searching. 
different machine maintenance techniques of rotary machine and their future scope a review. 
due to rapid industrial growth the maintenance work in our industry have also be increase. 
the primary objective of this paper be to state the traditional maintenance technique follow by maintenance people as well as available technique they can use for maintenance to increase productivity. 
alongside present maintenance practice this paper be here also to explain the future growth of advanced maintenance technology. 
now a day maintenance work be no long limit to diagnosis only. 
machine prognostic have also become popular. 
people be now interested to know the remain useful life rul of machinery. 
rul have become an interesting part of machine maintenance as the future trend can be analyze. 
recently the focus have be shift to machine learning as a condition monitor tool. 
different algorithm have be develop by the researcher regard condition monitoring purpose due to high accuracy. 
some of the algorithm will be introduce here. 
a matlab gui toolbox for surrogate base design and optimization. 
the surrogate model technique a fast solving and data base technology have great significance in design and optimization of complex engineering system and have be use to approximate problem without explicit function. 
in this paper a surrogate base design and optimization sbdo graphical user interface gui name sbdo toolbox be propose which combine the powerful mathematical analysis capability of matlab with the superb interfacial design function of guide. 
this toolbox consist of three module design of experiment doe construction of surrogate model and prediction optimization. 
user can address an optimization problem easily by inputte the information of independent variable set some option or just keep default value and the result of each module can be display graphically. 
the datum transmission between module be continuous so the integrity of design process can be guarantee. 
the propose sbdo toolbox can be commonly apply to engineering design and optimization by simply set parameter without any professional knowledge about surrogate model technique. 
therefore the development of sbdo toolbox be to simplify the step and operation of the sbdo process in engineering system and to promote the sbdo technology. 
a compact asymmetrical manipulator for robotic dentistry. 
in contemporary society there be an increase gap between supply and demand for dental healthcare service. 
meanwhile robotic technology have the potential to greatly improve the work efficiency of dental surgery hence fill the widen gap. 
however newly develop dental robot which be base on exist large sized industrial manipulator have over qualified workspace for dental application. 
thus a miniaturized six degree of freedom robotic manipulator with tendon drive mechanism be develop. 
with the manipulator be able of cover the whole human oral cavity the overall size of the propose manipulator have be successfully constrain in a 50x50x50cm(3 cube which be hardly possible for exist surgical manipulator. 
meanwhile the inverse kinematic algorithm be establish through d h modeling and be then implement onto an operator console to achieve remote control. 
moreover a dental handpiece be utilize as the surgical end effector. 
the overall performance of the robotic system be validate with a fabricate prototype where joint linearity and torque transmission performance be analyze from experimental result. 
development of an ankle detection platform for foot drop rehabilitation. 
with the aging of china s social population the incidence of stroke have also increase and the sequelae such as hemiplegia have become a problem that can not be ignore. 
timely detection access to patient with walk hemiplegia gait information be the therapist for the patient to develop an important part of the rehabilitation plan. 
at present the new gait detection system mostly use three dimensional analysis the three dimensional gait analysis system be large in size high in cost and inconvenient in operation and have great limitation in active rehabilitation training. 
in this paper a gait detection system for the ankle joint intelligent rehabilitation robot be design and develop base on the method of detect in electrical signal. 
the system can judge the motion state of the ankle joint in real time by measure the plantar pressure of patient the measure state of the patient can be analyze far. 
the gait situation of the object can also meet the requirement of the new ankle assist rehabilitation robot system which can be control by the subjective awareness of patient and provide theoretical support for the design of the new ankle rehabilitation robot. 
distribute polynomial kernel learn ng for large scale classification. 
the advent of the big datum era have bring many new challenge to machine learning. 
it be necessary to develop efficient machine learning algorithm and way to process massive datum. 
most exist machine learning algorithm be not well scalable and even maybe inefficient when deal with large scale data set. 
in this paper we propose a distribute polynomial kernel approach by divide the original datum set into multiple machine in order to overcome the difficulty cause by massive datum in the field of machine learn we mainly exploit a suitable select feature map base on polynomial kernel and an alternate direction method of multipliers(admm algorithm to solve the associate non smooth convex optimization problem. 
the classification result of the simulation experiment and the real datum set show that distribute polynomial kernel learning can effectively process large scale datum set without lose generalization performance very much. 
optimization of comprehensive stiffness performance index for industrial robot in milling process. 
low stiffness of serial robot be the main factor limit its application in mill task. 
in order to improve the stiffness characteristic of the robot the stiffness model of the robot be establish base on the kinematic model and jacobian matrix. 
then for the mill task the milling process be analyze and the cut force model be introduce. 
base on that the stiffness model of the robot be far analyze and the stiffness performance index be propose. 
at the same time in order to avoid the singular posture of the robot during the milling process. 
condition number be introduce to measure the dexterity of the robot. 
a comprehensive stiffness performance optimization model be establish and the posture of the robot in milling process be optimize. 
finally the posture with optimal stiffness be obtain. 
a novel distribute source seek method base on multi robots flocking. 
the purpose of this paper be to present a novel distribute source seek scheme and the scheme be base on multiple robot flocking(dssf. 
source seek be to seek the source of some signal in environment. 
flocking be a form that multiple robot move with flexible topological structure. 
therefore the propose dssf scheme be highly effective during the source seek process. 
furthermore the propose dssf scheme will more efficient to finish source seek task. 
particularly there exist two step in dssf scheme. 
in the first step a robot calculate gradient velocity with its concentration information and its neighbor. 
in the second process the seek velocity of robot be achieve by the importance of a robot in the flock. 
at last the effectiveness and robustness of dssf scheme be demonstrate. 
effect of actuation errors on a purely translational spatial cable driven parallel robot. 
in this paper we analyze a spatial three dof cable drive robot with a finitesize endeffector. 
the robot have six cable that define three parallelogram each compose by two cable thus the robot can not rotate but only perform translational motion. 
also since the two cable in a parallelogram be always keep at the same length they can be actuate by the same motor thereby mean that the three dof cable suspend robot require only three actuator. 
the kinematic and dynamic behaviour of such robot be study in previous work. 
the property of purely translational motion depend on a precise control of the extension of the cable. 
therefore in this paper we study how the platform pose change as some error of know maximum magnitude be introduce in the cable length. 
finally the result from both numerical simulation and test be present. 
the orientation of the platform be show to be robust to cable extension error. 
research on lower limb exoskeleton base on multi sensor information mature technology. 
exoskeleton be a new intelligent wearable robot develop in recent year. 
user work with exoskeleton which can provide assistant support and power as real human bone. 
in this paper an integrative joint structure use for low limb exoskeleton be propose. 
by use of this integrative joint a low limb exoskeleton structure be design. 
in order to judge walk intention of use some exoskeleton sensor be design for the low limb exoskeleton. 
this paper set up electrical system and control system. 
one low limb exoskeleton prototype be manufacture. 
for the purpose of testify the performance of the low limb exoskeleton some experiment have be do. 
time optimal planning within constraints in robot operating space. 
this paper propose an optimize interpolation method for motion along tool path in operating space in which motion time be minimum federate profile be adjust follow the constraint with maximum accelerate ability of give acceleration and jerk but not exceed they. 
the constraints on robot end effector federate along tool path be analyze to obtain velocity limit curve. 
then a discrete interpolation algorithm be propose to generate time optimal profile within constraint. 
finally the effectiveness of the algorithm be verify by experiment. 
an improved lhs approach for constrain design space base on successive local enumeration algorithm. 
surrogate model arc commonly use to replace expensive simulation in engineering design and optimization by virtue of their low computational cost and high prediction accuracy. 
the design of experiment doe play an indispensable role in construct surrogate model. 
however most of exist does be apply to regular design space such as rectangular or cube space and not apply to constrain design space. 
an approach of latin hypercube sample lhs base on successive local enumeration sle name sle lhs be such a kind of algorithm. 
in this paper an improve sle lhs approach for constrain design space be propose name as sle clhs approach. 
compare with the exist lhs method base on maximin algorithm sle lhs algorithm employ global objective function and a sequential local objective function aim at maximize the minimum distance between the sample point and the untried point. 
the propose sle clhs be an improved algorithm of sle lhs which take into account constraint between the sample variable and can be use in the constrain space. 
in the process of design the point that do not satisfy the constrain condition be to be eliminate then new point be generate in the constrain space and they will be update until the optimal position have be attain. 
two numerical example arc give in this paper and the result of two d and three d sample in constrain design space indicate that the sle clhs approach perform well both in space filling and in projection. 
decouple dynamic analysis of a three parallelogram hybrid spray paint robot. 
hybrid robot have the time vary dynamic load characteristic which can affect the performance of electromechanical system include the stability and motion accuracy then determine the spray quality. 
in this paper the dynamic characteristic analysis be perform for a hybrid spray paint robot with a three parallelogram structure take into account the numerical property of each component in the dynamic load. 
firstly the dynamic modeling of the mechanism be carry out by the principle of virtual work and the inertia matrix and gravity matrix be calculate and analyze. 
then by take the dynamic load as the disturbance in the servo control system the transfer function of the electromechanical system of the spray paint robot be analyze. 
the analysis result show that the stability will not change with the motion and the coupling effect of multi axis electromechanical system be weaken under low acceleration condition. 
finally the motion verification experiment be carry out to show that the gravity and friction be the main component of the drive force and the motion accuracy will vary with the dynamic load. 
a 3d point cloud reconstruction method. 
in order to quickly obtain a precise point cloud model of the target this paper propose a 3d point cloud reconstruction method. 
first a point cloud acquisition system which consist of kinect turntable green background frame and computer be construct to acquire the point cloud model of the target at 16 shooting angle. 
after that when the coordinate system conversion be finish the original point cloud model be process by both a pass through filter and a yowl filter the green background and other obstacle in the original point cloud model be remove by the straight through filter and cloud model be far simplify by the voxel filter in order to alleviate the computer s computational pressure improve the registration speed and reduce the interference of noise on the registration process. 
at this point the number of point cloud be simplify to an acceptable level and the basic feature of the target point cloud model be not miss. 
finally this paper propose a improved icp algorithm with curvature as the feature descriptor and the kd tree as the search mechanism to register the process point cloud model. 
in this improved method the curvature can be calculate relatively simply and not susceptible to noise interference as well as the kd tree can solve the problem of the inefficiency of the classical icp algorithm search mechanism and boost the search speed. 
and a layer by layer registration strategy be adopt in the register to reduce the cumulative error. 
several experiment have be carry out on several target in this paper use the above method and satisfactory experimental result be obtain. 
a time optimal velocity planning algorithm with machining precision constraints for cnc system. 
in order to realize the high speed and high precision machining a time optimal velocity plan algorithm with precision constraint for cnc system be propose. 
the algorithm take the total machining time of the give trajectory as optimization target. 
on the basis of kinematic constraint in order to ensure the machining accuracy the precision constraint be introduce for the two dimensional trajectory and three dimensional trajectory respectively include chord error track error and contour error constraint. 
in order to solve the above nonlinear optimization model the two step optimization strategy be adopt to transform the nonlinear optimization problem into two convex optimization problem. 
a smooth time optimal velocity plan algorithm with precision constraint be realize. 
performance of the present algorithm be evaluate both by simulation and experiment. 
event base planning and control for active collision avoidance in human robot collaboration. 
as the industrial manufacturing be go towards flexible and intelligent manufacturing human machine collaboration play important role in achieve high productivity and efficiency. 
in human robot collaborative environment the space separation between human and robot be cancel and it be very important to prevent human machine collision. 
this paper propose an active collision avoidance control method base on event base planning and control. 
firstly the autonomous motion of the robot drive by non time reference be achieve. 
then real time modification of the autonomous motion base on artificial potential field to avoid the obstacle be present. 
finally experiment of event base autonomous motion and simulation of collision avoidance control be conduct. 
design modeling and analysis of a novel flexure guide three dof fast tool servo device. 
a piezo actuated flexure guide three degree of freedom three dof fast tool servo fts device be present in this paper a kind of microstructure surface machining device which be design to achieve the motion and compensate the error along the three axis x y  and z  so as to cater for the rigorous requirement and the increasingly extensive demand of the optical element with microstructure surface. 
matrix base compliance modeling mcm method and the theory of vibration be adopt for the static modeling and the dynamic modeling of the device respectively. 
then the establish model be validate by finite element analysis fea via software. 
the evaluated result show the satisfactory performance of the propose three dof fts device demonstrate its great potential to achieve microstructure surface machining with well accuracy. 
health evaluation method of cnc machine tools base on fuzzy grey clustering and combined weighting method. 
health evaluation of computerized numerical control cnc machine tools be an important step to realize condition base maintenance. 
in this paper the evaluation method that merge fuzzy grey cluster and combine weighting be propose to determine the health status of cnc machine tool. 
the evaluation process be firstly weight of relevant parameter of the key component of cnc machine tool be calculate and determine by use the entropy weight method and the analytic hierarchy process ahp respectively. 
then the bvo weight arc combine by the combination weighting method and the combination weight with subjective and objective significance be obtain. 
then the grey cluster method be use to evaluate the health status of each key component of cnc machine tool. 
accord to the evaluation result the fuzzy evaluation matrix of machine tool health evaluation be create by the cluster coefficient of each key component of cnc machine tool. 
then base on the matrix the weight of each key component be calculate by entropy weight method and ahp and the weight of each key component be obtain by the combination weight method. 
finally the fuzzy comprehensive evaluation method be use to evaluate the health status of cnc machine tool and the health status be divide into four grade. 
finally the health status of cnc machine tool be determine base on the principle of maximum degree of membership. 
at the end of the paper the evaluation experiment be carry out on machine center which show the propose approach be reasonable and usable. 
kinematics and dynamics analysis of a novel ankle rehabilition robot. 
as the population continue to grow stroke have become one of the major disease that threaten the health of the elderly people. 
ankle rehabilitation be an essential part of the recovery. 
at present the patient complete the training mainly with the help of a physiotherapist which not only increase the burden on the physiotherapist but also delay the patient s recovery process. 
to meet the rehabilitation need of stroke patient and improve the rehabilitation efficiency this paper present a novel ankle rehabilitation robot to mimic the practical skill of the physiotherapist. 
base on the design robot mechanism the corresponding kinematic be analyze to obtain the displacement expression of the foot pedal of the ankle joint rehabilitation robot as well as verify the correctness of the robot structure design. 
subsequently the joint actuation torque of the ankle robot in the joint space be calculate base on the second kind of lagrange s equation in matlab and then the dynamical model of the ankle robot be perform. 
finally import the solidworks model into the adams software for a dynamic simulation to obtain the change of the joint driving torque of the rehabilitation robot be achieve. 
the datum of adams simulation be consistent with numerical result in matlab. 
therefore the joint calculation method can be use for motor control of the ankle rehabilitation robot. 
estimation and compensation for discrete time it2 fuzzy systems against time delay switch attack. 
this paper examine estimation and compensation for discrete time interval type two it2 against time delay switch tds attack. 
our goal be to propose a novel method to attenuate the negative effect derive from the tds attack. 
to synchronously estimate the system state and attack perturbation an augmented observer be first propose by use the descriptor system approach. 
the attenuation of negative effect from the tds attack to the system performance be then realize by use the compensation controller. 
finally we use a numerical simulation to demonstrate the effectiveness of the propose method. 
key technologies and platform of auxiliary safety management and operation for distribution network. 
in order to effectively improve the visualization and intellectualization level of field safety management and control this paper study key technology and platform of auxiliary safety management and operation system for distribution network. 
to achieve the visualization and intellectualization of the system five function module device access and image processing module image intelligent service processing module application service processing module storage module and application processing module be design. 
the architecture of the auxiliary safety management and operation system be design with perception layer network layer and application layer which be deploy in both transformation substation and remote control center. 
key technology of the system include behavior recognition base on machine vision and a safety monitoring robot system base on machine vision and expert system arc introduce. 
finally a safety management and control platform develop by state grid nantong power supply company be provide to illustrate the feasibility and effectiveness of the propose design and technology. 
wrist mems sensor for movements recognition in ball games. 
in ball game the arm movement be diverse and complex. 
the accurate recognition of the arm movement be of great significance to the quality of training and sport guidance. 
wrist sensor be one of the important mean. 
traditional wrist sensor recognize batting action by measure the acceleration and angular velocity of the arm and have a good performance. 
but they measure few feature and it have a slightly large size that have some effect on player performance. 
in this paper we develop a motion recognition platform for basketball ping pong and badminton. 
it be accurate enough for recognize these motion whether hit or miss the ping pong ball. 
the system integrate a low  power nine  axis inertial sensor and a low  power environment sensor that can output eleven different characteristic such as triaxial acceleration triaxial angular velocity triaxial magnetic field strength air pressure and temperature. 
this system include the power management part attitude detection part bluetooth wireless communication part and mobile terminal monitor part. 
the inertial sensor can identify the arm action and then transmit posture datum to the microcontroller unit mcu for analysis and processing. 
bluetooth 5.0 be use between the mcu and the mobile monitor for information exchange which make data transmission fast and more stable. 
experiment of the three athlete have demonstrate that the movement can be accurately identify. 
and the entire system have very low power consumption and very small size 23.05mm*9.25mm*5.5 mm. 
it provide a multi  feature measurement platform for body movement posture research and can recognize a variety of ball game movement which be of great significance for intelligent sport training and research. 
a 0.7mm(2 8.54mw focusnet display lsi for power reduction on ole smart phone. 
the first report focusnet display lsi integrate an 11 layer fully convolutional neural network and support color contrast and sharpness visual quality enhancement engine be design. 
a focusnet deep learning dl model be propose to predict the human s focus region apply a tone mapping curve so as to decrease the pixel luminance lead to 19.5mw of system power save on ole smart phone. 
implement in 10 nm cmos technology the propose dl assist focusnet display lsi cost 3.21 m gate and 52kb sram with 0.7mm(2 area. 
operate at 0.9v and 205mhz this lsi consume 8.54mw of power dissipation. 
a maximum eye track cdr with biased data level and eye slope detector for optimal timing adaptation. 
in this paper a maximum eye track cdr met cdr for minimum bit error rate ber be present. 
the propose cdr do not require a ber counter or eye opening monitor to find the optimal sampling phase. 
the biased datalevel obtain from the weighted sum of up and dn be propose to extract the actual eye height information consider the precursor isi. 
two error sample with small time space detect the current eye height and the slope of the eye height so that the cdr track the maximum eye height where the slope become zero. 
measure result prove that the maximum eye height phase and the minimum ber phase match well. 
a prototype receiver fabricate in 28 nm cmos process operate at 26gb s with an eye opening of 25 ui and consume 87mw while equalize 21db of loss at 13ghz. 
leader follower controls in systems with two controller. 
the classical control theory deal with dynamical system that be control by one controller design to ensure maximum performance of the system over a specific interval of time. 
more recently there have be considerable interest in system that be control by more than one controller. 
in this paper we consider control system that be control by two independent controller whose role and objective in term of the performance of the system be generally different. 
more specifically we consider system where one controller have an advantage over the other in that it have the capability of design and implement its control first before the other controller. 
with such control hierarchy this controller be designate as leader and the other as follower. 
to take advantage of its primary role the leader control be design by anticipate and take into consideration the follower s control. 
the follower become the sole controller in the system after the leader s control have be implement. 
in this paper we describe such system and derive in detail the control of both the leader and follower. 
we consider an economic control system that model the behavior of two firm in a dynamic market where one firm be more powerful than the other and as a result assume the role of a market leader. 
we derive the general condition that govern the existence of the leader and follower s control function. 
we then treat in detail the case where the system dynamic be linear and production cost be quadratic. 
finally we illustrate the result with a numerical example. 
blockchain for power grids. 
share information be an important part of regulate and maintain efficient and safe power grid. 
this project s goal be to develop a way of use blockchain technology to share transaction information among different power grid in a secure control monitor and efficient manner. 
the big concern regard the datum be integrity. 
by leverage blockchain technology the datum will be reliable and resilient to attack such as man in the middle and datum spoof attack. 
the hyperledger fabric implementation provide a permissione network in which power grid will act as node that maintain ledger information. 
by use a distribute ledger to validate transaction though the process of consensus the system can share information in a manner that be more secure and transparent than traditional information sharing system in which data be less secure and take long to validate. 
the additional layer of security and speed that hyperledger technology provide help to prevent issue such as power grid failure that could stein from the latency or integrity issue involve with traditional method of validate processing and react to share datum. 
modeling of sensor network for autonomous landslide monitoring base on neural network. 
landslide forecasting can lead to prevent great human injury and financial loss in the world. 
for this purpose monitoring of slope displacement be necessary. 
in this paper a sensor network that monitor the actual displacement of soil layer to predict landslide be describe. 
the propose landslide monitoring system determine the movement of soil layer by use the change in the sensor network. 
the processor of the system be a train computational model. 
at first by use a calibration device the datum of the sensor network be collect and then the obtain datum have be use to train the computational model. 
accord to the dependence analysis result an artificial neural network have be select to computational model. 
finally the result show that the landslide monitoring system can measure the displacement of soil layer accurately. 
beephon a web application for beehive audio exploration. 
honey bee be die at an alarming rate due to colony collapse disorder ccd. 
monitor honey beehive use the audio and video recording obtain from the beehive have be make possible with the availability of embed system such as raspberry pis. 
conveniently analyze a large number of audio file obtain from the hive be challenge but can provide an opportunity to learn about the behavior of the bee. 
beephon be a system of tool develop to enable exploratory analysis of audio recording take from inside honey beehive and efficiently annotate they. 
it primarily consist of a web application user interface for perform nonnegative matrix factorization nmf. 
label datum and component be store in a database and can be use to improve subsequent decomposition. 
use this system we annotate over 2000 audio file in four month. 
a technique to enable online machine learning applications for simulation optimization. 
simulation optimization refer to an optimization problem with a stochastic and potentially computationally expensive objective function. 
machine learning surrogate modeling technique have significant potential for enable efficient simulation optimization but typically require the user to retain all input output pair evaluate by the objective function and can suffer from numerical stability issue if sample be tightly cluster. 
a modification to the traditional surrogate modeling process be present that enable robust online learn through use of a kalman filter. 
the result of training kriging and radial basis function model be present for both the conventional training process and the modify training process. 
the modification result in minimal loss in the ability of the surrogate model to represent moderately complex objective function. 
a comparison of simulation optimization algorithm performance. 
simulation optimization refer to an optimization problem with a stochastic and potentially computationally expensive objective function. 
machine learning surrogate modeling technique have significant potential for enable efficient simulation optimization but typically require the user to retain all input output pair evaluate by the objective function and can suffer from numerical stability issue if sample be tightly cluster. 
a modification to the traditional rbf surrogate modeling process be present that enable robust online learn through use of a kalman filter. 
the capability of this modified surrogate modeling approach be present in comparison to a number of other simulation optimization algorithm. 
result indicate that the filter surrogate model algorithm be more efficient than other method for optimization problem that do not have complex topology. 
performance comparison of local versus cloud malware detection on android use machine learning technique. 
malware detection be a key component of mobile system security today. 
while standard virus detection software be an important tool in the light against mobile intrusion it can not detect zero day attack due to its reliance on previously detect signature. 
recognize first time attack require a different approach and commonly involve machine learning. 
the problem be that such approach be more computationally intensive and can create a user experience problem if the mobile device be not responsive enough. 
an experiment be conduct use machine learning specifically a genetic algorithm compare performance of zero day attack analysis run on a mobile device versus use cloud resource. 
it be demonstrate that even with a high end mobile device the use of a hybrid model that use a cloud base server for run the machine learning module vastly out perform the all local model. 
urbanbox a low cost end to end platform for smart city sensing. 
this paper present a low cost end to end and open source urban sensor node call urbanbox which be base on the concept of the internet of things iot. 
through the sense platform make by multiple urbanbox node user can collect visualize and store the real time datum from urban environment. 
the platform can serve as a tool for develop data rich smart city. 
this paper present the design data collection architecture and the sensor validation process fur the implement prototype. 
an iot base common platform integrating robots and virtual characters for high performance and cybersecurity. 
two humanoid robot be develop. 
both robot be human like in appearance though one be more human like than the other. 
a virtual human with human like appearance be also develop. 
various similar functionality and interaction modality for the robot and the virtual human be develop. 
various technology be incorporate with they to make they intelligent and autonomous. 
a common platform in the form of an internet of thing iot be develop that can integrate the robot and the virtual human for their real world collaboration. 
then the collaboration between each robot and the virtual human be separately implement via the common platform base on some control algorithm for find a hidden object in a homely environment. 
the collaboration between the robot and the virtual human be evaluate. 
the status of cybersecurity in the iot be briefly analyze. 
the result show that the collaboration be satisfactory in various term which justify their social integration in the form of an iot. 
two robot with different appearance be actually use to investigate the effect of anthropomorphism on the interaction. 
the result can help employ artificial intelligent agent of heterogeneous reality to perform real world task through their cooperation in the form of iot that can provide high performance and cybersecurity. 
transient stability in power systems use a convolutional neural network. 
monitor power system use intelligent system for post fault transient stability assessment tsa be critical for the grid to avoid cascade instability. 
machine learning method with synchrophasor measurement have be adopt widely for tsa due to the gradual deployment of wide area protection and control system. 
tsa method be crucial to alert operator or control not only that a fault have occur but also that the power system have lose or will lose stability and therefore action must be take. 
the two condition that be important in real time application for a power system be accuracy and response time. 
artificial neural networks and support vector machines have be implement in the past and have achieve satisfy classification accuracy. 
in this paper a convolutional neural network cnn system be propose for tsa to maximize accuracy while minimize response time to distinguish from old method of machine learning. 
the propose methodology be implement on a brazilian seven bus system and the wscc nine bus system. 
powerworld be use for simulate the three phase short circuit fault on all bus in the case study and matlab be use for simulate the cnn algorithm. 
supervised machine learning techniques for trojan detection with ring oscillator network. 
with the globalization of the semiconductor manufacturing process electronic device be powerless against malicious modification of hardware in the supply chain. 
the ever increase threat of hardware trojan attack against integrated circuit have spur a need for accurate and efficient detection method. 
ring oscillator network ron be use to detect the trojan by capture the difference in power consumption the power consumption of a trojan free circuit be different from the trojan insert circuit. 
however the process variation and measurement noise be the major obstacle to detect hardware trojan with high accuracy. 
in this paper we quantitatively compare four supervised machine learning algorithm and classifier optimization strategy for maximize accuracy and minimize the false positive rate fpr. 
these supervised learning technique show an improved false positive rate compare to principal component analysis pca and convex hull classification by nearly 40 while maintain 90 binary classification accuracy. 
spatial frequency domain entropy dissimilarity measure. 
an entropy base spatial frequency domain 2d image dissimilarity measure be propose and demonstrate. 
the metric be an extension to pixel pixel base entropy dissimilarity measure edm propose by tsai and wu. 
the new spatial frequency domain edm maintain all desire feature of edm while overcome limitation such as require the two digital image to be compare to have the same size in pixel. 
the research in inspire by the need of analyze the advanced ligo time series datum set in develop a real time and blind gravitational wave event detection algorithm. 
compare to other dissimilarity measure frequency domain entropy dissimilarity measure fd edm be spatial information sensitive and agnostic to image size and resolution. 
it also far improve the computational efficiency of normal pixel pixel edm. 
process improvement cost management in the quality management system of an industrial enterprise. 
modem enterprise management focus on the principle and requirement of iso 9000 standard. 
at present the quality management of an organization be view as a system of interrelated process aim firstly at satisfying and anticipate consumer demand and secondly at improve the efficiency of work base on leadership of manager and active use of continuous improvement method. 
analysis and accounting of production cost must be carry out base on concept and method of quality management use a systematic approach. 
quality be determine by several its component form a so call quality loop. 
quality be embed in product from the very beginning and be control at all stage. 
a quality product be obtain only if the necessary requirement be meet at all stage. 
quality begin with research need. 
this be the most important stage in the life cycle of any product since it be on it that the overall design of the product be decide the image be form the most common characteristic be determine. 
the propose approach allow identify and comprehensively represent the cost accounting process. 
the use of resource management activity at the enterprise allow reduce the share of material cost in the total cost of production and increase the efficiency of the organization. 
efficiency analysis of implement hybrid printing technology. 
the paper analyse four print technological flow case consider the author s experience over 15 year in the print industry to improve the production efficiency. 
the productivity the quality and the delivery time be the main area of interest for people work in the printing finish industry where the print demand structure evolve and the cost of replace machine be very high. 
the implementation of the organisational and reconfiguration of machine change contribute to the development of new efficient working structure within the printing process therefore increase the efficiency of it as one can notice from the diagram present in the paper. 
the time and the cost present have be obtain through a couple of trial of modify the work parameter the colour and the material accord to the colour management guideline in use. 
ultimately the optimal technological structure have be choose for quality improvement cost and delivery time reduction. 
good practice to increase manufacturing productivity comparative study. 
nowadays manufacture company be involve in a big competition each of they look to increase productivity and profit by implement good practice within the company. 
the present paper present an analysis of good practice of manufacture company which contribute to increase and improve the productivity and also have be identify new trend regard good practice implement in manufacture company. 
in order to accomplish this research have be analyze a successful manufacture company in the field of manufacturing and automation from romania. 
to collect datum for this study there be access two database different specialized website in the field but the most important source of information be obtain from the analyze company. 
one of the good practice identify in this study be to improve the productivity through re engineering practice that the company study have implement. 
in order to highlight this good practice namely reengineere be analyze in parallel both of exist manufacturing type from the analyze company respectively production on cnc processing center and classical production. 
the exemplification of both type of production be do by use a lean manufacturing method namely value stream mapping identify the operational flow of both type of production. 
consideration on the optimization of natural gas delivery by use automate control system. 
the current paper aim at optimize the natural gas delivery from an underground storage by implement automate control system and fiscal measurement system accord to the harmonized european legislation in the area of metrology. 
in the first part the author have carry out an analysis regard the state of the art at international level with regard to technical solution for optimize the delivery of natural gas by mean of a constriction element of a measurement panel. 
in the following a software application be create for monitor the parameter take from the process gas chromatograph and transfer they to the flow computer by implement software filter. 
the novelty element here be that it allow the trading of the nominate natural gas amount in a set period of time. 
optimal selection of equipment for injection molding process use the ahp method. 
increase interest in the study of plastic have lead to the development of processing technology use such material. 
the variety of plastic have lead to a diversification of the technical process through which the finished plastic product can be obtain. 
we approach the idea of design plastic injection equipment consider that various research could be make on the phenomena involve during the process as well as the observation of the technological property of the plastic. 
to design such equipment some know method use in conception process could be apply. 
optimize the equipment design process be one of the element that can ensure high efficiency of the entire injection molding process. 
thus the method choose in this case be the analytic hierarchy process ahp method which be one of the method that offer the possibility to choose a solution when there be many alternative. 
the relative simplicity and precision of this method be some of the argument behind this method. 
the combination of require equipment and application of the ahp method allow the choice of an optimal solution for testing injection molding. 
the result of design activity be an alternative to equipment that can be use for develop future research. 
electromagnetic forming analysis of the al 99.0 sheet with tools of different configurations. 
electromagnetic forming be an advanced manufacturing procedure characterize by the fact that the tool carry the deformation force do not touch the workpiece. 
this paper present research regard the electromagnetic forming of al 99.0 en aw 1200 sheet with coil have different configuration. 
the purpose of the research be to find the flat spiral coil configuration that ensure maximum deformation of the workpiece. 
flat spiral coil with different gap between the coil and the workpiece and coil with different number of winding be test. 
the influence of these parameter be monitor on the maximum strain of the free bulge part. 
the analysis of the result obtain for different configuration of the flat spiral coil allow the selection of the significant parameter that influence the electromagnetic forming process of the al 99.0 flat workpiece which aim to elaborate the mathematical model and to optimize the investigate process. 
current trend in the exploitation of mature gas field in the context of rehabilitation concept. 
the exploitation of mature natural gas field have be and will be an increasingly topic that will attract the attention of the production company give that most of the production about 60 70 come from these reservoir. 
implementation of the project management into the exploitation of mature gas reservoir have a notable ascension because of the fact that in the execution of the operational program always have develop a mechanism to achieve the objective in a sustainable manner the project management in gas industry it be know as rehabilitation concept or integrate reservoir development which have a major impact on increase the recovery factor. 
the paper intend to present the current trend in the exploitation of mature gas field in romania by apply the concept of rehabilitation as well as expansion opportunity in order to drive the business performance result. 
use of sound spectral signal analysis to assess the technical condition of mechanical device. 
the article present the result of a part of research conduct by the author into a wide range of work on automation of public safety system. 
their main purpose be to create on the basis of sound signal analysis system of warning against the use of firearm monitor public place not only at the time of shooting but at the stage of prepare the firearm reloading process. 
the range of acoustic measurement present in the article and their analyze include variability of sound emission of select type of firearm depend on the number of operation and thus the degree of wear. 
analysis of the record datum will allow in the future to develop a system enable not only to determine a type of firearm or tp narrow down the search area of individual specimen but also to determine the degree of wear in term of suitability for further use. 
the result discuss in the article correspond to two state of the same firearm model. 
the first be the initial state from the manufacturer s factory after return 50 control shot the other after over 20,000 cycle. 
the used firearm be technically fully efficient with no need to replace the element during operation as well as test. 
the present scope of measurement include spectral analysis of sound in the near field and time analysis of sound emission level in the successive operation phase of the firearm mechanism. 
a model for integrate work safety into the design of technical equipment. 
the paper propose a model unfold for occupational safety aspect inclusion in the design and management of change stage for a piece of machinery. 
the integrated safety technical equipment iste model substantiate a logical connection between various taskbase feature to be fulfil hazardous area and occurrence hazard risk assessment way to wedge in workplace characteristic the effect of the work environment work crew as well as apparatus tool and/or basically correspond to and follow a set of prior theoretically ground guideline find in literature. 
at the same time the paper give the outline of the case study perform to give proof of the practical model s illustrate operational safety design for a mechanical press line use for sheet metal milling. 
resort to the developed model it be perform the design construction and assembling of the automatic press line which be compliant in term of occupational safety. 
monitor the technological process in the wood industry in order to make they more efficient through technical overhauling. 
of many technique that be use to optimize production and cost the study conduct within a profile company lead to our choice for test the 6sigma method the most use method in the automotive industry in view of the economic efficiency apply in the wood industry company. 
this method measure how many flaw exist in a process and determine in a systematic way how to improve it by technical overhaul and eliminate or minimize the process for efficiency. 
this research article aim to study the state of research on the optimization of the production process through technical overhaul for panel reconstitute from solid wood and way to make production more efficient by cut cost through technical overhauling. 
from preliminary research we estimate that all the item found and other that will result from further research will result in a significant decrease in production cost that be reflect in the cost of the finished product and consequently in increase the yield of the company by maximize its profit. 
at the same time it may be the basis of future research study in the field. 
the easy it be to maximize profit the low the operating cost be and the high recovery rate of investment be that will result a change in the operate mode work smarter not hard. 
the possibility of cut shape on cnc machine tool. 
the development of computer technology have enable it to be introduce to machine tool. 
the widespread use of cnc machine tool have result in a rapid development of the processing industry. 
so far obtain the profile of the curve have require the use of a complicated machine tool kinematic design or it have be impossible to implement it otherwise than by copy. 
the numerical control of machine tool be base on the mathematical description of motion. 
this provide the capability to form curve of the same shape but with different dimension use parametric program. 
the article describe the practical use of parameter in machining on an fys mill machine with mitsubishi control. 
study of the cutting process parameter that influence the surface quality machine by end milling of the aluminum alloy. 
this research aim to carry out an elaborate experiment by witch result in relevant conclusion that have practical applicability in the aeronautical industry. 
the surface roughness measure transversely and longitudinally on the feed motion direction of the cut tool constitute the dedicated objective function on which the study be conduct in this case. 
the end milling be choose of an aluminum alloy use explicitly in the aeronautical industry. 
the actual experiment be carry out in the only aeronautical industry in romania carry out these type of machining and be make accord to the methodology with rigorous experimental planning of the research. 
the experimental plan conceive after which the practical experiment be conduct lead to apply research already put into practice within the above mention industrial organization. 
some aspect regard the thermic behaviour of a basalt part in machine building industry. 
this work aim to present some aspect regard the opportunity of use basalt in manufacture the subassemblie of machine tool. 
melt and recrystallize basalt have demonstrate promising behavior with regard of its use in manufacturing as report in the literature. 
the research present in this work be focus on analyze the behavior of basalt part for machine tool submit to thermic stress. 
the test be make use grey cast iron and steel part as reference for a comparative study. 
testing methodology specific measuring apparatus use experimental test datum record datum processing and result conclusion regard the possibility of use basalt in machine tool manufacturing be present in the paper. 
the improvement of quality management system in a porcelain factory. 
accord to sr en iso 9000:2015 quality management system can be consider a set of policy procedures processes and resource use to achieve the organization objective and desire result by manage the interact process resource require and inter related part of the business. 
the requirement of a quality management system that need to be implement by company in order to produce high quality product and to achieve continual improvement be describe in iso 9001. 
the aim of this research be to improve the quality management system implement in a porcelain factory name s.c. 
apulum s.a. 
the implementation of iso 9001:2015 in the organization involve monitor process performance through different performance indicator. 
the first performance indicator highlight the situation regard the quality of the product manufacture in a certain period and the second one emphasize the most common defect of one of the product fabricate in the organization hence identify nonconformity be analyze use 8d method in order to identify the root cause and to remove it. 
the result show that different solution be identify and implement in order to enhance the quality management system in the company consider. 
measurement system analysis by attribute an effective tool to ensure the quality of the visual inspection process within an organization. 
a successful quality assurance program in any organization need good measurement system. 
the concept of measurement system refer to the manpower machine material method and mother nature involve in obtain measurement. 
measurement system analysis msa be a set of procedure which be use to determine the amount of variation due to the measurement system and if the measurement datum be valid. 
most problematic measurement system issue come when the result of a measurement system be qualitative value such as pass or fail attribute datum rather than quantitative value variable data. 
because in industry many measurement system deal with qualitative datum the assessment of the visual inspection process be a contemporary approach for quality assurance in most manufacturing organization. 
the aim of this paper be to apply the msa attribute study in a local company from the sibiu region supply product for automotive industry to ensure the quality of the visual inspection process for one of their part respectively the exterior lighting projector day running light drls. 
the output datum be analyze use minitab software. 
the conclusion be that the visual inspection process must be improve by appraiser training and develop panel with sample for the most common defect type of drl. 
technical and commercial communication method use in semi finished industrial good market in south east european market. 
south east european industrial market be cross a period of strong development. 
this progress be also strongly feel by industrial supplier include semi finished non ferrous metal product trader. 
industrial marketing present a lot of feature which differ from the consumer marketing. 
analyze these market one can observe an increase communication between sale team and buy center. 
this communication have two major line technical and commercial. 
buying team which include very often engineer need special detailed and customize technical information relate to product delivery and payment condition etc. 
the clarity and efficiency of this communication be one of the key factor of commercial success on industrial market. 
in our paper we intend to analyze the communication method channel prefer on the mention market focus on the interaction of personal and digital communication and other issue which be specific for industrial marketing. 
research method include on site observation of sale team back office analysis of industrial supplier website professional in depth interview. 
our goal be to deeply understand the trend and interaction of different communication method and channel on this field and to propose new concept in order to improve this communication. 
development of distance learning concept with graphic machines working process visualization. 
the paper present the distance learn concept development by visualize the work process of graphic machine. 
the basic goal be realize through the application development that include machine simulation and their element. 
a large number of simulation and explanation of the work process be include in the knowledge base. 
the concept be expand to learn how to program machine so that the future operator can master significant knowledge that will enable he to engage in the production process quickly. 
the paper present concrete type of machine for different printing technique and machine for make packaging prototype. 
for the realization of object visualization modern software tool be use which fmally provide good quality. 
a study of thermo elastic characteristic of the machine tool spindle. 
in order to avoid the failure of machine tool spindle in the real machining process due to an increase in temperature it be essential to predict its thermal behavior in the designing phase. 
the characteristic of machine tool significantly depend on the thermal elastic behavior of the spindle. 
these parameter directly affect the productivity and quality of machine operation. 
this paper present a thermal elastic model of the machine tool spindle which be base on the quasi static model of bearing and the finite element fe model of the spindle shaft. 
base on quasi static model of bearing with angular contact heat generate and thermal contact resistance tcr be determine for each position of the ball. 
the aforementioned constraint have be apply to the 3d fe model of the spindle which allow for establish non stationary change of temperature and thermal deformation. 
in order to prove the efficacy of the propose model experimental measurement of spindle and bear temperature be do use thermocouple and thermal imager. 
path planning for mobile robot use improved adaptive rapidly explore random tree. 
path planning base on rrt have achieve great achievement in a complex and high dimensional environment. 
rrt algorithm require the user to choose an appropriate stepsize and bias probability before path planning however select algorithm parameter suitable for various environment be not only difficult but also time consume. 
an improved adaptive rrt algorithm be propose in this paper and have two notable feature. 
firstly it can automatically determine the initial range of stepsize and bias probability accord to the relative complexity of the robot working environment which be ever highly problem dependent and time consume process. 
secondly it can automatically adjust these two parameter on the basis of the collision detection result as the iteration continue various numerical experiment be demonstrate and validate to illustrate the effectiveness and obvious advantage of the propose algorithm over the basic rrt algorithm under different environmental condition. 
adaptive neural disturbance observer based nonsingular fast terminal sliding mode control for underwater robot manipulators. 
this paper present an adaptive neural disturbance observer base nonsingular fast terminal slide mode nftsm control method for underwater robot manipulator in the presence of external disturbance. 
radial basis function rbf neural network be use in the disturbance observer to approximate the unknown external disturbance which can improve the robustness of the control system. 
moreover an improved reach law be apply in the nftsm strategy to quicken the response of input signal in the different control period. 
afterward it can be demonstrate that all the state signal be ultimately bound via the lyapunov stability theory. 
finally numerical simulation result be carry out to verify the effectiveness of the propose method. 
configuration design and simulation of novel petal tooth nutation joint drive for robot. 
as the core component of the robot the transmission performance of the precision joint drive directly affect the efficiency of the whole system. 
the purpose of this paper be to propose and analyze a new joint drive for robot about a novel nutation drive with petal tooth. 
configuration design be develop and the model be then verify by kinematic simulation and interference detection by virtual prototype technology. 
far the digital design and motion simulation of the nutation gear drive and cnc machining of the key part be accomplish. 
the verification of the working process of the nutation joint drive can show the validity of the desire value on the design joint drive for robot. 
regenerative chatter control with piezoelectric actuator for micro structure surface turning. 
micro structure surface be widely use in optic and industry because of their excellent optical property wear resistance adhesion and lubricity. 
at present there be many method for micro structure surface processing among which the ultra precision machining be commonly use processing method. 
in the process of micro structure surface manufacturing the dynamic change of cut depth can cause instability in the machining process result in the generation of chatter which be one of the most important factor affect the quality of machining in the declination of surface quality and generation of noise and tool wear. 
the study of regenerative chatter have become a focus in the current manufacturing industry. 
ultra precision diamond cutting by use fast tool servo fts structure be a widely use microstructure surface processing method. 
in this paper the chatter of turn process use fts be model and the occurrence of chatter be simulate and analyze. 
then bp neural network be apply for the chatter control of the propose fts system the corresponding vibration curve be obtain. 
semantic situation extraction from satellite image base on neural network. 
satellite image situation awareness sisa be a task that generate semantic situation from satellite image automatically. 
it require not only the position and basic attribution color size etc of target but also the relationship counting relative position existence comparison etc among they and realization of the situation analysis rule. 
we propose a novel framework which consist of the background process visual question answer vqa and association rules set ars in which the background process deal with the situational map the vqa and ars identify the relationship through answer a set of question on sisa. 
to verify the performance of our method we build the evaluation dataset base on clevr. 
experiment demonstrate that our approach outperform the traditional sisa system on accuracy and automaticity. 
to the good of our knowledge we be the first to solve sa problem use vqa method. 
the meaning of our research be one we provide the possibility that sisa can be accomplish through vqa without precise scene graph. 
two we broaden the application of vqa. 
movement mode switch mechanism for a hybrid wheel legged mobile robot. 
this paper introduce a movement mode switching mechanism for a hybrid wheel legged mobile robot. 
with the switching mechanism two movement mode be achieve independently share the same actuator thus few actuator be use in the robot. 
a clutch be design to accomplish the movement mode switching process. 
the trapezoid tooth mesh as a tolerance design be use which not only lead to well engagement but also increase the transmission accuracy. 
the drawing back and recovery of the shape memory alloy conduce to the reciprocation of the clutch which transfer motion towards wheel and leg from the bevel gear respectively. 
then motion and force simulation of the switching process be make with adams. 
the result be use to check the material of the clutch and ensure the feasibility of the switching mechanism. 
finally a practical application be introduce use the switching mechanism show an adaptive capacity of the system to most wheel legged robot. 
design and kinematic analysis on a novel serial parallel hybrid leg for quadruped robot. 
aim to improve the performance and reduce the manufacturing cost of the current leg for quadrupe robot this paper present a novel three dof serial parallel hybrid leg. 
we design a prototype 3d model and give the analytical expression of inverse and forward kinematic. 
end effector workspace be compute use the numerical forward kinematic. 
the analysis and calculation show that this hybrid leg with simple structure combine the advantage of both serial and parallel mechanism high stiffness high bearing capacity low structural inertia and large workspace. 
this research have great significance to a series of further study on dynamic analysis mechanism optimal and system control of this novel hybrid leg. 
fault tolerant control of robotic manipulators with without output constraints. 
this paper investigate the tracking control problem of rigid robot manipulator with asymmetric output constraint and actuation fault. 
to lower the rigorous requirement on the initial condition of system output a novel output dependent universal barrier function ubf be develop such that the normally employ conservative design of convert the output constraint into track error relate constraint be remove. 
in addition such control be also able to the robot free from output constraint without change the control structure to solve the time vary yet undetectable fault of robotic manipulator in the long term operation a robust method base fault tolerant control ftc be propose such that neither fault detection and diagnosis(fdd)/fault detection and identification fdi nor controller reconfiguration be require. 
both theoretical analysis and numerical simulation verify the effectiveness and benefit of the propose method. 
robust adaptive force tracking impedance control for robotic capturing of unknown object. 
the manipulation for space know object have be study extensively however the case for unknown object still need further investigation because there be little information to assist measurement and manipulation. 
this paper propose a robust adaptive force track impedance controller for robotic capturing of space unknown object which have a great adaptability to the environmental parameter of the object a force track capability of capture different type of space object and robustness to uncertainty. 
first the position control base impedance control scheme be give. 
second an environmental parameter adaptive law be design to estimate the environmental location and the stiffness of the grasp object. 
third by use the nonlinear high gain tracking differentiator hgtd and linear extended state observer leso a robust adaptive dynamic surface position controller for a space robot be propose to guarantee a good position tracking performance of the controller and the robustness to system s parametric uncertainty. 
at last numerical simulation be conduct to demonstrate the position force track control performance of the propose impedance control scheme. 
intelligent robot arm vision base dynamic measurement system for industrial applications. 
current industrial robot arm be not satisfied in flexibility and intelligence due to the lack of visual perception. 
the production efficiency also run into a bottleneck because most part must be completely fix when assemble and weld. 
we propose a vision base intelligent robot arm which can dynamically sense the environment and perform appropriate operation. 
the measurement system consist of operator face authentication gesture remote control abnormal entry detection and move target tracking. 
the capability of human machine interaction and dynamic measurement meet the need of high performance robot arm in intelligent manufacturing with the characteristic of intelligence safety efficiency and flexibility. 
various function of the intelligent robot arm be verify through a large number of experiment in laboratory. 
development of four rotor fire extinguishing system for synchronized monitoring of air and ground for fire fighting. 
in view of the increase fire hazard the fire in the place of high rise building and crowd have cause work burden on firefighter due to various factor result in failure to rescue in time in recent year this paper study the four rotor fire extinguish system for fire fight air ground synchronous monitoring. 
the system be divide into two part the air ground communication position navigation system base on stm32 core processor and the fire detection and fire extinguish system base on stc89c51 core processor the two part realize the function of four rotor obstacle avoidance navigation information positioning zigbee wireless communication fire detection and fire extinguish device startup. 
the design of this system make the fire hazard greatly reduce achieve real time communication and position navigation more smooth it s applicable to urban community high rise building security large scale shopping mall fire forest orchard fire and other natural disaster fire facility. 
modern method of form an innovation strategy of the banking sector of the economy. 
the aim of this study be to develop modern approach to the formation of innovation strategy of credit institution base on non technological innovation. 
as a result of the analysis of theoretical material a conceptual model be develop for the formation of the innovation policy of credit institution and the impact of non technological innovation on the efficiency of their functioning be assess. 
base on the classification of the portfolio of innovation tool a mathematical model have be develop and a methodology have be propose for operative control over the process of implement a set of innovation strategy include in the development plan of a credit institution. 
operational risk management in finance environmental activity and personnel management project. 
project on environmental protection and personnel management have a significant impact on the level of fix cost and change in operational risk of industrial enterprise. 
the most effective implementation of these project be possible at the stage of production growth and expansion of sale of company. 
at the stage of recession this work require strict control over the level of operational risk and change in the share of fix cost in the cost of production. 
improve the efficiency of environmental and personnel management project require maintain an optimal level of operational risk. 
it be propose to retain project risk at the planned level by control and regulate the amount of fix cost at the enterprise. 
various regulatory system be propose for period of recovery and recession of economic activity of enterprise. 
development of the industrial sector in the region through innovation. 
the purpose of the study be to consider the development level of innovative perspective base on prioritization put in the first place the industrial sector as the quintessence of all activity in the region. 
innovative transformation be an integral part of the strategy implementation for the development of the economy of the russian federation in general and regional strategy in particular. 
at the same time each of the participant in innovation activity seek to save they which lead to the search for less resource intensive or alternative technology to consider the possibility of use element of outsource or engaging regional authority in the implementation. 
in most case when form view on innovation process the sectoral complex as a whole be consider which do not take into account the peculiarity of the functioning of individual sector. 
the result of the study can be useful for meet the condition of the compliance of the goal and objective of the region s innovative development the common vision of project investment the dynamic of the industrial sector development will be meet and the foundation for the further projection of the propose tool to manage the economy of the region and the country. 
digitalization of labor market parameter to improve the efficiency of the enterprise s personnel policy. 
the article analyze the characteristic of the labor market on the internet that affect the formation of personnel policy of the enterprise. 
the author propose a develop software product to order the processing a large amount of information and determine the parameter and key indicator which determine the successful personnel policy of the enterprise. 
the software tool include an analysis of the basic parameter of the labor market on the internet the ratio of supply and demand for major vacancy average wage of supply and demand the dynamic of supply and demand take into account the region territorial specific. 
the possibility of programmatic monitoring of the labor market in order to promptly adjust the personnel policy of an organization to key personnel position base on the dynamic of change in the labor market environment make it possible to increase the effectiveness of personnel policy and its productivity. 
comparative analysis of key parameter of the labor market in various city of the russian federation and possible direction of personnel policy formation in the major vacancy in organization allow optimal analysis of large amount of information open on the internet job bank datum of personnel and recruiting agency job bank and resume in social network take into account the region allow you to quickly and correctly make management decision in the field of personnel management. 
the article discuss the contact of the parameter of the labor market with the main direction of the personnel policy of the enterprise the organization of personnel selection adaptation training motivation and incentive evaluation etc take into account possible personnel risk. 
innovative activity in primorsky krai a methodical approach to assess the effectiveness. 
the purpose of this work if to offer a model of the assessment of innovation effectiveness. 
innovation activity be a basic component of the innovation potential and be a tool and mechanism for the innovation economy. 
the author propose a holistic model for assess the effectiveness of innovation from several point of view. 
the methodological approach to determine the effectiveness of innovation involve compare the result of innovation activity with innovative expenditure that provide this result. 
this allow take into account the synergistic effect express in improve the economic efficiency and effectiveness of activity. 
when assess innovation efficiency it be necessary to consider not only the design criterion for evaluate investment project but also the assessment of the degree of influence of the result of innovation activity on the development of production. 
the obtain result can be use when form the project measure by the federal and regional municipal authority to increase the efficiency of the managerial impact on regional process. 
these element allow form the set of instrument that increase the efficiency of the managerial impact. 
sheet metal material resource management in lean production. 
industrial enterprise be responsible for increase production waste. 
the purpose of the research be to develop tool of material resource management in lean production for sheet metal cutting at engineering enterprise with single or serial type of production. 
at the previous stage of the research a situational analysis of the cutting process be conduct a literature review be carry out and the main provision of the sort method of sheet metal material resource after cut be define for divide they into group of business or non business material resource. 
the main provision of the propose method be specify in this article. 
further research task be also identify. 
simulation of thermal field dynamic in the erected reinforce concrete structure. 
during the heat treatment of concrete temperature field in the structure can be control by change the initial concrete temperature the heating power of the heating element and heat transfer condition at the surface of the structure. 
there be the task of find such heat treatment mode in which the temperature field have the desire characteristic. 
these characteristic include temperature rate of rise and temperature gradient. 
the first step in the solution of the heat treatment operation problem be to create a sufficient point of a mathematical model of the temperature field in the harden concrete. 
the second stage should be devote to the numerical solution of the equation of the model which allow a computer to determine the temperature field in harden concrete structure. 
with this method you can use a computer to study the dynamic of the temperature field at various mode of heat treatment and to develop the most rational mode without the need for a large series of scientific experiment. 
for the numerical solution of model equation a locally one dimensional scheme of the method of full approximation be apply. 
this scheme be economical relatively simple to program do not require a lot of memory and allow perform calculation on a computer. 
effective functioning of enterprise with regard to environmental risk. 
the relevance of the choose topic of the paper be cause by the need to analyze environmental risk arise during the operation of industrial treatment and processing enterprise. 
the external and internal factor affect the development and life cycle of an enterprise be present. 
in order to understand how to solve problem associate with environmental risk it be necessary to study the interaction of an enterprise with the environment in such area as resource provision production and sale of product. 
the system of effective functioning of an industrial enterprise be present schematically. 
as a conclusion it should be note that the enterprise s management team should pay increase attention to external and internal factor that may cause environmental risk. 
variational attention for commonsense knowledge aware conversation generation. 
conversation generation be an important task in natural language processing and commonsense knowledge be vital to provide a share background for well replying. 
in this paper we present a novel commonsense knowledge aware conversation generation model which adopt variational attention for incorporate commonsense knowledge to generate more appropriate conversation. 
give a post the model retrieve relevant knowledge graph from a knowledge base and then attentively incorporate knowledge to its response. 
for enhance attention to incorporate more clean and suitable knowledge into response generation we adopt variational attention rather than standard neural attention on knowledge graph which be unlike previous knowledge aware generation model. 
experimental result show that the variational attention base model can incorporate more clean and suitable knowledge into response generation. 
how question generation can help question answer over knowledge base. 
we study how to improve the performance of question answer over knowledge base kbqa by utilize the factoid question generation qg in this paper. 
the task of question generation qg be to generate a corresponding natural language question give the input answer while question answer qa be a reverse task to find a proper answer give the question. 
for the kbqa task the answer could be regard as a fact contain a predicate and two entity from the knowledge base. 
train an effective kbqa system need a lot of label datum which be hard to acquire. 
and a train kbqa system still perform poor when answer the question correspond with unseen predicate in the training process. 
to solve these challenge we propose a unified framework to combine the qg and qa with the help of knowledge base and text corpus. 
the model of qa and qg be first train jointly on the gold dataset then the qa model be fine tune by utilize a supplemental dataset construct by the qg model with the help of text evidence. 
we conduct experiment on two dataset simplequestions and webqsp with the freebase knowledge base. 
empirical result show that our framework improve the performance of kbqa and perform comparably with or even well than the state of the art. 
solve chinese character puzzles base on character strokes. 
chinese character puzzle be popular game in china. 
to solve a character puzzle people need to fully consider the meaning and the stroke of each character in puzzle. 
therefore chinese character puzzle be complicated and it can be a challenging task in natural language processing. 
in this paper we collect a chinese character puzzle dataset ccpd and design a stroke sensitive character guessing sscg model. 
sscg can consider the meaning and stroke of each character. 
in this way sscg can solve chinese character puzzle more accurately. 
to the good of our knowledge it be the first work which try to handle the chinese character puzzle. 
we evaluate sscg on ccpd. 
the experiment result show the effectiveness of the sscg. 
combine external sentiment knowledge for emotion cause detection. 
emotion cause detection ecd that aim to extract the trigger event of a certain emotion explicitly express in text have become a hot topic in natural language processing. 
however the performance of exist model all suffer from inadequate sentiment information fusion and the limited size of corpora. 
in this paper we propose a novel model to combine external sentiment knowledge for ecd task namely exsentiecd to try to solve these problem. 
first in order to fully fuse sentiment information we utilize a sentiment specific embed method to encode external sentiment knowledge contain in emotional text into word vector. 
meanwhile a new sentiment polarity corpus be merge from multiple corpora. 
then a pre training method be adopt to mitigate the impact of the limitation of annotate datum for ecd task instead of simply expand sample. 
furthermore we apply attention mechanism to take emotional context into consideration base on the observation that the context around emotion keyword can provide emotion cause clue. 
experimental result show that our model greatly outperform the state of the art baseline model. 
novel multiscale grid representation of deep neural network layer for model complex engineering process. 
a novel deep multiscale neural network dmnn architecture be propose in this paper for model complex engineering process. 
unique analytical function be first develop via couple the homogenization theory with multiscale perturbation analysis which be then attach as new activation function for connected neuron in the different hide layer of the propose multiscale nn model. 
the follow advantage can be derive from the propose methodology a effective feature extraction technique at the multiple scale of the engineering problem to compute optimal gradient of select cost function with respect to the weightage of the extract feature associate with the problem b pre determine the optimal number of neuron to be deploy for the different hide layer of the propose multiscale nn model and c identify critical feature to achieve high predictive accuracy during the combined training and testing stage of the propose model. 
experimental datum be then extract from the literature for a specific engineering problem to test the validity of the propose methodology. 
reasonably good accuracy be obtain between the respective measure datum and model s prediction on a preliminary stage. 
build upon the same methodology further research work be currently in progress to develop much deep multiscale nn model base on high performance computing with unified parallel c upc programming model to optimize the model s computational performance for model complex engineering process. 
hybrid modelling base on svm and ga for intelligent wi fi base indoor localization system. 
due to the growth of the ubiquitous positioning base service the development of indoor positioning system have attract the research intensely. 
wifi be one of the technology introduce to support the indoor positioning service. 
the wifi signal strength direct from advice localize in an indoor environment can be utilize to predict the device s location the user handle that device. 
the prediction of the user location can be consider as a classification problem where the model can predict the location of the user accord to predefined zone. 
machine learning ml technique have be apply widely in the literature to develop indoor positioning system. 
however these application suffer from poor generalization ability and/or high computational complexity. 
this paper propose an indoor positioning system base on a hybrid ml model that use support vector machine as a classifier tool. 
to improve predictive capability of the model svm s parameter be optimize use genetic algorithm. 
the propose model demonstrate promise result in term of significant correlation r2=0.99 and high classification accuracy rate acc= 98.3. 
a deep cnn for image analytics in automated manufacturing process control. 
computer vision be widely use in control of manufacturing process. 
however due to the relatively high cost automate visual inspection be apply only for the final product and not after each production phase. 
faulty product be identify at the end of the production pipeline little information be provide with regard the cause and the production phase that produce the defect product. 
this paper present a deep cnn for the enhancement of the computer vision system by provide additional information on the type of the product and consequently on the production phase that generate that product and fault respectively. 
the cnn have be integrate into the pipeline for the automate process control. 
this information be important for further decision making in production flow management. 
the paper present full description of the deep cnn model design with discussion base on image analytic carry out on 12k database of image of product from the porcelain industry. 
the numerical modeling of the inductive heating process at different frequencies use the flux 2d software. 
this paper present the numerical modeling of the induction heating process for the case of surface heating with the view of temper a steel bar use the flux2d software. 
the tempering of semi finished product be aim at change the structure of the superficial layer result in the hardening of surface subject to wear. 
smart service systems security and privacy challenges in internet of thing. 
monitoring and detect change in the environment and can be use for several purpose. 
to develop new advanced service for smart environment datum gather during the monitoring need to be store process and correlate to different part of the information that characterize or influence the environment itself. 
with the quick advancement in enable technology for ubiquitous computing more and more active or passive device sensor be augment in the smart indoor environment. 
service innovation enable by the confluence of big datum mobile solution cloud social and cognitive computing and the internet of things iot have gain a lot of attention among many enterprise in the past few year because they represent promising way for company to effectively and rapidly deliver new service. 
but one of today s most pervasive and bedevil challenge be how to start this journey and stay on course. 
in this paper we present our state of the art technology and iot device how they be play a vital role in make the world advance. 
the big conclusion be that all the information and communication technology ict) enabled service innovation need to be human center and focus on co create value. 
we take into consideration smart home office iot system the relate security and privacy challenge and an outlook on the possible solution towards a holistic security framework for these iot system. 
dismantle the confusion between the equivalent co2 and co2 concentration level. 
the paper present the result of the simultaneous determination carry out on the same gaseous medium on the one hand with a sensor measure co2 concentration and on the other with a digital gas sensor which base on intelligent algorithm process the measurement datum and offer they in equivalent co2 level. 
the purpose of the paper be to demonstrate through experimentation the erroneous idea to interchange the term due to confusion. 
experiment be perform use as reference a dedicated instrument for measure carbon dioxide base on infrared absorption principle testo 535 from testo. 
the digital gas sensor be the ultra low power digital gas sensor for monitor indoor air quality ccs811 from ams. 
smart street lights and mobile citizen apps for resilient communication in a digital city. 
while information and communication technology be crucial for the operation of urban infrastructure and the wellbeing of its inhabitant current technology be quite vulnerable to disruption of various kind. 
in future smart city a more resilient urban infrastructure be imperative to handle the increase number of hazardous situation. 
we present a novel resilient communication approach base on smart street light as part of the public infrastructure. 
it support people in their everyday life and adapt its functionality to the challenge of emergency situation. 
our approach rely on various environmental sensor and in situ processing for automatic situation assessment and a range of communication mechanism for maintain a communication network. 
furthermore resilience be not only achieve base on infrastructure deploy by a digital city s municipality but also base on integrate citizen through software that run on their mobile device. 
web base zero installation and platform agnostic app can switch to device to device communication to continue benefit people even during a disaster situation. 
our approach feature a covert channel for professional responder and a zero installation app be evaluate through a prototypical implementation base on a commercially available street light. 
leverage big data to identify corruption as an sdg goal 16 humanitarian technology. 
corruption be a serious impediment to global goal of ensure sustainable development and be now a threat specifically recognize in the un sustainable development goals under target 16.5. 
though corruption remains challenge to identify measure and combat technology advance provide new opportunity to advance humanitarian goal include the detection of corruption report by the public. 
in this study we address this challenge by develop a method use an unsupervised machine learn model to detect report of corruption relate activity on the micro blogging platform twitter. 
in total we collect over six million tweet contain keyword relate to corruption between january and february 2019. 
we use the biterm topic model to then isolate tweet from user who report corruption and find that most topic focus on police bribery and corruption in health care. 
though preliminary these result shave the potential of identify the scope and prevalence of corruption in society and also advance share goal of combat corruption and advance sustainable development in the 21st century. 
evaluate progress of a social venture in wakiso district uganda. 
monitoring and evaluation m&e of fund project be discuss. 
the goal be to determine an effective process with which ieee smart village isv can most easily collect the most valuable project datum. 
the presentation begin with an operational definition of sustainable community development scd. 
the dichotomy between economic sustainability and charity be point out. 
a general model of scd be discuss. 
social return on investment sroi be a number that be expect to reflect project efficacy. 
the process to determine sroi scrutinize a project under evaluation. 
the scrutiny uncover datum that become re hide in the single sroi number. 
the author of this paper take part in a sroi process apply to an ieee smart village fund non profit non governmental organization africa development promise adp. 
the focus be to inform the isv m&e process. 
some salient feature of the location wakiso district central region uganda be elucidated. 
some detail of the sub project that be under valuation be give. 
datum collect from the sroi process be use to determine what part of the sroi process be most relevant to m&e of the type of scd project that isv be monitor. 
an m&e process and its implementation be propose and discuss. 
data drive distribution tracking for stochastic non linear systems via pid design. 
this paper investigate the stochastic distribution tracking problem while the probability density function pdf of the stochastic non linear system output can be control to desire distribution. 
to achieve the control objective a data drive approach be propose in which no information of the system model be require. 
the output pdf can be estimate by kernel density estimation kde base on the collected system output datum. 
use the estimate pdf the probability state can be obtain by sample operation which can be use to re characterise the pdf of the system output. 
thus the tracking performance can be achieve by pid control. 
the parametric selection of the controller have be analyse follow the identify pdf dynamic model to assure the convergence of the system output. 
the effectiveness of the present algorithm be illustrate by a numerical example. 
motor current signal analysis base on machine learning for centrifugal pump fault diagnosis. 
centrifugal pump be widely use in various industrial process such as petrochemical production and power plant. 
it be important to develop an accurate and cost effective diagnosis approach for ensure effective condition monitoring method. 
in this paper the motor current signal have be investigate for the condition monitoring of the centrifugal pump. 
in specific a combined approach be propose base on intrinsic time scale decomposition itd for feature extraction and support vector machine svm for classify the health condition. 
the classification accuracy of svm be improve significantly when the itd method be apply to extract the diagnostic feature. 
the result have show that itd be efficient and effective for extract the most informative feature from the motor current signal. 
also this indicate that the propose diagnostic method base on itd with svm be more effective to classify the simulated fault of the centrifugal pump. 
sensor based cost modelling for a knowledge support system development. 
nowadays many small or medium size manufacturing company face significant challenge of quality cost and cycle time in their production life cycle. 
in order to deal with these challenge the utilization of knowledge management system in their facility become an appealing solution. 
however most their current knowledge management system be not flexible enough and adequate for handle high amount of production datum or calculate manufacturing cost of a product adaptively. 
therefore a novel knowledge support system framework for calculate unit product manufacturing cost through a generic cost model become necessary for small or medium size company smc to effectively optimise a manufacturing system in order to produce repair or remanufacture product with the high efficiency good quality performance and low cost. 
this paper present a generic cost model that consider production time base on sensor in a manufacture system. 
this mean the basic element of model would adapt cycle time variation which be one of the most important datum of the generic cost model that will be obtain from the sensor on the machine. 
an order insert predictive reactive batch splitting scheduling method. 
research on batch dynamic order insert scheduling have be study in scheduling field because it happen frequently in productive process. 
in this paper a batch splitting reschedule method base on genetic algorithm(ga with particle swarm optimization pso search which be also call pso search genetic algorithm psosga be put forward to decrease the delay due to an order insert in workshop batch scheduling. 
firstly we study a strategy to decide which batch should be split. 
secondly after take the minimum of the maximum completion time and the cost of the delay punishment as the optimal target the three layer gene chromosome be design include the production process the machine and the order splitting quantity and then the mathematic model for optimize the task sequence and distribute the order batch rationally be establish. 
thirdly base on particle swarm optimization method blend genetic algorithm the optimize solution of splitting order quantity can be acquire which can improve the evolutionary speed of the convergence and reduce the delay punishment and makespan. 
finally with the practical scheduling example the feasibility and validity of the algorithm be prove. 
a condition monitoring method of wind turbine base on long short term memory neural network. 
a reliable condition monitoring system can help improve the reliability of wind turbine and reduce cost. 
condition monitoring method base on supervisory control and data acquisition scada datum have be improve an effective method to achieve fault detection. 
with the development of machine learning technology high accuracy condition monitoring model can be establish by use historic datum. 
this paper propose a novel condition monitor method for wind turbine base on long short term memory lstm algorithm. 
in term of time series datum lstm model can construct the correlation between the prior know information and the current environment. 
the residual signal acquire by compare the predict datum in a prediction model and the actual measurement from scada datum can be use to achieve condition monitoring. 
the effectiveness of the propose method be validate in the case study. 
ant colony optimization algorithm for industrial robot programming in a digital twin. 
advanced manufacturing that be adaptable to constantly change product design often require dynamic change on the factory floor to enable manufacture. 
the integration of robotic manufacture with machine learning approach offer the possibility to enable such dynamic change on the factory floor. 
while ensure safety and the possibility of loss of component and waste of material be against their usage. 
furthermore development in design of virtual environment make it possible to perform simulation in a virtual environment to enable human in the loop production of part correctly the first time like never before. 
such powerful simulation and control software provide the mean to design a digital twin of manufacture environment in which trial be complete at almost at no cost. 
in this paper ant colony optimization be use to program an industrial robot to avoid obstacle and find its way to pick and place object during an assembly task in an environment contain obstacle that must be avoid. 
the optimization be complete in a digital twin environment first and movement transfer to the real robot after human inspection. 
it be show that the propose methodology can find the optimal solution in addition to avoid collision for an assembly task with minimum human intervention. 
design of an automatic lotus plumule removing machine. 
presently the traditional approach to remove plumule from lotus seed have several problem low work efficiency high labor intensity and safety issue. 
in this paper a novel plumule remove technology be propose with the mechanism analysis of plumule removal process design of the self adaptive plumule removal mechanism and control system development. 
firstly a plumule remove technique base on the fluid injection principle be present. 
the plumule be extrude and remove with a hollow needle by inject compressed air. 
then a self adaptive center method be implement to precisely center the position of plumule with regard to lotus seed of different size. 
the processing sequence be accomplish by the control system which be compose of a human machine interface hmi and a programmable logical controller plc aim to coordinate and control mechanical action in the process. 
finally the machine performance be experimentally evaluate by a number of test with the rate of successful separation be 73. 
the result demonstrate the design machine meet the requirement and thus effectively alleviate labor cost maximize processing efficiency while still preserve the economic value of the lotus seed. 
airborne acoustic signature analysis for fault diagnosis of reciprocate compressors use modulation signal bi spectrum. 
reciprocate compressor be the most important part of a petrochemical industry. 
in order to monitor the condition of this complex machine a remote fault diagnosis technique base on airborne acoustic signature analysis have be propose. 
however as there be many rotate and reciprocate component involve extract the characteristic feature from the non stationary and non linear acoustic signal result by those machine component be very difficult. 
the presence of structural or acoustic resonance may far contribute to the signal modulation which make the acoustic signal of the compressor very complex. 
in this paper the modulation signal bi spectrum method have be apply to the compressor sound signal with the capability of suppress random noise demodulate non modulation component and estimate modulation degree. 
it allow an in depth representation of the non linear effect of the modulation signal due to the repetitive valve impact airflow fluctuation resonance phenomenon and thereby provide a more accurate diagnose feature to identify the root cause of the fault. 
the experimental study examine various kind of reciprocate compressor rc fault include intercooler leakage discharge valve leakage and filter blockage. 
the analysis result show the effectiveness of the propose method in diagnosis of these fault base on the airborne acoustic signature analysis. 
an intelligent process fault diagnosis system integrating andrews plot pca and neural network. 
with industrial production process become more and more sophisticated traditional fault diagnosis system may not achieve reliable diagnosis performance. 
in order to improve fault diagnosis performance this paper propose an enhance fault diagnosis system by integrate neural network with andrews plot and principal component analysis pca. 
on line measurement be first process by andrews plot and then feed to a neural network directly or via pca for fault classification. 
application to a simulated cstr process indicate that the propose method can give more reliable and early diagnosis than the traditional neural network base fault diagnosis method. 
fault diagnosis for planetary gearbox use on rotor mems sensor and emd analysis. 
rotate machinery fault diagnosis base on micro electro mechanical systems mems technology have recently receive considerable attention. 
the significant advancement in mems make it easy and more conceivable to mount a low cost mems sensor directly on the rotate shaft allow more accurate dynamic characteristic of the rotor to be obtain for mechanical condition monitoring and fault diagnosis. 
however the measure signal contain strong background noise and modulation effect which result in low signal to noise ratio snr and consequently attenuate the accuracy of the diagnosis result. 
to improve the snr of the measure signal a denoise method base on empirical mode decomposition emd be develop in this paper to suppress the background noise and enhance the modulation component for accurate fault feature extraction. 
firstly emd be apply to decompose the original signal into a list of intrinsic mode function imfs and then the imf with the high correlation coefficient value be select for further analysis. 
finally the envelop analysis ea be employ to demodulate the denoise signal by emd for fault feature extraction and diagnosis. 
the experimental result show that the propose emd base denoise approach give a promising result in diagnose common pg fault. 
data drive evidential reasoning for interpretable machine learning and its application in fraud detection. 
in this presentation a transparent machine learning process be discuss which can help make decision by acquire evidence and evaluate the reliability of evidence from both experience and training datum. 
the evidential reasoning er rule be use to combine multiple piece of evidence gather for multiple feature variable. 
each piece of evidence be weight and combine conjunctively with the weight train for extended probabilistic inference. 
support by a multinational law firm and uk government the system be train by real world dataset on insurance claim and implement into the law firm s it system to help monitor and detect car insurance fraud for its client. 
result from the application be present which reveal that the propose method have high interpretability and outperform a number of widely use machine learning model. 
machine learning tools for engineering problems. 
the fast develop machine learning technique have be widely use as tool to solve many computer science and engineering problem. 
this workshop presentation be for our student who wish to start the journey of use the machine learn method in their research. 
i will use a hello world style case study as an example to explain how to develop an end to end machine learning system. 
i hope this topic can let you have an impression of the machine learn system pipeline and have a taste of how to develop a machine learning system from scratch. 
framework for trustworthy software development. 
intelligent software application be become ubiquitous and pervasive affect various aspect of our life and livelihood. 
at the same time the risk to which these system expose the organization and end user be grow dramatically. 
trustworthiness of software application be become a paramount necessity. 
trust be to be regard as a first class citizen in the total product life cycle and should be address across all stage of software development. 
trust can be look at from two facet one at an algorithmic level e.g. bias free discrimination aware explainable and interpretable technique and the other at a process level by make development process more transparent auditable and adhere to regulation and good practice. 
in this paper we address the latter and propose a blockchain enable governance framework for build trustworthy software. 
our framework support the recording monitoring and analysis of various activity throughout the application development life cycle thereby bring in transparency and auditability. 
it facilitate the specification of regulation and good practice and verifie for its adherence raise alert of non compliance and prescribe remedial measure. 
encoding adaptability of software engineering tools as algorithm configuration problem a case study. 
nowadays software be often highly configurable and the required adaptation be a complex and tedious task when perform manually. 
moreover hand craft configuration be often far from optimal. 
in this paper we study the software configuration problem in the context of the model comparison tool sidiff which need to be carefully adapt to domain specific modeling language use in model drive engineering. 
to tackle the configuration challenge we propose to draw from the field of automate algorithm configuration a research area which have study the optimization of parameterizable algorithm for many year and which have gain particular momentum through its application to hyper parameter tuning in machine learning. 
specifically we report on ongoing work encode the adaptability of sidiff as an algorithm configuration problem which be amenable to a sequential model base optimization tool know as smac. 
while empirical evaluation result be leave for future work the main goal of this paper be to foster active discussion at the workshop and to collect early feedback on our ongoing research. 
project achille a prototype tool for static method level vulnerability detection of java source code use a recurrent neural network. 
software have become an essential component of modern life but when software vulnerability threaten the security of user new way of analyze for software security must be explore. 
use the national institute of standards and technology s juliet java suite contain thousand of example of defective java method for a variety of vulnerability a prototype tool be develop implement an array of long short term memory recurrent neural networks to detect vulnerability within source code. 
the tool employ various datum preparation method to be independent of code style and to automate the process of extract method labeling datum and partition the dataset. 
the result be a prototype command line utility that generate an n dimensional vulnerability prediction vector. 
the experimental evaluation use 44,495 test case indicate that the tool can achieve an accuracy high than 90 for 24 out of 29 different type of cwe vulnerability. 
can ai close the design code abstraction gap. 
align the design of a system with its implementation improve product quality and simplifie product evolution. 
while developer be empower with ai ml augmented tool and technique that increasingly assist they in implementation task the abstraction gap between code and design limit automation for design task. 
in this position paper we argue that the software engineering community can take advantage of the experience build with ai ml technique to advance automation in design analysis. 
we summarize research challenge and describe two effort that apply machine learning to codebase to extract design construct and detect deviation from intend design and to use search base refactoring to make design improvement for extract functionality. 
optimize resource allocation for secure sdn base virtual network migration. 
recent evolution in cloud infrastructure allow service provider to tailor new service for demand customer. 
provide these service confront the infrastructure provider with cost and constraint consideration. 
in particular security constraint be a major concern for today s business as the leak of personal information would tarnish their reputation. 
recent work provide example on how an attacker may leverage the infrastructure s weakness to steal sensitive information from the user. 
specifically an attacker can leverage maintenance process inside the infrastructure to conduct an attack. 
in this paper we consider the migration of a virtual network as the maintenance process. 
then we determine the optimal monitoring resource allocation in this context with a markov decision process. 
this model take into account the impact of monitor the infrastructure the migration process and finally how the attacker may choose particular target in the infrastructure. 
we provide a working prototype implement in python(1. 
identify running data path in software defined networking driven data plane. 
in software defined networking sdn different application may configure different coexist forwarding rule the result running datum path a specific network flow traverse may not be the intend one. 
furthermore the sdn component may be defective or compromise. 
in order to provide reliable communication within the sdn drive datum plane assure that the run data path be the requested and expect one be necessary. 
in this paper we propose an approach that rely on distribute traffic generation and monitoring to identify the running datum path in a give sdn drive datum plane. 
we show that differently from the exist approach under certain assumption there exist necessary and sufficient condition for formally guarantee that all run datum path be discover use our approach. 
a data path discovery toolkit have be implement use the propose approach. 
we describe the corresponding set of tool and showcase the obtain experimental result that reveal inconsistency in well know sdn application. 
additionally we show the scalability of our approach. 
dynamic control of cpu cap allocations in stream processing and data flow platform. 
this paper focus on timely dataflow programming model for process stream of datum. 
we propose a technique to define cpu resource allocation i.e. cpu capping with the goal to improve response time latency in such type of application with different quality of service qos level as they be concurrently run in a share multi core computing system with unknown and volatile demand. 
the propose solution predict the expect performance of the underlying platform use an online approach base on queue theory and adjust the correction require in cpu allocation to achieve the most optimize performance. 
the experimental result confirm that measure performance of the propose model be highly accurate while it take into account the percentile on the qos metric. 
the theoretical model use for elastic allocation of cpu share in the target platform take advantage of design principal in model predictive control theory and dynamic programming to solve an optimization problem. 
while the prediction module in the propose algorithm try to predict the temporal change in the arrival rate of each datum flow the optimization module use a system model to estimate the interference among collocate application by continuously monitor the available cpu utilization in individual node along with the number of outstanding message in every intermediate buffer of all tdf application. 
the optimization module eventually perform a cost benefit analysis to mitigate the total amount of qos violation incident by assign the limited cpu share among collocated application. 
the proposed algorithm be robust i.e. its bad case output be guarantee for arbitrarily volatile incoming demand come from different datum stream and if the demand volatility be not large the output be optimal too. 
its implementation be do use the tdf framework in rust for distribute and share memory architecture. 
the experimental result show that the propose algorithm reduce the average and p99 latency of delay sensitive application by 21 and 31.8 respectively while can reduce the amount of qos violation incident by 98 on average. 
design of cricket automatic control system base on computer vision technology. 
this paper design a cricket control system base on computer vision technology. 
this system be control by pid algorithm. 
the acquisition system be openmv camera and the processing system be stm32 series mcu. 
the design be use to control the small ball to roll on the evenly distribute smooth square plate so that the ball can be remove on the square plate without any external force except for the self gravity the support force of the plate and the friction force. 
various specify requirement be fulfil between circular area of three cm in outer diameter. 
in this design the image datum be collect by the camera on the smooth flat panel range and the collect data be transmit to the stm32 core board through the serial port for processing and the center coordinate of the hard ball be find through the process datum and the coordinate be adjust accord to the set destination coordinate and the actual coordinate. 
pid proportional integral derivative control the steering gear to rotate a certain angle to control the hard ball to achieve the relevant operational requirement. 
research on data interpolation model with missing data for intelligent greenhouse control. 
as far as intelligent greenhouse be concern there be many parameter affect the system. 
in order to support decision making of crop growth environment regulation in intelligent greenhouse long term monitoring of temperature in greenhouse be need. 
however it be difficult to access the temperature network in greenhouse and there be often miss value. 
currently the posterior distribution be generally base on datum and the miss value be usually depend on the estimate accord to the posterior distribution of the datum. 
it be difficult to guarantee the accuracy of this method after test. 
in this paper a new data interpolation model of intelligent greenhouse control model base on fuzzy technology and neural network be propose in order to enhance the comparability of the same period datum in different year the model deal measure with the datum use fuzzy technology processing synchronization datum and processing result be input into the neural network as auxiliary attribute. 
in the process of interpolation this method change the traditional way of use only the datum of the same period to predict the datum of the later period and achieve good result. 
construction of jewelry design evaluation system and eva analysis under the background of big data. 
jewelry usually refer to precious ornament wear by people such as necklace earring and ring. 
jewelry not only can make up for the lack of clothing but also can play the role of embellishment emphasis and finish touch. 
from the perspective of design creativity the rich styling of jewellery reflect the artistic style and characteristic of the era reflect every major trend of design art and its constituent material and technique reflect the level of science and technology in the era this paper use the analytic hierarchy process to analyze the first level indicator and the second level indicator of jewelry design. 
the first level indicator be design concept design material and jewelry element. 
the correspond secondary indicator be traditional culture western thought emotional thinking and jewelry. 
material jade material gold and silver material design talent innovative idea design inspiration. 
accord to the construct judgment matrix and assignment the consistency test be carry out and finally the most significant factor for jewelry design be clearly define which have positive promotion significance for the development of jewelry design. 
development of amt calibration system base on can bus and ccp protocol. 
this paper complete a set of monitoring and calibration system base on can controller area network bus and ccp(can calibration protocol protocol and introduce the system hardware structure software structure function communication protocol the communication process of the host computer(personal computer and the slave computer(ecu electronic control unit. 
practical research on measuring method of high precision parts in nc turning. 
measurement of high precision parts by n c turning measurement by comparison of old and new measure instrument a new measuring method use new measuring tool be propose. 
experiment show that the new digital display measure instrument have high measurement accuracy. 
it be very i m orta not to study the measurement method of high precision part in nc turning. 
cross layer multi cloud real time application qos monitoring and benchmarking as a service framework. 
cloud computing provide on demand access to affordable hardware e.g. multi core cpu gpu disk and networking equipment and software e.g. database application server and datum processing framework platform with feature such as elasticity pay per use low upfront investment and low time to market. 
this have lead to the proliferation of business critical application that leverage various cloud platform. 
such application host on single multiple cloud provider platform have diverse characteristic require extensive monitoring and benchmarke mechanism to ensure run time quality of service qos e.g. latency and throughput. 
this paper propose develop and validate clambs cross layer multi cloud application monitoring and benchmarking as a service for efficient qos monitoring and benchmarking of cloud application host on multi clouds environment. 
the major highlight of clambs be its capability of monitor and benchmarke individual application component such as database and web server distribute across cloud layer aas spread among multiple cloud provider. 
we validate clambs use prototype implementation and extensive experimentation and show that clambs efficiently monitor and benchmark application component on multi cloud platform include amazon ec2 and microsoft azure. 
fault tolerant synchronization control for markovian switching complex dynamical networks with stochastic perturbations and nonlinearly time vary delay interaction. 
in this study the fault tolerant exponential synchronization control be research for the multi manipulator system which be characterize by the large number of interconnect manipulator the stochastic perturbation and the nonlinearly time vary delay interaction. 
after abstract the correspond mathematical complex dynamical network model from the system an effective controller be design with some definition assumption and lemma. 
particularly base on the linear matrix inequality lmis ito s formula and the lyapunov stability theory the control network model be prove to be stochastically synchronous under the actuator failure by construct a switch stochastic lyapunov krasovskii functional and some sufficient condition for the mean square exponential synchronization be derive. 
a numerical example be illustrate for the further verification and conclusion. 
c 2019 the authors. 
publish by elsevier b.v.. 
sequence planning consider human fatigue for human robot collaboration in disassembly. 
disassembly which play an essential role in remanufacturing be the first step to extend the service life of end of life eol product. 
traditional disassembly be always accomplish by either human or robot. 
manual disassembly be a time consume process and the high labour intensity will also pose a threat to human health while robotic disassembly be difficult to flexibly handle complex part. 
continuous manual work lead to the accumulation of fatigue which decrease the efficiency of manual work. 
in this paper sequence planning consider human fatigue for human robot collaboration in disassembly hrcd be propose. 
this method involve assign disassembly task to human and robot accord to their respective characteristic model for hrcd consider human fatigue be establish. 
in the case of disassemble batch product with the same type discrete bees algorithm be use to obtain the optimal disassembly sequence to minimize the total disassembly time. 
case study base on gear pump show that the propose algorithm outperform the other two optimization algorithm in solution quality. 
c 2019 the authors. 
publish by elsevier b.v.. 
robotic task orient knowledge graph for human robot collaboration in disassembly. 
traditional disassembly method such as manual and robotic disassembly be no long competent for the requirement of the complexity of the disassembly product. 
therefore the human robot collaboration concept can be introduce to realize a novel disassembly system towards increase the flexibility and adaptability of they. 
in order to facilitate the efficient and smooth human robot collaboration in disassembly it be necessary to make the disassembly system more intelligent. 
in this paper a robotic knowledge graph be propose to provide an assistant for those who lack the relevant knowledge to complete the disassembly task. 
by natural language processing method this paper extract entity and relationship from the disassembly datum to build a knowledge base in the form of knowledge graph. 
combine graph base knowledge representation a prototype system be develop for human to acquire analyze and manage the disassembly knowledge. 
finally a case study demonstrate that the propose robotic knowledge graph have saving in term of disassembly time idle time and human workload and it can be apply to assist human operator in disassembly by provide human and robot with various kind of the need knowledge. 
c 2019 the authors. 
publish by elsevier b.v.. 
home health care routing problem via off line learning and neural network. 
as the age problem of china worsen a new industry name home care be rise aim to handle the ever grow demand of elderly care that nursing home could no long handle. 
in the meantime smart and autonomous decision making be face a new explosion recently due to the rise of machine learning. 
therefore this paper tend to build an algorithm that could autonomously allocate demand to worker in home care scenario follow complex constraint base on off line learning with a neural network approximator replace the action value function. 
experimental result on several large scale instance show that the fully connected network can precisely predict the action value base on full information of the environment enable the agent to make decision that outperform the baseline model and algorithm. 
in addition managerial insight be draw accord to the result give by the neural network base agent. 
conclusion and future research direction be discuss as well. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
application review of lca life cycle assessment in circular economy from the perspective of pss product service system. 
at present the enormous environmental pressure cause by the manufacturing industry have promote the development of the recycling industry. 
the recycling industry be pivotal for sustainable utilization of regional resource pollution reduction and environmental protection. 
lca life cycle assessment as a comprehensive analytical tool play an important role in the analysis of the cyclical industry from different level include regional level industry level enterprise level and product service level. 
the product service system a new production system with high integration and overall optimization of product and service be conducive to obtain complete product service information and management. 
the lca base product service system in the field of circular economy be not only crucial in the life cycle management of the product service for the enterprise but also contribute to the comprehensive assessment of the environmental benefit of the recycling enterprise. 
this paper summarize and systematic review the application of the lca and pss product service system integration in circular economy from a micro perspective. 
base on that the study identify the challenge for current research and propose future research direction to promote the development of lca in circular economy from the perspective of enterprise. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
optimal design of the variable sampling interval np control chart for monitor service process. 
as customer satisfaction be a key success factor for a service system the main purpose of this paper be to design a control chart for monitor the service process. 
the variable sampling interval vsi control chart be useful and have important application in service industry which sample at a high rate when there be evidence of a change in the process and be thus able to detect process change fast than the traditional fixed sampling interval fsi control chart. 
this paper evaluate and compare the performance of the vsi np control chart with the average time to signal ats property when the process parameter be know and estimate the result demonstrate that these performance of the vsi np chart be quite different when the number of sample use during phase i be small. 
then we suggest new dedicated chart parameter for the vsi np chart with estimate parameter to have approximately the same in control ats value as in the know parameter case. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
application of an improved spider monkey optimization algorithm for component assignment problem in pcb assembly. 
this paper present a new optimization method for print circuit board assembly pcba process base on improved spider monkey optimization smo algorithm and a production model for pcba be create. 
the propose method prove to be suitable for product service system(pss. 
pcba process mainly consist of three part. 
first be the assignment of pcb second be the assignment of machine the last be the component assignment problem. 
in this research the smo algorithm be apply on optimization of component assignment which be divide into two stage local leader phase llp and global leader phase glp. 
in the first stage the electronic component be assign to the feeder by glp. 
in the second stage the component placement sequence which be apparently know as a travel salesman problem tsp be determine by llp. 
numerical experiment be perform to compare the performance of smo algorithm with other under various experimental setting the result show that the propose method be more effective than other traditional method. 
a production model be create with the propose method which be calime to be able to increase the efficiency of the product service. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
deep learning base human motion prediction consider context awareness for human robot collaboration in manufacturing. 
the interest of human robot collaboration hrc for intelligent manufacturing service system be gradually increase. 
fluent human robot coexistence in manufacturing require accurate estimation of the human motion intention so that the efficiency and safety of hrc can be guarantee. 
human motion be mainly define as the sequential position of the joint of human skeleton among traditional motion prediction solution which lead to a deficiency of tool or product component hold in hand. 
context awareness base temporal processing be the key to evaluate human motion before the accomplishment of it so as to save time as well as recognize the intention of the human. 
in this paper a deep learning system comb convolutional neural network cnn and long short term memory network lstm towards vision signal be explore to predict human motion accurately. 
creatively this paper utilize lstm to extract temporal pattern of human motion automatically output the prediction result before motion take place. 
not only do it avoid complex feature extraction due to its end to end characteristic but provide a natural interaction between human and robot without wearable device or tag that may become a burden for the former. 
a case study of desktop computer product disassembly be execute to demonstrate the feasibility of the recommend method. 
experimental performance prove that our method outperform the other three optimization algorithm on the prediction accuracy. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
information requirement for a data base analysis of product and service complexity. 
analysis of datum be currently be discuss in research and practice across a wide range of area but mainly with focus on production. 
improved datum availability be not only a relevant factor in production but also in other area such as management of product as well as service complexity. 
a major challenge in this area be the trade off between standardization and customer specific solution. 
however the variety of product and service lead to an increase complexity and therefore increase cost. 
transformation from a supplier to a buyer market shorten product life cycle rise speed of innovation and differentiation of customer need have lead to an increase product and service variety. 
as a result offer product and service be grow in both width through diversification and depth through variation due to a pursue differentiation strategy. 
hence company must respond to increase product and service complexity with an appropriate variant and complexity management. 
in the first step this require transparency about product  and service induce complexity. 
this paper introduce a methodology for a systematic identification of complexity relevant information requirement as well as correspond datum input. 
these information requirement form the basis for the design of a data model and provide input for analysis as well as visualization of complexity. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
framework for define information quality base on data attribute within the digital shadow use lda. 
the amount of datum which be create in company be increase due to modern communication technology and decrease cost for store datum. 
this lead to an advancement of method for data analysis as well as to an increase awareness of benefit result from data base knowledge. 
in the context of product service system and product development there be two major concept for provide product information. 
the digital twin collect every information possible while the digital shadow provide a sufficient and content relate picture of the product. 
since these concept merge datum from different source comprehension about information quality and its relation to the datum quality become immanently important. 
this paper introduce a framework to determine information quality with respect to data relate and system relate attribute. 
an extensive literature review with focus on information quality and datum quality identify the important approach for describe information and datum quality. 
a latent dirichlet allocation lda algorithm be apply on 371 definition and identify 12 data relate and system relate attribute for information quality. 
those attribute be assign to six dimension for information quality. 
so the propose framework depict the relationship between datum attribute and the influence on information quality. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
smart service canvas a tool for analyze and design smart product service system. 
service that be deliver through so call smart product be increasingly popular under the term smart service. 
while customer benefit from smart service through the intelligent maintenance of equipment that avoid unwanted and expensive downtime it enable manufacture firm to collect and analyze extensive datum on the actual use of machinery and equipment help they to offer solution tailor to customer need. 
method for the design of the correspond smart product service system pss however have not yet be adopt widely in practice emphasize to the need for lightweight tool that be ready to use. 
this article introduce the smart service canvas as such an instrument to analyze and design smart pss concept. 
we demonstrate the canvas in workshop setting with various participant. 
we find that the canvas stimulate multi perspective discussion during service design and that it be helpful in provide a quick overview of a smart pss. 
c 2019 the authors. 
publish by elsevier b.v.. 
quality control in production process of product service system a method based on turtle diagram and evaluation model. 
to address the quality control problem of product service system pss include job shop manufacturing and customization of order disability and default of process quality control we build a model of process quality control system use improved turtle diagram and evaluation method base on vda for more achievement of sustainability through pss. 
we show that the model of process quality control be effective and practical for continuous improvement in pss quality management and sustainable development of enterprise. 
this study provide further supplement for exist theory of enterprise quality management and product service system. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
how the imperfect e diagnostic impact the capacity planning and pricing decision of a maintenance service provider. 
provide online monitoring e diagnostic have become a value add practice for equipment maintenance service provider to improve the service quality and efficiency. 
however the e diagnostic be always imperfect whose accuracy depend on how much component of the equipment be monitor namely e diagnostic depth in our research. 
this research analyze the optimal capacity planning and pricing problem by take into account the imperfect e diagnostic. 
in addition we consider the e diagnostic accelerate effect to the service process and attempt to find how the effect influence the service provider s decision. 
our result reveal that the optimal pricing and capacity planning decision be dependent on customer failure cost and service provider s compensation cost. 
specifically if customer failure cost be large than service provider s compensation the service provider would improve the price as the e diagnostic depth increase otherwise the price should be lower as the e diagnostic depth increase. 
in addition we find as the accelerate effect become increasingly obvious customer expect wait time increase but the service price decrease. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
a survey of intelligent algorithm for open shop scheduling problem. 
in the open shop scheduling problem two processing order name operation within job and operation on machine need to be decide. 
when the problem size become large the exist exact method can hardly solve it. 
therefore intelligent algorithm be introduce to solve the problem. 
the aim of this study be to find out effective intelligent algorithm which can be use in the open shop scheduling problem. 
four intelligent algorithm namely genetic algorithm particle swarm optimization cuckoo search algorithm and ant colony optimization have be propose and modify for this specific problem and two experiment have be carry out to compare the effectiveness of these algorithm. 
the result show that these intelligent algorithm have an acceptable performance and can be use for large scale problem which can not be solve by the exact method. 
among these algorithm cuckoo search algorithm be the good one and can solve problem effectively due to the levy flight and other feature. 
further research be still require to far improve the performance of these algorithm. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
the evolutionary research of modular master structure oriented to product service systems. 
nowadays the ever increase and variable personalized requirement make the speed of product evolution accelerate constantly. 
meanwhile the direction of product evolution be more and more extensive. 
so it be particularly important to predict the direction of product evolution and control the process of product evolution. 
for this reason most factory begin to implement the modular product platform strategy and establish product service system pss base on the modular master structure mms of product. 
the mms contain almost all the information of product and module and the completeness of mms relate to the quality of pss. 
so the research of mms evolution be important. 
therefore a three dimension evolutionary modeling framework of mms be propose which point out the evolution of mms in the whole life cycle dimension time dimension and product configuration dimension. 
the evolution behavior of mms have be illustrate from evolution prediction to the generation of stage master structure. 
so the individualized product be configure. 
it be significative for the determination of the research direction of product evolution. 
it lay a foundation for the subsequent research on the evolution control method of mms in the three dimension. 
and it be significative for the management and application of enterprise resource. 
finally the application of evolution control orient to the pss be describe so that the pss for staff and customer can be construct. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
base type selection of product service system base on convolutional neural network. 
customer preference for product reflect the product and service requirement of the product service system pss. 
pick out and associate the proper product unit and service unit be the key point of configure a product service system to meet the requirement of individual customer some intelligent algorithm be use in product selection as well as in the design of product and service. 
however exist selection method be difficult to convert customer requirement into base type of pss in highly complex mapping space. 
in order to realize the rational allocation of product service system and provide crucial information for company staff in product design department we use convolutional neural network to study the nexus of customer demand attribute and product service system base type in this paper through train the convolutional neural network to obtain the complex nonlinear mapping relation between customer demand attribute and product service system base type and product service can be select. 
the propose method have be verify in the base type selection of cnc machine tool product service system. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
gas turbine exhaust system health management base on recurrent neural network. 
predictive maintenance of gas turbine exhaust system play an important role in reduce the risk of failure and improve the safety of gas turbine operation. 
this paper propose an effective method base on the recurrent neural network rnns and statistical process control chart to predict the condition of the gas turbine exhaust system. 
firstly the fuel flow and air flow of the input gas chamber be use to predict exhaust gas temperature by an rnn model. 
secondly an xbar s statistical process control chart be construct via compare the current exhaust gas temperature predict by rnn with that measure by sensor. 
then the chart can be use to monitor whether there be failure in gas turbine exhaust system and temperature sensor. 
this be the first time that recurrent neural network be use to address the health management of gas turbine exhaust system. 
and the sensor faiilure be also take into consideration. 
finally the propose approach be evaluate in the numerical experiment. 
c 2019 the authors. 
publish by elsevi b.v. 
peer review under responsibility of the scientific committee of the 11th cirp conference on industrial product service systems. 
association rule mine in r for product performance management in industry 4.0. 
industry 4.0 optimize the digitalization of automation and datum exchange in manufacturing and service innovation. 
the evolution of technology in today s manufacturing system need advanced prediction approach to inform operation decision optimize product and service performance and meet customer need. 
association rule mining have be widely use across business intelligent application and smart manufacturing system for decision making. 
however there be few study on predictive manufacturing system for product performance management in industry 4.0. 
this paper propose association rule mine in r for provide the predictive analytic to improve product quality with production stability and efficiency thereby enhance product service satisfaction. 
in this paper one of the useful and efficient algorithm of association rule mining name as apriori algorithm be introduce the r package arule be construct and a case study be conduct to illustrate the feasibility of the propose method be demonstrate. 
c 2019 the authors. 
publish by elsevier b.v.. 
research on design method of intelligent service system in product processing under pss concept. 
accord to the concept of product service system pss this paper analyze the relationship between product and service and integrate the service into the product aim at the shortcoming of the traditional service system in the process of processing product such as the lack of intelligence. 
it analyze the relationship between the product and the service. 
by integrate service element to set up product service system and combine artificial intelligence technology the matching model of product and service be construct and the framework of intelligent service system in the process of product processing be design. 
the intelligent service system framework can effectively solve the problem of product utilization and adaptability realize the matching of product and service requirement and function realize remote monitoring therby extend the product and service function and optimize the system performance. 
this paper solve the problem of product utilization rate and adaptability and make the good product performance. 
it expand the product and service function and optimize system performance to optimize product performance provide user with an intelligent service system that integrate product and service that meet individual need. 
the research have a certain practical significance and theoretical value and provide a guide method for design intelligent service system in the process of product processing under the concept of pss. 
c 2019 the authors. 
publish by elsevier b.v.. 
graphical deduction model based production instruction service system for smart job shops in industry 4.0. 
the arrival of the industry 4.0 era have make the intelligentization and informationization of manufacturing become the mainstream trend. 
the workshop production control system need to be more intelligent to meet the need of real time control and dynamic coordination. 
this paper propose a production instruction service system base on graphical deduction model construct the structural framework of production instruction service system establish a graphical deduction model of smart job shop production process and briefly describe the key enable technology for realize production instruction service system. 
c 2019 the authors. 
publish by elsevier b.v.. 
an efficient signal processing technique for automated myocardial infarction detection. 
electrocardiography(ecg be a non invasive diagnostic tool for diagnose cardiovascular disease such as coronary artery disease. 
ecg be a recording of electrical activity of heart lie in mv range so the process of manual detection of heart disease be challenge consume time and liable to human error. 
thus an automatic detection of myocardial infarction(mi be do by use single lead(v3 with variable length beat for you all eleven class of mi. 
in this paper the discrete wavelet transform(dwt coefficient s be compute for each heartbeat and after that principal component analysis(pca technique be deploy for minimize the number of coefficient. 
dwt coefficient s along with pca be deploy for optimum feature extraction further support vector machine(svm with radial basis function(rbf kernel be utilize for classification of 11 type of mi and healthy control. 
the experiment be carry out in matlab use ptb ecg diagnostic database. 
the propose method give good accuracy as compare with exist work of 99.02 for classify 12 class. 
set up of the standard 2d dic system for quantification of residual stress. 
the paper deal with the set up of the standard single camera digital image correlation dic system for the quantification of residual stress. 
to find proper parameter of the camera some measurement be perform include found for a convenient distance of the camera from analyzed speciman create of speckle pattern with adequate speckle size and density analysis of the calibration parameter influence on the measurement result obtain by camera calibration perform by calibration target of various size. 
moreover the investigation of optimal correlation parameter use for evaluation of strain be present in the paper. 
finally the paper include information about the result obtain by simulate the change of position between the hole drilling device and the camera during the incremental drilling process. 
advanced material model for numerical simulation of fine blanking. 
advanced manufacturing process include fine blanking be widely use in the mass production of sheet metal part. 
in the present article numerical modelling and a real world test of fine blanking be discuss with a focus on material characterization. 
the material be 1.4301 stainless steel and its model be construct use measure mechanical property. 
tensile test plane strain test and shear test be carry out to determine steel characteristic under various stress state. 
all the test be perform at room temperature and under quasi static condition. 
local strain be determine use the aramis digital image correlation dic system from gom company. 
after testing metallographic analysis of the specimen be conduct for characterize their fracture surface. 
by correlate the datum from the dic system result of numerical modelling and metallographic examination the instant of failure initiation in a speciman can be determine. 
when a ductile failure model be calibrate against test under various stress state and use for modelling of blanking it improve the description and the accuracy of the computational model of the process. 
the choice of the failure model have a substantial impact on the calculated magnitude of fine blanking force. 
to validate the material model choose an additional fine blanking test and metallographic examination be perform in order to assess the creation and shape of the sheared edge. 
a material model develop and validate by this procedure become useful in the design and optimization of real world blanking process. 
use modal parameter base analysis of the behaviour of alkali activate material with surface degrade by ultraviolet radiation. 
monitor the behaviour of construction building structure and material cause by degradation process be the main purpose of non destructive testing method. 
most building material be expose to the action of environment. 
as some part of building structure come into contact with external effect such as sunshine they may be alter by ultraviolet radiation. 
for building material monitor their structure degradation be a much more difficult task than for metal structure mostly due the non homogeneity. 
since for homogeneous structure impulse acoustic method can be use to advantage particularly because the monitoring they enable be non destructive they be use in this case too. 
to monitor the degradation cause by ultraviolet radiation the impact echo method be employ. 
experimental and fem modelling for optimization of lightweight steel structure support by fatigue test of modern high strength structural steel. 
structural optimization have become very popular thank to modern and powerful software tool. 
nowadays a lot of various software for mechanical design and fem analysis be available. 
use those software tool some very nice lightweight structure can be design in fact but in real practice there can be see unexpected fatigue failure of those structure very often. 
this paper show that optimization of modern lightweight structure use modern software tool can be do relatively easy but it also show that optimization of lightweight structure which undergo cyclic loading should be in direct connection with fatigue testing of use material. 
in this study the optimization process of real lightweight structure frame of the semitrailer be support by experimental determination of fatigue endurance mechanical property microstructural and fractography analysis of use steel. 
connection of structural optimization and detailed material research result in successful and safety design of new lightweight frame of the semitrailer. 
mechanical property of cement paste with fine old concrete influence of different type of approach mix. 
the article focus on the impact of different type of approach mix on result mechanical property of cement composite. 
we investigate of influence speed of mixing of fresh mixture and process of mix the individual component of the cement composite. 
the mechanical property be investigate by use non destructive resonance method and destructive method on sample with dimension equal to 40 x 40 x 160 mm. 
among the monitor mechanical parameter be dynamic modulus of elasticity dynamic shear modulus flexural strength and compressive strength. 
measurement of residual stress in the hole of railway axle. 
value of the residual stress be very important for fatigue life of machinery component. 
it be likely to be the same for the railway wheelset. 
in the most of the case the pressure value of stress be require in proximity of the surface the standart en 13 261 for railway axle allow the maximum value of stress +100mpa in the distance of 0,1 mm under the surface. 
in many case the hollow railway axle be use with the advantage of design motor axle. 
the determination of residual stress be not feasible with the regard to usual diameter of the hole from o30 mm to o110 mm. 
this thesis be focus on the possibility to determin of the value of the residual stress in the bore of railway axle by hole drilling method. 
the measuring be do with the use of hole drilling device restan 3000. 
measure value of residual stress in close proximity of the bore of axle be compare with the measurement of x ray method. 
optimization of cement composite composition with milled recycle concrete and admixture of slag and lime hydrate. 
sustainable development and construction be a very topical topic. 
this be relate to waste management where construction waste be a significant part and waste concrete be one of the most voluminous component. 
it turn out that after the necessary modification such as mill waste concrete can be return back into the building process not only in the form of aggregate but also as part of the binder. 
this paper deal with optimization of the composition of cement composite use recycled ground concrete lime hydrate and other waste material slag. 
select parameter such as workability modulus of elasticity and strength be monitor. 
comparison study between two type of nozzle for a turbocharger balancing machine use ansys software. 
turbocharger balancing machine require a specific tooling for spin the center housing rotating assembly in order to balance it dynamically. 
the tooling require a nozzle to guide the air to the blade of the turbine wheel in order to spin it. 
depend on the type of nozzle choose the maximum rotational speed achieve and the acceleration curve can be different. 
in today s market there be an increase demand for a high turbocharger speed generally drive by the demand for engine downsize and for a high performance. 
due to that turbocharger need to be well balanced thus require a wide measurement range of the unbalanced in order to see how the part perform in all its work range. 
consequently the nozzle use by turbocharger balancing machine need to be verify at a high speed limit. 
design of shape and dimension of exchangeable jaw for pneumatic chuck of cnc lathe emco concept turn 105. 
the emco concept turn 105 cnc lathe be part of the icim 3000 production system. 
currently only a narrow range of product be process which be cause by the small clamp range of the three jaw pneumatic chuck marked kfd 85/3. 
base on the requirement to expand or change the range of manufacture component new interchangeable jaw will be design to clamp more diameter despite a small clamp range. 
the design of the replaceable jaw for the pneumatic chuck be base on the determination of the shape and dimension of the component produce on the lathe as well as on the shape dimension and characteristic of the pneumatic chuck. 
study on mill strategy influence on the quality characteristic in case of composite material. 
composite material be widely use today. 
in this paper we want to conduct a research on the strategy of mill processing of composite material. 
a cad model be require to perform this research. 
this 3d model must have different area where the difference between the climb strategy and the conventional strategy can be observe. 
special tool and cut parameter correspond to the material to be machine be require for this 3d model. 
influence of coolant pressure size on surface roughness when stainless steel machining. 
the paper be focus on the influence of the coolant pressure on the surface roughness of the workpiece when machine stainless steel. 
the component be machine on a star sr 32j dual spindle machining center and an external cool unit hytek chav 160/150 af f ol be use for cool. 
two stainless steel component be investigate namely the gas control valve rod and the high pressure control valve housing which require low roughness ra after machine less than 0.375 and 0.25 micrometer respectively. 
the first component be test at eight different pressure in the range of 150 bar 10 bar and the second component at four different pressure in the range of 120 bar 10 bar. 
the roughness parameter be measure by the contact method use the mitutoyo surftest sj 410 roughness tester and the alicona infinitefocus optical microscope. 
base on these sample input parameter it be evaluate how much the pressure affect the surface quality or suggest its reduction due to the high cost of operation of the external high pressure equipment. 
method and program for the interpolation of experimental result of determine the mechanical property of mineral composite for modern machine tool. 
the paper present a method of interpolate bifactorial experimental datum with the aim of extend the result over the entire domain define by the independent variable. 
this approach can be use in determine the optimum mineral cast mix for a give application. 
mechanical property such as stiffness ultimate tensile strength yield strength and poisson s coefficient can be improve. 
the paper describe the implementation of a radial basis function rbf algorithm in a matlab program for the interpolation of datum plot of the result and the identification of the maximum dependent variable and the independent variable that correspond to it. 
it also provide the source code for the program along with explanation regard its use. 
rbf interpolation can be use successfully in response surface methodology to generate approximation of the study variable base on the experimental result. 
the program can be extend to work on any number of input and output variable. 
effect of thermal degradation on rheological property of polymeric material. 
the aim of this paper be to monitor the melt volume index of thermoplastic material and other rheological property such as shear rate and viscosity. 
the aim be to compare and assess whether several time ground and subsequently re melt sample of pure polymer granulate will have the same or similar rheology property and whether adjustment of the injection molding machine will be require or will need to reduce or increase production time. 
thermo scientific with haake meltflow mt software be use to determine the melt flow rate index mvr of thermoplastic material. 
base on the melt flow rate mvr shear rate and viscosity evaluation it have be find that although the select material have undergo multiple change in the rheology of the polymeric material there be no problem in the molding process and mvr do not change significantly. 
in this case no change in the setting of the injection molding machine and reduction or increase in production time will be necessary. 
when re melt the granulate sample no excess waste be generate which would then need to be dispose of and the sample could be re use for further measurement after grind. 
optimization and efficiency of toolpath generation in cad cam system. 
the optimization have an important role in machine process preparation of nc program. 
the article deal with the possibility of the optimization use at utilization of the nc tool path in cad cam system. 
the experiment deal with the possibility of optimization option in concrete cad cam system. 
particularly be compare optimize toolpath from cad cam system creo with toolpath optimize in an optimization program optimizer base on genetic algorithm. 
use of neural networks in tool wear prediction. 
modern cnc machine tool include a number of sensor that collect machine status datum. 
these datum be use to control the production process and for control of the cnc machine status. 
no less important part of the production process be also a machine tool. 
the condition of the cut tool be important for the production quality and its failure can cause serious problem. 
monitor the condition of the cut tool be complicated due to its dimension and working condition. 
the article describe how the tool wear can be predict from the measure value of vibration and pressure by use neural network. 
study and performance improvement of the drive systems for a class of machine tools. 
this paper deal with some problem in the modernization of a type of machine tool with multi coordinate drive system. 
the basic requirement to the drive of each coordinate axis and the spindle be present. 
use the analysis carry out a practical approach to appropriate selection of the respective drive be apply. 
the methodology offer be illustrate with some example for choice of drive with direct current and alternate current motor. 
some experimental research of case with different feed and spindle drive be describe and discuss. 
well capability of the modernized machine for process more complex workpiece be achieve at a relatively low price. 
this research and the obtain result can be use in the design and tuning of electric drive for the considered type of machine with numerical program control. 
optimisation of production process with the use of the modelling and simulation method. 
the paper present an application of the modelling and simulation method for find an optimum solution relate to design production process. 
use simulation in connection with optimization make it possible to check almost all admissible variant of the propose improvement comparatively quickly in order to evaluate they and to choose the good solution. 
the paper present how a simulation model be create and show an example of multi criteria optimization. 
application of industrial robot in five axis milling process. 
present in machining create constantly new requirement to increase economic efficiency productivity and product quality. 
with this advancement industry be no long focus only on commonly use machining technology but be pay increase attention to the implementation of robot in the manufacturing process by machine. 
the paper describe the design of equipment for the implementation of five axis mill with the help of a robot arm abb irb 140. 
it describe the design of the mill head and deal with the creation of nc machining program in software autodesk fusion 360. 
the generate nc program be then use in robodk to create a robotic arm control program. 
at the end of the paper be describe laboratory test of machining use the design prototype mill head. 
study on chip fragmentation and hole quality in drilling of aluminium 6061 alloy with high pressure internal cooling. 
the drilling process be one of the most common process on many manufacturing area. 
it be use for high quality hole drilling of aluminium 6061 alloy. 
in this experimental study precise hole be drill use drill with high pressure internal cooling 50 bar. 
the influence of the process parameter on hole quality be analyse. 
another aspect study be chip shape and evacuation. 
the effect of vibro finish treatment on the porosity of the surface layer of powder metallurgy products. 
the article be devoted to the method of surface plastic deformation treatment to change the porosity of part obtain from powder material. 
functional dependence between the concentration of the solid part of the system and the size of the plastic print on the example of vibro finish and harden treatment vf and ht be establish. 
the reduction in porosity upon hardening of the surface material be experimentally confirm. 
the result can be use to predict the surface porosity of powder metallurgy product that have undergo additional processing of spd as well as for further study of the field of application of vf and ht. 
base on the particle interaction in the work medium with the part surface make from powder material we obtain functional dependence of the density coefficient of the surface layer of the powder material after vf and ht. 
experimental study be carry out on sample of powdered iron pk6. 
the porosity of the sample be determine by stereoscopic metallography microhardness of the surface layer on hardness tester. 
everything be perform by standard method. 
the result be present in a series of porosity chart. 
maximum hardening be 30 of almost twofold porosity reduction. 
the expert in the field of powder metallurgy may be interested in the obtain result. 
theoretical probability model of metal removal during magnetic abrasive treatment. 
the work be devoted to the issue of calculate material removal during magnetic abrasive processing. 
cut grain have random dimensional characteristic be randomly locate on the surface of the tool the workpiece have an irregular profile. 
the cut part of the grain top partially remove the chip and partially elastically plastic deform the metal. 
part of the vertex fall into the risk on the surface of the workpiece form by the previous machining and part into the risk from pass through the previous vertex. 
this process be determine by the probability of the contact of the top of the grain with the metal. 
the develop stochastic model make it possible to predict the removal of metal from the treat surface depend on the time and parameter of the operation which create the prerequisite for their use in the design of polish operation. 
crm systems management of metallurgical companies in kazakhstan base on the tri m system methodology. 
the article present material on the practical implementation of crm program in metallurgical organization and the experience of its usage. 
in the result of the study an attempt be make to generalize the configuration of the crm approach to relationship and program account as well as typical impression of the entire crm implementation process use as integrate platform for the stakeholder in the form of tri m system an analytical tool. 
the step feed mechanisms for auger machines. 
the paper present the result of study of technical solution propose in kuzbass state technical university and implement in auger drilling equipment characterize by the presence of a cyclic feed of a boring machine on the face and the correspond reverse of the work by hydraulic jack. 
operation of complex which design feature be to provide a common plane for the axis of the boring hole and vector of axial force of the auger feeding mechanism be research. 
the stress state of the cyclic step feed mechanism s functional element by mathematical and software mean of the finite element analysis be consider. 
the threshold value of the feed force be determine from the point of view of ensure the safety margin of weld joint use in the cyclic step feed mechanism s structure and from the point of operational reliability of the system as a whole. 
the obtain datum allow make recommendation for further improvement for the subsystem of the auger s cyclic step  feeding mechanism. 
automation of operations design for complex shape surfaces processing. 
research work be aim at model the process of mill surface of complex shape in automate cad cam system. 
to reduce labour input of this process an algorithm for design mill operation be propose. 
the algorithm be implement in the form of software write in the vba programming language from office excel. 
the software allow to select cut tool and cut mode for roughing semi finish and finish mill. 
the initial datum for this be process material part configuration profile depth technical requirement on the surface. 
the work of the algorithm be test on the part of the mold type. 
it be find that the set of cut tool for all type of mill surface of complex shape be select take into account the overall dimension of the treat surface its curvature and radius of surface round. 
the result of simulation of mold processing in sprut cam system accord to the assign set of cut tool and cut mode allow to choose the tool path with minimal processing time. 
integrate the innovation management methodology into the existing quality management system of a machine building enterprise. 
the problem of integrate european standard in the field of innovation management sim into the exist quality management system qms of organization be consider. 
the author analyze the most relevant development of the methodological foundation of innovation management as a promising direction of scientific knowledge and research aim at summarize the practical experience of its implementation in various sector of the economy and the service sector. 
particular attention be pay to analyze scientific publication in the field of industrial innovation. 
the main direction of integrate innovation management methodology into the system of quality management of product and service operate at enterprise and organization be propose. 
the conceptual model of the innovation management system be present which contain its key element. 
it be show that for industrial enterprise and manufacturing firm it be inappropriate to have two different system qms and sim which tend to the same goal namely to improve the product quality. 
a process model of innovation management that implement the principle of quality management call improvement be propose and the description of the model be give. 
the specificity of implement qms and sim integration process at russian enterprise of the machine building complex be reveal. 
improvement of human resource management in the quality management system of the enterprise. 
the paper deal with the principle of improve the management of human resource in the quality management system qms of the enterprise base on the concept of human resource management and process approach in accordance with the requirement of international standard iso 9000:2015. 
there be a dual nature of human resource identify where the staff be consider on the one hand as the most important specific resource determine the competitiveness of the enterprise and on the other hand as an internal consumer of the rewarding mechanism offer to employee for quality work. 
the procedure to design personnel process of qms of the enterprise be consider. 
the expediency of integrate idefo model and the methodology of functional cost analysis fca into the enterprise s qms. 
there be no formal approach to analysis and assessment of personnel risk in the management of process. 
the application of swot analysis adapt to the personnel management of the enterprise be justify in order to use it for control qms personnel risk. 
there be criterion give to apply this approach to ensure the quality of personnel process in qms of the enterprise. 
the influence of tthe grinding grains shape and orientation on performance of coated abrasive tools. 
the issue of the influence of the orientation and shape of grind grain of coated abrasive tool on their basic performance characteristic be consider in the article. 
the advantage of machine with flexible grinding tool be list. 
the feature of the abrasive grain contain in tool on a flexible basis be present. 
the low efficiency of use standard tool be justify. 
a method be describe for increase the efficiency of the grind process with tool on a flexible basis due to an integrated approach to the design of new tool design. 
it be propose to use abrasive grain of a give shape and orient in a certain way relative to the surface of the tool base. 
the main stage of work relate to the development of new tool design and study of their operational characteristic be present. 
experimental datum of the dependency of cut capability wear temperature in the cut zone power spend on cutting and the cut surface quality on the shape and the orientation angle of grind grain be present. 
practical recommendation for the application of tool contain in their structure certain variety of grind grain be propose. 
integration processes in russia engineering condition for business continuity. 
the article discuss the nature and main approach to the integration of enterprise and organization of mechanical engineering introduce the concept of business continuity and business continuity management offer recommendation for the implementation of a business continuity management procedure in mechanical engineering enterprise. 
accord to the author integration refer to the process of strengthen production relation and economic relation the organizational and economic merging of several component component part into a single whole acquire a high quality than the arithmetic addition of part. 
the limit of the integration process of the organization be analyze accord to the three possible modern concept of the company. 
the evolution and main stage of the integration process in the engineering industry of russia for the period from 1991 to the present be analyze in the article. 
the current state of the level of integration in the engineering industry of russia be also give. 
the assumption about the direct correlation between business continuity and the degree of integration in the engineering industry of russia be formulate. 
the prospect for the further development of the integration of industrial enterprise in russia be evaluate. 
form small diameter holes in tungsten cobalt alloys. 
the perspective of combine the process of electrochemical dissolving and electro erosive removal of the process material in form small diameter hole in alloy wc 8co by a hollow electrode  tool be present in the paper. 
it be establish that in use immovable electrode form the cone in the hole take place. 
the dependence of the pierce depth change on time be obtain. 
it testify the decrease in the processing speed with increase the inter electrode gap. 
it be show that during the electro erosive electrochemical process with immovable electrode the productivity of small diameter hole pierce increase by three time in comparison with the electrochemical processing. 
topsis technique in self government case study of kosice region. 
in the last decade most of the democratic country have reallocate tax revenue from collect taxis between the state budget and local government budget. 
it be possible to monitor the effort to increase the relative financial autonomy of local government to strengthen own revenue of local self government and to increase the autonomy of decision make body regard their use. 
the manuscript focus on usage of topsis technique as a tool for comprehensive evaluation in self government in slovakia. 
eight criterion be use and their weight be calculate base fuller triangle method and 25 expert. 
base on this analysis it be possible to recommend this method for usage not only in public sector but also in private sector as well. 
its use be also condition by the appropriate selection of the monitor indicator and their weighting which significantly determine the overall result. 
sensor platform for data management services in the european tool making industry. 
data management be one of the critical point of the tool industry since all application be heavily base on the industrial datum processing mould machine etc as well as the business process that be enable thank to such datum and their smart interpretation. 
this paper give a brief overview of a software architecture for sensor platform for data management services that could be implement into the european tool making industry. 
form a regular surface topography of a cylindrical part use oscillate ironing. 
a new technological practice for the formation of a regular surface topography by mean of oscillate ironing be present. 
the result be base on analytical calculation and experimental study. 
surface topography after oscillate ironing depend on workpiece rotation frequency deform tool advance oscillation frequency deform tool amplitude and tilt angle. 
the influence of the oscillating iron process parameter on the size and shape of contact patch be confirm. 
domain specific fusion of unstructured text for situation understanding poster. 
this paper present the initial design and the current and envisage functionality of a novel tool for information extraction and reasoning from open source datum osd namely the open source information collection analysis and reasoning oscar. 
it have the ability to ingest and process vast amount of osd to provide situation understanding and decision support about domain specific situation. 
the datum be pre filter use a custom create knowledge base kb while the information be extract use the rule based information extraction rubie a natural language processing nlp and tag tool. 
the extract information be subsequently cluster and transform into a relation graph of entity of interest. 
this proof of concept be present in the context of a use case base on the social crisis in venezuela in 2019. 
informative path planning in the presence of adversarial observer. 
this paper consider the problem of gather information about feature of interest in adversarial environment use mobile robot equip with sensor. 
the problem be formulate as an informative path planning problem where the objective be to maximize the gather information while minimize the tracking performance of the adversarial observer. 
the optimization problem that at first glance seem intractable to solve to global optimality be show to he equivalent to a mix integer semidelinite program that can be solve to global optimality use off the shelf optimization tool. 
assess situation awareness on fusion driven emergency management systems. 
situational awareness saw be a widespread concept in area that require critical decision making and refer to the level of consciousness that an individual or team have about a situation. 
a poor saw can induce human to failure in the decision making process lead to loss of life and property damage. 
data fusion process present opportunity to enrich the knowledge about situation by integrate heterogeneous and synergistic datum from different source and transform they into more meaningful subsidy for decision making. 
however a problem arise when information be subject to problem concern its quality especially when human be the main source of datum humint. 
this work describe the assessment of situation awareness provide by an emergency situation assessment system esas build base on the principle of a new information fusion model. 
expert from the sao paulo state police pmesp evaluate esas use sart methodology situation awareness rating technique which show high rate of saw compare to another system base on the state of the art high level fusion model especially in question relate to the component of informational supply and situational understanding. 
unsupervised bayesian estimation and tracking of time vary convolutive multichannel systems. 
in this paper we focus on bayesian blind and semi blind adaptive signal processing base on a broadband mimo fir model e.g. for blind source separation bss and blind system identification bsi. 
specifically we study in this paper a framework allow we to systematically incorporate various type of prior knowledge one source signal statistic two deterministic knowledge on the mix system and three stochastic knowledge on the mix system. 
in order to exploit all possible type of source signal statistic one our consideration be base on trinicon a previously introduce generic framework for broadband blind and semi blind adaptive mimo signal processing. 
the motivation for this paper be threefold a the extension of trinicon to bayesian point estimation to address three in addition to one and b more specifically to unify system base blind adaptive mimo signal processing with the tracking of time vary scenario and finally c to show how the bayesian trinicon base tracking can be formulate as a sequence estimation approach on arbitrary partly smooth manifold. 
as we will see in this paper the bayesian approach to incorporate stochastic prior and the manifold learning approach to exploit deterministic system knowledge two complement one another very efficiently in the context of trinicon. 
from social network graphs to causal bayes nets. 
this paper propose a new method for morph an exist social network graph into a causal bayes net. 
we assume only that an undirected graph of a social network exist with large amount of text datum associate with each distinct node person or organization. 
it be desire to convert such a graph into a causal probabilistic representation for predictive analysis. 
the probabilistic representation can also be use as part of a system for manage a set of soft sensor. 
the propose method rely on lexical rather than semantic analysis by extract the corpus of word use by a node remove common connective word and compute the set intersection among the vocabulary of several node. 
these set intersection can be use to identify distinct domain of knowledge as well as those node which have common interest. 
we far propose that temporal analysis of the movement of word from one node s domain of knowledge to another node can differentiate influencer from disciple in order to convert the undirected graph to a direct graph with conditional probability a bayes net. 
this research be differentiate from other lexical analysis base on document stream in that it seek to manage the datum acquisition rather than process stream for topic of interest. 
a latent variable model state estimation system for image sequences. 
self drive car need to be able to assess and understand the state of their surrounding. 
to achieve this goal it be necessary to construct a model which hold information about the state of the environment base on sensor measurement. 
in common state estimation system like kalman filter it be necessary to explicitly model state transition and the observation process. 
these model have to match the internal dynamic of the observed system as closely as possible to yield reliable estimation result. 
in this work we propose a method that can learn an approximation of the internal dynamic of a system without the need to explicitly model these process. 
our system even work on highly complex datum like frame of a video sequence. 
the approach be base on a latent variable model with a continuous hide state space. 
to deal with the fact that the estimate process be sequential we use recurrent neural network. 
as an example to show the potential of this system result predict future frame of short video sequence be show. 
the propose system show a general approach for state estimation without the need for any knowledge about the underlie state transition or observation process. 
how to calibrate your enemy s capabilities inverse filtering for counter autonomous systems. 
we consider the follow adversarial bayesian signal processing problem involve we and the enemy an enemy observe our state in noise update its posterior distribution of the state and then choose an action base on this posterior. 
give knowledge of our state and sequence of enemy s action observe in noise we consider two problem i how can the enemy s posterior distribution be estimate estimate the posterior be an inverse filtering problem involve a random measure we formulate and solve several version of this problem in a bayesian setting. 
ii how can the enemy s observation likelihood be estimate this tell we how accurate the enemy s sensor be. 
we compute the maximum likelihood estimator for the enemy s observation likelihood give our measurement of the enemy s action where the enemy s action be in response to estimate our state. 
the above question be motivate by the design of counter autonomous system give measurement of the action of a sophisticated autonomous enemy how can a counter autonomous system estimate the underlie belief of the enemy predict future action and therefore guard against these action. 
online video anomaly detection methodology with highly descriptive feature set. 
this paper present a novel methodology for online video anomaly detection. 
the proposed algorithm divide each video sequence into non overlapping cuboid and assign a state of the art feature vector to each of they. 
the incoming pattern in testing phase will be then evaluate base on their similarity to the learned pattern. 
the first achievement of the propose method be to introduce and apply highly descriptive feature and build a histogram of vertical component of optical flow for different region of the scene. 
since the vertical component of optical flow contain both information of magnitude and orientation it can be consider as an abstract feature rather than use magnitude and orientation separately. 
as a result the dimension of feature vector decrease which lead to reduce the complexity of entire system. 
the entropy of vertical component be also consider and hence the difference in velocity and direction of the movement will be monitor. 
finally an efficient technique for anomaly detection search be present that make the propose algorithm an applicable candidate for online performance. 
the simulation result on ucsd and umn datum set confirm that the propose methodology achieve high performance result in case of accuracy and total processing time compare with counterpart approach. 
house bombing in ravixe a bench for high level fusion evaluation. 
many benchmark exist for the evaluation of algorithm in field such as numerical optimization automatic planning sat solve natural language processing automatic code parallelization signal processing machine learning and low level fusion. 
to the good of our knowledge however there be no such bench exist for the evaluation of high level information fusion. 
in this paper we describe a benchmark that we develop with the aim of evaluate high level fusion algorithm. 
the bench be relate to a house bombing scenario in a fictive world. 
the scenario be fictional and take place in a city within a context of instability in the population between the member of two different community. 
we describe the scenario itself as well as the different source of information and the kind of information they provide. 
the whole set of information available in the bench be describe. 
start from a complete version of the bench that contain all the information item exchange during the scenario we derive several other bench that contain less or alter information item. 
this will enable evaluate the robustness of the high level information fusion system accord to the quality of the information they be provide with and without the imperfection of information extractor exhibit piece of information from raw datum. 
optimize maritime vessel service time with adaptive quay crane deployment through level four hard soft information fusion. 
commercial maritime port must maintain high service throughput in order to remain profitable. 
one of the most critical operation in a commercial maritime port be the loading and unloading of shipping container on a vessel i.e. 
service a vessel and store they in the storage yard. 
a delay in this process would cause cascading delay in service further vessel cause delay in move cargo across land rail and sea. 
furthermore the port itself may incur fine for allow such delay in their operational procedure. 
this work highlight a fuzzy system optimize by a genetic algorithm to adaptively control the deployment of quay crane and their operator and all other support equipment and personnel to optimize the time require to service a vessel while simultaneously reduce the operational cost of do so. 
complex signal denoising and interference mitigation for automotive radar use convolutional neural network. 
driver assistance system as well as autonomous car have to rely on sensor to perceive their environment. 
a heterogeneous set of sensor be use to perform this task robustly. 
among they radar sensor be indispensable because of their range resolution and the possibility to directly measure velocity. 
since more and more radar sensor be deploy on the street mutual interference must be deal with. 
in the so far unregulated automotive radar frequency band a sensor must be capable of detect or even mitigate the harmful effect of interference which include a decrease detection sensitivity. 
in this paper we address this issue with convolutional neural networks cnns which be state of the art machine learning tool. 
we show that the ability of cnn to find structured information in datum while preserve local information enable superior denoise performance. 
to achieve this cnn parameter be find use training with simulated datum and integrate into the automotive radar signal processing chain. 
the present method be compare with the state of the art highlight its promising performance. 
hence cnn can be employ for interference mitigation as an alternative to conventional signal processing method. 
code and pre train model be available at https://github.com/johannarock/imricnn. 
towards a knowledge base framework for digital chain monitoring within the industry 4.0 paradigm. 
the industry 4.0 paradigm be currently one of the domain that present various problematic with high challenge for research and manufacture expert. 
among the industry 4.0 topic digital chain monitoring have a great impact on the performance of the company. 
indeed less connection of enterprise information system and datum sharing between business department of the company can result on over cost and serious delay regard the operational planning. 
in manufacture company virtual barrier can exist between the operational management and the shop floor due to security confidentiality and interoperability issue. 
consequently feedback about the real activity and event in the shop floor be not regularly transfer to the decision make department i.e. 
process engineering maintenance etc. 
in this context this paper discuss the potential of knowledge structure through a common repository as a solution to support the continuity of the whole digital chain. 
a knowledge base platform be propose as part of the smartemma french research project with the aim to provide actor with relevant contextual information and useful indicator base on datum collect from machine and other information system. 
c 2019 the authors. 
publish by elsevier b.v.. 
inversion of flow and heat transfer of the paramagnetic fluid in a differentially heat cube. 
the present study address the detailed numerical analysis of the flow and heat transfer of a paramagnetic fluid inside a differentially heated cubical box and subject to a strong non uniform magnetic field. 
two different heating scenario be consider regard an initial thermal stratification unstable heat from the bottom and stable heat from the top both subject to the same magnetic field. 
for a fix value of the thermal rayleigh number ra 1.4 x 10(5 integral heat transfer be measure over a range of impose magnetic field zero vertical bar b(0)vertical bar max 10 t. 
to obtain detailed insight into local wall heat transfer and its dependency on the flow pattern generate numerical simulation of the experimental setup be perform. 
a relatively good agreement between experiment and numerical simulation be obtain in predict the integral heat transfer with an average delta(nu over bar seven over the entire range of work parameter for both heating configuration. 
it be demonstrate that a strong convective motion can be generate under the influence of the magnetization force even for the heat from above situation that initially be in the pure conduction state. 
this magnetically assist heat from the bottom and magnetically inverted heat from the top rayleigh benard convection produce up to five and 15 time more efficient heat transfer compare to the initial neutral situation respectively. 
c 2020 the authors. 
publish by elsevier ltd.. 
transitional natural convection flow in a vertical channel impact of the external thermal stratification. 
the impact of the external thermal stratification on the flow behavior and the mass flow rate in an open end vertical channel with one side uniformly heat be investigate experimentally and numerically. 
both experimental and numerical study show that the increase of the external stratification lower the velocity and the mass flow rate but also displace the transition height at a low location in the channel. 
the numerical model be use to study the case of weak and negative thermal stratification which be barely achievable in non control experimental laboratory condition but be common in the atmosphere. 
different flow regime be identify with flow be fully laminar when the stratification be weak or negative and flow be transitional to turbulent for high stratification. 
finally the numerically obtain mass flow rate with the various external thermal stratification be show to be in excellent agreement with a theoretical model develop in a previous work. 
c 2020 elsevier ltd. 
all right reserve. 
numerical modeling of a benchmark experiment on equiaxed solidification of a sn pb alloy with electromagnetic stirring and natural convection. 
a three phase volume average equiaxed model be apply to simulation of an experiment on solidification of the binary alloy sn 10 wt.% pb subject to the electromagnetic stirring. 
the experiment whose description be publish early be perform in a parallelepipe cavity under control cool condition and with real time two dimensional temperature measurement over a lateral surface of the cavity co planar with direction of solidification. 
apply numerical model treat motion of the liquid and equiaxed grain whose growth kinetic be take into account and use a double time step scheme to accelerate solution. 
growth of columnar dendrite be not consider. 
it be show that electromagnetic force act in a direction opposite to the natural convection flow create moderately turbulent flow in pure liquid which be treat with a realizable k(epsilon) epsilon model. 
it be demonstrate that calculate temperature distribution in the cavity well reproduce temperature map reconstruct from thermocouple measurement throughout the experiment. 
final macrosegregation map and distribution of density grain number be qualitatively similar to those obtain in the experiment. 
variation of intensity of electromagnetic stirring in numerical model show that this affect shape and localization of positive segregation region at the bottom of the cavity. 
c 2020 elsevier ltd. 
all right reserve. 
mangrove an inference base dynamic invariant mining for gpu architectures. 
likely invariant model property that hold in operating condition of a compute system. 
dynamic mining of invariant aim at extract logic formula represent such property from the system execution trace and it be widely use for verification of intellectual property ip block. 
although the extract formula represent likely invariant that hold in the considered trace there be no guarantee that they be true in general for the system under verification. 
as a consequence to increase the probability that the mine invariant be true in general dynamic mining have to be perform to large set of representative execution trace. 
this make the execution base mining process of actual ip block very time consume due to the trace length and to the large set of monitored signal. 
this article present mangrove an efficient implementation of a dynamic invariant mining algorithm for gpu architecture. 
mangrove exploit inference rule which be apply at run time to filter invariant from the execution trace and thus to sensibly reduce the problem complexity. 
mangrove allow user to define invariant template and from these template it automatically generate kernel for parallel and efficient mining on gpu architecture. 
the article present the tool the analysis of its performance and its comparison with the well sequential and parallel implementation at the state of the art. 
mpc net a first principles guided policy search. 
we present an imitation learning approach for the control of dynamical system with a know model. 
our policy search method be guide by solution from model predictive control mpc. 
typical policy search method of this kind minimize a distance metric between the guide demonstration and the learn policy. 
our loss function however correspond to the minimization of the control hamiltonian which derive from the principle of optimality. 
therefore our algorithm directly attempt to solve the optimality condition with a parameterized class of control law. 
additionally the propose loss function explicitly encode the constraint of the optimal control problem and we provide numerical evidence that its minimization achieve improved constraint satisfaction. 
we train a mixture of expert neural network architecture for control a quadrupedal robot and show that this policy structure be well suited for such multimodal system. 
the learned policy can successfully stabilize different gait on the real walking robot from less than 10 min of demonstration datum. 
fret life of the a17050 t7451 under out of phase load numerical and experimental analysis. 
this study investigate the effect of the phase angle between fret and fatigue load on the life of al7050 t7451 aluminum alloy specimen. 
test with phase angle of zero degree 45 degree 90 degree and 135 degree be carry out use a bi actuator system which permit the distinct control of fret and fatigue load. 
a numerical stress analysis for the in phase condition be develop and compare with the closed form solution to provide a benchmark for the study. 
life be estimate use three different critical plane criterion couple with extended version of the theory of critical distance. 
result show that the introduction of a phase angle between load play a significant role on the fatigue life of this alloy. 
sra secure reverse auction for task assignment in spatial crowdsourcing. 
in this paper we study a new type of spatial crowdsourcing namely competitive detour tasking where worker can make detour from their original travel path to perform multiple task and each worker be allow to compete for preferred task by strategically claim his her detour cost. 
the objective be to make suitable task assignment by maximize the social welfare of crowdsource system and protect worker private sensitive information. 
we first model the task assignment problem as a reverse auction process. 
we formalize the win bid selection of reverse auction as an n$n to one weight bipartite graph matching problem with multiple zero 1 knapsack constraint. 
since this problem be np hard we design an approximation algorithm to select win bid and determine correspond payment. 
base on this a secure reverse auction sra protocol be propose for this novel spatial crowdsourcing. 
we analyze the approximation performance of the propose protocol and prove that it have some desire property include truthfulness individual rationality computational efficiency and security. 
to the good of our knowledge this be the first theoretically provable secure auction protocol for spatial crowdsourcing system. 
in addition we also conduct extensive simulation on a real trace to verify the performance of the propose protocol. 
robust error base non collocated output track control for a heat equation. 
in this paper an output tracking problem for a heat equation be consider where all possible disturbance produce from an exosystem and a systematic uncertainty be consider and the performance output be non collocate with control. 
the objective be twofold to look at how the internal model principle work for the output tracking of pde and to see how to design a robust tracking error feedback control for pde. 
to this purpose we first select a frozen case with specially select frozen coefficient of the disturbance. 
for this frozen system we design a feedforward control by solve simply regulator equation and an infinite dimensional extended state observer in term of track error only which give an estimation of both state of the frozen plant and exosystem. 
an observer base tracking error feedback control be then design for the frozen system which be show to be in line with the internal model principle. 
as a result the system be show to be robust to system uncertainty and disturbance in all channel. 
the numerical simulation validate the result. 
c 2020 elsevier ltd. 
all right reserve. 
a unitary distribute subgradient method for multi agent optimization with different coupling source. 
distribute optimization technique offer high quality solution to various engineering problem such as resource allocation and distribute estimation and control. 
in this work we first consider distribute convex constrain optimization problem where the objective function be encode by multiple local and possibly nonsmooth objective privately hold by a group of agent and propose a distribute subgradient method with double averaging abbreviate as dsa(2 that only require peer to peer communication and local computation to solve the global problem. 
the algorithmic framework build on dual method and dynamic average consensus the sequence of test point be form by iteratively minimize a local dual model of the overall objective where the coefficient approximate subgradient of the objective be supply by the dynamic average consensus scheme. 
we theoretically show that dsa(2 enjoy non ergodic convergence property the local minimizing sequence itself be convergent a distinct feature that can not be find in exist result. 
specifically we establish a convergence rate of o(1 root t in term of objective function error. 
then extension be make to tackle distribute optimization problem with couple functional constraint by combine dsa(2 and dual decomposition. 
this be make possible by lagrangian relaxation that transform the coupling in constraint of the primal problem into that in cost function of the dual thus allow we to solve the dual problem via dsa(2. 
both the dual objective error and the quadratic penalty for the couple constraint be prove to converge at a rate of o(1 root t and the primal objective error asymptotically vanish. 
numerical experiment and comparison be conduct to illustrate the advantage of the propose algorithm and validate our theoretical finding. 
c 2020 elsevier ltd. 
all right reserve. 
symbolic abstraction for nonlinear control system via feedback refinement relation. 
this paper study the construction of symbolic abstraction for nonlinear control system via feedback refinement relation. 
both the delay free and time delay case be address. 
for the delay free case to reduce the computational complexity we propose a new approximation approach for the state and input set base on a static quantizer. 
and then a novel symbolic model be construct such that the original system and the symbolic model satisfy the feedback refinement relation. 
for the time delay case both static and dynamic quantizer be combine to approximate the state and input set. 
this lead to a novel dynamic symbolic model for time delay control system and a feedback refinement relation be establish between the original system and the symbolic model. 
finally a numerical example be present to illustrate the obtain result. 
c 2020 elsevier ltd. 
all right reserve. 
epsilon nash mean field game for general linear quadratic system with application. 
this paper be concern with general mean field mf linear quadratic lq game of stochastic large population system where the individual diffusion coefficient can depend on both the state and the control of the agent. 
moreover the control weight in the cost functional could be indefinite. 
the asymptotic suboptimality property namely epsilon nash equilibrium of the decentralize strategy for the lq game be derive through the consistency condition. 
the impact of the population s collective behavior and the consistency of the mean field estimation be illustrate by the numerical result. 
a pricing problem be also study for which the decentralized suboptimal price be obtain. 
c 2020 elsevier ltd. 
all right reserve. 
an extremum seeking base approach for nash equilibrium seek in n cluster noncooperative game. 
this paper consider nash equilibrium seek for n cluster noncooperative game in which the explicit expression of the agent local objective function be not available to the agent. 
as an alternative the output value of the agent local objective function be suppose to be measurable. 
an extremum seeker be design to achieve the nash equilibrium seek for the n cluster noncooperative game. 
the design of the extremum seeker be base on a dynamic average consensus protocol and the modulation of the sinusoidal dither signal. 
through lyapunov stability analysis the convergence result be analytically study. 
local and nonlocal convergence result be derive under local and global characterization of the nash equilibrium for the n cluster noncooperative game respectively. 
compare with our previous work on nash equilibrium seek for the n cluster noncooperative game the main advantage and characteristic of the propose method be threefold. 
firstly the propose method broaden the applicability of the exist nash equilibrium seek strategy to circumstance in which the agent can not access the explicit expression of their local objective function. 
moreover the propose seek strategy perform as a unified strategy that solve the noncooperative game and the social cost minimization problem without utilize explicit model information. 
secondly the propose seek strategy require each agent to update few auxiliary variable compare with the exist method and hence reduce the communication and computation cost. 
thirdly different from most of the exist work that adopt singular perturbation to analyze the stability of extremum seeker this paper establish the convergence result via lyapunov stability analysis which be novel and provide some new insight on the analysis of extremum seeker. 
a numerical example be provide to verify the effectiveness of the propose method. 
c 2020 elsevier ltd. 
all right reserve. 
adaptive decentralize controller design for a class of switched interconnected nonlinear systems. 
this paper be concern with the switch decentralize adaptive control design problem for switch interconnect nonlinear system under arbitrary switching where the actuator failure may occur infinite time and the control direction be allow to be unknown. 
by introduce a nussbaum type function and an integrable auxiliary signal a switch decentralize adaptive control scheme be develop to deal with the potentially infinite time of actuator failure and the unknown control direction. 
the basic idea be to design different parameter update law and control law for distinct switched subsystem. 
it be prove that the state variable of the result closed loop system be asymptotically stable. 
finally a numerical simulation on a double inverted pendulum model be give to verify the propose control scheme. 
consensus tracking for heterogeneous interdependent group systems. 
this paper be concern with the consensus tracking problem for heterogeneous interdependent group system with fix communication topology. 
first the interdependent model of the heterogeneous system be build from the perspective of the difference of the individual characteristic and the difference of the subgroup topology structure. 
a class of distribute consensus tracking control protocol be propose for realize the consensus tracking of the heterogeneous interdependent group system via use local information. 
then for fix communication topology some correspond sufficient condition be give to ensure the achievement of the consensus tracking. 
two parameter be define which denote respectively the proportion of interdependence individual and the redundancy of interdependence. 
the effect of these parameter be analyze on the consensus tracking of group system. 
numerical simulation be provide to illustrate the effectiveness of the theoretical analysis. 
prespecifie time cluster synchronization of complex networks via a smooth control approach. 
most exist finite /fixe time synchronization control scheme be nonsmooth or discontinuous and the settling time be estimate with conservatism. 
it be due to the utilization of signum function or fraction power state feedback. 
this brief consider the problem of prespecifie time cluster synchronization of complex network with a smooth control protocol. 
the synchronization time be independent of any control parameter or any system initial condition which be actually uniformly prescribe accord to task requirement without any estimation. 
moreover the cluster synchronization can maintain after the specify time and the smooth control input can always keep uniformly bound in an infinite time interval as well. 
finally one numerical example be provide to illustrate the effectiveness of the propose protocol and design method. 
peckvis a visual analytics tool to analyze dominance hierarchies in small group. 
the formation of social group be define by the interaction among the group member. 
study this group formation process can be useful in understand the status of member decision make behavior spread of knowledge and disease and much more. 
a define characteristic of these group be the pecking order or hierarchy the member form which help group work towards their goal. 
one area of social science deal with understand the formation and maintenance of these hierarchy and in our work we provide social scientist with a visual analytic tool peckvis to aid this process. 
while online social group or social network have be study deeply and lead to a variety of analysis and visualization tool the study of small group in the field of social science lack the support of suitable tool. 
domain expert believe that visualize their datum can save they time as well as reveal finding they may have fail to observe. 
we work alongside domain expert to build an interactive visual analytic system to investigate social hierarchy. 
our system can discover pattern and relationship between the member of a group as well as compare different group. 
the result be present to the user in the form of an interactive visual analytic dashboard. 
we demonstrate that domain expert be able to effectively use our tool to analyze animal behavior datum. 
ultimate boundedness control for uncertain nonlinear impulsive switched systems a fuzzy approach base on a complete takagi sugeno structure. 
this paper deal with the ultimate boundedness control of nonlinear impulsive switch system which ensure that the state trajectory ultimately converge to a sufficient small region contain the origin. 
give a general model we first propose novel stability criterion that do not need to be satisfied on the entire space and include a condition to guarantee the remaining of trajectory within the ultimate bind even though the impulse size be not zero at the origin or be not vanish near the origin. 
apply these criterion to a closed loop system lead to a set of matrix inequality that may be infeasible when the subsystem be highly nonlinear. 
therefore we redevelop they for an impulsive switch system represent by takagi sugeno t s fuzzy structure with nonlinear consequent part. 
since this structure have few rule than the traditional t s model with linear consequent part the number of establish stabilization matrix inequality be sharply reduce. 
we then derive an optimization problem with linear and bilinear constraint to achieve a fuzzy controller that guarantee convergence to the small ultimate bind as well as practical control issue. 
finally a numerical example and a practical motivated example be give to demonstrate the applicability of the propose approach. 
application of artificial potential field for coverage control with collision avoidance under sense constraint. 
in multi agent coverage control the voronoi diagram optimization strategy be widely use. 
however the limitation of sense radius make voronoi diagram optimization strategy not suitable to implement. 
moreover when the agent s dimension and obstacle be consider the voronoi diagram can not deal far due to the collision that may occur. 
consider these limitation power diagram optimization strategy be use. 
to deal with obstacle artificial potential field strategy be combine with the power diagram. 
despite its simplicity the numerical study show that the propose scheme of coverage control work well under sense constraint even with the presence of obstacle. 
the propose strategy be convergent to the objective without collision with obstacle as well as among the agent. 
inhomogeneous deformation behavior of oblique hole flange part during electromagnetic forming. 
the electromagnetic flanging of oblique hole flange part be characterize by inhomogeneous deformation which be closely relate to the final form quality of workpiece. 
in this work the inhomogeneous deformation behavior of a workpiece form by electromagnetic flanging whereby an initial blank make of anneal 2219 aluminum alloy with a circular precut hole be form into an oblique hole flanging part be investigate and the influence mechanism be reveal by conduct numerical simulation. 
a comparison of the form process for three typical radial deformation region along the circumferential direction of zero degree 90 degree and 180 degree be make. 
the result show that during the electromagnetic form emf of the oblique hole flange part the deformation region along path 90 degree deform fast and impact the die first at the maximum velocity. 
the deformation region along path 180 degree impact early than that along path zero degree. 
the result flanging angle of the workpiece be low than the target flanging angle with a maximum deviation of approximately 4.8 degree and the form height distribute as a wavy pattern along the circumference. 
in the emf of oblique hole flange part the direct influence factor responsible for the inhomogeneous deformation behavior of the workpiece include the deformation requirement area of the deformation region and electromagnetic force. 
the inhomogeneous deformation behavior be essentially due to the uneven deformation requirement. 
the area of the deformation region be the most important factor influence the inhomogeneous deformation behavior with the electromagnetic force have a significant influence as well. 
base on the finding process parameter can be optimize to control the inhomogeneous deformation behavior and to realize the precision emf for nonaxisymmetrical irregular part. 
application of ultrasonic testing and machine learning method to predict the static fatigue behavior of spot weld joint. 
ultrasonic testing ut be one of the well know non destructive techniques ndt of spot weld inspection in the advanced industry especially in automotive industry. 
however the relationship between the ut result and strength of the spot weld joint subject to various loading condition be unknown. 
the main purpose of this research be to present an integrate search system as a new approach for assessment of tensile strength and fatigue behavior of the spot weld joint. 
to this end resistance spot weld rsw specimen of three sheet be make of different type of low carbon steel. 
afterward the ultrasonic test be carry out and the pulse echo datum of each sample be extract utilize image processing technique ipt. 
several experiment tensile and axial fatigue test be perform to study the mechanical property of rsw joint of multiple sheet. 
the novel approach of the present research be to provide a new methodology for static strength and fatigue life assessment of three sheet rsw joint base on the ut result by utilize artificial neural network ann simulation. 
next genetic algorithm ga be use to optimize the structure of ann. 
this approach help to decrease the number of test and the cost of perform destructive test with appropriate. 
investigation on the laves phase formation during laser clad of in718 alloy by ca fe. 
a deleterious laves phase form in the solidify structure of inconel 718 in718 alloy during laser cladding and the dynamic formation of laves phase be difficult to be observe by experiment directly. 
in this paper a novel multi scale numerical model be establish. 
as a consequence the influence of the laser clad process parameter on solidification parameter be analyze especially on shape control factor k and cool rate r firstly. 
afterward a series of dynamic solidification process be simulate include nucleation dendrite growth solute distribution and laves phase formation. 
furthermore the refined laves phase be obtain by optimization of laser clad processing parameter and the cool environment. 
finally the propose model be far testify by experiment. 
from the result of simulation and experiment that high cool rate inhibit composition undercooling in molten pool and decrease the secondary dendrite arm space. 
at the same time the niobium nb segregation be improve and laves phase be refine in clad layer. 
the present investigation provide a comprehensive understanding of the laves phase formation in in718 alloy during laser cladding and have certain reference significance on minimize the laves phase concentration in actual processing. 
laser micro drilling of 316l stainless steel orthopedic implant a study. 
it have recently be show that there be a requirement of inclined micro hole with smooth side wall without crack and burr high aspect ratio low taper reduce heat affect zone haz and thin recast layer on orthopedic implant. 
so with the aim of improve hole quality characteristic and functionality of implant a multi objective optimization of laser micro drilling with argon as an assist gas be address in this study. 
a hybrid statistical approach base on grey relational analysis gra and coefficient of variation cov be propose to analyse the experimental datum. 
the key process variable responsible for quality improvement be identify. 
four statistical test be perform to compare the hybrid and gra approach. 
far it be find that the propose hybrid be more superior to gra in term of computational time and ease of computation. 
it be also observe that focal point position and diode current have strike effect of hole quality. 
an important implication of this paper be that thin recast layer small haz width and spatter area be observe when argon be use as an assist gas. 
artificially intelligent adaptive search fast motion estimation algorithm for hd video. 
this paper present a new machine learning base approach to video fast motion estimation which improve quality minimize power consumption and provide control over the performance vs power balance render it very suitable for hardware implementation into a motion co processor. 
many mobile and hand hold device today deploy such hardware accelerator. 
the main goal of the present algorithm be to achieve maximum quality motion estimation per unit of consume power by minimize the number of search point and also provide an optional mechanism for find an optimal early termination point. 
the paper present the creation of a dictionary of adaptively pre learned fix search pattern along with a pre train neural network to adaptively help select the most adequate search pattern from a dictionary accord to the dynamic of the motion within a specific region of the video frame not the frame or scene as a whole. 
there be often motion in various direction within the same scene or frame and the ability to focus on a local region within the frame improve quality significantly. 
full search represent the quality goal and upper boundary for any integer fast motion estimation. 
the present algorithm add about one db of psnr to state of the art fix search pattern. 
there be only about 0.5 db of psnr remain between our algorithm and full search. 
effect of rheological property of friction enhance grease on the friction between friction lining and wire rope. 
in this paper the relationship between rheology and friction be establish by test the rheological property of friction enhance grease and monitor the change of temperature and friction coefficient during the friction process between friction lining and wire rope. 
it show that the loss modulus of friction enhance grease be proportional to the friction coefficient. 
as the pressure and friction temperature increase the loss modulus of the grease decrease and the friction coefficient decrease. 
it be find that when the loss modulus of the grease be large the coefficient of friction be high. 
it be also find that when the rheology be stable the friction transmission be smooth. 
these result provide a theoretical basis for improve and develop new type of friction enhance grease. 
topography transformation due to running in of roll slide non conformal contact. 
a ball on disc machine be operate under condition relevant to heavily load gear. 
various level of isotropic surface finish be evaluate to reveal the influence on elasto hydrodynamic lubrication ehl. 
stribeck test be conduct for insight about roughness effect in all regime whereas lift off test be conduct to investigate the influence on running in. 
a 3d surface re location approach be develop to enable study of the topography on exactly the same area before and after test. 
this help to find asperity level detail about how topography must transform to allow a shift from the mixed  and boundary lubrication regime into the full film micro ehl regime. 
the micro conformity be highlight to play a key role for ehl lift off that precede the completion of running in. 
influence of lubricant on nonlinear vibration characteristic of linear rolling guideway. 
linear rolling guideway be widely use in precision mechanical system such as robot and machine tool. 
clarify the natural vibration characteristic of a linear rolling guideway be important for improve the performance of mechanical system because the dynamic characteristic of the guideway strongly influence the dynamic and posture accuracy of mechanical system. 
this study focus on the natural vibration characteristic of linear rolling guideway. 
we discuss both the nonlinear relationship between friction and natural vibration and the influence of the lubricant specification on the nonlinearity of nonlinear natural vibration. 
additionally the effect of the lubricant specification on the damp ratio be different for different vibration mode owe to the difference between the damp mechanism. 
estimation of time dependent heat transfer coefficient in unidirectional casting use a numerical model couple with solidification analysis and datum assimilation. 
we have recently develop a method to estimate the heat transfer coefficient base on datum assimilation. 
to understand its usefulness for estimate the time dependent heat transfer coefficient herein we perform unidirectional cast experiment of al one mass%si alloy and obtain the cool curve during solidification. 
the experimental datum be then use to validate the estimate time dependent heat transfer coefficient. 
consequently the measure cool curve could be accurately simulate and the average error between measure and simulate cool curve be below 0.8. 
the estimate time dependent heat transfer coefficient be 29461.5 wm( two k one at the initial stage of cooling which rapidly decrease to about 6000 wm( two k one and then gradually decrease to about 1000 wm( two k one. 
these value be reasonable as the heat transfer coefficient for casting of al base alloy. 
additionally the effect of the set parameter of the datum assimilation be evaluate. 
it be find that the position of the cool curve(s use in the estimation be the most important factor and a cool curve measure at the position near the surface of the mold should be utilize. 
this method allow the reasonable estimation of the time dependent heat transfer coefficient between the mold and molten alloy for unidirectional casting without use trial and error and experimentally measure cool curve can be accurately reproduce by solidification analysis. 
c 2019 elsevier ltd. 
all right reserve. 
analysis of discharge channel characteristic base on plasma flow and heat transfer in usv mf complex assist wedm ls. 
in this paper the analysis of discharge channel characteristic from the view of plasma flow and heat transfer in ultrasonic vibration usv and magnetic field mf assist low speed wire electrical discharge machine wedm ls process be propose. 
accord to the particle orbit theory the motion equation of multi electron be modify by monte carlo collision model. 
the study of discharge channel parameter reveal that the spatial shape of channel be change and the length of channel path be increase when additional magnetic field be apply to the discharge machining thus cause the channel current fluctuation. 
the simulation result of electron motion process in magnetic field indicate that the time from cathode to anode increase by 15.38 and the diffusion of electron reduce by five. 
the electron distribution on anode surface be relatively homogeneous after the completion of the discharge. 
the experimental result indicate that under the influence of magnetic field the peak current in discharge channel increase obviously the material removal rate mrr increase by 48.8 on average and the number of micro crack on machine surface decrease significantly. 
c 2019 elsevier ltd. 
all right reserve. 
the effect of interfacial mass transfer of slip rise gas bubble on two phase flow in the vertical wellbore pipeline. 
during drilling or oil recovery it be common that the formation trap gas invade the vertical wellbore pipeline to cause the gas liquid two phase flow which bring challenge and danger to wellbore pipeline pressure control. 
in this paper couple the interfacial mass transfer theory of slip rise bubble base on bubble hydraulic to the gas liquid two phase flow theory a new transient non isothermal gas liquid two phase flow model in the vertical wellbore pipeline be develop. 
in this model the effect of flow regime and heat transfer on the mass transfer rate be consider. 
the propose model be validate use the measure experiment datum and field datum. 
use this model the effect of interfacial mass transfer of slip rise bubble on the evolution of gas liquid two phase flow in a special gas kick scenario be analyze. 
the simulation result indicate that the mass transfer rate between oil dispersion and invasion gas be relatively slow which make the gas not instantaneously dissolve in the oil dispersion or not instantly saturate the oil dispersion. 
under the same gas invasion rate the fraction and mass of free gas calculate by this model be always large than those obtain by yin s model result in a fast of the bottomhole pressure reduction rate and pit gain increase rate. 
additionally increase the gas concentration and flow rate could promote the interphase mass transfer rate while increase the temperature would inhibit it. 
this model could characterize the wellbore pipeline gas liquid two phase flow with interphase mass transfer in more detail and accurately. 
c 2020 elsevier ltd. 
all right reserve. 
user orient design of active monitoring bedside agent for old adult to prevent falls. 
a small bedside agent for prevent fall have be develop. 
it talk to a person on a bed to prevent they from get out of bed abruptly until a care worker arrive. 
this paper describe the user orient design process of the agent system. 
the development process involve user such as nurse and caregiver as well as old adult be describe. 
first hardware design such as the outer shape size and function of the agent be review by nurse and caregiver mainly from a safety viewpoint. 
the prototype agent incorporate improvement base on their opinion be use experimentally by old adult after several review process. 
second the software design of the agent such as the content of voice call be study through multiple experiment to improve its acceptability. 
lastly the integrated model be introduce into care facility and hospital to investigate the practical serviceability of the system. 
a shift bottleneck procedure with multiple objective in a complex manufacturing environment. 
scheduling problem have be study extensively over the year. 
broad range of focus area exist from optimization to heuristic production planning to production sequence customize algorithm to general purpose algorithm and from simple machine to complex environment. 
in this research a heuristic approach have be propose to overcome the scheduling problem on a complex job shop find at a manufacturer of commercial building product. 
the research be aim at sequence production order in near real time primarily to minimize total tardiness but also to reduce total setup time. 
a layered shifting bottleneck procedure be employ with the top layer determine release date and due date for individual job and the bottom layer apply algorithm to individual work center. 
the outcome of this research be a well production schedule than current method with minimal computation cost. 
the propose framework perform well and could be apply to other production area. 
on the application of domain adaptation in structural health monitoring. 
the application of machine learning within structural health monitoring shm have be widely successful in a variety of application. 
however most technique be build upon the assumption that both training and test datum be draw from the same underlying distribution. 
this fact mean that unless test datum be obtain from the same system in the same operating condition the machine learn inference from the training datum will not provide accurate prediction when apply to the test datum. 
therefore to train a robust predictor conventionally new training datum and label must be recollect for every new structure consider which be significantly expensive and often impossible in an shm context. 
transfer learning in the form of domain adaptation offer a novel solution to these problem by provide a method for map feature and label distribution for different structure label source and unlabelled target structure onto the same space. 
as a result classifier train on a label structure in the source domain will generalise to a different unlabelled target structure. 
furthermore a holistic discussion of context in which domain adaptation be applicable be discuss specifically for population base shm. 
three domain adaptation technique be demonstrate on four case study provide new framework for approach the problem of shm. 
c 2019 the authors. 
publish by elsevier ltd.. 
a linear discrete time extended state observer base intelligent pd controller for a 12 dof low limb exoskeleton lle repa. 
to perform the motion control of a 12 dof low limb exoskeleton for rehabilitation and power augmentation lle repa this paper propose a linear discrete time extended state observer ldeso base intelligent pd ipd controller with sigmoid function base tracking differentiator std. 
a three order discrete time std be design to obtain smooth real time reference velocity and acceleration signal. 
the adopt ipd controller be a kind of model free method base on ultra local model which formulate complex human exoskeleton dynamic in a simple way and make closed loop pd parameter easy to be tune. 
the ldeso be utilize to estimate and eliminate the lump total disturbance in ultra local model which contain unknown model dynamic and unpredictable human exoskeleton interaction influence. 
the estimation result of ldeso be use to compensate the control input. 
simulation and experimental result with exoskeleton lle repa demonstrate the high performance of the propose method. 
c 2019 elsevier ltd. 
all right reserve. 
application of machine learning to machine fault diagnosis a review and roadmap. 
intelligent fault diagnosis ifd refer to application of machine learn theory to machine fault diagnosis. 
this be a promising way to release the contribution from human labor and automatically recognize the health state of machine thus it have attract much attention in the last two or three decade. 
although ifd have achieve a considerable number of success a review still leave a blank space to systematically cover the development of ifd from the cradle to the bloom and rarely provide potential guideline for the future development. 
to bridge the gap this article present a review and roadmap to systematically cover the development of ifd follow the progress of machine learn theory and offer a future perspective. 
in the past traditional machine learning theory begin to weak the contribution of human labor and bring the era of artificial intelligence to machine fault diagnosis. 
over the recent year the advent of deep learning theory have reform ifd in far release the artificial assistance since the 2010s which encourage to construct an end to end diagnosis procedure. 
it mean to directly bridge the relationship between the increasingly grow monitoring datum and the health state of machine. 
in the future transfer learn theory attempt to use the diagnosis knowledge from one or multiple diagnosis task to other related one which prospectively overcome the obstacle in application of ifd to engineer scenario. 
finally the roadmap of ifd be picture to show potential research trend when combine with the challenge in this field. 
c 2019 elsevier ltd. 
all right reserve. 
a state of the art review on theory and engineering application of eigenvalue and eigenvector derivative. 
eigenvalue and eigenvector derivative with respect to system design variable and their application have be and continue to be one of the core issue in the design control and identification of practical engineering system. 
many different numerical method have be develop to compute accurately and efficiently these required derivative from which a wide range of successful application have be establish. 
this paper review and examine these method of compute eigenderivative for undampe viscously damp nonviscously damp fractional and nonlinear vibration system as well as defective system for both distinct and repeat eigenvalue. 
the underlie mathematical relationship among these method be discuss together with new theoretical development. 
major important application of eigenderivative to finite element model updating structural design and modification prediction performance optimization of structure and system optimal control system design damage detection and fault diagnosis as well as turbine bladed disk vibration be examine. 
exist difficulty be identify and measure be propose to rectify they. 
various example be give to demonstrate the key theoretical concept and major practical application of concern. 
potential further research challenge be identify with the purpose of concentrate future research effort in the most fruitful direction. 
c 2019 elsevier ltd. 
all right reserve. 
efficient uncertainty propagation for parameterized p box use sparse decomposition base polynomial chaos expansion. 
uncertainty propagation up be the process of determine the effect of input uncertainty on a response of interest. 
these input uncertainty may be characterize as either aleatory uncertainty which be irreducible variability inherent in nature or epistemic uncertainty which be reducible uncertainty result from a lack of knowledge. 
in this paper we propose an efficient uncertainty propagation analysis method for problem with parameterized probability box p box accounting for aleatory and epistemic uncertainty. 
firstly the sparse decomposition base polynomial chaos expansion pce method be present to tackle the aleatory uncertainty in which a basis selection strategy base on the sparse decomposition be devise to automatically detect the significant basis set of pce. 
then to deal with the epistemic uncertainty on the distribution parameter the coefficient of the sparse decomposition base pce be treat as quadratic polynomial function of the interval value distribution parameter of parameterized p box. 
finally the bound of the first four moment and the cumulative distribution function cdf of the response function can be successfully obtain. 
four numerical example be analyze to verify the effectiveness of the propose method. 
c 2019 elsevier ltd. 
all right reserve. 
data drive thermally induce error compensation method of high speed and precision five axis machine tool. 
the data drive thermal error compensation method of high speed and precision five axis machine tool be propose base on the homogeneous transformation. 
the compensation component be obtain by analyze the error transmission chain of machine tool and be express as the transmission matrix consist of thermal error term of linear axis and spindle system accord to the differential movement of the compensation axis. 
from the view of thermal error generation mechanism the thermal error of the linear axis be formulate as the product of the polynomial function with time as its independent variable and the polynomial function with position as its independent variable. 
then the thermal error of the linear axis be decompose and identify from the measured positioning error. 
the thermal error of the spindle system be identify by the thermal characteristic experiment. 
the compensation component in each direction be calculate by substitute the identify thermal error term of the linear axis and spindle system into the data drive thermal error model. 
finally to demonstrate the effectiveness of the propose method the thermal error at a new working condition be predict and then the error compensation and actual machining be carry out. 
the result show that the machining error be reduce by more than 85 and 37 with the present error compensation compare with that without compensation and that without traditional error compensation respectively. 
this research shed new light on both the generation mechanism and the compensation method of the thermally induce error of five axis machine tool. 
c 2019 elsevier ltd. 
all right reserve. 
experimental and numerical study on the thermal control strategy for a gas foil bearing enhance with thermoelectric module. 
the author report the method for temperature gradient control in gas foil bearing with the use of thermoelectric module. 
the paper present a prototype installation consist of a gas foil bearing with integrate 36 thermoelectric module an electric spindle measurement and control system. 
the result of a preliminary qualitative and quantitative assessment of the investigate temperature gradient control be show make use of the carry out numerical simulation. 
steady state thermal analysis be perform for the define control current assign to the peltier module. 
the metamodeling technique improve the search for a suboptimal choice on the control current value in term of temperature gradient control efficiency. 
consideration of simultaneous forward and backward heat pump direction for the select thermoelectric module improve temperature gradient reduction by additional 10. 
moreover the paper be complement with the result of an experimental test perform for a prototype installation of a gas foil bearing. 
a straightforward adaptive algorithm dedicate to control thermal parameter of the bearing s foil be successfully test. 
the control algorithm allow for a significant temperature gradient reduction however considerable oscillation in the temperature profile be observe. 
in order to eliminate these oscillation a pid controller be implement into the algorithm. 
consequently the magnitude of the temperature oscillation be reduce by 60. 
c 2019 the authors. 
publish by elsevier ltd.. 
blind filter base on envelope spectrum sparsity indicator for bearing and gear vibration base condition monitoring. 
this paper investigate a novel perspective on blind filtering of vibration signal with the purpose of fault detection in rotate machinery. 
instead of maximize a property of the time domain signal such as kurtosis to find an optimal filter the sparsity of its envelope spectrum be maximize. 
the underlie assumption for this approach be that fault of rotate component such as bearing introduce second order cyclostationary content into the signal. 
this cyclostationary content manifest itself as discrete peak in the envelope spectrum give the speed be stationary. 
these peak thus increase the sparsity of the envelope spectrum as a consequence. 
therefore this paper derive blind filter formulation that try to filter out a signal with the most sparse envelope spectrum. 
blind filter be derive use three different sparsity measure i.c. 
l(2)/l(1) norm hoyer index and spectral negentropy. 
key in the iterative optimization procedure be the usage of the rayleigh quotient to update the filter coefficient. 
one major advantage of this approach be that no prior information about characteristic fault frequency of the mechanical component of interest need to be know. 
inspection of simulation and experimental result show that the propose approach be a simple yet effective way of track fault with a cyclostationary signature. 
c 2019 elsevier ltd. 
all right reserve. 
a non contact high precision measure method for the radial runout of cylindrical gear tooth profile. 
gear radial runout eccentricity be one of the common error of gear and it cause dynamic load vibration and noise seriously in a machine system. 
therefore the radial runout measurement be indispensable in gear manufacturing run and maintain. 
with the advantage of low cost high precision and universal applicability a non contact measuring method for the radial runout of cylindrical gear tooth profile be propose only use a single laser displacement sensor in this paper. 
a theoretical optimization model be establish accord to the measurement principle and the laser sensor characteristic and the optimal installation position and angle of the laser sensor be present for measurement arrangement. 
a mathematical model and algorithm for the circumferential measure datum of cylindrical gear tooth profile be deduce and propose a calculate initial value of radial runout eccentric modulus and phase angle be predict by least square linear regression and then the exact value of radial runout be determine by an iterative loop approximation with jacobian gradient matrix. 
numerical simulation of measure process be carry out by set different precision level of system parameter to evaluate the method accuracy and applicability in the view of error distribution and sensitivity analysis. 
for a gear shaft with 11 21 and 32 tooth gear a specialized experiment be carry out to validate the correctness and reliability of the propose measuring method by compare with a conventional measure method of the gear radial runout. 
c 2019 elsevier ltd. 
all right reserve. 
simulation and experiment on tonal vibration transmission control with a multi channel global control method. 
a multi channel global control method be propose in combination with active isolator to suppress tonal vibration transmission in structure. 
this method be build on a modify adaptive control algorithm and the mutual interference in control channel be compensate. 
the efficacy of the global control method be investigate by use a mechanical system which consist of a hull structure a controllable vibration source and four active mount. 
a dynamic model of the mechanical system be establish and the result of numerical simulation indicate that the global control method be more effective as the channel interference be compensate and the convergence rate of it be fast than the local control method which consider the local vibration feedback only. 
experimental result also demonstrate that the global control method be able to suppress tonal vibration transmission effectively even in the circumstance of strong mutual interference in control channel. 
c 2019 elsevier ltd. 
all right reserve. 
approximate eigenvalue decomposition of orthonormal and symmetric transformation with a few householder reflector. 
the ability to decompose a signal in an orthonormal basis a set of orthogonal component each normalize to have unit length use a fast numerical procedure rest at the heart of many signal processing method and application. 
the classic example be the fourier and wavelet transform that enjoy numerically efficient implementation fft and fwt respectively. 
unfortunately orthonormal transformation be in general unstructured and therefore they do not enjoy low computational complexity property. 
in this paper base on householder reflector we introduce a class of orthonormal matrix that be numerically efficient to manipulate we control the complexity of matrix vector multiplication with these matrix use a give parameter. 
we provide numerical algorithm that approximate any orthonormal or symmetric transform with a new orthonormal or symmetric structure make up of product of a give number of householder reflector. 
we show analysis and numerical evidence to highlight the accuracy of the propose approximation and provide an application to the case of learn fast mahalanobis distance metric transformation. 
c 2020 elsevier inc. 
all right reserve. 
development of an armored upper limb exoskeleton. 
personal safety be a critical aspect of daily life but also in the military. 
active soldier often have to carry heavy gear during mission which put pressure on their back. 
therefore the military must come up with new technology that allow both protection and movement. 
in this paper it be explain the development of an armored upper limb exoskeleton with three degree of freedom. 
to ensure portability it be use battery fed dc actuator. 
the system be encase in a metal matrix that double up as a protective plate. 
the exoskeleton the control system the actuator and the plate be integrate so that they offer protection while support the flexion and extension of the upper limb. 
an improved simulated anneal linear programming hybrid algorithm apply to the optimal coordination of directional overcurrent relay. 
the coordination of directional overcurrent relay docrs be a constrained and nonlinear optimization problem which consist in find suitable plug and time dial setting so that the relay operational time be minimize keep selectivity and sensitivity characteristic. 
recently several effort have be devote to automate the coordination of docr. 
this paper propose a hybrid technique entitle simulated anneal linear programming sa lp to achieve the optimal coordination of docr. 
five test system ieee three ieee six ieee eight ieee 15 and ieee 30 bus be use to verify the effectiveness of the propose technique. 
result obtain with the sa lp be confront against other optimization technique report in specialized literature under identical condition. 
the propose approach present good quality solution low computational processing time and great convergence towards the optimum solution present an advantage over adaptive coordination tendency by enhance monitoring communication capability and grid control. 
snap through of shallow circular arches with variable horizontal supports under unilateral displacement control. 
this study propose a numerical method to solve the snap through problem of elastic shallow inextensible circular arch. 
specifically the snap through behavior of arch subject to a downward load at a point along the span be systematically evaluate for variable elastic horizontal support under unilateral displacement control. 
through theoretical analysis base on a dimensionless formulation the critical state of snap through can be determine by embed ordinary differential equation into the nonlinear unconstrained optimization. 
then critical stiffness line for horizontal spring and snap region with vary loading position be systematically analyze to judge whether a snap through phenomenon will occur. 
parametric analysis be far carry out to investigate the influence of variable horizontal spring stiffness and different arch length on the overall deformation and the critical displacement of critical state. 
the result show that the critical stiffness increase with the decrease of arch length and the decrease of horizontal stiffness and arch length can both expand the snap region. 
this study highlight the important role of stiffness of support in snap through behavior control and provide a numerical method for more accurate evaluation of the snap through behavior of arch under various support and loading condition in engineering application. 
a systematic literature review on semantic web enable software testing. 
software testing as a major verification and validation activity which revolve around quality test be a knowledge intensive activity. 
hence it be reasonable to expect that it can be improve by effective application of semantic web technology ontology which have be frequently use in knowledge engineering activity. 
the objective of this work be to investigate and provide a well understanding of how semantic web enable technique the technique that be base on the effective application of the semantic web technology have be use to support software testing activity. 
for this purpose a systematic literature review base on a predefined procedure be conduct. 
a total of 52 primary study be identify as relevant which have undergo a thorough meta analysis with regard to our pose research question. 
this study indicate the benefit of semantic web enable software testing in both industry and academia. 
it also identify main software testing activity that can benefit from the semantic web enable technique. 
furthermore contribution of such technique to the testing process be thoroughly examine. 
finally potential and difficulty of apply these technique to software testing along with the promising research direction be discuss. 
c 2019 elsevier inc. 
all right reserve. 
represent software project vision by mean of video a quality model for vision video. 
establish a share software project vision be a key challenge in requirements engineering re. 
several approach use video to represent vision. 
however these approach omit how to produce a good video. 
this miss guidance be one crucial reason why video be not establish in re. 
we propose a quality model for video represent a vision so call vision video. 
base on two literature review we elaborate ten quality characteristic of video and five quality characteristic of vision which together form a quality model for vision video that include all 15 quality characteristic. 
we provide two representation of the quality model a a hierarchical decomposition of vision video quality into the quality characteristic and b a mapping of these characteristic to the video production and use process. 
while the hierarchical decomposition support the evaluation of vision video the mapping provide guidance for video production. 
in an evaluation with 139 student we investigate whether the 15 characteristic be relate to the overall quality of vision video perceive by the subject from a developer s the point of view. 
six characteristic video length focus prior knowledge clarity pleasure and stability correlate significantly with the likelihood that the subject perceive a vision video as good. 
these relationship substantiate a fundamental relevance of the propose quality model. 
therefore we conclude that the quality model be a sound basis for future refinement and extension. 
c 2019 elsevier inc. 
all right reserve. 
formalizing hierarchical scheduling for refinement of real time system. 
the event b formalism offer a stepwise development approach for manage complexity in system design. 
however the exist work that extend event b model with discrete timing property inadequately represent the communication and competition between concurrent task in concurrent system. 
in this paper we present the semantic of the parameterized real time trigger response property of event eight model base on timing invariant. 
we show a method of syntactically encode parameterized real time trigger response property in event b machine. 
to capture the concurrency between task we distinguish end to end timing property and scheduler base timing property from the perspective of different system design phase. 
we model end to end timing property as parameterized timing property and scheduler base timing property as unparameterized timing property. 
a nondeterministic queue base scheduling framework be propose to replace end to end timing property with scheduler base timing property. 
additional gluing invariant be provide for this refinement. 
to demonstrate the usability of the framework we formalize a two level hierarchical scheduling system with local resource sharing manage by a time division multiplexe global scheduler and two alternative local scheduler refine by the nondeterministic queue base scheduling policy. 
model be prove use the rodin tool. 
c 2020 elsevi b.v. 
all right reserve. 
comparative study of city level sustainability assessment standard in china and the united states. 
in analysis of urban environment city level sustainability assessment standard have receive a lot of attention. 
many country particularly in the developed world have develop the standard to measure the performance of neighborhood district and city in achieve sustainable development goal. 
in this study four standard from china and the united states be select and analyze within the scope of green and sustainable development. 
china s new assessment standard for green eco district asge target to support china s new type urbanization plan from the conceptual stage to the concrete implementation. 
leed r rating system be one of the important reference for the development of asge. 
by compare asge with the advanced standard it draw from this study aim to evaluate asge s work in adapt to china s national condition point out the strength and weakness and propose improvement. 
the study result indicate that the rating system of asge be in line with china s national condition and that some non technical indicator be forward look but that there be still room for improvement in term of implementation path weight assignment number of indicator and index system. 
base on these exploration this study provide suggestion for aspect of principle and method that could be use for the construction of similar standard in develop country. 
c 2019 elsevier ltd. 
all right reserve. 
evaluate the effect of organizational architecture in develop science and technology park under differ innovation environment. 
science and technology parks stps be often use as tool to foster regional development. 
they seek innovation innovator and encourage innovation amongst the constituent firm include by network and knowledge spill over between the inhabitant university and source of capital. 
the low success rate of stps lead we to investigate how stp architecture can well cope with a change and challenging innovation environment through start up to early maturity and full maturity in a preliminary effort to arrive at an evidence base scheme to help avoid failure. 
three different type of architecture be investigate open market star hierarchy and close strong adhocracy ambidextrous. 
open market architecture suffer both from high transaction cost while not protect against poor decision making. 
result show that it be very beneficial to have a central cluster initiative ci control the decision make process star hierarchy in the early stage of stp development where potential gain and loss be relatively modest. 
however in the early maturity stage with commitment to a high growth trajectory a high quality of decision making be require amongst manager and decision be well take by the ci with the input of optimally two individual on cluster firm. 
the situation where ci be support by good quality decision from on cluster firm an ad hoc ambidextrous situation be superior when good innovation abound and the stp have acquire some maturity. 
however in environment with a surfeit of poor fit innovation this become a high risk strategy with high potential loss and indeed in this situation retain a hierarchical ci only decision process be most helpful even when the quality of decision making amongst ci manager be poor. 
result indicate that success involve attract enough small innovative firm which in turn attract large firm whose detailed sector relevant insight improve ci decision making. 
error bounds for pd control mechanical systems under bounded disturbances use interval arithmetic. 
we present a numerical algorithm base on invariant set theory to evaluate the bad case performance of pd control mechanical system affect by bound disturbance. 
by perform a specific coordinate transformation the search and computation of positive invariant set be simplify. 
it be show that thank to the preservation of problem structure the propose method allow to obtain tight component wise bound on the state which be especially useful for performance evaluation and tuning of a pd controller. 
the bound be formally guarantee and can be use for safety certification. 
the method be compare to ultimate boundedness and the superior result be show via numerical simulation. 
machine learning based predictive model for afp base unidirectional composite laminates. 
manufacturing of composite use automate fiber placement afp be a complex process that involve large number of processing condition and variable. 
improper selection of these parameter adversely affect the quality and integrity of the manufacture laminate. 
thus it be important to develop a predictive model that can assess how change in critical process condition alter the output of the manufacturing process. 
the goal of this investigation be to learn the complex behavior of composite by develop an intelligent model which can subsequently be use for the prediction of various characteristic of the composite. 
however manufacturing of afp composite be both expensive and time consume and therefore the available data sample be less from the prospective of machine learning which lead to the small data learning problem. 
this article first solve this problem through virtual sample generation and then a neural network base predictive model be develop to accurately learn the complex relationship between various processing parameter in afp. 
a fuzzy control strategy of burn through point base on the feature extraction of time series trend for iron ore sintering process. 
sinter ore be the main raw material for ironmaking and burn through point btp be one of the significant factor to measure the stability of the sintering process. 
in this article through the feature extraction of time series trend a fuzzy control strategy be present for the btp. 
first the hurst exponent of the time series for the btp be calculate by resort to the rescaled range analysis method by which the trend feature be analyze. 
then by use the mann kendall test both global and local trend feature variable of the time series for the btp be extract and regard as the input of the fuzzy controller. 
next a fuzzy controller for the btp be design to produce the control quantity of the strand velocity. 
finally base on a semiphysical simulation system and the raw datum collect from an iron and steel plant an experiment be carry out to demonstrate the effectiveness of the propose control strategy. 
enhance density peak clustering via density normalization. 
clustering be able to find out implicit data distribution and be especially useful in datum drive machine learning. 
density base clustering have an attractive property of detect cluster of arbitrary structure. 
the density peak algorithm make use of two assumption to detect cluster center and then group the other datum. 
this approach be simple to implement and show to be promise in many experiment. 
however we find its clustering result be dependent on density kernel type and kernel parameter and density difference across cluster also influence the result significantly. 
in this paper we make a detailed study of the density peak algorithm and attribute the problem to the local density criterion in detect cluster center. 
we then use density normalization to relieve the influence of the problem and present a density kernel to far improve cluster result. 
we conduct experiment with different type of dataset to demonstrate the performance of our approach. 
a comprehensive exploration on spider with fuzzy decision text to sql model. 
the challenge of natural language processing be from natural language to logical form sql. 
in this article we present an fuzzy semantic to structure query language f semtosql neural approach that be a fuzzy decision semantic deep network query model base on demand aggregation. 
it aim to address the problem of the complex and cross domain text to sql generation task. 
the corpus be train as the input word vector of the model with lstm and word2vec embed technology. 
combine with the dependency graph method the problem of sql statement generation be convert to slot filling. 
complex task be divide into four level via f semtosql and construct by the need of aggregation. 
at the same time to avoid the order problem in the traditional model effectively we have adopt the attention mechanism and use a fuzzy decision mechanism to improve the model decision. 
on the challenge text to sql benchmark spider and the other three dataset f semtosql achieve fast convergence and occupy the first position. 
implement ai as cyber iot device the house valuation example. 
internet of thing iot have be widely utilize with artificial intelligence ai. 
however it require substantial effort to integrate ai and big datum with iot. 
to mitigate this problem aitalk be propose. 
by treat ai as a cyber iot device we do not need to write code of the ai mechanism in the network application as traditional ai base iot application do. 
this article describe how the ai tool such as scikit learn and tensorlayer be accommodate as cyber iot device in aitalk and extend aitalk for non iot application. 
we use house valuation as an example to show how aitalk can flexibly include the factor that have significant impact on the house price. 
we show that by add extra feature other than housing profile feature the accuracy for the prediction valuation can be improve by 38 x0025. 
we also investigate the communication overhead of the distribute aitalk structure which be 3.7 x0025 for the computation of one house price valuation. 
data drive two dimensional deep correlated representation learning for nonlinear batch process monitoring. 
dynamic and nonlinearity may exist in the time and batch direction for batch process thereby complicate the monitoring of these process. 
in this article we propose a two dimensional deep correlate representation learn 2d dcrl method to achieve the efficient fault detection and isolation of the nonlinear batch process. 
three way historical datum be first unfold as two way time slice datum. 
second a stacked autoencoder base deep neural network be construct to characterize the correlation among the process variable. 
consider that the time and batch direction may be dynamic for each time slice measurement a construct two d measurement contain sample from the previous time instant and batch be then obtain. 
subsequently dcrl be perform between the current running batch measurement and the construct two d measurement to characterize the two d dynamic and nonlinearity. 
the 2d dcrl base monitoring examine the status of a sample by consider the two d nonlinear and dynamic information provide improved monitoring performance. 
application on two typical batch process demonstrate the effectiveness of the propose 2d dcrl monitoring scheme. 
the complex step derivative approximation on matrix lie group. 
the complex step derivative approximation be a numerical differentiation technique that can achieve analytical accuracy to machine precision with a single function evaluation. 
in this letter the complex step derivative approximation be extend to be compatible with element of matrix lie group. 
as with the standard complex step derivative the method be still able to achieve analytical accuracy up to machine precision with a single function evaluation. 
compare to a central difference scheme the propose complex step approach be show to have superior accuracy. 
the approach be apply to two different pose estimation problem and be able to recover the same result as an analytical method when available. 
distal hyperextension be handy high range of motion in cluttered environments. 
as robot branch out from the manufacturing sector into the home there be a press need for new technology that can operate in cluttered and unstructured human environment. 
loading and unload a dishwasher serve as a difficult representative challenge for in home robot and a new robotic end effector have be develop for this type of task. 
the actuation of the finger be integrate with a bend degree of freedom that be nearly coincident with the proximal joint of the finger an arrangement that greatly increase the kinematic workspace in constrain environment. 
in addition the distal joint of the finger be capable of hyperextension bend backwards allow they to pinch a wide range of surface curvature and angle securely. 
a third feature of the hand be a palm that combine a granular jamming substrate with suction cup to adhere to wet and slippery object of vary curvature. 
integration of these feature into a single prototype allow the hand to grasp and manipulate dirty dish reliably and with low gripping force as demonstrate in object acquisition and manipulation with less than 10 n of apply force. 
thermal radiation model for the buoyancy control diffusion plume from rectangular fire source. 
this study investigate the thermal radiation from a rectangular fire source with different aspect ratio. 
fire experiment with burner of the same surface area but different aspect ratio be conduct. 
the flame be split into several sub flame as the aspect ratio of burner increase. 
compare with the axis symmetric fire source the flame split in the rectangular fire source lead to a change in the thermal radiation mechanism. 
thus a multicuboid flame model be develop to estimate the radiant heat flux from a rectangular fire source. 
the number of sub cuboid flame consider in the propose model depend on the aspect ratio of the rectangular fire source. 
compare with experimental result and datum available in the literature the standard error of estimation by the develop model be 0.505 indicate that the propose model outperform the cuboid flame and point source model find in the literature. 
this develop model have well prediction for the thermal radiation from rectangular fire source with large aspect ratio. 
base on sensitivity analysis of model parameter the ratio of the aspect ratio of the burner to the number of sub cuboid flame could be consider as a constant. 
thus this propose model can be apply to risk assessment of rectangular fire. 
thermal diffusivity measurement of insulate material at high temperature with a four layer 4l method. 
this article present a temperature temperature thermal characterization method for the measurement of the thermal diffusivity of insulate material at high temperature. 
this novel method note 4l be a transient absolute measurement method base on the estimation of the transfer function at the center of a symmetrical stack compose of two speciman of an insulate material sandwich between two conductive metallic plate. 
two different direct 1d semi analytical model be develop. 
the first one consider purely conductive opaque material and the second one take into account the coupling between radiative and conductive heat transfer mode for purely scatter semi transparent material. 
the first model be use to estimate the thermal diffusivity of two different opaque insulate material calcium silicate board up to 800 degree c with accuracy well than 10. 
the second model be use to estimate the thermal diffusivity of a semi transparent insulate material ceramic foam up to 1000 degree c with an accuracy of approximately 10. 
the second model be use to identify significant estimation error occur if a purely conductive model be use for semi transparent material. 
the conducto radiative model be also use to estimate an average value of the mean extinction coefficient of the semi transparent material. 
investigation of the effect with linear circular and polynomial blade on contact characteristic for face hob hypoid gear. 
on this research the effect of the three different type of blade section include linear circular and polynomial on mesh characteristic for face hob hypoid gear be investigate. 
firstly with the equation of three blade section and the transformation matrix base on the processing method derive the mathematical model of gear flank and loaded finite element mesh model be propose. 
then the impact of different blade section on tooth surface deviation and mesh characteristic be analyze. 
result show that the effect be almost identical when the parameter choose reasonable for the three blade. 
however with the circular radius reduce the peak to peak value of transmission error decrease but the contact pattern area shrink and the location of maximum bend stress will change. 
for the polynomial blade the effect the design parameter on mesh characteristic be obvious. 
c 2019 elsevier ltd. 
all right reserve. 
multi objective optimization of hypoid gear to improve operate characteristic. 
in this paper a multi objective optimization method of hypoid gear correlate to the operate characteristic be present. 
optimal design of hypoid gear demand that multiple objective be simultaneously achieve. 
four objective consider in this study be the minimization of the maximum tooth contact pressure transmission error and the average temperature in the gear mesh and the maximization of the mechanical efficiency of the gear pair. 
the goal of the optimization be achieve by the optimal modification of meshing teeth surface. 
in practice these modification be introduce by apply the appropriate machine tool set for the manufacture of the pinion and the gear and/or by use a tool with an optimize profile. 
the propose optimization procedure rely heavily on the loaded tooth contact analysis for the prediction of tooth contact pressure distribution and transmission error and on the mixed elastohydrodynamic analysis of lubrication to determine temperature and efficiency. 
a fast elitist nondominate sort genetic algorithm nsga ii be apply to solve the model. 
the effectiveness of the method be demonstrate by use hypoid gear example. 
the obtain result have show that by the optimization considerable improvement in the operate characteristic of the gear pair be achieve. 
c 2019 the author. 
publish by elsevier ltd.. 
combine size base load balancing with round robin for scalable low latency. 
when dispatch job to parallel server or queue the highly scalable round robin rr scheme reduce the variance of interarrival time at all queue to a great extent but have no impact on the variance of service process. 
contrariwise size interval task assignment sita routing have little impact on the variance of interarrival time but make the service process as deterministic as possible. 
in this paper we unify both static approach to design a scalable load balancing framework able to control the variance of the arrival and service process jointly. 
it turn out that the result combination significantly improve performance and be able to drive the mean job delay to zero in the large system limit it be know that this property be not achieve when both approach be consider separately. 
within realistic parameter we show that the optimal number of size interval that partition the support of the job size distribution be small with respect to the system size. 
this enhance the applicability of the propose load balance scheme at a large scale. 
in fact we find that add a little bit of information about job size to a dispatch operating under rr improve performance a lot. 
under the optimal scaling of size interval and assume highly variable job size numerical simulation indicate that the propose algorithm be competitive with the less scalable join the short workload algorithm even when the system size grow large. 
all pass filter base pll systems linear modeling analysis and comparative evaluation. 
all pass filter apf pass all frequency component of a signal without alter their amplitude but change their phase. 
this feature have make the apf a versatile building block in different signal processing application. 
the focus of this article be on apf base phase lock loop pll where the apf be require for create a 90 degree phase shift at the fundamental frequency. 
such a phase shift be need for generate a fictitious orthogonal signal in single phase application and reject the grid voltage imbalance in three phase system. 
to the good of author knowledge none of the apf base pll have an accurate model yet. 
this gap in knowledge make the analysis of these synchronization system and identify their advantage disadvantage compare to state of the art structure complicate. 
the main objective of this article be to bridge this knowledge gap. 
real time hil emulation for a segmented rotor switched reluctance motor use a new magnetic equivalent circuit. 
this article present a new magnetic equivalent circuit mec for a real time emulation of a 1610 segment rotor switch reluctance motor ssrm base on the hardware in the loop hil configuration. 
the propose real time mec contain the reluctance of slot leakage air gap and iron core of the ssrm. 
to speed up the emulation a ten by ten matrix system be develop for the mec. 
a new algorithm be propose to solve the matrix system to reduce the computation time. 
to carry out the experiment the hil be employ in this article. 
it can provide a precise and real time condition for the application of the new method. 
in the test bench the field programmable gate array provide an operating platform to realize the real time emulation of the mec model. 
as verify the propose real time mec model benefit the real time emulation and the performance evaluation of the ssrm. 
the propose method can be apply to other switched reluctance motor as an efficient way to verify their real time characteristic with high accuracy and low emulation cost. 
enable grid feed converters with a dissonant resonant controller for negative sequence voltage elimination. 
the mitigation of the adverse effect of voltage unbalance in equipment and power quality can be perform by the power electronic converter that interface distribute generator to the grid. 
inspire in a resonant controller this article present a dissonant resonant controller for negative sequence voltage elimination for a grid feed converter connect to the grid. 
the controller eliminate the negative sequence voltage at the converter output with a regulable precision it do not require know the grid impedance for successful operation and it can be a good candidate for parallel operation because it operate not like an integrator but like an untuned integrator. 
use the stationary frame a closed loop model be develop in a complex space vector build from the complexification of the stationary component. 
this allow extract stability condition for safe closed loop operation as well as derive design guideline for the controller parameter. 
numerical and experimental result show the ability of the propose controller to meet its design goal thus corroborate the theoretical approach. 
a machining program employ a slip line field modelling technique over other constitutive model. 
machining involve complex plastic material flow at the chip separation site which make it difficult to predict force and other machine output to high accuracy. 
modelling be a common technique which facilitate incorporation of analytical and experimentally derive equation to visualize the process and analyse the mechanism. 
it save time and machining factor can be optimize without any trial and error method. 
in this paper the significance of slip line field model over other constitutive law in define the complex region in machining be thoroughly review and a slip line field model be choose which incorporate build up edge bue of a large size than the other previously define slip line model for machine. 
the modified model also incorporate a region of shear zone instead of a shear line take into account the chip curl effect and conform to the velocity discontinuity and stress equilibrium. 
the slip line field be generate use matlab and employ dewhurst collin s matrix technique. 
dt ii digital twin enhance industrial internet reference framework towards smart manufacturing. 
in this paper the interplay and relationship between digital twin and industrial internet be discuss at first. 
the sense transmission network capability which be one of the main characteristic of industrial internet can be a carrier for provide digital twin with a mean of datum acquisition and transmission. 
conversely with the capability of high fidelity virtual modeling and simulation computing analysis digital twin evolve from lifecycle management for a single product to application in production manufacturing in the shop floor enterprise can far greatly enhance the simulation computing and analysis of industrial internet. 
this paper propose a digital twin enhance industrial internet dt ii reference framework towards smart manufacturing. 
to far illustrate the reference framework the implementation and operation mechanism of dt ii be discuss from three perspective include product lifecycle level infra enterprise level and inter enterprise level. 
finally steam turbine be take as an example to illustrate the application scene from above three perspective under the circumstance of dt ii. 
the difference between with and without dt ii for design and development of steam turbine be also present. 
a robust cardinality constrain model to address the machine loading problem. 
several deterministic model have be propose in the literature to solve the machine loading problem mlp which consider a set of product type to be produce on a set of machine use a set of tool type and determine the quantity of each product type to be produce at each time period and the correspond machine tool loading configuration. 
however processing time be subject to random increase which could impair the quality of a deterministic solution. 
thus we propose a robust mlp counterpart search for an approach that properly describe the uncertainty set of model parameter and at the same time ensure practical application. 
we exploit the cardinality constrain approach which consider a simple uncertainty set where all uncertain parameter belong to an interval and allow tune the robustness level by bound the number of parameter that assume the bad value. 
the result plan provide accurate estimation on the minimum production level that a system achieve even in the bad condition. 
the applicability of the robust mlp and the impact of robustness level have be test on several problem variant consider single  vs multi machine and single vs multi period mlp. 
we also consider the execution of the plan in a set of scenario to evaluate the practical implication of mlp robustness. 
result show the advantage of the robust formulation in term of improved feasibility of the plan identification of the most critical tool and product and evaluation of the maximum achievable performance in relation to the level of protection. 
moreover low computational time guarantee the applicability of the propose robust mlp counterpart. 
disassembly sequence planning use discrete bees algorithm for human robot collaboration in remanufacture. 
remanufacturing help to improve the resource utilization rate and reduce the manufacturing cost. 
disassembly be a key step of remanufacturing and be always finish by either manual labor or robot. 
manual disassembly have low efficiency and high labor cost while robotic disassembly be not flexible enough to handle complex disassembly task. 
therefore human robot collaboration for disassembly hrcd be propose to flexibly and efficiently finish the disassembly process in remanufacture. 
before the execution of the disassembly process disassembly sequence planning dsp which be to find the optimal disassembly sequence help to improve the disassembly efficiency. 
in this paper dsp for human robot collaboration hrc be solve by the modify discrete bees algorithm base on pareto mdba pareto. 
firstly the disassembly model be build to generate feasible disassembly sequence. 
then the disassembly task be classify accord to the disassembly difficulty. 
afterward the solution of dsp for hrc be generate and evaluate. 
to minimize the disassembly time disassembly cost and disassembly difficulty mdba pareto be propose to search the optimal solution. 
base on a simplified computer case case study be conduct to verify the propose method. 
the result show the propose method can solve dsp for hrc in remanufacturing and outperform the other three optimization algorithm in solution quality. 
sera self repair architecture for dark silicon era. 
the lifetime reliability of processor have become a major design constraint in the dark silicon era. 
processor reliability issue be mainly due to design defect and age. 
unlike design defect however age fault gradually accumulate over time. 
many method have recently be propose to monitor the performance degradation of circuit. 
in this study an architectural solution that extend the circuit level age monitoring to processor stage be propose for monitor performance degradation. 
when degradation of a stage quantify as delay of half of the reference clock occur a self repair mechanism be trigger. 
this mechanism configure an field programmable gate array fpga which take over the function of the degraded unit. 
the propose self repair mechanism be apply to the stage of the processor data path. 
this method sera have less area overhead compare with the state of art solution. 
wideband input matching cmo low noise amplifier with noise and distortion cancellation. 
in this paper a wideband low noise amplifier lna be design base on the resistive feedback topology with a tsmc 0.18 mu m standard rf cmos process. 
bandwidth expansion be provide by the second order chebyshev filter. 
the noise figure nf increase at high frequency because of the source parasitic capacitor of the cascode transistor so noise cancelling technique be apply to the cascode transistor of the propose lna. 
bias condition and size of the transistor be optimize to cancel the nonlinear transconductance g(m g(m. 
with this modify technique low noise figure high linearity and improve input and output matching can be attain for 3.1 10.6 ghz frequency band. 
post layout simulation result of the propose lna show the maximum power gain of 17 db at 5.5 ghz frequency nf of low than 4.5 db over the whole band of 3.1 10.6 ghz maximum iip2 of +28 dbm and iip3 of +7.5 dbm while dissipate nine mw with buffer from a 1.8 v supply voltage. 
it occupy 773.3 mu m x 676 mu m silicon die area. 
recolibry suite a set of intelligent tool for the development of recommender system. 
recommendation system be a key part of almost every modern consumer website. 
recommender system include technique to filter explore and rank a huge amount of information and item accord to the user s current interest and the similarity among user and item. 
design and implement a recommender system usually require high programming and machine learning skill. 
to alleviate these process we present recolibry suite a set of intelligent tool to assist different type of user on the development of recommender system. 
recolibry suite support not only the design and development of recommender system but also its deployment as software as a service. 
we have evaluate the usability of the propose tool with real user. 
marginal restraint mandrel free spinning process for thin walled ellipsoidal head. 
metal sheet spinning be an advanced near net form technology for the manufacture of thin walled ellipsoidal head. 
the exact control of dimensional accuracy however be a considerable problem for spin thin walled part with large diameter to thickness ratio. 
in this work a marginal restraint mandrel free spinning process with two pass be propose for the fabrication of thin walled ellipsoidal head without wrinkle. 
a finite element model be establish and verify to study the influence of spin parameter on the dimensional precision of thin walled ellipsoidal head. 
it be find that the spin parameter considerably influence the deviation of wall thickness and contour characteristic. 
a small form angle or small roller fillet radius during the first pass spinning as well as the small angle between pass or high feed ratio during the second pass spinning can improve the wall thickness precision. 
meanwhile as the form angle or feed ratio be increase during the first pass spinning the contour precision initially increase and then decrease. 
during the second pass spinning the contour precision can be improve at a small angle between pass whereas it deteriorate at a large roller installation angle. 
the optimize spinning parameter be obtain and verify by experiment. 
two sided ultrasonic surface roll process of aeroengine blade base on on machine noncontact measurement. 
as crucial part of an aeroengine blade be vulnerable to damage from long term operation in harsh environment. 
the ultrasonic surface rolling process usrp be a novel surface treatment technique that can highly improve the mechanical behavior of blade. 
during secondary machining the nominal blade model can not be use for secondary machining path generation due to the deviation between the actual and nominal blade. 
the clamp error of the blade also affect the precision of secondary machining. 
this study present a two sided usrp ts usrp machining for aeroengine blade on the basis of on machine noncontact measurement. 
first a ts usrp machining system for blade be develop. 
second a 3d scan system be use to obtain the point cloud of the blade and a series of point cloud processing step be perform. 
a local point cloud automatic extraction algorithm be introduce to extract the point cloud of the strengthened region of the blade. 
then the tool path be design on the basis of the extract point cloud. 
finally an experiment be conduct on an actual blade with result show that the propose method be effective and efficient. 
prediction of leakage from an axial piston pump slipper with circular dimples use deep neural network. 
oil leakage between the slipper and swash plate of an axial piston pump have a significant effect on the efficiency of the pump. 
therefore it be extremely important that any leakage can be predict. 
this study investigate the leakage oil film thickness and pocket pressure value of a slipper with circular dimple under different working condition. 
the result reveal that flat slipper suffer less leakage than those with textured surface. 
also a deep learning base framework be propose for model the slipper behavior. 
this framework be a long short term memory base deep neural network which have be extremely successful in predict time series. 
the model be compare with four conventional machine learning method. 
in addition statistical analysis and comparison confirm the superiority of the propose model. 
dynamic capability building and social upgrading in tourism potential and limit of sustainability standard. 
the tourism sector be often characterize by precarious working condition. 
with the aim of promote sustainable business practice and address labour concern many tourism service provider be keen to set and enforce sustainability standard in their value chain. 
however there be a contest debate on the local impact of voluntary standard. 
this paper focus on tourism labour and investigate how sustainability standard can contribute to capability building and social upgrading process at the firm level. 
it argue that most research on sustainability standard have analyse the visible outcome of standard implementation while a process base perspective be largely miss. 
the paper address this gap through a novel approach and make both theoretical and empirical contribution. 
conceptually it integrate the dynamic capability approach into global value chain gvc research. 
this enhance current conceptualisation of capability and the understanding of upgrade process within gvc. 
empirically the paper investigate the south african standard fair trade in tourism through a longitudinal mixed method research design that extend over a period of eight year. 
the finding show how sustainability standard in tourism can contribute to capability building and upgrade at the firm level. 
the paper conclude by argue that policy maker should well resource local standard set organisation. 
transdisciplinarity science for and with society in light of the university s role and function. 
the idea that university should become entrepreneurial commercialize private commodity or should serve politician and governmental agency have be promote by the university industry government relationship base triple helix approach and be reality in many place. 
in contrast a reemphasis on university serve the public good have be demand by proponent of transdisciplinary sustainability research. 
to well understand the tension between public good orient approach of transdisciplinarity and entrepreneurial market orient triple helix and third mission approach of science practice collaboration this paper take a close look at the history of university role and function. 
we then elucidate the practice of transdisciplinary process and discuss the science for and with society approach of transdisciplinary sustainable transitioning. 
we argue that transdisciplinarity for produce groundbreaking sociotechnical solution have to serve a the public good and b call for independence academic freedom institutionalization and proper funding scheme. 
third mission conception that follow the commercialization capitalization of scientific knowledge be in conflict with the conception of science and of transdisciplinarity serve sustainable transitioning. 
the development of groundbreake idea for sustainable transition must acknowledge the complexity and contextualization of real world setting. 
therefore collaboration between practice and transdisciplinarity call for the input and cooperation of authentic practitioner the expert of practice and real wold complexity. 
the challenge of transdisciplinarity be to properly relate the fundamental expertise of practice to validate academic rigor. 
this imply that transdisciplinary research be a critical element of the university s research mission. 
a review of prognostic and health management of machine tool. 
this paper present a survey of the application of prognostic and health management maintenance strategy to machine tool. 
a complete perspective on this industry 4.0 cutting edge maintenance policy through the analysis of all its preliminary phase be give as an introduction. 
then attention be give to prognostic whose different approach be briefly classified and explain point out their advantage and shortcoming. 
after that all the work on prognostic of machine tool and their main subsystem be review highlight current open research area for improvement. 
gradient self weight linear collaborative discriminant regression classification for human cognitive state classification. 
in recent decade huge volume of datum be available to inspect human brain activity for disease detection. 
specifically the functional magnetic resonance imaging fmri be a powerful tool to enquire the brain function. 
in fmri identify the active pattern of the specific cognitive state be one of the emerge concern for neuroscientist. 
the high dimensional feature make fmri datum difficult for mining and classification because if the volume of the datum space increase then the acquire datum become sparse which lead to the curse of dimensionality problem. 
to address this concern a new feature selection and classification methodology be propose for classify the human cognitive state from fmri datum. 
initially the fmri datum be collect from the starplus and haxby dataset. 
then k near neighbor algorithm k nn) based genetic algorithm be develop to choose the optimal voxel from the active region of interest. 
the propose approach select the datum to feature subset base on k nn algorithm so the datum volume be effectively reduce and the voxel information be maintain significantly. 
the most informative voxel be give as the input for gradient self weighting that produce an optimal weight value. 
respective weight value be add to the projection matrix of linear collaborative discriminant regression classification for identify the future projection matrix that reduce the error between two individual voxel in subspace. 
the experimental outcome show that the propose methodology improve the accuracy in fmri data classification up to 0.7 23 compare to the exist method. 
event base bipartite multi agent consensus with partial information transmission and communication delay under antagonistic interaction. 
this paper mainly concentrate on the event base bipartite consensus bcs in multi agent network mans with partial information transmission pit and communication delay. 
two type of communication constraint time delay and partial information transmission make the bcs problem in mans more challenging and practical. 
a distribute event trigger scheme ets be propose for the consider mans. 
base on the propose ets it be observe that the address mans reach bc provide that the network be balance. 
a numerical example be present to demonstrate the effectiveness of the theoretical result. 
necessary and sufficient condition for normalization and slide mode control of singular fractional order system with uncertainty. 
the slide mode control smc problem for a normalize singular fractional order system sfos with match uncertainty be investigate. 
firstly sfos be normalize under constrain condition. 
then the linear slide mode sm function be design use a fractional order fo positive definite matrix and a linear matrix inequality lmi. 
the sm controller be subsequently construct base on switch law. 
finally the feasibility of the method be evaluate use a numerical example. 
event trigger hybrid impulsive control for synchronization of memristive neural network. 
this paper be concern with the complete synchronization of memristive neural network mnn with time vary delay. 
an event trigger hybrid state feedback and impulsive controller be design to save the limited system communication resource and parameter mismatch be consider in the control design process. 
base on the lyapunov functional approach and the comparison principle for impulsive system a sufficient synchronization criterion be develop to derive the master mnn and response mnn. 
additionally under the event trigger mechanism there exist a positive lower bind for inter execution time which imply the avoidance of zeno behavior. 
finally a numerical example be provide to demonstrate the effectiveness of the propose synchronization design method. 
hierarchical and multi level demand response programme consider the flexibility of load. 
demand response dr have a key role in reduce the peak load and avoid the construction of unnecessary power plant. 
in this study the new modify framework be present to plan and control dr programme drp with a novel mathematical model. 
the propose hierarchical drp be design at three time level to flatten the load curve to balance between supply and demand and to support system frequency. 
the propose structure consist of three control loop with different response time from a fraction of a second to several hour for schedule dr via define control parameter in this programme. 
to minimise load variation and customer cost the novel objective function base on weight matrix be present. 
to optimally transfer load these matrix be weight base on power market price load level and flexibility of load. 
moreover the demand flexibility index be use to take into account the uncertainty in the predict load pattern and reduce error of aggregation demand. 
the propose programme have be implement on a 20 kv feeder to indicate its effective performance compare to hop dr and centralise direct load control dlc. 
the propose mathematical model be verify by numerical result. 
the effect of cut tool coating on the form and dimensional error of machine hole in glare r fibre metal laminate. 
fibre metal laminate fml be multilayere metal composite material currently use in aeronautical structure especially where fatigue and impact resistance be require. 
fml be produce in large panel and often require assembly use the drilling process for riveting purpose. 
hole making be a critical machining process in the joining and assembly of aeronautical component which have to meet stringent tolerance requirement. 
this paper report a systematic analysis of hole integrity when drill an fml know as glare r. 
in particular the primary objective be to investigate the impact of three different drill coating tialn tin and altin tialn against several important hole parameter thrust force hole size circularity cylindricity and perpendicularity. 
the result show that tialn coat drill produce the high thrust force while tin coat drill produce hole with the low deviation between the hole diameter measure at the entry and the exit and that the drill coating be the most influential parameter for the result hole size. 
tialn coat drill result in the high circularity at the upper part of the hole while hole cylindricity tend to be good when use altin tialn  and tin coat drill. 
the anova analysis show that the drill coating and the spindle speed have a significant influence on hole size and circularity while drill coating be the only influential parameter on hole cylindricity and spindle speed be the only contribute parameter on hole perpendicularity. 
finally scan electron microscopy analysis show two distinct hole wall surface damage phenomenon due to break fibre and evacuate metallic chip. 
improvement in fatigue strength of 41cr4 steel through slide diamond burnish. 
slide burnish sb be a static mechanical surface treatment base on the severe plastic deformation of the surface for which the contact between the deform element and the surface be treat be slide friction. 
sb improve the surface integrity of metal structural and machine component dramatically. 
this paper be devoted to improve the fatigue strength of 41cr4 steel hourglass shape specimen subject to sb with a spherical end deform diamond via different combination of basic govern parameter. 
since the residual compressive stress introduce play a significant role for the fatigue behavior of the burnished component a comprehensive parametric study of the sb process be conduct use fully couple thermal stress finite element fe simulation. 
the fe model s adequacy be prove via comparison of the fe result for the residual stress with x ray diffraction measurement. 
the result obtain show that the diamond radius and the burnish force have the strong effect on the residual stress which in turn have a significant influence on the fatigue strength respectively fatigue life. 
an extensive experimental investigation of the effect of the select sb basic parameter on the fatigue limit of the slide burnish specimen be carry out use locatti s method. 
the latter be base on the palmgren miner linear damage hypothesis which be a particular case of a general cumulative damage theory. 
a plan experiment be carry out with the govern factor change among four level. 
regression analysis of the experimental result be carry out and a model for predict the fatigue limit be obtain. 
base on the model obtain a one purpose optimization be carry out use a genetic algorithm. 
by mean of the optimal basic parameter the fatigue limit of the process specimen be increase by 22.7% from 440 to 540 mpa. 
the fatigue life increase more than 100 time over after sb with the optimal basic parameter. 
error control of non equal diameter machining of globoidal cam profile base on adaptive method. 
in order to effectively tackle the machining error of globoidal cam profile an adaptive compensation method of tool position error be propose. 
the actual profile equation of the non equal diameter machining of globoidal cam be construct through the space meshing principle and the rotation transformation tensor method. 
to minimize the maximum deviation of the actual tool axis be regard as an objective and then the adaptive compensation of the tool position be perform through search the optimal tool offset amount and direction during the machining process. 
when tool radius compensation amount delta r be the value optimize by the adaptive method the theoretical maximum value of the normal error of globoidal cam be close to the simulation result. 
the validity of the error control technique of tool position of the adaptive method be verify by the simulation result and calculation. 
consequently the machining accuracy of the globoidal cam in non equal diameter machining be improve greatly. 
adaptive backstepping control for autonomous shipboard landing of a quadrotor with input saturation. 
this paper present a novel autonomous shipboard landing control algorithm of a quadrotor subject to external disturbance and input saturation. 
a couple six degree of freedom six dof nonlinear relative motion model be derive to facilitate the controller design. 
to overcome the under actuate property of the quadrotor and avoid collision the shipboard landing process be cooperatively complete by a relative position controller rpc and a relative attitude altitude controller rac. 
the rpc be propose for use when the quadrotor be far away from the ship aim to drive the quadrotor to the vicinity of the ship. 
the rac be use for the situation when the quadrotor be close enough to the ship to land the quadrotor on the ship steadily. 
an adaptive backstepping technique be propose for both rpc and rac where unknown bound of the lump disturbance be estimate online by the adaptive law. 
to satisfy the input constraint requirement a smooth model be employ to describe the control input saturation. 
stability analysis prove that all state of the closed loop system be uniformly ultimately bound. 
a numerical example verify the performance of the control approach. 
full load analysis model and experimental study on the static characteristic of linear rolling guideway joint. 
linear rolling guideway have be widely use in machine tool. 
the overall performance of machine tool be directly influence by the linear rolling guideway characteristic. 
in this study a contact model for a single ball raceway joint surface be establish base on the fundamental characteristic parameter of the joint surface which be obtain experimentally. 
base on this model a novel full load analysis model of the linear rolling guideway joint be propose and six linear rolling guideway joint stiffness type namely the tangential normal compressive and normal tensile stiffness and the pitch yaw and roll angular stiffness be obtain. 
testing device be develop for the six stiffness type. 
the stiffness of the medium preloade hjg da35aa hjg da45aa and hjg da55aa linear rolling guideway be achieve use the developed testing device and the result obtain from the full load analysis model be approximately consistent with the experimental result. 
mechanism of online dressing for micro diamond grind wheel during the ultrasound aid electrolytic in process dress grind. 
a high precision continuous dressing technology namely ultrasound aid electrolytic in process dressing method be propose in this paper aim at overcome the difficulty in continuous dressing for fine diamond wheel during the super mirror processing such as optic and aeronautic. 
firstly the influence of high frequency ultrasonic vibration on electrolysis be analyze on the basis of the mechanism of electrolysis. 
then the compare test between the common electrolytic in process dress grind and the ultrasound aid electrolytic in process dress grind of the grind wheel be employ to observe the effect of dressing and the state of abrasive particle. 
it be find experimentally that under the latter dressing the well dressing effect could be gain and the number of abrasive particle per unit area the sharpness of abrasive and the average grain protrude height be improve meanwhile the distribution of grain become more uniform. 
in addition compare with the former dressing the average distance between grain be decrease and the microscopic roughness of grind wheel physiognomy be increase in the latter dressing. 
finally the grind experiment be carry out to illustrate the advantage of the ultrasound aid electrolytic in process dress grind. 
the experimental result reveal that the removal rate and machining surface quality be increase compare with the common electrolytic in process dress grind. 
rotate consensus control of double integrator multi agent system with event base communication. 
this paper solve the rotate consensus problem for a group of double integrator agent with event base communication only. 
we propose a distribute event base rotate consensus protocol which guarantee that a consensus regard both position and velocity be achieve when all agent exhibit circular motion around the same center. 
it be observe that overall less communication be require as the communication between agent be only need at event time. 
moreover with the propose event base protocol it be prove that zeno behavior can be strictly avoid for each agent. 
numerical simulation show that this event base control law can efficiently solve the rotate consensus problem. 
a comprehensive error compensation strategy for machining process with general fixture layout. 
the modeling of equivalent fixture error efe in machining process have be prove to be an effective way for variation reduction. 
however previously develop approach do not describe the efe phenomenon of workpiece deformation. 
this paper propose a comprehensive efe model that can simultaneously transform the datum error machine tool path error and workpiece deformation to efe. 
the developed model can also describe the efe phenomenon for general fixture layout rather than be limit to an orthogonal three 2 one layout case. 
base on this comprehensive error compensation strategy the datum error machine tool path error and workpiece deformation can be compensate for machining process with general fixture layout. 
the case study demonstrate the model validity through the real machining experiment and also show a simple simulation process for error compensation. 
optimal control for discrete time descriptor noncausal systems. 
in this paper optimal control problem govern by linear discrete time descriptor noncausal system with quadratic input variable be investigate in order. 
a descriptor system assume to be regular alone be call descriptor noncausal system. 
accord to bellman s principle of optimality in dynamic programming a recurrence equation for simplify the optimal control problem be derive. 
then employ the recurrence equation a bang bang optimal control problem subject to a linear descriptor noncausal system and an optimal control problem subject to a descriptor noncausal system with quadratic input variable be both settle and the optimal solution be give through exact expression. 
a numerical example be present to illustrate the effectiveness of the result obtain concern the bang bang optimal control problem. 
learn multi agent communication with double attentional deep reinforcement learn. 
communication be a critical factor for the big multi agent world to stay organized and productive. 
recently deep reinforcement learning drl have be adopt to learn the communication among multiple intelligent agent. 
however in term of the drl setting the increase number of communication message introduce two problem one there be usually some redundant message two even in the case that all message be necessary how to process a large number of message in an efficient way remain a big challenge. 
in this paper we propose a drl method name double attentional actor critic message processor daacmp to jointly address these two problem. 
specifically daacmp adopt two attention mechanism. 
the first one be embed in the actor part such that it can select the important message from all communication message adaptively. 
the other one be embed in the critic part so that all important message can be process efficiently. 
we evaluate daacmp on three multi agent task with seven different setting. 
result show that daacmp not only outperform several state of the art method but also achieve well scalability in all task. 
furthermore we conduct experiment to reveal some insight about the propose attention mechanism and the learn policy. 
rolling bearing performance rating parameter review and engineering assessment. 
the choice of a rolling bearing for a particular application rely on performance rating parameter as the static the dynamic and the fatigue limit load of bearing. 
the value of these parameter define the calculate performance of the bearing. 
endurance testing of high quality rolling bearing have be use for the development of rolling bearing performance standard like the iso 281 and iso 76 that be commonly use throughout the industry. 
however standard test method for the measurement and validation of load rating of rolling bearing be not available in the standard. 
this lead to the undifferentiated use of the status of the art standardize performance to the very large variety of rolling bearing type and quality that be produce today. 
the current paper revisit the origin definition and development of rolling bearing performance parameter. 
a numerical study for the determination process of bear load rating be carry out. 
the result be compare with standardized value and value quote by bear manufacturer. 
this provide an overview of the load rating practice that be in use. 
the limitation and possible improvement of the present methodology be discuss. 
real time monitoring of change in build tilt angle use double square artificial mark. 
to monitor change in build tilt angle more accurately and efficiently and to safeguard the people s safety and property a new tilt angle monitoring method be propose in this paper. 
this method adopt double square artificial mark and a plumb line determine by matlab to record change in the building tilt angle base on image processing technology. 
two black square artificial mark with the size of 10 mm x 10 mm be place near the side of the plumb line. 
a digital camera be adopt to collect tilt image which be save in the computer. 
the tilt image be successively subject to image greying binarization denoising image segmentation and pixel calibration. 
finally the true length of a single pixel and tilt angle change value would be obtain. 
the experimental result show that the accuracy of the method be 96 high than the manual method. 
compare with traditional manual method and three dimensional scanning monitoring method the advantage of this method be that the equipment use be relatively cheap the image calculation workload be small and be suitable in dangerous working condition. 
in conclusion the propose technique could accurately concisely and effectively calculate the change in build tilt angle and improve work efficiency. 
level set topology and shape optimization by density method use cut element with length scale control. 
the level set and density method for topology optimization be often perceive as two very different approach. 
this have to some extent lead to two compete research direction work in parallel with only little overlap and knowledge exchange. 
in this paper we conjecture that this be a misconception and that the overlap and similarity be far great than the difference. 
to verify this claim we employ without significant modification many of the base ingredient from the density method to construct a crisp interface level set optimization approach use a simple cut element method. 
that is we use the same design field representation the same projection filter the same optimizer and the same so call robust approach as use in density base optimization for length scale control. 
the only noticeable difference lie in the finite element and sensitivity analysis here base on a cut element method which provide an accurate tool to model arbitrary crisp interface on a structured mesh base on the thresholding of a level set or density field. 
the present work include a heuristic hole generation scheme and we demonstrate the design approach on several numerical example cover compliance minimization and a compliant force inverter. 
finally we provide our matlab code downloadable from www.topopt.dtu.dk to facilitate further extension of the propose method to multiphysic problem. 
an adaptive failure boundary approximation method for reliability analysis and its application. 
in practical engineering problem accurate reliability assessment often be computationally expensive with time consume numerical model or simulation model. 
how to obtain an accurate reliability index with a few number of call to original performance function in reliability analysis have become an important challenge. 
for the purpose of reduce the computational cost in reliability analysis this work develop an adaptive failure boundary approximation method afbam by combine kriging and uniform sample with a new adaptive learning strategy. 
the propose afbam make full use of the binary classification feature of reliability analysis in the way that the failure boundary of the original model can be efficiently approximate. 
the number of experimental design sample be constantly update by select informative sample with the propose learning strategy. 
in order to ensure classification accuracy of the constructed kriging model a new stopping criterion be design base on average misclassification probability and misclassification ratio. 
the propose afbam technically make reliability evaluation phase independent of adaptive iterative process which greatly improve the efficiency of model refinement phase. 
at last five example involve nonlinearity problem small failure probability problem and practical engineering problem be test to verify the efficiency of the propose afbam. 
machinability property of al 7si al 7si 4zn and al 7si 4zn 3cu alloy. 
al 7si al 7si 4zn al 7si 4zn 3cu alloy be produce by permanent mold casting method to investigate the effect of copper and zinc addition on the machinability property of al 7si alloy. 
the structural and mechanical property of the produce alloy be investigate with conventional method. 
machinability property of these alloy be determine by turn and they be associate with structural and mechanical property of the alloy. 
machinability experiment be carry out in cnc vertical machining center under dry cutting condition use uncoated carbide drill and constant cutting speed 120 m min feed 0.15 mm rev and depth of cut 15 mm value. 
the microstructure of al 7si binary alloy be observe to be compose of aluminum rich alpha phase primary silicon crystal and eutectic al si phase. 
the addition of four zn to the al 7si alloy do not form a different phase in the microstructure. 
however al2cu intermetallic phase be form by addition of three cu. 
while the hardness and tensile strength of the alloy increase elongation to fracture significantly reduce. 
as a result of machinability experiment it be observe that the minimum thrust force and surface roughness occur in al 7si 4zn 3cu alloy while the maximum build up edge be observe during drilling of al 7si and al 7si 4zn alloy. 
microhardness value of machine surface in al 7si alloy be find to be the minimum while the maximum al 7si 4zn 3cu alloy be observe. 
out of roundness compensation technique in machining of femoral head prosthesis use conventional cnc machine. 
in manufacturing of femoral head prosthesis the roundness of the femoral head be important. 
in order to reduce out of roundness when machine with a conventional cnc machine a compensation technique with a fast tool servo be develop. 
the fast tool servo with piezoelectric actuator be fabricate and instal on a conventional cnc machine and a compensation technique be implement to compensate for the out of roundness. 
the profile of machine femoral head be analyze and use to develop a representative profile. 
the experiment be conduct to confirm the prior statistical analysis. 
the result show that the compensation technique reduce the out of roundness of femoral head prosthesis to 4.04 0.54 mu m.. 
a spectral clustering method to improve importance rating accuracy of customer requirement in qfd. 
quality function deployment qfd be a method commonly use in manufacture industry to identify customer requirement crs and the manufacturing capacity to meet cr. 
importance rate ir of cr play an important role in the qfd method. 
the exist method in determine ir of cr can not consider all relate factor of customer satisfaction need importance personal information and relationship between customer satisfaction and function implementation. 
this paper propose a method to improve the ir accuracy. 
base on comment of customer for a product importance rate of cr be define use integrated importance performance analysis ipa and kano model. 
ipa and kano model be integrate by spectral clustering where a similarity matrix w be form to balance the influence proportion between the ipa and kano model consider comment of different customer for the product. 
ir of cr be use in the qfd method to define function and structure of the product. 
the propose method be compare with several exist method in case study of design an upper limb rehabilitation device and a feed drive system of the cnc machine. 
result show that the propose method have improve accuracy of ir of cr for the product design and manufacturing. 
digital twin base production scheduling system for heavy truck frame shop. 
exist scheduling system can not respond quickly and efficiently to the appearance of uncertain variable interference factor in the scheduling process. 
the efficiency of the enterprise be hence seriously affect by these factor. 
the concept of the digital twin provide new research direction for scheduling system. 
in order to improve the overall performance of the production scheduling system in a frame shop virtual real fusion technology utilize the digital twin be first introduce to integrate the information and logistic flow in the scheduling process as part of the manufacturing execution system base production scheduling mechanism. 
the balance optimization of the mixed flow production line be then carry out and the mix flow production line balance and sequence model be establish. 
a scheduling system for the frame shop combine various system function be finally design base on the sequence model and production status. 
the scheduling system comprehensively consider the two uncertain factor of material and order to generate scheduling information through an intelligent scheduling mode while realize real time synergy between the information and logistic flow. 
the system have achieve excellent implementation result in the frame shop and provide a reference for the application of digital twin in production workshop. 
a novel approach to plasma channel radius determination and numerical modeling of electrical discharge machining process. 
in this investigation a single discharge of electrical discharge machining edm have be simulate use finite element method fem to obtain the temperature distribution on the workpiece surface. 
the dimension of discharge crater on workpiece surface be calculate use temperature distribution profile and a fem model for material removal rate be develop for edm process. 
also the plasma channel radius be obtain by a newly develop mathematical model and use at simulation stage. 
consider the maximum error of 8.2 between the recast layer thickness obtain by numerical and experimental approach the numerical result be use to study the influence of pulse current and pulse duration as input parameter on plasma efficiency in ejection of the molten material from molten puddle on machine surface and recast layer thickness. 
the result show that enhancement of pulse current lead to increase plasma flush efficiency and increase pulse duration decrease plasma flush efficiency and enhance recast layer thickness. 
an efficient approach to improve the finish property of abrasive flow machining with the analysis of initial surface texture of workpiece. 
abrasive flow machining afm be a non traditional finishing process by use the semi solid abrasive medium as a finish tool and usually apply to finish fine complex component in manufacturing industry. 
in afm process the final surface quality and finish efficiency be crucial finish property which have draw wide attention and be always affect by initial surface texture of the workpiece. 
in the present research the flow direction of abrasive medium be determine accord to the calculation of surface anisotropy ratio s tr and texture direction s td of the initial surface texture by use the autocorrelation function and selection of particle size be give after calculation of the spatial frequency of the initial surface texture use a fast fourier transform. 
it be find that the flow direction of abrasive medium should be perpendicular to the orient surface texture and the particle size in abrasive medium have a strong relationship to the first harmonic frequency f(1 of surface texture. 
finally the above approach be employ to the surface finish analysis of an aero engine blade and its efficiency be verify in the improvement of finish property. 
analysis of insulation diagnosis for generator motor stator wind in pumped storage power plant. 
in this study insulation diagnostic test be conduct on pump storage power plant pspp generator motor stator bar with artificially simulate defect in order to improve solution to perform preventive maintenance and track insulation diagnostic datum for generator motor by prove the effectiveness of insulation index. 
moreover ozone o three concentration be estimate in order to relate it to partial discharge pd in laboratory to ensure the effectiveness of ozone as another index for insulation deterioration. 
by perform an offline pd test and ultraviolet uv observation on one of the generator motors during overhaul and an ozone concentration measurement for the identical machine after the overhaul it be conclude that ozone estimation could be a powerful index for insulation diagnosis under actual operational condition. 
it be far develop that ozone measurement be useful to detect not only discharge in slot as mention in some study but also discharge at the end winding as prove in this study. 
the finding of this study be expect to contribute to more reliable maintenance of generator motors in pspp by achieve elaborate insulation diagnosis via multiple diagnostic index. 
a hybrid circular economy game theoretical approach in a dual channel green supply chain consider sale s effort delivery time and hybrid remanufacturing. 
the circular economy ce and the marketing activity be the key subject to attract the market share in today s complex supply chain. 
here dual selling channel the online delivery time and the distributor sale effort be consider as marketing activity to attract the customer. 
moreover in order to meet the economic and environmental principle of the ce three responsibility to ease the carbon emission as approach for the return on investment be devise include investment in the green production the cap and trade regulation and the hybrid remanufacturing via both the manufacturer and the distributor under the technology license. 
this such complex supply chain need to determine the equilibrium amount of the distinguish element include the pricing strategy remanufacture approach delivery time and sale effort to abate the conflict between the member and consequently to enhance the economic and ce objective of the supply chain sc. 
in order to obtain the equilibrium decision making three game theoretical approach include the manufacturer stackelberg game sm the distributor stackelberg game sr and the nash game n be employ. 
the interaction between the game sequence and the remanufacturing process be the key purpose of this paper to not only maximize the profit of sc but also to enrich the ce and marketing goal of this research. 
the outcome present that the sm game where the manufacturer remanufacture most of the defect product which be collect via the distributor be the good game strategy to improve the profit of both the distributor and the manufacturer and also to enhance the other distinguish element. 
in addition in the sr game when most of the return remanufacture via the distributor under the manufacturer license it not only maximize the profit of member but also lead to the improvement of the distinguish element. 
in the nash game however there be a conflict between the member about the remanufacturing process which reduce the sc profit in this game as compare to other one. 
c 2019 elsevier ltd. 
all right reserve. 
script capital h two and script capital h infinity analysis and state feedback control design for discrete time constrain switch linear system. 
this paper present the stability and performance condition for discrete time constrain switch linear system under arbitrary switching. 
design method for such system which constrain the set of admissible switch sequence to attain stability and a desire performance level be also present. 
the key procedure present in this paper be base on classic convex optimisation and graph theory result. 
simulation and numerical example be include to illustrate the main feature of the develop theory. 
a study on automatic fixture design use reinforcement learning. 
fixture be use to locate and secure workpiece for further machining or measurement process. 
design of these fixture remain a costly process due to the significant technical know how require. 
automate fixture design can mitigate much of these cost by reduce the dependence on skilled labour make it an attractive endeavour. 
historical attempt in achieve automate fixture design solution predominantly rely on case base reasoning cbr to generate fixture by extrapolate from previously prove design. 
these approach be limit by their dependence on a fixture library. 
attempt in use rule base reasoning rbr have also show to be difficult to implement comprehensively. 
reinforcement learning on the other hand do not require a fixture library and instead build experience and learn through interact with an environment. 
this paper discuss the use of reinforcement learning to generate optimize fixture solution. 
through a propose reinforcement learn drive fixture design rl fd framework reinforcement learning be use to generate optimize fixture solution. 
in response to the fixture environment adjustment to the reinforcement learning process in the exploration phase be study. 
a case study be present compare a conventional exploration method with an adjust one. 
both agent show improved average result over time with the adjust exploration model exhibit fast performance. 
morphological characteristic and formation mechanism of the ud cfrp drill exit damage. 
carbon fiber reinforce plastic cfrp be use widely in many industry. 
during drill cfrp exit drill induce defect such as burr and delamination be easy to occur. 
in the exist model the crack zone be assume as a circle or an ellipse and concrete forming process of the delamination and the burrs do not be truly involve. 
in this study the formation mechanism of the delamination and the burr be analyze base on the analytical model and the experimental observation. 
the result indicate that the critical thrust force only reflect the vulnerability of the crack but can not determine the size of the crack. 
the critical deflection of the fiber tip correspond to the interlaminar crack extension point determine the size of crack. 
the burr appear in four fundamental type. 
statistical approach for semi supervised anomaly detection in machine. 
numerous method have be develop to detect process anomaly during machine. 
statistical approach for semi supervised anomaly detection compute decision boundary use information of normal running process for process evaluation. 
in this paper two statistical approach for semi supervised anomaly detection in machining base on envelope be present and compare. 
the propose parametric approach assume normal distribute envelope to compute decision boundary. 
however experiment show that deviation from a normal distribution can reduce the monitoring quality. 
the new approach be non parametric and employ kernel density estimation kde to estimate the probability density function of the envelope. 
both approach be evaluate for several machining process. 
it be find that the parametric approach be robust against high scattering process and yield low false alarm rate. 
by mean of the select safety factor the number of detect anomaly can be increase use the non parametric approach. 
fuzzy logic and sub clustering approach to predict main cutting force in high pressure jet assist turn. 
due to the complexity of the high pressure jet assist turning knowledge and prediction of the cut force be essential for the planning of machine operation for maximum productivity and quality. 
however it be well known that during processing use this procedure there be difficulty in collect datum. 
it be require to establish an adequate model that would make it possible to predict the cut force base on the input parameter. 
during machine to avoid difficulty in acquisition datum two model have develop base on fuzzy logic that will allow indirect monitoring of the cut force. 
this research use the improve fuzzy logic method for modeling whereby it can make prediction of the main cutting force accord to the different input parameter. 
the contribution of this work reflect through the application of two innovative method base on reduce the number of rule which lead to well interpretability of model. 
first be the mamdani with rule reduction method and second be the sugeno sub clustering method base on the identification of the model structure it come down to find the required number of rule by form specific cluster. 
both approach differ by reduce the number of rule without affect the accuracy of the model. 
the ability to predict the model determine by apply different statistical parameter. 
it conclude that mamdani and sugeno model give an approximate quality of the prediction. 
the result model also have an acceptable error to predict datum that do not participate in their creation. 
furthermore obtain model can be use at the generalization stage where the cut force information be require and where direct measurement be not possible. 
spoken language identification base on particle swarm optimisation extreme learning machine approach. 
the determination and classification of natural language base on specify content and datum set involve a process know as spoken language identification lid. 
to initiate the process useful feature of the give datum need to be extract first in a mature process where the standard lid feature have be previously develop by employ the use of mfcc sdc gmm and the i vector base framework. 
nevertheless optimisation of the learning process be still require to enable a comprehensive capturing of the extract feature embed knowledge. 
the training of a single hide layer neural network can be do use the extreme learning machine elm which be an effective learning model for conduct classification and regression analysis. 
nevertheless the learning process of this model be not entirely effective i.e. 
optimise due to the random selection of weight within the input hide layer. 
this study employ elm as the lid learning model centre upon the extraction of the standard feature. 
the enhanced self adjust extreme learning machine esa elm be one of the elm s optimisation technique which have be choose as the benchmark and be enhance by adopt a new alternative optimisation approach pso instead of eatlbo in term of achieve high performance. 
the improved esa elm be name particle swarm optimisation extreme learn machine pso elm. 
the generate result be base on lid with the same benchmarke datum set derive from eight language which indicate the superior performance of the particle swarm optimisation extreme learn machine lid pso elm lid with an accuracy of 98.75 in comparison with the esa elm lid which only achieve 96.25. 
real time automatic optical system to assist operator in the assembling of electronic component. 
this work present an optical inspection guide system for electronic board manufacturing. 
the system monitor in real time the mount process of electronic component perform by an operator. 
it visually guide the operator through the mount process while check the correctness of its action. 
as a consequence mount error be reduce while operator comfort be enhance. 
this work also introduce a novel method to generate virtual image from a few real image in order to generate enough datum for model training. 
the propose method be test use seven different descriptor combination and four different classifier. 
we have also collect generate and evaluate a component dataset of 20 different component call ecad. 
the solution be test with 16 real scenario different electronic board which be empty or full with component. 
finally a usability test be carry out with 21 different people compare the original and propose solution. 
the propose system be advantageous since it enhance operator s comfort and satisfaction increase mount speed and reduce error ratio. 
neural network adaptive finite time control of stochastic nonlinear system with full state constraint. 
this paper investigate the issue of neural network adaptive finite time tracking control for stochastic nonlinear system subject to full state constraint. 
in the controller design process neural network be employ to cope with the pack uncertainty and the log type barrier lyapunov function be introduce to prevent the violation of the state constraint. 
by use approximate base neural network and adaptive backstepping technique a novel finite time control approach be present. 
the design control method not only make the tracking error converge to a small neighborhood of the origin in a finite time but also surmount the effect of state constraint to system performance. 
a numerical simulation example be provide to illustrate the validity of the design control method. 
automated testing in robotic process automation project. 
robotic process automation rpa have receive increase attention in recent year. 
it enable task automation by software component which interact with user interface in a similar way to that of human. 
an rpa project life cycle be closely resemble a software project one. 
however in certain context e.g. business process outsourcing a testing environment be not always available. 
thus deploy the robot in the production environment entail high risk. 
to mitigate it an innovative approach to automatically generate a testing environment and a test suite for an rpa project be present. 
the activity of the human whose process be to be robotize be monitor and a ui log be confirm. 
on one side the test environment be generate as a fake application which mimic the real environment by leverage the ui log information. 
the control flow of the application be govern by an invisible control layer that decide which image to show depend on the interface action that it receive. 
on the other side the test case check whether the robot can reproduce the behaviour of the ui log. 
promising result be obtain and a number of limitation be identify such that it may be apply in more realistic domain. 
optimization of wedm process parameter in machine nimonic 75 alloy use brass wire. 
purpose an experimental study have be conduct to model and optimize wire electric discharge machining wedm process parameter such as pulse on time pulse off time servo voltage and peak current for response characteristic during machining of nimonic 75 alloy. 
design methodology approach the response surface methodology rsm) base box behnken s design have be employ for experimental investigation. 
rsm be use for develop quadratic regression model for select response variable material removal efficiency and kerf width. 
to validate the model confirmation experiment have be perform. 
the multi response optimization have be do use desirability function approach. 
finding through analysis of variation the percent contribution of process parameter on the response characteristic have be find. 
pulse off time be the most significant parameter affect the kerf width and material removal efficiency follow by pulse on time. 
the quadratic regression model have be develop for prediction of select response variable. 
an attempt have be make to optimize the wedm parameter for material removal efficiency and kerf width. 
the recommend process parameter set for maximum material removal efficiency and minimum kerf width have be find to be pulse on time 0.6 mu s pulse off time 14 mu s servo voltage 25 v and peak current 200 a. 
originality value the kerf width be an important response variable for maintain dimensional accuracy of the machine component but have not be give due attention by the researcher. 
in the present work the develop regression model for kerf width can be use in estimate wire offset setting and thereby get a dimensionally accurate product. 
the optimum process parameter obtain in wedm of nimonic 75 alloy will contribute in database of machine. 
the outcome of this study would be add to scare database of the machining of nimonic 75 alloy and also would be extremely useful for make the technology chart for wedm. 
optimization and experimental study of an intelligent bamboo splitting machine charge manipulator. 
a nonautomatic bamboo splitting machine must charge with material and change tool manually. 
however manual charging be very dangerous. 
an intelligent bamboo splitting machine can feed automatically and change tool intelligently and have broad application prospect. 
a charge manipulator be an important part of an intelligent bamboo splitting machine. 
the size of the manipulator be optimize here use a genetic algorithm. 
the capture rate center rate and dynamic characteristic of an intelligent bamboo splitting machine charge manipulator in which key factor be consider be experimentally study. 
first three different manipulator with arm length at 210 220 and 230 mm be develop. 
then the bamboo material be divide into three gradient 60 85 85 110 and 110 135 mm accord to diameter range. 
accelerator be use to measure the manipulator arm dynamic characteristic and a high speed charge couple device be use to record the grasping process. 
experimental result show that the manipulator capture rate with an arm length of 220 mm be as high as 100 but that of manipulator with arm length of 210 and 230 mm be 96 and 98.67 respectively. 
thus the manipulator with a 220 mm arm length show well performance than the other two manipulator. 
trend curve of the influence of material diameter on capture time be similar to an exponential function. 
machine vibration monitoring base on dynamic clamp force measure in thin walled component mill. 
in milling of thin walled structure such as impeller or blisk critical workpiece vibration occur due to the excitation by the cut force and the dynamic interface between the workpiece and the fixture. 
vibration may cause instable state of the milling process thus decrease the production outcome by cause reject. 
in respect to the milling process of thin walled workpiece a challenging task be to monitor the critical vibration occur in the workpiece itself or the contact surface between the workpiece and the clamp system. 
vibration can be reflect in the clamp system and thus the clamp force variation monitoring be a potential scenario or solution to the challenging task. 
this article introduce a measurement prototype for the real time dynamic clamp force monitoring. 
with respect to the measurement of clamp force two case study be carry out by a direct sensing method with pvdf thin film sensor. 
in the first study the measurement prototype with embed pvdf sensor be locate on the dynamometer and an additional eddy current transducer be apply for monitor the workpiece deflection during the milling process. 
deflection signal and cut force signal from dynamometer be use as two referential signal to demonstrate the reliability of the prototype with embed pvdf sensor. 
in the second study mill test with the same tool and workpiece be implement with only pvdf sensor monitor. 
dynamic clamping signal vary with different cutting duration in time frequency and time frequency domain and different milling surface result be perform. 
relationship between the collected signal and machining result be preliminarily analyze. 
case study with thin walled workpiece show the performance of the measurement prototype. 
bend process for produce uniform angle distribution from ultra high strength steel sheet have thickness distribution. 
because of the elastic deformation of roll mill in rolling the edge drop in thickness of roll ultra high strength steel sheet be remarkable thus the thickness distribution be not uniform. 
the distribution of angle before and after unload in v bending of the ultra high strength steel sheet have such a thickness distribution be measure. 
the bend angle be nonuniformly distribute by the insufficient bend angle at the bottom dead centre and springback during unload. 
the effect of the bent angle and thickness distribution on the springback in thin and thick edge be discuss. 
the distribution of bend angle be reduce by bottom with a three piece die use a rubber pad. 
it be find that bottom with a divide die use a rubber pad in bend be effective in improve the dimensional accuracy of ultra high strength steel sheet have a thickness distribution by finite element simulation and experiment. 
on the singular risk sensitive stochastic maximum principle. 
we consider a risk sensitive stochastic control problem of a nonlinear system in which the variable control have two component the first be absolutely continuous and the second be singular. 
the author generalize the result obtain in risk neutral into risk sensitive performance cost. 
the auxiliary process have be introduce to solve the problem of risk sensitive. 
the relationship between the expect exponential utility and the quadratic backward stochastic differential equation have be give and prove. 
actually i have prove in detail two result the first be necessary optimality condition while the second be sufficient optimality condition for risk sensitive performance cost. 
two example to carry out to illustrate our main result of risk sensitive control problem under nonlinear stochastic dynamic with exponential quadratic cost function with numerical investigation while the second will be in the exponential utility optimization problem. 
research on key control technology of intelligent rolling contact fatigue test facility. 
an intelligent rolling contact fatigue test equipment be develop and the control method be present. 
for obtain the slip accurately the control method base on master slave synchronization be propose. 
for control the load in high precision the control method take into consideration the influence by two factor displacement and the load. 
the nonlinear interference and excess torque in load control be effectively suppress. 
base on the simotion d425 which be the siemens integrate motion control system the control system architecture of the intelligent rolling contact fatigue test equipment be construct. 
the solution of slip ratio and the experimental load control by these method be satisfactory with the requirement of design precision. 
in the validation experiment the load control accuracy be three the average error of load control be 1.77 and the average error of slip control be 0.26. 
the experiment result show the propose control method be feasible and effective. 
analysis fabrication and detailed comparative study of surface and interior rotor pmsm prototype of identical nominal rating and stator. 
this paper present an in depth analysis performance evaluation and comparative study of two five kw eight pole 750 rpm laboratory prototype of a permanent magnet synchronous motor pmsm of identical nominal rating with surface and interior permanent magnet pm rotor structure have same stator and armature wind fractional slot distribute wind. 
the key electrical such as rate voltage current power speed number of pole etc and mechanical variable such as overall volume air gap length rotor diameter shaft dimension and magnetic material of the fabricate prototype have also be keep same to pin point the direct influence of the two different rotor configuration surface and interior pmsm on the parameter performance and operation of these pmsm. 
for the two machine a detailed comparison of air gap flux density distribution thd in induce voltage torque ripple loss efficiency torque speed characteristic field weakening capability steady state parameter at different operating condition etc. 
have be conduct. 
the salient observation from this comparative study have be duly highlight. 
this paper also include an in depth comparison of volume and cost of pm use in the two type of pmsm. 
the short time performance figure of the say motor have also be present. 
the possibility of demagnetisation of pms during a sudden fault have also be investigate for both pmsm. 
challenge of making of both rotor have be discuss. 
the theoretically determined parameter and analytically evaluate performance figure have be verify through standard fem package and then validate experimentally on the prototype. 
dynamic output feedback control of system with event drive control input. 
in this paper a dynamic output feedback control problem be investigate for system with event drive control input. 
with both continuous and sample output measurement in the system two type of dynamic output feedback controller be design base on a predefine event drive scheduler for the control signal respectively. 
with the propose event drive control scheme the zeno behavior can be avoid and the state of closed loop system be also guarantee to be globally uniformly ultimately bound. 
detailed parameter of the event drive controller be construct under the stabilizable condition of the closed loop system. 
finally both the effectiveness and merit of the propose design technique be verify by the numerical example. 
technological frames and care robots in eldercare. 
care robot be often portray as an exciting new technology for improve care practice. 
whether these robot will be accept and integrate into care work or not be likely to be affect by the assumption expectation and understanding hold by potential end user such as frontline staff and the people that be care for. 
this paper describe how the conceptual framework of technological frame be use to identify the nature of care robot care robot in use and care robot strategy as share group level assumption expectation and understanding of care robot among care staff and potential care receiver. 
focus group be conduct with 94 participant. 
these group consist of line manager frontline care staff old people and student training to become carer. 
the technological frame of the nature of care robot reveal two complementary component care robot as a threat to the quality of care and care robot as substitute for human and human care hold together by imaginary of care robot. 
the technological frame of care robot in use reveal aspect of prospective end user uncertainty of their ability to handle care robot and their own perceive lack of competence and knowledge about care robot. 
in addition the follow potential criterion for successful use of care robot be identify adequate training incentive for usage need and motive usability accessibility and finance. 
the technological frame of care robot strategy be reveal as believe cost saving and staff reduction. 
the novelty of the result and their relevance for science and practice be derive from the theoretical framework which indicate that adoption of care robot will be dependent on how well society succeed in collectively shape congruent technological frame among different stakeholder and align technological development accordingly. 
from 360 degree camera toward to virtual map app design low cost pilot study. 
currently virtual reality vr be a trend both in general and in specific field such as interactive map. 
the article aim to test the possibility of deployment of low cost virtual reality environment for the 3d spatial panoramic application. 
it discuss and compare modern trend in hardware panoramic camera and glass and software in the field of virtual reality. 
many panoramic map application e.g. the well know google street view allow we to navigate through application use vr headset or on an ordinary 2d monitor. 
the main aim of the article be to design develop and deploy vr map application with different level of user interaction. 
it present two pilot study with different user s interactivity and technical solution simple 2d base map with 360 degree panoramic photo and true 3d application for vr glass. 
the article focus on the possibility of create low cost map application. 
therefore the working process from camera toward to virtual map application be describe as follow up case study. 
recognise waste use potential to achieve a circular economy. 
waste management historically focus on the protection of human health and the natural environment from the impact of littering and dispersion of pollutant. 
an additional and more recent concern be the resource value of waste. 
our analysis show that the regulatory concept of waste in the european union which comprise environmental principle the legal definition of waste legal requirement and policy implementation be not fit for address this concern. 
the legal definition of waste overlook the context of waste fail to consider the interest of the waste user as oppose to the waste holder and aim to control the impact of careless discard rather than stimulate careful discard. 
to address these challenge we suggest a legal requirement to recognise the potential of waste to be use operationalise by formulate a waste use potential which express how and how much waste can be use as a resource give enable condition. 
recognition of waste use potential highlight local opportunity for reuse and recovery reduce the likelihood of careless discard and reveal the interest of possible waste user to the waste holder. 
the waste use potential may be employ in the formulation and evaluation of policy for industrial and municipal solid waste in a circular economy. 
c 2020 elsevier ltd. 
all right reserve. 
numerical solution of fractional optimal control problems with inequality constraint use the fractional order bernoulli wavelet functions. 
this paper study the fractional optimal control problem focp with inequality constraint. 
use the caputo definition an optimization method base on a set of basis function namely the fractional order bernoulli wavelet function f bwfs be propose. 
the solution be expand in term of the f bwfs with unknown coefficient. 
in the first step we convert the inequality condition to equality condition. 
in the second step we use the operational matrix om of fractional integration and the product om of f bwfs with the help of the lagrange multiplier technique for convert the focp into an easy one describe by a system of nonlinear algebraic equation. 
finally for illustrate the efficiency and accuracy of the propose technique several numerical example be analyse and the result compare with the analytical or the approximate solution obtain by other technique. 
estimation of tool wear and optimization of cut parameter base on novel anfis pso method toward intelligent machining. 
compact graphite iron cgi play an important role in contemporary manufacturing of automobile engine and coated tool be the good choice for milling of cgi. 
but study about the estimation of the wear of coated tool be still rare and incomplete. 
as tool wear be the main factor that affect the quality of machine surface in this study we propose an intelligent model adaptive neuro fuzzy inference system anfis to estimate the tool wear and anfis be learn by the improved particle swarm optimization pso algorithm. 
as the pso algorithm be easy to fall into the local minimum the vibration and communication particle swarm optimization vcpso algorithm be propose by introduce the self random vibration and inter particle communication mechanism. 
besides that to obtain the optimal combination of mill parameter the multi objective optimization base on minimum cutting power surface roughness and maximum material removal rate mrr be study use vcpso algorithm. 
the experimental result show that the anfis learn by vcpso algorithm anfis vcpso have well performance for the estimation of tool wear compare with other intelligent model. 
the vcpso algorithm be test use benchmark function and the result show vcpso algorithm have the global optimization ability. 
meantime the good combination of mill parameter under different tool wear status be obtain through vcpso algorithm. 
the propose anfis vcpso model as a new intelligent model can be apply for real time tool wear monitoring which can improve the machining efficiency and prolong tool life. 
in order to meet the requirement of green and intelligent manufacturing the good combination of mill parameter be also obtain in this work. 
the development of a micro pattern manufacturing method use rotate active tool with compensation of estimate error and an lms algorithm. 
in this paper technique for machining and micro structuring dimple and groove on the interior of cylinder use an active rotate tool be discuss. 
microscopic dimple and groove pattern on the inner surface of a cylinder act as lubrication and reduce friction. 
the active rotate tool present here be equip with a gap sensor that can measure the distance between the tool workpiece and machine tip so that micron scale dimple and groove can be pattern and connect to piezoelectric actuator. 
electronic control and power connection be make to the external controller via a slip ring. 
accurate measurement of the distance between the tool and workpiece be use to increase the lubrication effect by machine pattern with uniform size and depth. 
it be difficult to accurately measure error in cylinder of various shape use a single gap sensor thus we employ two gap sensor to ensure accurate assessment of cylinder shape and a least mean square algorithm be implement to compensate for the measure runout error which be track and compensate use the gap sensor. 
the method present here reduce error on the inner face of a cylinder and produce a uniform pattern. 
examine the use of temporal difference incremental delta bar delta for real world predictive knowledge architectures. 
prediction and predictive knowledge have see recent success in improve not only robot control but also other application range from industrial process control to rehabilitation. 
a property that make these predictive approach well suited for robotic be that they can be learn online and incrementally through interaction with the environment. 
however a remain challenge for many prediction learning approach be an appropriate choice of prediction learn parameter especially parameter that control the magnitude of a learn machine s update to its prediction the learning rate or step size. 
typically these parameter be choose base on an extensive parameter search an approach that neither scale well nor be well suited for task that require change step size due to non stationarity. 
to begin to address this challenge we examine the use of online step size adaptation use the modular prosthetic limb a sensor rich robotic arm intend for use by person with amputation. 
our method of choice temporal difference incremental delta bar delta tidbd learn and adapt step size on a feature level importantly tidbd allow step size tuning and representation learn to occur at the same time. 
as a first contribution we show that tidbd be a practical alternative for classic temporal difference td learning via an extensive parameter search. 
both approach perform comparably in term of predict future aspect of a robotic data stream but td only achieve comparable performance with a carefully hand tune learning rate while tidbd use a robust meta parameter and tune its own learning rate. 
secondly our result show that for this particular application tidbd allow the system to automatically detect pattern characteristic of sensor failure common to a number of robotic application. 
as a third contribution we investigate the sensitivity of classic td and tidbd with respect to the initial step size value on our robotic datum set reaffirm the robustness of tidbd as show in previous paper. 
together these result promise to improve the ability of robotic device to learn from interaction with their environment in a robust way provide key capability for autonomous agent and robot. 
reliability analysis of a tendon drive actuation for soft robot. 
the reliability of soft robotic device will be the bottleneck that slow their commercialization. 
in particular fatigue failure issue be a major concern. 
thus reliability should be take into account from the early stage of development. 
however to date there have be no attempt to analyze the reliability of soft robotic device in a systematic manner. 
when soft robot be employ to force transmission application reliability be typically a dominant issue since soft robotic structure be construct with soft material component these material have highly nonlinear property that arise due to the large distribution in the material property. 
furthermore reliability should be analyze from the robot s system down to the component use domain knowledge about the system this require a systematic approach. 
this study present a framework for reliability analysis of soft robotic device take into account a probability distribution that have not be consider before and examine a case study of a tendon drive soft robot. 
this study focus specifically on the a concept design process b lifetime analysis process and c design and optimization process. 
a life model that consider distribution be propose using accelerate life testing base on analysis of the failure mechanism of the tendon drive system. 
the tensile stress of the wire be varied during the experiment with different bend angle and output tension. 
the result be validate with different stress level use a testbed to simulate an actual application. 
the propose reliability analysis methodology could be apply to other soft robotic system such as pneumatic actuator to improve the reliability relate property during the robot design stage and the life model can be use to estimate the device lifetime under various stress condition. 
research on quality problem management of electric power equipment base on knowledge data fusion method. 
the quality of electric power equipment directly affect and decide the securable and stable operation of the power grid. 
reveal the quality problem cause and influence factor be consider as the key point to improve and guarantee the quality of power apparatus. 
however the datum of power supply quality problem have the feature of diversity and complexity. 
it be of great value to take the full advantage of the multi source heterogeneous datum especially the possess flow information trace time and space to locate vulnerable process problem cause and influence factor. 
this study put forward a data source system which include general information quality problem information process flow information and other supplementary information. 
furthermore an improved neural network model utilise knowledge data fusion method be propose. 
in this way the efficiency and accuracy of analysis for quality problem be available and enhance. 
to verify the validity of the knowledge data fusion model a case study with 2084 sample datum of gas insulate switchgear be carry out prove help to strengthen the management and control measure of power equipment quality problem. 
synthesised objective collaborative model and its solution algorithm for transmission distribution coordinate optimisation. 
as the coupling between transmission system and distribution system be significantly enhance transmission distribution coordinate optimisation become more and more necessary. 
consider that the objective of the transmission system operator tso and the distribution system operator dso be usually significantly different in the type and dimension a synthesised objective collaborative model be propose in this study by normalise different objective introduce a weight factor to reflect the importance degree difference of multiple objective and construct a common objective. 
then a modified heterogeneous decomposition m hgd algorithm be propose to solve the model. 
in the m hgd two modification on the update of iterative variable and the stop criterion be propose which effectively relieve the fluctuation of the iterative variable and restrain the tail effect of the convergence curve. 
the propose model and algorithm can avoid privacy issue between the tso and the dso achieve pareto optimality solution and have powerful flexibility. 
numerical experiment validate the effectiveness of the propose model and demonstrate that the m hgd have high accuracy and have well convergence and efficiency than traditional distribute optimisation method. 
investigation on laser induce oxidation assist micro milling of inconel 718. 
poor surface quality and rapid tool wear be the main problem in micro cutting of inconel 718. 
in this study a novel hybrid machining method name laser induce oxidation assist micro milling be propose to solve the aforementioned problem. 
a loose oxide layer and a relatively flat sublayer be form on the material after laser irradiation. 
under optimize laser parameter with a scan speed of one mm s and an average laser power of 4.5 w the thickness of the oxide layer and the sublayer be 24 and 18 mu m respectively. 
the influence of cut parameter on mill force surface roughness surface quality and top burr size be study in detail. 
cut force and thrust force in the propose hybrid machining process be low than those in the conventional micro mill. 
result show that for the investigate range of parameter the optimal feed per tooth and depth of cut in the hybrid process be three mu m z and three mu m respectively. 
when use the optimal parameter the surface roughness of the machine slot bottom be 108.5 nm. 
the top burr size on the up mill side and the down mill side be 26.8 and 36.2 mu m respectively. 
in addition the tool wear mechanism be coat delamination in hybrid process whereas chip coating delamination tool nose breakage and adhesion be the main tool wear mechanism in the conventional micro mill. 
for the same amount of material removal the propose hybrid process can decrease the tool wear and enhance the service life of the micro end mill as compare to conventional micro milling. 
a soft computing methodology to analyze sustainable risk in surgical cotton manufacturing company. 
a well organize sustainable risk management in an organization often generate environmental and economic advantage. 
address sustainability and risk simultaneously an organization be more capable of endure challenge that produce environmental and operational stability in management. 
in an industrial organization these primary area of concern involve social responsibility and a focus on occupant health and well being both area address environmental and climate change with an end result of increase competitiveness and profitability. 
the key challenge lie in explore sustainable risk associate with the industry so that they be address strategically. 
this research work be one such attempt to find sustainable risk in the manufacturing sector. 
this research be the outcome of a case study conduct in three lead surgical cotton manufacturing company in the southern part of india. 
a hybrid multi criterion decision make base fuzzy decision make trial and evaluation laboratory and analytic network process with preference rank organization method for enrichment evaluation fdanp with promethee methodology be use to derive the result. 
the final outcome of this paper present the identify critical sustainable risk from the case study and also serve as a model for risk manager in manufacture sector. 
by identify sustainable risk at an early stage a company may avert the occurrence of undesirable incident while at the same time may enhance their production capacity. 
effect of horizontal vibration on mass flow rate and segregation during hopper discharge discrete element method approach. 
vibration be often utilize as a means of initiate and/or control flow from hopper in industry deal with powder granular material such as packing conveying etc. 
the effect of horizontal vibration on gravity flow of granular material from conical hopper be model use the discrete element method. 
material consider in this study include glass bead of diameter range between 0.7 mm and 2.0 mm. 
the flow dynamic and segregation of material be analyze for different mixture characterize base on mass percentage of small particle fine and multi component mixture binary and ternary at different vibration parameter. 
the study include the influence of vibration frequency acceleration amplitude fine percentage diameter ratio and mixture component on segregation and mass flow rate during vibratory hopper discharge. 
the extent of segregation be calculate by mean of mass fraction of fine inside hopper for different operating condition. 
the numerical result indicate that the increase in vibration acceleration at a fix frequency result into increase mass flow rate and there exist acceleration amplitude beyond which segregation be predominant. 
mixture component play significant role in segregation behaviour and binary mixture suffer more segregation as compare to ternary mixture. 
the spatial distribution of the velocity profile indicate that different mixture behave differently at a particular vibration condition. 
the phenomenon like sieve or percolation be also observe base on the analysis of top view simulation snap shot. 
discrete time mean field stochastic linear quadratic optimal control problem with finite horizon. 
in this paper we consider the discrete time mean field stochastic linear quadratic mf lq optimal control problem with indefinite weight matrix. 
first we establish the maximum principle and by the solvability of mean field forward backward stochastic difference equation derive from the maximum principle we characterize the existence of the open loop optimal control for the mf lq problem. 
then by virtue of introduce the linear matrix inequality condition we obtain the solvability of the generalize difference riccati equation gdres. 
moreover we show that the indefinite mf lq problem be well pose if and only if the gdre be solvable. 
finally a numerical example be use to show the effectiveness of the obtain result. 
slide mode preview control for a class of continuous time linear systems. 
in this paper the slide mode preview control problem for a class of continuous time linear system be study. 
firstly an extended error system consist of the error equation and the state equation of the original system be construct and the tracking problem be transform into the regulation problem. 
secondly a quadratic performance index function be introduce for the state variable of the extended error system and the preview slide surface be design base on the exist conclusion of the optimal preview control. 
thirdly the slide mode controller with preview effect for the extended error system be design by use the reach law method then the desire slide mode preview controller of the original system can be obtain through the integral. 
the numerical simulation verify the feasibility of the propose method. 
model base reinforcement learning variable impedance control for human robot collaboration. 
industry 4.0is takinghuman robot collaborationat the center of the production environment. 
collaborative robot enhance productivity and flexibility while reduce human s fatigue and the risk of injury exploit advanced control methodology. 
however there be a lack of real time model base controller account for the complex human robot interaction dynamic. 
with this aim this paper propose amodel base reinforcement learning(mbrl variable impedance controller to assist human operator in collaborative task. 
more in detail an ensemble of artificial neural networks anns be use to learn a human robot interaction dynamic model capture uncertainty. 
such a learned model be keep update during collaborative task execution. 
in addition the learned model be use by amodel predictive controller(mpc withcross entropy method(cem. 
the aim of the mpc+cem be to online optimize the stiffness and dampingimpedance controlparameter minimize the human effort i.e minimize the human robot interaction force. 
the propose approach have be validate through an experimental procedure. 
a lifting task have be consider as the reference validation application weight of the manipulate part 10 kg unknown to the robot controller. 
a kuka lbr iiwa 14 r820 have be use as a test platform. 
qualitative performance i.e questionnaire on perceive collaboration have be evaluate. 
achieve result have be compare with previous develop offline model free optimize controller and with the robot manual guidance controller. 
the propose mbrl variable impedance controller show improved human robot collaboration. 
the propose controller be capable to actively assist the human in the target task compensate for the unknown part weight. 
the human robot interaction dynamic model have be train with a few initial experiment 30 initial experiment. 
in addition the possibility to keep the learning of the human robot interaction dynamic active allow account for the adaptation of human motor system. 
cut performance investigation base on the variable friction model by consider slide velocity and limit stress. 
fast and accurate cut force prediction be still one of the most complex problem and challenge in the machining research community. 
in this study a modify finite element model be present to predict cut force and cut length in turn operation of aisi 1018. 
unlike the exist research in which the mean friction coefficient mu be take a variable friction coefficient mu involve the slide velocity between chip and tool be present in this article. 
the sticking slide friction model be adopt and the maximum limit stress in stick region be calculate by consider the thermal softening and normal stress distribution. 
experiment have be perform for machine aisi 1018 use tungsten carbide tool and simulation result have be compare to experiment. 
the simulation result of the modify finite element model have show well output in predict cut force tangential force and tool chip contact length on the rake face. 
the result of this article not only be meaningful to optimize tool design and cut parameter but also can provide a clear understanding of contact behavior between tool rake face and chip. 
an experimental analysis of the driver s attention during train driving. 
the article deal with the experimental monitoring of the driver s attention during train operation. 
smi eye track technology and eye track glass we use to measure the train driver s attention. 
this unique experiment we perform on the slovak railway zsr line no. 
120 bratislava zilina in the section zilina puchov. 
the measurement take place in the spring of 2017 and the passenger train be operate by the zssk electric unit series 671. 
the article analyse in detail the monitoring of the driver s attention during train operation. 
we analyse two typical process during train driver work drive at the section without stop and drive through the train station with stop. 
realise analysis can lead to the identification of critical point on the line to a well understanding of the driver s way of work and to contribute to increase railway safety. 
the unique measurement procedure and the use technology do not affect the safety of the train operation. 
a multiobjective optimization model for sustainable reverse logistic in indian e commerce market. 
a clean and sustainable environment be become a topmost priority for both owner and stakeholder involve in business. 
it could be achieve by adopt well sustainable practice like reduction in waste through process of recycling recovery and remanufacturing which help to minimize both the cost and environmental loss. 
with a recent surge in e commerce market and online shopping in india there be a need for a more efficient sustainable and reliable reverse logistics design by include cost environmental and social factor into consideration. 
with the factor consider above this paper propose a multi objective logistic network model for the return product specifically pertain to the indian e commerce market. 
the component of this multi echelon supply chain consider be customer markets warehouses delivery hubs landfills incineration centres and recycling centre. 
the multiobjective optimization be do on the three front of sustainability namely economical represent by cost environmental represent by environmental impact of different process and social which be represent by work day create and lose due to harm at work. 
different technology be consider in delivery hub and mother warehouse which could result in a more efficient way of transfer and processing product. 
weighted goal programming wgp technique be use by weigh different objective to minimize cost environment impact and maximize the social responsibility. 
finally model be validate with a numerical example base on an online retail selling clothe. 
this study will help the manager in decide the number of facility store and warehouse need to open and operate technology to be adopt for a more efficient way of transfer and processing product. 
c 2019 elsevier ltd. 
all right reserve. 
multi criteria decision make model to assess the sustainability of girder and truss case study for roof of sport hall. 
the first and probably the most determining decision that engineering team need to make when face the structural design of any infrastructure be the choice of both an appropriate material and the suitable structural typology for its component. 
each component be require to satisfy technical and functional aspect impose by standard and stakeholder. 
currently the aspect that be most frequently consider in decision make process be economic. 
nevertheless environmental and social criterion be also require if one aim at make sustainability base decision. 
in this regard to the good of the author knowledge very few tool or study exist that can support decision maker. 
the few that do exist be rather limited either because they fail to incorporate many relevant factor in the sustainability assessment of a project or because they only evaluate environmental and social impact of a project as a whole. 
although a global assessment be useful to gain a holistic understanding of impact of a project and to compare they to other project it do not necessarily help engineering team understand the impact of fundamental decision make when design individual structural component. 
therefore the aim of the present research paper be to develop a new method for the sustainability analysis of build structural component which have be specifically orient to beam and girder. 
this be do by mean of the integrated value model for the evaluation of sustainability method which be know by its spanish acronym mives modelo integrado de valor para una evaluacion sostenible. 
this method draw on multi attribute utility theory and that allow build an integrate value model as an approach for multi criteria decision making. 
the developed model have be apply to assess the sustainability of different alternative of beam and trust to support the non accessible roof of a sport hall in vila seca spain. 
different material type and structural typology be analyse. 
the finding show that the most sustainable alternative be timber and reinforce concrete truss which be actually two option that be seldom use in practice. 
c 2019 elsevier ltd. 
all right reserve. 
collaborative emission target join and quantity flow decision in a stackelberg set. 
emission target join decision along a channel be recently introduce for firm to join their target to be more effective in keep their emission below a certain level. 
non collaborative emission target join decision under a stackelberg setting with one leader and one follower have be analyze in the literature. 
here we investigate collaborative emission target join decision. 
in particular we discuss that when join decision be collaboratively make both the leader and follower will agree upon join their emission target which be not necessarily the case under non collaborative scenario. 
then two allocation mechanism be propose to share the cost saving of join emission target namely sharing base and fix payment allocation. 
we characterize the case when these allocation mechanism be rational fair and coordinate the channel and compare they to shapley value allocation. 
furthermore we analytically compare the channel cost and emission under three different joining approach no non collaborative and collaborative joining. 
it be show that collaborative joining can reduce not only the channel cost but also the channel emission as compare to no and non collaborative joining. 
numerical example be present under an application set to demonstrate how different joining decision approach compare in term of channel cost and emission. 
c 2019 elsevier ltd. 
all right reserve. 
alleviate bias to enhance sustainable construction dispute management. 
efficient dispute management contribute to clean production of construction work. 
alleviate bias have be identify as an effective way to enhance construction dispute settlement so as to improve sustainability level of construction project. 
in these regard this study have two objective. 
first a robust bias conceptualization in construction dispute negotiation be develop. 
datum on practice of biased behavior in construction dispute negotiation cdn be collect from three source i by self reflection of disputant ii by self realization of disputant in a dispute negotiation simulation iii by observation of dispute resolution third party neutral. 
consistent taxonomy of bias in cdn be obtain and these be preconception self affirmation optimism and interest orient. 
the second objective of the study be to suggest bias minimize approach to address the afore mention bias. 
bias minimize approach be firstly identify from literature and their usefulness against biased behavior be evaluate by both the simulation and third party neutral sample. 
three bias minimize approach be propose strategy base attitude base and process base. 
it have be find that strategy base approach be helpful in deal with preconception bias and self affirmation bias. 
furthermore attitude base approach work to alleviate interest orient bias and optimism bias while process base approach be suitable for preconception bias and interest orient bias minimization. 
successfully curtail the influence of bias would smooth and shorten the dispute resolution process and save valuable resource that can be well deploy for productive use. 
bias minimization in cdn contribute to sustainability of construction project in the aspect of economic environment and social influence. 
c 2019 elsevier ltd. 
all right reserve. 
a new algebraic tool for simultaneous targeting and design of a mass exchange network with stream splitting for sustainable environment. 
process effluent recovery can be a potential source of revenue and an effective way to reduce environmental footprint of industrial process. 
use of resource conservation technology resource efficient process and measure to reduce recycle and reuse of various raw material and waste be among sustainable manufacturing and clean production option to consider. 
mass integration take place in mass exchange network men be an establish concept for more efficient use of raw material. 
the integration can help to reduce both waste disposal flow and external mass separate agent. 
this work present a novel algebraic tool for simultaneous targeting and design of mass exchange network to overcome the limitation of previously develop mass integration algebraic target approach such as the composition interval table cit. 
the newly develop segregated composition interval table secit show mass cascade profile across composition range for individual rich and lean stream. 
the tool can simultaneously target and design men locate mass pinch point and to visualise mass exchange network. 
the secit method be demonstrate for a multiple pinch and threshold problem as well as stream splitting scenario. 
three literature case study be present to illustrate the applicability of the new approach. 
c 2019 elsevier ltd. 
all right reserve. 
barrier to the adoption of modular integrated construction systematic review and meta analysis integrate conceptual framework and strategy. 
the benefit of modular integrate construction mic be extensively document. 
rapid and effective implementation of mic will leverage significant gain in construction project performance. 
however its widespread diffusion and uptake have be hinder. 
although manifold empirical study have identify the barrier to the adoption of mic in different country holistic international review and integrated conceptual framework for the barrier be not well establish. 
this research analyse study on the barrier conduct in 15 country across five continent. 
base on a meta synthesis framework the research identify 120 barrier to the adoption of mic. 
the analysis reveal a co existence of both perceive and real barrier for which the author argue that some exist study may have engage inexperienced participant during their survey. 
an extended classification framework be propose to group the 120 constraint into knowledge attitudinal financial technical aesthetic industry process and policy cluster of barrier. 
the paper propose an integrate conceptual framework map the interaction among the barrier. 
the framework reveal that the five most symbiotic cluster include industry knowledge process financial and technical barrier which have at least four interaction with other group. 
the paper far propose strategy to address the identify group of barrier. 
thus this research have establish the ecosystem of the barrier and how they hinder the wide diffusion of mic. 
as such it provide a holistic perspective of the barrier to the wide diffusion of mic and initiate a debate towards develop integrate strategy to promote uptake of the technique. 
c 2019 elsevier ltd. 
all right reserve. 
a structural model of the impact of green intellectual capital on sustainable performance. 
this study examine the relationship between green intellectual capital and sustainable performance. 
while many study have focus on sustainability this study be one of the first that focus exclusively on green intellectual capital. 
this research use survey datum from 112 manufacturing firm in malaysia. 
as anticipate the result find that green intellectual capital positively influence economic environmental and social performance. 
the finding of this study have various implication for green company and organization in general and green manufacturing firm in particular. 
the novelty of this study be unfold the contribution of green intellectual capital as an intangible resource for organization in achieve sustainable performance and a competitive advantage for future researcher. 
manufacturing industry of develop or develop country can enhance their clean production capability by incorporate this model as a strategy. 
c 2019 elsevier ltd. 
all right reserve. 
multi objective optimization of wire electrical discharge machining of 20mncr5 alloy steel. 
purpose wire electric discharge machining wedm be a non conventional machining process which be use to provide difficult and intricate shape. 
the purpose of this research work be to apply taguchi s technique to optimize the process parameter in wedm. 
alloy steel 20mncr5 have be select as base material for experimentation. 
the effect of the input process parameter such as wire type pulse on time pulse off time peak current wire feed rate and servo voltage have be calculate on the material removal rate mrr and surface roughness ra in wedm operation. 
design methodology approach in the research work taguchi s technique be apply to optimize the process parameter in wedm. 
findings anova indicate that pulse off time be the most significant factor for the mrr and servo voltage be the most significant factor for surface roughness sr. 
as a part of the project 20mncr5 be machine in wire electric discharge machine and the optimal control parameter be find to get high mrr and well sr use taguchi s technique. 
originality value to the good of author knowledge after review the literature material include alloy of metal such as 16mncr5 and 20mncr5 have not be investigate so far and research regard machining of these material be limit. 
therefore 20mncr5 material have be select for this research work to generate wedm datum. 
optimization of the edm machinability of deep and shallow cryogenically treat corrosion resistant superalloy. 
in this study machinability test be carry out on a corrosion resistant superalloy subject to shallow and deep cryogenic treatment via electrical discharge machining and the effect of the cryogenic treatment type apply to the material on the electrical discharge machining processing performance be investigate. 
experimental parameter include pulse on time 300 400 and 500 mu s amperage six and 10 a and material type untreated and with shallow cryogenic treatment and deep cryogenic treatment be use to construct the full factorial experimental design. 
the result average surface roughness ra and material removal rate result be optimize use the taguchi l 18 method. 
accord to the taguchi base gray relational analysis the optimal parameter for both ra and material removal rate be determine as cryogenic treatment pulse on time and amperage respectively. 
the response table obtain use the taguchi method show the most effective factor as a(1)b(l)c(3 for ra and a(2)b(2)c(1 for material removal rate value. 
accord to the anova result for determine parameter affect performance amperage be the most effective factor for average surface roughness and material removal rate at 74.79 and 86.43 respectively. 
when examine in term of taguchi gray relational degree the optimal parameter for both ra and material removal rate be observe in the experiment perform with the shallow cryogenic treatment sample at an amperage of six a and 300 mu s pulse on time. 
pylur efficient software for land use regression model the spatial distribution of air pollutant use gdal ogr library in python. 
land use regression lur model have be widely use in air pollution modeling. 
this regression base approach estimate the ambient pollutant concentration at un sample point of interest by consider the relationship between ambient concentration and several predictor variable select from the surround environment. 
although conceptually quite simple its successful implementation require detailed knowledge of the area expertise in gis statistic and programming skill which make this modeling approach relatively inaccessible to novice user. 
in this contribution we present a lur modeling and pollution mapping software name pylur. 
it use gdal ogr library base on the python platform and can build a lur model and generate pollutant concentration map efficiently. 
this self develop software comprise four module a potential predictor variable generation module a regression modeling module a model validation module and a prediction and mapping module. 
the performance of the newly develop pylur be compare to an exist lur modeling software call rlur with similar function implement on r language platform in term of model accuracy processing efficiency and software stability. 
the result show that pylur out perform rlur for modeling in the bradford and auckland case study examine. 
furthermore pylur be much more efficient in data processing and it have a capability to handle detailed gis input datum. 
an integrate machine code monitor for a risc v processor on an fpga. 
this paper propose an integrate machine code monitor imcm write in a hardware description language hdl and implement in an fpga together with a processor. 
the imcm reconfigure monitor function to be provide accord to the verification progress of the processor design and the development situation of basic program. 
the imcm be implement in the fpga together with the processor as hardware synthesize from hdl description for request imcm function. 
the imcm be implement its function base on survey questionnaire result for six developer of some processor in fpga. 
and its correct operation be confirm by simulation and evaluation use fpga device. 
risc v be adopt as an isa of the target processor. 
a subset compose of 27 instruction of the compression type instruction set extension with 16 bit instruction word length among risc v be employ. 
all state machine and sequential process be write in verilog hdl and implement together with the processor core as a single circuit by circuit synthesis placement and route. 
a 41 lut be add to the implementation of the imcm against the simple processor implementation. 
this addition depend on the monitor function to be select and reconfigure. 
furthermore the imcm program in the fpga be confirm to operate at 100 mhz with the circuit mount on an fpga evaluation board. 
forecast spare part demand use condition monitor information. 
purpose the control of an inventory where spare part demand be infrequent have always be difficult to manage because of the randomness of the demand as well as the existence of a large proportion of zero value in the demand pattern. 
the purpose of this paper be to propose a just in time jit spare part availability approach by integrate condition monitoring cm with spare part management by mean of proportional hazard model phm to eliminate some of the shortcoming of the spare part demand forecasting method. 
design methodology approach in order to obtain the event datum lifetime and cm datum first natural frequency require to build the phm for the spare demand forecasting a series of fatigue test be conduct on a group of turbomachinery blade that be systematically fatigue on an electrodynamic shaker in the laboratory through base excitation. 
the process of datum generation in the numerical as well as experimental approach comprise introduce an initial crack in each of the blade and subject the blade to base excitation on the shaker and then propagate the crack. 
the blade fatigue life be estimate from monitor the first natural frequency of each blade while the crack be propagate. 
the numerical investigation be perform use the msc.marc/2016 software package. 
finding after build the phm use the datum obtain during the fatigue test a blending of the phm with economic consideration allow determine the optimal risk level which minimize the cost. 
the optimal risk point be then use to estimate the jit spare part demand and define a component replacement policy. 
the outcome from the phm and economical approach allow propose development of an integrate forecasting methodology base not only on failure information but also on condition information. 
originality value this paper present a way to address some exist shortcoming of traditional spare part demand forecasting method by introduce the phm as a tool to forecast spare part demand not consider the previous demand as be the case for most of the traditional spare part forecasting method but the condition of the part in operation. 
in this paper the blade bend first mode natural frequency be use as the covariate in the phm in a laboratory experiment. 
the choice of natural frequency as covariate be justify by its relationship with structural stiffness and hence damage as well as be a global parameter that could be measure anywhere on the blade without affect the result. 
integrated reliability and maintainability analysis of computerized numerical control turning center consider the effect of human and organizational factor. 
purpose reliability maintainability and availability of modern complex engineer system be significantly affect by four basic system or element hardware software organizational and human. 
computerized numerical control turning center cnctc be one of the complex machine tool use in manufacturing industry. 
several research study have show that the reliability and maintainability be greatly influence by human and organizational factor hofs. 
the purpose of this paper be to identify critical hof and their effect on the reliability and maintainability of the cnctc. 
design methodology approach in this paper 12 human performance influence factor pif and 10 organizational factor ofs which affect the reliability and maintainability of the cnctc be identify and prioritize accord to their criticality. 
the opinion of expert in the field be use for prioritizing whereas the field failure and repair datum be use for reliability and maintainability modeling. 
findings experience training and behavior be the three most critical human pif and safety culture problem solve resource corrective action program and training program be the four most critical of which significantly affect the reliability and maintainability of the cnctc. 
the reliability and maintainability analysis reveal that the weibull be the good fit distribution for time between failure datum whereas log normal be the good fit distribution for time to repair datum. 
the failure rate of the cnctc be nearly constant. 
nearly 66 percent of the total failure and repair be typically due to the hardware system. 
the percentage of failure and repair influence by hofs be nearly only 16 percent however the failure and repair impact of hofs be significant. 
the hof can increase the mean time to repair and mean time between failure of the cnctc by nearly 65 and 33 percent respectively. 
originality value the paper use the field failure datum and expert opinion for the analysis. 
the critical sub system of the cnctc be identify use the judgment of the expert and the trend of the result be verify with publish result. 
ais datum analytic for adaptive rotate shift in vessel traffic service. 
purpose consider the varied and dynamic workload of vessel traffic service vts operator design an adaptive rotate shift solution to prevent they from get tired while ensure continuous high quality service and finally guarantee a benign maritime traffic environment. 
design methodology approach the problem of rotate shift in vts and its influence factor be analyze first then the framework of automatic identification system ais datum analytic be propose as well as the datum model to extract spatial temporal information. 
besides k mean base anomaly detection method be adjust to generate anomaly free datum with which the traffic trend analysis and prediction be make. 
base on this knowledge strategy and method for adaptive rotate shift design be work out. 
findings in vts vessel number and speed be identify as two most crucial factor influence operator workload. 
base on the two factor the propose datum model be verify to be effective on reduce data size and improve datum processing efficiency. 
besides the k mean base anomaly detection method could provide stable result and the work shift pattern planning algorithm could efficiently generate acceptable solution base on maritime traffic information. 
originality value this be a pioneer work on utilize maritime traffic datum to facilitate the operation management in vts which provide a new direction to improve their daily management. 
besides a systematic data drive solution for adaptive rotate shift be propose include knowledge discovery method and decision make algorithm for adaptive rotate shift design. 
the technical framework be flexible and can be extend for manage other activity in vts or adapt in diverse field. 
application of levenberg marquardt method for estimation of the thermophysical properties and thermal boundary conditions of decompose material. 
this study be devoted to inversely estimate the thermophysical property and thermal boundary condition of a carbon phenolic composite which be one of the widely use char ablator. 
conventional and modify levenberg marquardt method be apply to determine the unknown parameter and function respectively. 
the unknown parameter include specific heat and thermal conductivity over a wide temperature range and the unknown function be the time vary cold wall heat flux and surface temperature. 
before invert the datum a correlation analysis be perform to demonstrate the dependency of the unknown quantity and also to determine the number and location of sensor. 
an in house version of char material ablation code be use to both compute the sensor measurement and invert the datum. 
the current study pursue three scenario include avoid crime in the inversion add random error to the simulated measurement and use different decomposition model to generate the measurement temperature and invert the datum. 
the obtain result demonstrate the efficiency of the propose method in retrieve the boundary condition at the recede surface of char composite as well as the temperature dependent thermophysical property. 
deep learn parallel computing and evaluation for embed system cluster architecture processor. 
in the era of intelligence the processing of a large amount of information and various intelligent application need to rely on embed device. 
this trend have make machine learning algorithm play an increasingly important role. 
high performance embed computing be an effective mean to solve the lack of compute power of embed device. 
aim at the problem that the calculation amount of new intelligent embed application base on machine learning technology be high the compute power of traditional embed system be difficult to meet their need this paper study the parallel optimization and implementation technique of convolutional neural network in parallella platform. 
the parallel optimization strategy of convolutional neural network on the cluster architecture processor of heterogeneous multi core system be give. 
then the high performance implementation of convolutional neural network on parallella platform be study and the function of convolutional neural network system be implement. 
a set of performance evaluation method for embed parallel processor be propose. 
from the application point of s698p the ecos operating system be select as the platform. 
the single core mode and multi core mode be compare on the simulator grsim and the parallel performance evaluation be give. 
experiment have show that the efficiency of deep learning task be significantly improve compare to traditional parallel method. 
ultra compact taper branch orthomode transducer. 
this article propose an ultra compact orthomode transducer omt with novel taper branch structure. 
by comb the taper section and split part the overall omt can be implement in a monoblock which be as small as waveguide flange. 
furthermore the good matching effect achieve by ridge and split make the omt maintain the most compact structure with high performance. 
the whole structure can be fabricate use the conventional computer numerical control mill technique. 
a k band omt be design and test. 
the measure result compare with the simulated result validate the propose design. 
machine learning for the preliminary diagnosis of dementia. 
objective. 
the reliable diagnosis remain a challenging issue in the early stage of dementia. 
we aim to develop and validate a new method base on machine learning to help the preliminary diagnosis of normal mild cognitive impairment mci very mild dementia vmd and dementia use an informant base questionnaire. 
method. 
we enrol 5,272 individual who fill out a 37 item questionnaire. 
in order to select the most important feature three different technique of feature selection be test. 
then the top feature combine with six classification algorithm be use to develop the diagnostic model. 
result. 
information gain be the most effective among the three feature selection method. 
the naive bayes algorithm perform the good accuracy 0.81 precision 0.82 recall 0.81 and f measure 0.81 among the six classification model. 
conclusion. 
the diagnostic model propose in this paper provide a powerful tool for clinician to diagnose the early stage of dementia. 
a digital signal processor dsp) based system for embed continuous time cuffless blood pressure monitoring use single channel ppg signal. 
novel robust observer controller synthesis method for takagi sugeno system. 
for the output feedback control problem of a t s fuzzy system an h infinity observer controller synthesis method be propose. 
first with parallel distribute compensation fuzzy observer and controller an augmented error system be obtain. 
base on lyapunov function approach system stability and robust condition be achieve. 
then by divide the non convex condition into observer dominant and controller dominant part the condition be convert into convex form to facilitate the numerical solving process. 
also input saturation and system measurement disturbance be consider in the synthesis procedure. 
finally a numerical and a vessel control example be adopt to make comparison with exist method with the result clearly show the conservatism reduction effect and good control performance of the propose method. 
redesign of approximate dynamic inversion for pure feedback nonaffine in control nonlinear system via input saturation. 
in this paper a redesign approximate dynamic inversion radi method be develop for a class of pure feedback nonaffine in control nonlinear system pfnnss. 
recently the approximate dynamic inversion adi) based algorithm have be widely implement for nonaffine in control nonlinear system. 
to employ adi base method a fast dynamic subsystem have to be establish to derive the explicit inversion of the nonaffine equation. 
however the previous research on adi rarely consider that the amplitude of actual input derive from the fast augmented subsystem can be extremely high which maybe intolerable for practical system. 
in this paper we set up input saturation and view the difference between input with and without saturation as a perturbation. 
then an intermediate subsystem be construct to compensate the influence of this perturbation by approximate its inversion. 
the exponential stability of the overall closed loop system be ensure via singular perturbation theorem. 
numerical example be provide to demonstrate the effectiveness of the propose method. 
two method for terminal slide mode synchronization of fractional order nonlinear chaotic system. 
the self adaptive terminal slide mode synchronization of fractional order nonlinear chaotic system be investigate under uncertainty and external disturbance. 
a novel non singular terminal slide surface be propose and prove to be stable. 
base on lyapunov stability theory a slide mode control law be propose to ensure the occurrence of slide mode motion. 
in addition two method of the controller and the self adaptive rule be use to establish the slide mode function and two sufficient condition for achieve self adaptive terminal sliding mode synchronization of fractional order uncertain nonlinear system be identify. 
the result show that design appropriate control law and slide mode surface can achieve self adaptive terminal slide mode synchronization of the fractional high order system with uncertainty. 
the effectiveness and applicability of the slide mode control technique be validate through numerical simulation. 
an approach and benchmark to detect behavioral change of commit in continuous integration. 
when a developer push a change to an application s codebase a good practice be to have a test case specify this behavioral change. 
thank to continuous integration ci the test be run on subsequent commit to check that they do no introduce a regression for that behavior. 
in this paper we propose an approach that detect behavioral change in commit. 
as input it take a program its test suite and a commit. 
its output be a set of test method that capture the behavioral difference between the pre commit and post commit version of the program. 
we call our approach dci detect behavioral change in ci. 
it work by generate variation of the exist test case through i assertion amplification and ii a search base exploration of the input space. 
we evaluate our approach on a curate set of 60 commit from six open source java project. 
to our knowledge this be the first ever curate dataset of real world behavioral change. 
our evaluation show that dci be able to generate test method that detect behavioral change. 
our approach be fully automate and can be integrate into current development process. 
the main limitation be that it target unit test and work on a relatively small fraction of commit. 
more specifically dci work on commit that have a unit test that already execute the modify code. 
in practice from our benchmark project we find 15.29 of commit to meet the condition require by dci. 
discussion on experiences with big datum account from a data scientist s perspective. 
i congratulate the author for their interesting and insightful discussion on big datum in production environment. 
although problem with big datum be trendy research topic there be many practical opportunity and challenge for its use by quality practitioner for data drive activity such as assurance diagnosis monitoring and control. 
i appreciate the opportunity to discuss and provide my insight on the topic. 
in the following i confine my assessment to datum acquisition and preprocessing and statistical method for quality engineering. 
optimization of machine parameter in sink electrical discharge machine of caldie plastic mold tool steel. 
the aim of this study be to investigate the machinability of caldie cold work tool steel use the electro erosion technique. 
in the experimental study graphite and copper be use as the electrode material. 
three level for discharge current six 12 and 25 a and three level for pulse duration 50 100 and 200 mu s be use as machine parameter. 
the experimental model be design accord to the taguchi l 18 orthogonal array. 
signal noise ratio graphs and regression analysis be use to evaluate the result of the experiment. 
use the taguchi technique the optimum machining parameter be determine with process output for surface roughness material removal rate and electrode wear rate. 
the optimum level be find to be a(1)b(1)c(1 for surface roughness and electrode wear rate and a(2)b(3)c(3 for material removal rate. 
the effect of control factor on experimental output be calculate by perform anova. 
accord to the anova result discharge current be the most effective parameter on machinability. 
when the experimental datum be compare statistically with the taguchi optimization and regression model datum the result of the design model be show to be successful. 
a smart adaptive particle swarm optimization support vector machine android botnet detection application. 
support vector machine svm be a renowned machine learning technique which have be successfully apply to solve many practical pattern classification problem. 
one of the difficulty in successful implementation of svm be its different parameter i.e. kernel parameter(s penalty parameter c and the feature available in the dataset which should be well adjust during the training process. 
in this paper a new approach call smart adaptive particle swarm optimization support vector machine sapso svm be develop to adapt the parameter of optimization algorithm i.e. inertia weight and acceleration coefficient to the late change in the search space so that each particle explicitly explore the search space base on the late change make to personal good global good and other particle location. 
in this algorithm use the change in personal good and global good at each stage of execution the new evolution factor value be designate and the interference of the interval of inertia weight be eradicate. 
then the state of each particle i.e. convergence exploitation exploration jumping out at each stage of administration base on the interval weight be specify accurately. 
by fine tune the parameter of sapso this algorithm can acquire the good optimal response for svm parameter. 
the result obtain from the sapso svm method demonstrate the superiority of this method in four different measure i.e. sensitivity specificity precision accuracy in comparison with the other three similar one. 
finally the top 20 feature of android botnet be somehow introduce by the propose approach and three other approach firstly these feature be not encrypt by android botnet and secondly be select base on the good result. 
damer a novel diagnosis aggregation method with evidential reasoning rule for bear fault diagnosis. 
ensemble learning method have show its superiority in bear fault diagnosis base on the condition base monitoring. 
nevertheless feature extract from the monitoring signal of bear system often contain interrelated and redundant component lead to poor performance of the base classifier in the ensemble. 
moreover the current ensemble method rely on vote strategy to aggregate the diagnostic prediction of these base classifier without consider their reliability and weight simultaneously. 
to address the aforementioned issue we propose a novel diagnosis aggregation method with evidential reasoning rule damer for bear fault diagnosis. 
in this method a semi random subspace approach use a structure sparsity learning model be develop to decrease the negative effect of interrelated and redundant feature and in the meanwhile to generate accurate and diverse base classifier. 
furthermore an adaptive evidential reasoning rule er rule incorporate with ensemble learning theory be utilize to aggregate the diagnostic prediction of the base classifier by take both their weight and reliability into account. 
to validate the propose damer an empirical study be conduct on case western reserve university bear vibration dataset and the experimental result verify the effectiveness of the propose damer as well as its superiority over commonly use ensemble method. 
the performance of feature subset from multiple domain and the aggregation capability of the adaptive er rule be also investigate. 
result illustrate that damer can be utilize as an effective method for bear fault diagnosis. 
efficient frequency response computation for low order modelling of spatially distribute system. 
motivate by the challenge of design feedback controller for spatially distribute system we present an efficient approach to obtain the frequency response of such system from which low order model can be identify. 
this be achieve by combine the frequency response of constituent low order subsystem in a way that exploit the interconnectivity arise from spatial discretisation. 
this approach extend to the singular subsystem that arise upon spatial discretisation of system govern by pdae with fluid flow be a prime example. 
the main result of this paper be a proof that the computational complexity of form the overall frequency response be minimise if the subsystem be merge in a particular fashion. 
do so reduce the complexity by several order of magnitude a result demonstrate upon the numerical example of a spatially discretised wave diffusion equation. 
by avoid the construction storage or manipulation of large scale system matrix this modelling approach be well condition and computationally tractable for spatially distribute system consist of enormous number of subsystem therefore bypass many of the problem with conventional model reduction technique. 
extended state observer for mimo nonlinear system with stochastic uncertainty. 
in this paper both linear extended state observer eso and nonlinear eso with homogeneous weight function be propose for a class of multi input multi output mimo nonlinear system compose of couple subsystem with large stochastic uncertainty. 
the stochastic uncertainty in each subsystem include internal couple unmodelled dynamic and external stochastic disturbance without known statistical characteristic be lump together as the stochastic total disturbance extended state of each subsystem. 
the linear eso and nonlinear eso be design separately for real time estimation of not only the unmeasured state but also the stochastic total disturbance of each subsystem. 
the practical mean square convergence of these two class of eso be develop. 
some numerical simulation be present to demonstrate the effectiveness of the eso with the advantage of small peaking value and more accurate estimation by the nonlinear eso. 
relaxed observer base controller design method of discrete time multiplicative noise lpv system via an extended projective lemma. 
the aim of this paper be to discuss a relaxed observer base control problem of multiplicative noise linear parameter varying lpv system with unmeasurable state. 
for discuss the problem positive definite matrix without neglect any element be employ to construct a novel parameter dependent lyapunov function. 
base on the lyapunov function some relaxed sufficient condition be derive to hold the freedom in search feasible solution. 
furthermore an extended projective lemma be develop to convert those condition into linear matrix inequality lmi form. 
solve these lmi condition controller gain and observer gain can be simultaneously obtain in one step procedure via use convex optimization algorithm. 
therefore an observer base controller can be establish to guarantee the asymptotical stability of the multiplicative noise lpv system in the sense of mean square. 
at last two numerical example be use to show effectiveness and applicability of the propose design method. 
stabilisation of stochastic delay system with levy noise on network via periodically intermittent control. 
this paper investigate the stabilisation of stochastic couple system with time vary delay and levy noise on network scstln via periodically intermittent control. 
and here internal delay white noise and levy noise be consider in the network. 
to ensure stability of scstln with a periodically intermittent controller several simple and useful criterion be obtain by establish a new differential inequality and use a graph theoretic approach. 
the intensity of control be closely relate to the coupling strength and the perturb intensity of white noise and levy noise. 
in particular the stabilisation of stochastic couple oscillator with time vary delay and levy noise on a network as a practical application of our theoretical result be study. 
finally a numerical example about oscillator network be carry out to show the validity and feasibility of our analytical result. 
stability analysis of nonlinear multi agent relay tracking system over a finite time interval. 
this paper explore the stability of a class of multi agent system with propose relay tracking strategy over a finite time interval. 
in this paper agent be deploy in an area to monitor and track the intrude target. 
accord to propose relay tracking strategy the track agent and their communication topology switch during the whole tracking process. 
this result in impulsive effect on the overall tracking error. 
the relationship of finite time interval against desire overall tracking error and control parameter be derive quantitatively for the multi agent relay tracking system. 
moreover stability condition for the system with disturbance and impulsive effect be obtain. 
performance of propose relay tracking strategy and correctness of derive result on stability over finite time interval be demonstrate by a set of simulation. 
adaptive fault tolerant vibration control of a wind turbine blade with actuator stick. 
this paper propose an adaptive fault tolerant boundary vibration control method design to resolve unknown failure and stuck actuator problem in the wind turbine blade control process. 
the blade be model as a distribute parameter system describe by two couple partial differential equation. 
the propose boundary control achieve the fact that the vibration of the blade can still be suppress even when the actuator fail and the bend and torsional deformation be eventually reduce to zero. 
base on the lyapunov direct method a fact have be confirm that the stability of the system be guarantee under the boundary controller. 
the effectiveness of the controller be demonstrate by numerical simulation. 
study on torsional vibration of rt60 crane transmission system. 
in the process of engineering use the elastic coupling of the rt60 crane transmission system have a large noise and even break down sometimes. 
in this paper rt60 crane transmission system be the research object. 
a finite element model and a discrete model for torsional vibration of transmission system be establish by finite element method and lumped parameter method. 
through the study of the finite element model and the vibration test of transmission system the correctness of the system model equivalent parameter calculation method and matlab program be verify. 
because of the high efficiency of the torsional vibration discrete system the discrete model be use in this paper to replace the finite element model. 
the free vibration and response vibration of the crane transmission system be calculate and analyze and the reason for the existence of the system noise be explain in the starting stage. 
through the study of the vibration theory and the matching method of the elastic coupling the cx 45 vfa 60 11 elastic coupling be propose to replace the cx 45 vfa 11 elastic coupling. 
in this paper the data signal be collect by the hall gear sensor and the datum be analyze by the self develop vibration tester. 
the vibration amplitude of the torsional vibration of the crane transmission system be greatly reduce by test the transmission system of the replacement of the elastic coupling. 
this paper provide a theoretical guide significance for the low noise design of the crane transmission system. 
contact analysis for dual peg in hole assembly of automobile alternator frame. 
the modeling and analysis of the assembly contact problem in the picking and placement of the automobile alternator frame be carry out in the multi station processing. 
accord to the three dimensional assembly characteristic of the actual alternator frame and the fixture the assembly model in the drilling and milling station be simplify. 
the alternator frame and fixture assembly problem as a whole be simplify to a dual peg in hole assembly problem. 
all possible one point contact state and two point contact state during the assembly process be proposed(l 1)similar to(r 10. 
the contact force analysis be carry out on the typical one contact state l one and the typical two point contact state l five and the relationship between the correspond assembly force f x f y f z and the assembly moment m x m y m z be obtain. 
accord to the relationship between these assembly force and assembly moment the corresponding jamming diagram be obtain. 
finally accord to the three dimensional size of the actual alternator frame the experimental verification be carry out by use a six dof force moment sensor. 
the experimental result confirm the validity of the analysis. 
technical support be provide for the assembly of automobile alternator frame base on force sense control for the follow up work. 
finite time adaptive fault tolerant control for rigid spacecraft attitude track. 
this paper provide a new solution for the finite time attitude maneuver of rigid spacecraft. 
uncertainty involve unknown inertial parameter external disturbance and actuator failure be take into account. 
with an effort to achieve attitude track despite the impact of uncertainty a non singular terminal slide mode ntsm manifold consist of attitude error and angular velocity error be first construct. 
after that a simple but efficient adaptive updating law be derive to estimate the upper bound of the lumped unknown function in the derivative of slide surface. 
combine ntsm technology and pure adaptive control a chatter free fault tolerant controller be present. 
the premise assumption on uncertainty in most of the exist achievement be eliminate which make the controller less constrained and more practical. 
the rigorous proof of finite time stability be provide and the convergent region of tracking error be explicitly express. 
finally numerical simulation be conduct to verify the effectiveness of the propose control scheme and the comparison experiment with relevant literature demonstrate the satisfactory performance. 
improve disturbance observer base fault tolerant control for the linear system subject to unknown actuator fault and multiple disturbance. 
the problem of fault tolerant control for the time invariant system subject to actuator fault and multiple disturbance be focus. 
the multiple disturbance be compose of two kind one be a norm bound vector the other describe by an exogenous system be view as a harmonic signal with know amplitude and unknown frequency and phase. 
an improved disturbance observer be design to obtain the model disturbance with partially know information. 
base on this two novel fault tolerant control algorithm be put forward to the analysis and compensate two different type of actuator fault one be norm bound and the other be with an unknown boundary. 
the effectiveness and robustness of control scheme can be exhibit through some numerical simulation with different case. 
research and experimental analysis of drill string dynamic characteristic and stick slip reduction mechanism. 
stick slip of the drill string as one of the critical factor affect drill efficiency have always be a hot topic for expert and scholar in relate field. 
serious stick slip vibration affect the well construction efficiency drilling cost and even lead to a downhole accident. 
therefore base on the current research this paper take a new type of composite vibration tool as the research object study the work mechanism of the tool and analyze the effect of stick slip reduction. 
after establish the multi degree of freedom torsional dynamic model we obtain the result of torsional vibration dynamic by case analysis base on working condition and related mechanical parameter. 
in addition the result of the example compare with the field experimental datum verify that the vibration shock generate by the new composite tool can effectively reduce the torque fluctuation range of the system avoid the occurrence of stick slip phenomenon improve the rop rate of penetration and make drilling process more stable. 
this paper can provide reference for the optimization and development of stick slip technology in drilling engineering and the theoretical method can also be develop to study the dynamic of drill string. 
torsional vibration analysis of a planetary gear type antiresonant vibration isolator use transfer matrix method part i system modeling. 
recently a new type of vibration isolator call a dynamic antiresonant vibration isolator davi have be study for torsional system as well as translational system. 
in the davi for torsional system the inertia couple for the anti resonance effect be generate by a planetary gear that connect control inertia and inertia at the input and output terminal. 
in this research an analytical modeling approach call the transfer matrix method be apply to design a planetary gear type davi for complex system such as an automotive powertrain. 
unlike a previous study inertia of the pinion gear be newly include in the transfer matrix model to improve the model accuracy in this paper. 
in this part one of series paper the internal configuration of a planetary gear type davi system be describe and its dynamic model be derive use the transfer matrix method. 
the derived transfer matrix model be then validate by compare its frequency response with those obtain by conventional and numerical method. 
finally the effect of different gear ratio and pinion gear inertia be examine use the derive transfer matrix model. 
research on the sticking slide contact ratio in high speed cutting of cupronickel b10. 
accurate understanding of the frictional behavior at the tool chip interface be critical for the cutting process. 
to quantitatively analyze the ratio of the stick contact length to tool chip contact interface length a concise calculation model be propose. 
orthogonal cut experiment and friction experiment be conduct to acquire the friction coefficient for use as input parameter to the model. 
calculation find that the ratio the slide contact length and the tool chip contact interface length show downward tendency with increase cut speed. 
the maximum value of the ratio be 63.2 achieve at 1000 m min whereas the minimum be 58.6 achieve at 800 m min. 
furthermore as the cut speed rise the slide and apparent friction coefficient decrease while the stick friction coefficient remain nearly constant. 
the finding be helpful to improve people s cognition of sticking slide contact the quality of machining and determine the thickness and length of the tool coating. 
design of couple andronov hopf oscillator with desire strange attractor. 
this paper develop a design method for the interconnection of a network of andronov hopf oscillator such that the system exhibit a desire strange attractor. 
because of the structure of the oscillator the desire behavior can be achieve via weak linear coupling which destabilize the oscillator phase difference. 
first a set of sufficient condition be establish that result in phase destabilization and thus instability of a desire periodic solution. 
then an additional condition be determined to ensure that all harmonic periodic orbit will be unstable. 
finally additional numerical property be assess where tuning of a small parameter can result in chaos. 
estimation of municipal waste generation of turkey use socio economic indicator by bayesian optimization tune gaussian process regression. 
accurate estimation of municipal solid waste msw generation have become a crucial task in decision make process for the msw planning and management system. 
in this study the gaussian process regression gpr model tune by bayesian optimization be use to forecast the msw generation of turkey. 
the bayesian optimization method which can efficiently optimize the hyperparameter of kernel function in the machine learning algorithm be apply to reduce the computation redundancy and enhance the estimation performance of the model. 
four socio economic indicator such as population gross domestic product per capita inflation rate and the unemployment rate be use as input variable. 
the performance of the bayesian gpr bgpr model be compare with the multiple linear regression mlr and bayesian support vector regression bsvr model. 
different performance measure such as mean absolute deviation mad root mean square error rmse and coefficient of determination r two value be use to evaluate the performance of the model. 
the exponential gpr model tune by bayesian optimization show superior performance with minimum mad 0.0182 rmse 0.0203 and high r two 0.9914 value in the training phase and minimum mad 0.0342 rmse 0.0463 and high r two 0.9841 value in the testing phase. 
the result of this study can help decision maker to be aware of social economic factor associate with waste management and ensure optimal usage of their resource in future planning. 
raf resilience assessment framework a tool to support cities action planning. 
urban area be dynamic face evolve hazard having interact strategic service and asset. 
their management involve multiple stakeholder bring additional complexity. 
potential impact of climate dynamic may aggravate current condition and the appearance of new hazard. 
these challenge require an integrated and forward look approach to resilient and sustainable urban development be essential to identify the real need for its achievement. 
several framework for assess resilience have be develop in different field. 
however consider the focus on climate change and urban service specific need be identify particularly in assess strategic urban sector and their interaction with other and with the wide urban system. 
a resilience assessment framework be develop direct and facilitate an objective drive resilience diagnosis of urban city and service. 
this support the decision on selection of resilience measure and the development of strategy to enhance resilience outline a path to co build resilience action plan and to track resilience progress in the city or service over time. 
this paper present the framework and the main result of its application to three city have diverse context. 
it be demonstrate that the framework highlight where city and urban service stand regard resilience to climate change and identify the most critical aspect to improve include expect future impact. 
on apply machine learning and simulative approaches to railway asset management the earthworks and track circuits case studies. 
the objective of this study be to show the applicability of machine learning and simulative approach to the development of decision support system for railway asset management. 
these technique be apply within the generic framework develop and test within the in2smart project. 
the framework be compose by different building block in order to show the complete process from data collection and knowledge extraction to the real world decision. 
the application of the framework to two different real world case study be describe the first case study deal with strategic earthwork asset management while the second case study consider the tactical and operational planning of track circuit maintenance. 
although different methodology be apply and different planning level be consider both the case study follow the same general framework demonstrate the generality of the approach. 
the potentiality of combine machine learning technique with simulative approach to replicate real process be show evaluate the key performance indicator employ within the considered asset management process. 
finally the result of the validation be report as well as the develop human machine interface for output visualization. 
capture the city s heritage on the go design requirements for mobile crowdsourced cultural heritage. 
intangible cultural heritage be at a continuous risk of extinction. 
where historical artefact engine the machinery of intercontinental mass tourism socio technical change be reshape the anthropomorphic landscape everywhere on the globe at an unprecedented rate. 
there be an increase urge to tap into the hidden semantic and the anecdote surround people memory and place. 
the vast cultural knowledge make of testimony oral history and tradition constitute a rich cultural ontology tie together human being time and situation. 
altogether these complex multidimensional feature make the task of data mapping of intangible cultural heritage a problem of sustainability and preservation. 
this paper address a suggest route for conceiving design and appraise a digital framework intend to support the conservation of the intangible experience from a user and a collective centre perspective. 
the framework be design to help capture the intangible cultural value of all place exhibit cultural historical significance support by an extensive analysis of the literature. 
we present a set of design recommendation for design mobile app that be intend to converge crowdsourcing to intangible cultural heritage. 
how past failure predict subsequent entrepreneurial intention a comparative study of mainland china and taiwan. 
entrepreneurship be the center of economic growth process and it be context sensitive. 
we compare mainland china and taiwan by investigate the impact of past failure on individual entrepreneur. 
use a large amount of datum from gem global entrepreneurship monitor a logistic regression approach be adopt and most of the major variable in model be correlate positively. 
we demonstrate that past failure do affect entrepreneur perceive capability and next enterprising activity positively in the two region. 
unlike the moderate role of culture entrepreneurial motivation exert a quite different impact on the relationship between past failure and entrepreneur future intention in the two region. 
our result provide not only theoretical implication for context relate entrepreneurial motivation but practical suggestion for entrepreneur and policy maker. 
the spatial distribution influencing factor and development path of inbound tourism in china an empirical analysis of market segment base on travel motivation. 
accord to china s tourism statistic the inbound tourism market be compose of eight type of travel motivation sightseeing leisure business meeting business m visit relative and friend visit rf shopping religious worship religious w culture and sport culture s and health care health c and the spatial distribution of each type of travel motivation be significantly different. 
four inbound sub market foreigner hong kong macao and taiwan be select as our research object. 
through empirical analysis of the variable elasticity of eight different inbound motive market segment we find that the sensitivity elasticity of the influence factor traffic condition traffic c destination image destination i industry structure industry s infrastructure consumer price index cpi resource endowment resource e and dress index icl be different. 
therefore investment option in the target market can have differential treatment base on the rate of marginal return on investment. 
in accordance with the characteristic of different market segment we suggest more feasible development path and countermeasure provide a decision make basis for the accurate development of the inbound tourism market. 
deformation failure mechanism of deep vertical shaft in jinchuan mining area. 
vertical shaft play an important role in the safe operation of mine. 
the stability of vertical shaft have always be a difficult problem in mining engineering especially with the increasing of mining depth. 
in order to keep the engineering work stable it be necessary to make the deformation failure mechanism of vertical shaft clear. 
this paper describe a case study of the deformation and failure mechanism of the vertical shaft in jinchuan no. 
two mining area in gansu province china. 
long term deformation trend and characteristic of the vertical shaft be analyze through ground movement and gps monitoring of ground fissure. 
then base on previous research experience and a detailed field investigation the mode influence factor and mechanism of deformation failure in the vertical shaft be study. 
to far investigate the mechanism of shaft deformation failure and damage process under mining the universal discrete element code udec software with trigon approach be employ to build the numerical model of the vertical shaft. 
through displacement stress and damage analysis the time location and cause of vertical shaft failure during mining be explicitly illustrate. 
the result suggest that the upper and low part of the fault be activate in different way. 
the damage to the vertical shaft be still develop at a very high rate under mining with fill method. 
all our result throw light on the nature of deformation and failure of vertical shaft and several suggestion for the engineering of deep vertical shaft be finally put forward provide a reference for other engineering. 
the influence of leaders positive and implicit followership theory of university scientific research teams on individual creativity the mediating effect of individual self cognition and the moderating effect of proactive personality. 
leader positive and implicit followership theory lpift in a university scientific research team influence innovation in university scientific research. 
individual creativity be an important aspect of innovation in university scientific research. 
however the influence mechanism of lpift of a university scientific research team on individual creativity remain unclear. 
base on social cognitive theory and the input process output ipo theoretical model we select a postgraduate supervisor and postgraduate of a university scientific research team as the research object. 
we explore the influence between lpift of a university scientific research team leader and individual creativity use a questionnaire. 
a total of 413 valid pair sample be collect from the postgraduate and postgraduate supervisor. 
we draw the following conclusion lpift of the university scientific research team have a direct positive effect on individual creativity. 
individual creative role identity individual creative self efficacy and individual willingness to create knowledge have completely mediate effect on the relationship between lpift of the university scientific research team and individual creativity. 
proactive personality positively moderate the relationship between lpift of the university scientific research team and individual creative role identity as well as lpift of the university scientific research team and individual creative self efficacy. 
proactive personality also positively moderate the mediate effect of individual creative role identity and individual creative self efficacy. 
however the moderate effect of proactive personality between lpift of university research team and individual willingness to create knowledge be not significant. 
proactive personality also do not positively moderate the mediate effect of individual willingness to create knowledge. 
priority analysis of right remedy of basic living recipients in korea. 
through an active administration approach the local living security commission llsc have provide relief to protect the poor strata and reinforce the distribution of entitlement. 
however the absence of a system to monitor operational performance make it difficult to manage it efficiently. 
the purpose of this study be to find way to strengthen and efficiently operate the function of the llsc through priority analysis of its operation. 
to this end the analytic hierarchy process ahp be conduct base on the result of the focus group interview to derive priority for the operation of the llsc. 
the variable use in the ahp analysis include regional condition operational performance organizational method and network. 
the result of the analysis reveal first that the performance of the committee have increase due to a joint evaluation or verification survey conduct at the end of each year second that the creation of a budget for the organization and the operation of an independent llsc be necessary and third that operational performance be the most important follow by organizational method network and regional condition. 
therefore a system for monitor performance should be establish to improve the operation performance of the llsc. 
additionally it be necessary to establish an independent llsc and secure the budget for each city and county. 
it should be possible to provide feedback on operation through regular priority analysis. 
a novel approach for forecasting of ground vibration result from blast modify particle swarm optimization couple extreme learning machine. 
ground vibration be one of the most important undesirable effect induce by blast operation in the mining or tunneling project. 
hence develop a precise model for prediction of ground vibration would be much beneficial to control environmental issue of blast. 
the present study propose a new hybrid machine learning ml technique autonomous group particle swarm optimization agpso) extreme learning machine elm to predict ground vibration result from blast. 
in fact agpso elm model be a modify version of pso elm that can solve problem in a way with high prediction performance. 
for comparison purpose pso elm minimax probability machine regression least square support vector machine and gaussian process regression model be also propose to estimate ground vibration. 
the said ml model be train and test base on a database comprising of 102 dataset collect from a quarry site in malaysia. 
in the modeling of ml technique six input parameter be consider burden to space ratio maximum charge per delay stemming distance from the blasting face powder factor and hole depth. 
the result of ml technique be evaluate in both stage of training and testing base on five fitness parameter criterion. 
consider result of both training and testing dataset agpso elm model be able to provide high prediction performance for ppv prediction. 
root mean square error value of 0.08 and 0.08 and coefficient of determination value of 0.92 and 0.90 be obtain respectively for training and testing dataset of agpso elm model which reveal that the new hybrid model be capable enough to forecast ground vibration induce by blast. 
the newly propose model can be use in other field of science and engineering in order to get high accuracy level of prediction. 
fuzzy adaptive two bit trigger control for nonlinear uncertain system with input saturation and output constraint. 
in this work a fuzzy adaptive two bit trigger control be investigate for the nonlinear uncertain system with input saturation and output constraint. 
the considered system be more widespread. 
without sufficient transmission resource how to resolve the constraint issue while guarantee the control performance be difficult and challenging. 
then hyperbolic tangent function and barrier lyapunov function be integrate with the design auxiliary system to solve input saturation and output constraint. 
meanwhile face with the transmission resource limitation this work both consider the triggering condition and the control signal transmission bit. 
a two bit trigger control be propose to economize the transmission resource. 
furthermore improve fuzzy logic system be establish to far promote the control performance. 
it combine with the time vary approximation error for process. 
the boundedness of all the system signal can be prove. 
simulation result illustrate the validity of the propose approach. 
design optimization by integrate limited simulation datum and shape engineering knowledge with bayesian optimization bo dk4do. 
surrogate model have be widely study for optimization task in the domain of engineering design. 
however the expensive and time consume simulation cycle need for complex product always result in limited simulation datum which bring a challenge for build high accuracy surrogate model because of the incomplete information contain in the limited simulation datum. 
therefore a method that build a surrogate model and conduct design optimization by integrate limited simulation datum and engineering knowledge through bayesian optimization bo dk4do be present. 
in this method the shape engineering knowledge be consider and use as derivative information which be integrate with the limited simulation datum with a gaussian process gp. 
then the gp be update sequentially by sample new simulation datum and the optimal design solution be find by maximize the gp. 
the aim of bo dk4do be to significantly reduce the required number of computer simulation for find optimal design solution. 
the bo dk4do be verify by use benchmark function and an engineering design problem hot rod roll. 
in all scenario the bo dk4do show fast convergence rate than the general bayesian optimization without integrate engineering knowledge which mean the require amount of datum be decrease. 
cyclic shear angle for lamellar chip formation in ultra precision machining. 
shear angle be classically consider constant. 
in the study a series of straight orthogonal cutting test of ultra precision machining reveal that shear angle cyclically evolve with each lamellar chip formation cyclic shear angle. 
it grow up from an initial shear angle of zero degree to a final shear angle 90 degree alpha alpha tool rake angle and undergo a series of transient shear angle like classical shear angle and a critical shear angle. 
the critical shear angle be the sum of the half of the tool rake angle and the characteristic shear angle determine by material anisotropy without the friction effect. 
moreover a new model be develop. 
far a series of face turn test of ultra precision machining verify that the cyclic shear angle be the intrinsic mechanism of cyclic cut force and lamellar chip formation to induce twin peak high frequency multimode diamond tool tip vibration. 
significantly the study draw up an understanding of shear angle for the discrepancy among the classical model. 
quantifying disturbance risk on the process time for a robust synchronize individual production. 
due to high product variability determine the risk of a disturbance for a production process chain require frequent as well as deliberate determination. 
if a disturbance become effective it will have a tremendous negative effect on the adherence to delivery date. 
this apply also to the synchronized individual production sip principle. 
accordingly the principle lack robustness in scientific as well as in industrial application. 
for this reason this paper propose an approach to quantify disturbance risk that lead to uncertain process time that prevent a robust sip. 
the quantification methodology consist of a system definition risk identification and risk quantification. 
the assessment include extend the risk matrix adjust the failure mode and effects analysis plus determine general influence possibility for each risk type. 
the propose approach enable production planner to consider time uncertainty in form of a risk figure when determine nominal process time for each product or the production schedule. 
consequently delivery date be more feasible and its adherence lead to a high internal adherence to delivery of the production. 
the propose approach have a high practical orientation make its application easy on real production process chain in a sip. 
image retrieval for complex queries use knowledge embed. 
with the increase in popularity of image base application user be retrieve image use more sophisticated and complex query. 
we present three type of complex query namely long ambiguous and abstract. 
each type of query have its own characteristic complexity and thus lead to imprecise and incomplete image retrieval. 
exist method for image retrieval be unable to deal with the high complexity of such query. 
search engine need to integrate their image retrieval process with knowledge to obtain rich semantic for effective retrieval. 
we propose a framework image retrieval use knowledge embedding imreke for embed knowledge with image and query allow retrieval approach to understand the context of query and image in a well way. 
imreke ir_approach knowledge_base take two input namely an image retrieval approach and a knowledge base. 
it select quality concept concept that possess property such as rarity newness etc from the knowledge base to provide rich semantic representation for query and image to be leverage by the image retrieval approach. 
for the first time an effective knowledge base that exploit both the visual and textual information of concept have be develop. 
our extensive experiment demonstrate that the propose framework improve image retrieval significantly for all type of complex query. 
the improvement be remarkable in the case of abstract query which have not yet be deal with explicitly in the exist literature. 
we also compare the quality of our knowledge base with the exist text base knowledge basis such as conceptnet imagenet and the like. 
pivot trace dynamic causal monitoring for distributed systems. 
monitoring and troubleshoot distribute system be notoriously difficult potential problem be complex varied and unpredictable. 
the monitoring and diagnosis tool commonly use today log counter and metric have two important limitation what gets record be define a priori and the information be record in a component  or machine centric way make it extremely hard to correlate event that cross these boundary. 
this paper present pivot tracing a monitoring framework for distribute system that address both limitation by combine dynamic instrumentation with a novel relational operator the  happene before join. 
pivot tracing give user at runtime the ability to define arbitrary metric at one point of the system while be able to select filter and group by event meaningful at other part of the system even when cross component or machine boundary. 
pivot tracing do not correlate cross component event use expensive global aggregation nor do it perform offline analysis. 
instead pivot tracing directly correlate event as they happen by piggyback metadata alongside request as they execute. 
this give pivot trace low runtime overhead less than one for many cross component monitoring query. 
five challenge in cloud enable intelligence and control. 
the proliferation of connected embed device or the internet of thing iot together with recent advance in machine intelligence will change the profile of future cloud service and introduce a variety of new research problem both in cloud application and infrastructure layer. 
these problem be center around empower individually resource limit device to exhibit intelligent behavior both in sensing and control thank to a judicious utilization of cloud resource. 
cloud service will enable learn from datum perform inference and execute control all with assurance on outcome. 
this article discuss such emerge service and outline five result new research direction towards enable and optimize intelligent cloud assist sensing and control in the age of the internet of thing. 
a novel assessment approach to efqm drive institutionalization use integrate fuzzy multi criteria decision make method. 
it be become increasingly difficult for enterprise to survive under competitive condition. 
enterprise with high level of institutionalization be able to survive and reap more advantage than their competitor. 
excellence model be widespread tool for measure the degree of institutionalization of enterprise. 
in this study european foundation for quality management efqm criterion be evaluate with fuzzy multi criteria decision make technique. 
the fuzzy dematel method be use to determine the interaction amongst the main efqm criterion. 
accord to the relationship diagram obtain from the fuzzy dematel method the weight of the subcriteria be calculate accord to the expert evaluation use fuzzy analytic network process method. 
the criterion business results have be determine to be the most important criterion. 
the weight of the criterion be take as input for the vikor method. 
then the institutionalization level of six institution previously evaluate by efqm be reevaluate by the propose approach. 
as a result institution a b e and f achieve excellence award while institution c and d be assess to deserve the four star competency certificate. 
the institutional score obtain by the propose method and the score give by the efqm evaluator be statistically analyze to demonstrate that the propose method have produce meaningful result. 
c 2020 sharif university of technology. 
all right reserve. 
curriculum learn for distant supervision relation extraction. 
relation extraction under distant supervision leverage the exist knowledge base to label datum automatically thus greatly reduce the consumption of human labor. 
although distant supervision be an efficient method to obtain a large amount of label datum the training dataset label by distant supervision suffer from noise problem result in poor generalization ability of the relation extractor. 
to alleviate the noise problem we propose a novel relation extraction method base on curriculum learn. 
curriculum learning be utilize to guide the training process of relation extractor specifically through the predefined curriculum drive mentor network. 
mentor network can dynamically adjust the weight of sentence during training give low weight to noisy sentence and high weight to truly label sentence. 
relation extractor and mentor network be train collaboratively to optimize joint objective. 
the experimental result show that the propose method can improve the generalization ability of relation extractor in a noisy environment and obtain well performance for relation extraction. 
c 2020 elsevi b.v. 
all right reserve. 
optimization design and analysis of rotary indexing mechanism of tool magazine in machining center. 
in order to achieve a fast rotation speed and low impact load of the machining center armless type tool magazine during the rotary indexing process the rotation and positioning characteristic of the rotary indexing mechanism be study. 
the structural design of the geneva mechanism use to drive the tool magazine be complete and the optimize design scheme of the new double pin without the lock arc geneva mechanism to replace the single pin lock arc geneva mechanism be finally determine. 
the ttwo scheme be model and compare by kinematic base on nx and adams. 
the result of kinematic contrast simulation show that the double pin geneva mechanism structure without lock arc have the advantage of be fast in rotational speed small in impact load and more stable running condition so that the speed of machine tool change while greatly reduce device wear and improve the durability of the device. 
c 2020 jordan journal of mechanical and indusirial engineering. 
all right reserve. 
audio visual speech separation and dereverberation with a two stage multimodal network. 
background noise interfere speech and room reverberation frequently distort target speech in real listening environment. 
in this study we address joint speech separation and dereverberation which aim to separate target speech from background noise interfere speech and room reverberation. 
in order to tackle this fundamentally difficult problem we propose a novel multimodal network that exploit both audio and visual signal. 
the propose network architecture adopt a two stage strategy where a separation module be employ to attenuate background noise and interfere speech in the first stage and a dereverberation module to suppress room reverberation in the second stage. 
the two module be first train separately and then integrate for joint training which be base on a new multi objective loss function. 
our experimental result show that the propose multimodal network yield consistently well objective intelligibility and perceptual quality than several one stage and two stage baseline. 
we find that our network achieve a 21.10 improvement in estoi and a 0.79 improvement in pesq over the unprocessed mixture. 
moreover our network architecture do not require the knowledge of the number of speaker. 
features of magneto abrasive machining of taps. 
the feature of magneto abrasive machining of tap for metric thread cutting be investigate. 
the calculation method of integral intensity of the magneto abrasive machining of the work surface of the tap by the quantitative value of normal and tangential component of move speed of the quasi stable volume of the magneto abrasive tool be develop. 
base on the result of calculation it be possible to predict the probable influence of the tap location in the work zone on the quality and efficiency of machine their work surface. 
the calculation method be relevant for tap of all diameter with a profile angle of 60 degree. 
the work surface of the tool would not be effectively machine if the location angle of tap to the plane of the work zone of the machine equal 20 60 degree. 
depend on the expect major polishing or strengthen effect of magneto abrasive machining the tap be require to be locate at an angle of 60 90 degree to the plane of the work zone of the machine. 
reliability base robust design optimization base on sensitivity and elasticity factor analysis. 
in this paper a reliability based robust design optimization rbrdo base on sensitivity and elasticity factor analysis be present. 
in the first step a reliability assessment be perform use the first and second order reliability method form)/(sorm and monte carlo simulation. 
furthermore form method be use for reliability elasticity factor assessment which can be carry out to determine the most influential parameter these factor can be help to reduce the size of design variable vector in rbrdo process. 
the main objective of the rbrdo be to improve both reliability and design of a cylindrical gear pair under uncertainty. 
this approach be achieve by integration of two objective which minimize the variance and mean value of performance function. 
to solve this problem a decoupled approach of sequential optimization and reliability assessment sora method be implement. 
the result obtain show that a desire reliability with a robust design be progressively achieve. 
predictive control strategy for investment portfolio in the financial market with hidden regime switching. 
consider an investment portfolio consist of n risky asset and one risk free asset e.g. a bank account. 
let x(i)(k i=(1,n over bar denote the amount of the wealth invest in the ith risky asset x(n+1)(k zero be the amount invest in a risk free asset u(i)(+ k zero be the amount of money by which an investor buy the ith risky asset u(i)( k zero be the amount of money by which an investor sell the ith risky asset. 
the volume of borrowing of a risk free asset be equal to x(n+2)(k zero v(k be the amount of borrowing that transfer from borrow account to bank account r(1)(k one be the riskless lending rate over time period k k one r(2)(k one be the riskless borrowing rate. 
the ith stock hold x(i)(k i one n over bar satisfy the follow stochastic difference equation x(i)(k one x(i)(k u(i)(+)(k u(i)( )(k where eta(i)(k+1 be the return of the ith risky asset. 
the dynamic of the bank account be give by x(n+1)(k one x(n+1)(k v(k one lambda(+ sigma(n)(i=1 u(i)(+ k one lambda( sigma(n)(i=1 u(i)( )(k where lambda(+ lambda( be fraction of the amount transact on purchase u(i)(+ k and sell u(i)( )(k of the ith stock respectively. 
the evolution of the borrowing account be the follow x(n+2)(k one x(n+2)(k v(k. 
the wealth process satisfie v(k cx(k c n+2 x(k x(1)(k x(n+2)(k)](t. 
the follow constraint be take into account x(n+1)(k v(k one lambda(+ sigma(n)(i=1 u(i)(+ k one lambda( sigma(n)(i=1 u(i)( k zero x(n+2)(k v(k zero one x(i)(k u(i)(+)(k u(i)( k d(i)(k x(n+2)(k v(k d(0)(k d(0)(k);ui+(k zero u(i)( k zero i=(1 n over bar. 
two the evolution of the risky asset return eta(i)(k be describe by the equation eta(i)[theta(k),k mu(i)[theta(k),k sigma(n)(j=1 sigma(ij theta(k),k]w(j k where mu(i)[theta(k k be the expect return sigma[theta(k k sigma(ij)[theta(k k]}(i j=1),(.,n be the volatility matrix w(j)(k j one n be independent noise with zero mean and unit variance theta(k delta(alpha(k one delta(alpha(k),nu)](t delta(alpha(k),j be a kronecker function j one 2, ,v alpha(k be an element of one two .,v be a discrete time markov chain. 
our objective be to control the investment portfolio by track a deterministic portfolio with a desire return mu(0 which evolution be describe by the equation v 0(k one v 0(k),v 0(0 v(0. 
in this paper we design portfolio control strategy subject to constraint 1) (2 under the quadratic performance criterion with recede horizon m j(k m vertical bar k sigma(m)(i=1 e{rho(1)(k i)[v(k i vertical bar k v 0(k i)](2 rho(2)(k i)[v(k i vertical bar k v 0(k one u(t)(k i one vertical bar k)r(k i 1)u(k i one vertical bar k)v(k),theta(k where u(k i vertical bar k v(k i vertical bar k u(1)(+)(k i vertical bar k u(n)(+)(k i vertical bar k u(1)( )(k i vertical bar k u(n)( )(k i vertical bar k)](t be the predictive control vector rho(1)(k i zero rho(2)(k i zero be the weight coefficient scalar value r(k i zero be a symmetric weight matrix of dimension 2n one x 2n one. 
we assume that the state of the markov chain theta(k be not observe. 
to estimate the parameter of the hide markov model the on line adaptive em algorithm be apply. 
we present the numerical modelling result base on the real datum from the russian stock exchange. 
hardware protection of digital device. 
the task of protect project of digital device at a structural level from malicious misrepresentation and copyright infringement be consider. 
the algorithm of control coding of combinational structure base on the use of method and tool for test diagnostic be propose. 
the algorithm do not require the simulation of device malfunction in an explicit form which reduce the number of computational procedure for encode the circuit. 
the feature of soc design be consider. 
attention be focus on the need to create and develop a unified approach to review the task of monitoring and verification of project taxonomy of deviation. 
taxonomy deviation include the analysis of error that occur directly in the design process and deliberate distortion during the design and manufacturing stage. 
distribute model predictive control for linear systems with adaptive terminal set. 
we propose a distribute model predictive control scheme for linear time invariant constrain system that admit a separable structure. 
to exploit the merit of distribute computation algorithm the terminal cost and invariant terminal set of the optimal control problem need to respect the coupling structure of the system. 
exist method to address this issue typically separate the synthesis of terminal controller and cost from the one of terminal set and do not explicitly consider the effect of the current and predict system state on this synthesis process. 
these limitation can adversely affect performance due to small or even empty terminal set. 
here we present a unified framework to encapsulate the synthesis of both the stabilize terminal controller and invariant terminal set into the same optimization problem. 
condition for lyapunov stability and invariance be impose in the synthesis problem in a way that allow the terminal cost and invariant terminal set to admit the desire distribute structure. 
we illustrate the effectiveness of the propose method on several numerical example. 
robust economic model predictive control of continuous time epidemic process. 
in this paper we develop a robust economic model predictive controller for the containment of stochastic susceptible expose infect vigilant seiv epidemic process which drive the process to extinction quickly while minimize the rate at which control resource be use. 
the study we present here be significant in that it address the problem of efficiently control general stochastic epidemic system without rely on mean field approximation which be an important issue in the theory of stochastic epidemic process. 
this enable we to provide rigorous convergence guarantee on the stochastic epidemic model itself improve over the mean field type convergence result of most prior work. 
there be two primary technical difficulty address in treat this problem one construct a mean of tractably approximate the evolution of the process so that the design approximation be robust to the modeling error introduce by the apply moment closure and two guarantee that the design controller cause the closed loop system to drive the seiv process to extinction quickly. 
as an application we use the develop framework for optimize the use of quarantine in contain an seiv epidemic outbreak. 
integral input to state stability of networked control systems. 
we investigate integral input to state stability iiss of nonlinear networked control system ncss. 
the controller be design by emulation it be construct to ensure iiss for the closed loop system in the absence of the network. 
afterward the latter be take into account and explicit condition be provide on the scheduling protocol and the maximum allowable transmission interval to preserve iiss for the ncs. 
the result be apply to two case study bilinear systems and neutrally stable linear system under saturate feedback where the condition be formulate as linear matrix inequality. 
the effectiveness of the result be far illustrate via a numerical example. 
a bound variable least square solver base on stable qr update. 
in this paper a numerically robust solver for least square problem with bound variable bvls be present for application include but not limited to model predictive control mpc. 
the propose bvls algorithm solve the problem efficiently by employ a recursive qr factorization method base on gram schmidt orthogonalization. 
a reorthogonalization procedure that iteratively refine the qr factor provide numerical robustness for the describe primal active set method which solve a system of linear equation in each of its iteration via recursive update. 
the performance of the propose bvls solver which be implement in c without external software library be compare in term of computational efficiency against state of the art quadratic programming solver for small  to medium sized random bvls problem and a typical example of embed linear mpc application. 
the numerical test demonstrate that the solver perform very well even when solve ill condition problem in single precision float point arithmetic. 
stabilization of a class of nonlinear systems with random disturbance via intermittent stochastic noise. 
in this paper the issue of stochastic stabilization of nonlinear system via intermittent brownian motion under random disturbance be investigate. 
two type of noise be consider. 
one be brownian noise that be regard as an intermittent control input. 
the other be the random disturbance cause by the unknown external environment which can lead to time fluctuation of the intermittent brownian noise stabilization. 
we first present an intermittent stochastic system with random disturbance. 
we then propose an almost sure stability condition for the underlie system. 
the stability result be then use to stabilize the memristive lorenz system. 
numerical simulation be also give to validate the effectiveness of the theoretic result obtain. 
prediction of impactor shape by machine learning with voltage drop characteristics of carbon kevlar hybrid fabric. 
conductivity of carbon fiber can be utilize in a variety of application such as the damage detection in special suit and composite require structural health monitoring. 
in this study a methodology capable of predict the impactor shape be propose by apply the voltage drop information induce by the damage of carbon kevlar hybrid fabric to a decision tree base random forest algorithm. 
drop impact test be perform on the carbon kevlar hybrid fabric specimen accord to the impact shape and incident angle. 
use the gini index of the classification and regression tree cart statistical technique important variable of the impact shape prediction criterion be analyze. 
the validity of the technique be verify by out of bag oob error estimation and three fold cross validation. 
the shape of the impactor be precisely predict by the unknown impactor from the voltage drop datum which be not include in the training process of the random forest. 
this study be significant in that it predict the shape of the initial impactor through the machine learning technique by reflect a multitude of object signal rather than base on specific parameter. 
explosive boiling up in a swirl jet of superheated ethanol. 
base on the knowledge of the kinetic of liquid vaporization under condition of high and attainable superheat experimental datum on the atomization of a jet of boil ethanol at various speed of a flow swirl be discuss. 
it have be state that under condition of low superheat and boiling up on solitary non interacting heterogeneous site the rotation of the flow be consider to be the decisive factor in the atomization process. 
at high superheat and the realization of the mechanism of intense heterogeneous vaporization the effect of boiling up on the jet disintegration become dominant. 
when establish condition for explosive boiling up homogeneous nucleation under attainable superheat a complete jet breakup be observe both without a swirl and at low swirl speed. 
with an increase in the swirl speed the temperature range of the breakup narrow. 
with a strong swirl the breakup disappear completely. 
in the initial state of ethanol close to the thermodynamic critical point the jet shape be similar to a gas one with or without a swirl. 
the one f fluctuation reveal be cause by oscillation nutation of the precessional motion of the jet. 
they indicate a possibility of large scale outburst in the jet. 
c 2019 elsevier ltd. 
all right reserve. 
temperature distribution and heat generate transfer mechanism of the circular bilayer porous bearing for thermo hydrodynamic problem. 
circular porous bearing be a widely use self lubricate bearing structure but it exhibit high temperature rise in bear system heat produce can not be dissipate in time which lead to poorer lubricating performance and make it difficult to use in complex working condition. 
we establish the thermo hydrodynamic lubrication model of circular bilayer porous bearing in polar coordinate couple with the fluid pressure and heat transfer equation and reveal the fundamental origin of the heat generating and its transfer mechanism. 
the result indicate that the circumferential velocity be the major contributor to determine the temperature distribution and the oil film shearing cause temperature rise of the bearing system which be gradually transfer from oil film to porous medium through the heat conduction of porous metal and the convection of fluid. 
thus the temperature in the oil film region be high than that in the porous bearing. 
in the vertical direction the temperature rise first and then decrease from the bear bottom face to the counterpart surface while in the radial direction the temperature increase gradually from the inner radius to the outer radius. 
we find that the high temperature of the bearing system occur at the minimum film thickness of the external ring face in the oil film region. 
the numerical model be verify by compare the experimental and numerical result and the numerical accuracy of the lubrication performance have be improve after consider the thermal effect. 
our result can be employ to control the oil film temperature and exert a well lubricating performance. 
c 2019 elsevier ltd. 
all right reserve. 
determine the effect of tool posture on cut force in a turn milling process use an analytical prediction model. 
turn mill be a key technique that can be use to achieve high efficiency machining and improve life of tool use for difficult to cut material because intermittent cutting with multiple cut edge can suppress a rise in temperature compare with conventional turning. 
however the contact condition between the rotary tool and the cylindrical workpiece vary significantly depend on the tool posture which be define by the tool axis inclination angle against the workpiece namely lead and tilt angle. 
thus clarify the effect of the lead and tilt angle on cut force in turn mill be essential for determine the optimal tool posture. 
in this paper we propose a simulation model to predict the cut force for five axis turn mill consider the contact behavior between the tool and workpiece depend on the tool posture. 
the workpiece be model as a point cloud and any point that interfere with the tool volume be remove when the tool edge pass the surface of the workpiece. 
we examine the simulated cut force use a radius end mill as a linear function of the uncut chip thickness and find that the predict cut force be in agreement with the experimental result for several combination of tool posture and feed rate. 
we also clarify that the tool posture significantly affect the maximum cut force which vary even if the material removal rate be maintain at a constant value in the turn milling process. 
detection of deception attacks in supervisory control systems use bond graph. 
supervisory control and data acquisition scada system can be subject to cyber attack due to their extensive connectivity to information and communication technology. 
those communication be use to connect sensor actuator and programmable logic controller plcs to monitor and control the process. 
the use of communication network enlarge the vulnerability of scada to cyber attack that can drive the system to unsafe state. 
a variety of approach in the field of attack detection have be propose however they be characterize very expensive low detection rate or be system specific. 
one of the powerful cyber attack target scada system be deception attack where the attacker can change sensor read parameter. 
in this work we propose a new defense strategy that detect parameter change generate by deception attack in the sensor and control part in supervisory control system. 
to do so we use the bond graph bg modeling tool. 
huge page friendly virtualized memory management. 
with the rapid increase of memory consumption by application run on cloud datum center we need more efficient memory management in a virtualized environment. 
exploit huge page become more critical for a virtual machine s performance when it run large work set size program. 
program with large work set size be more sensitive to memory allocation which require we to quickly adjust the virtual machine s memory to accommodate memory phase change. 
it would be much more efficient if we could adjust virtual machine memory at the granularity of huge page. 
however exist virtual machine memory reallocation technique such as ballooning do not support huge page. 
in addition in order to drive effective memory reallocation we need to predict the actual memory demand of a virtual machine. 
we find that traditional memory demand estimation method design for regular page can not be simply port to a system adopt huge page. 
how to adjust the memory of virtual machine timely and effectively accord to the periodic change of memory demand be another challenge we face. 
this paper propose a dynamic huge page base memory balancing system hpmbs for efficient memory management in a virtualized environment. 
we first rebuild the ballooning mechanism in order to dispatch memory in the granularity of huge page. 
we then design and implement a huge page work set size estimation mechanism which can accurately estimate a virtual machine s memory demand in huge page environment. 
combine these two mechanism we finally use an algorithm base on dynamic programming to achieve dynamic memory balancing. 
experiment show that our system save memory and improve overall system performance with low overhead. 
a bim integrated relational database management system for evaluate building life cycle cost. 
sustainable procurement be an important policy for mitigate environmental impact attribute to construction project. 
life cycle cost analysis lcca which be an essential requirement in sustainable procurement be a principal tool for evaluate the economic efficiency for the total life cycle budget of a building project. 
lcca be a complex and time consume process due to repetitive complicated calculation which be base on various legal and regulatory requirement. 
it also require a large amount of datum from different source throughout the project life cycle. 
for conventional datum management system datum be usually store in the form of paper and be input into the system manually. 
this result in data loss and inconsistent datum which subsequently contribute to inaccurate life cycle cost lcc. 
build information modeling bim be a modern technology which can potentially overcome the asperity of the conventional building lcca. 
however exist bim tool can not carry out building lcca due to their limited capability. 
the relational database management system rdbms can be integrate with bim for organize store and exchange lcca datum in a logical and systematic manner. 
in this paper a bim integrate rdbms be develop for compile and organize the require datum and information from bim model to compute build lcc. 
the system integrate the bim author program the database management system the spreadsheet system and the visual programming interface. 
it be part of the bim database integrate system for build lcca use a multi parametric model. 
it represent a new automate methodology for perform building lcca which can facilitate the implementation of sustainable procurement in building project. 
improvement of thermal distribution in the rubber glove former conveyor oven by openfoam. 
the great number of rubber glove former be dry by the hot air after dip into the coagulant tank. 
the wet rubber glove have be convey by chain into the oven with the produce speed and then the hot air be blow to impinge the rubber glove former by the hot air branch duct which be instal under the conveyor chain path. 
the traditional design of hot air branch duct be the cause which the rubber glove former be not achieve the hot air thoroughly even though the grille of hot air branch duct be open along the path of former motion. 
the computational fluid dynamic cfd have be apply to model and analyze the hot air flow through the grille of the branch hot air duct inside the conveyor oven. 
the open source code cfd software openfoam be use to perform the computational technique to simulate the complex hot air flow. 
the hot air branch duct be improve to control the hot air temperature distribution for the most uniformity regard the cfd result. 
the temperature comparison between cfd and experiment at each point along the oven length be find that the cfd model confirm an effective improvement and accuracy under an average error be less than 8.99. 
magnet temperature estimation base on a novel frequency determination algorithm for the five phase pma synrm. 
this study present a novel frequency determination algorithm for the magnet temperature estimation of a five phase permanent magnet assist synchronous reluctance motor pma synrm use the signal injection method. 
the signal injection method be a convenient and non invasive approach to determine the magnet temperature in permanent magnet motor by exploit the temperature dependency of magnet resistance. 
however its implementation as a magnet temperature estimation tool warrant an adaptive frequency determination method in order to ensure its effective employability under more pragmatic dynamic operation. 
the propose method in this study propose an analysis of the frequency spectrum to isolate the fundamental and fault frequency and their respective harmonic to determine a range of available frequency that may be employ in this method. 
the available frequency be far concentrate base on the signal to noise ratio constraint. 
as an additional part of the contribution of this study an innovative rotate hardware set up be develop which would transmit the magnet temperature datum wirelessly to verify the accuracy of the propose temperature estimation algorithm. 
design principle of a 16 pole 18 slot two sectional modular permanent magnet linear synchronous motor with optimisation of its end tooth. 
in order to improve the performance of the linear motor system it be necessary to adopt a simple motor structure and effective optimisation method to reduce the detent force without decrease the average thrust. 
a 16 pole 18 slot two sectional modular permanent magnet linear synchronous motor pmlsm be investigate in this study in which the primary core be divide into two module and couple with the secondary form two section. 
it be find that the modular distance between the two section affect the detent force and back electromotive force of the whole motor. 
thus the characteristic of the detent force and the category of the winding arrangement be analyse. 
the modular distance of four tau/9 be choose after analysis and comparison. 
to far suppress the detent force and improve the average thrust a new end tooth structure include different wide and narrow tooth be propose which be set at the end of each section s primary core. 
the design method of the end tooth parameter be obtain by theoretical derivation and the optimisation efficiency of end tooth parameter be far improve by layered optimisation design. 
finally the experiment on the 16 pole 18 slot pmlsm validate the correctness and feasibility of the propose modular motor structure. 
robust design for reduce cog torque in surface mount permanent magnet synchronous motor consider tolerance of sub component. 
this study deal with a robust design for cog torque reduction consider the production tolerance of motor sub component which be relate to the dimension of the permanent magnet and stator core shape. 
a 14 pole and 12 slot fractional slot concentrate winding motor be employ as the design model. 
prior to a robust design an initial model be implement to satisfy the torque demand within some constraint. 
in the robust design the main design variable be first select for the design of experiment doe. 
the interaction effect be investigate use the full factorial design which be one of the doe technique. 
next the direction of design variable to minimise the cog torque and improve the signal to noise ratio be confirm use the taguchi method. 
then the response surface methodology be implement base on the result from the taguchi method to yield an optimum value of the design variable and approximate equivalent polynomial equation. 
finally the normal distribution curve of the cog torque be simply determine by the equivalent polynomial equation use the monte carlo method take production tolerance base on the process capability of the sub component into consideration. 
fpga base real time implementation of a direct torque control with second order slide mode control and input output feedback linearisation for an induction motor drive. 
a robust direct torque control dtc strategy for an induction motor be propose in this study. 
in fact the propose control strategy be define by a combination of dtc space vector modulation svm input output feedback linearisation iofl a second order super twist speed controller stsc and slide mode load torque and stator flux observer with stator resistance estimation. 
first non linear iofl be suggest to achieve decoupled flux and torque control and the svm technique be utilise to control the inverter switch frequency which decrease the torque ripple and noise. 
second to improve the speed regulation an stsc be add to an svm dtc iofl scheme. 
furthermore the slide mode observer of the stator flux and of the load torque be propose in order to improve the control performance by reduce uncertainty and to prevent the effect of the stator resistance variation. 
indeed this study present the importance of implement the suggest svm dtc iofl use a field programmable gate array fpga circuit. 
the main interest of the fpga implementation be the decrease in the control loop delay due to the parallel processing offer by the fpga. 
the performance of the propose control algorithm be investigate by digital simulation use a xilinx system generator tool and experimental implementation utilise fpga virtex five ml507. 
five axis dry milling of bottom of pocket by ball and circle segment end mill. 
at present five axis machining be often realize with ball end mill that do not achieve the advantage of modern circle segment end mill. 
however to exploit the potential of these modern tool it be necessary to use a special cam software include hypermill from westcam. 
this software increase the efficiency of machining be use in the present study which compare these tool with respect to the quality of the machine surface machine time and cut force. 
the workpiece material be aluminum alloy en aw 7075 t6. 
at give cut parameter the circle segment end mill achieve a low ra value and generally high machining efficiency. 
at the end of the study an assessment be make with respect to the economy. 
experimental setup for analyze fundamental of cut process use a modular system. 
machine operation like mill exhibit complex process kinematic which restrict the identification and analysis of fundamental cause effect interrelation. 
in order to differentiate the impact of relevant process parameter a reduction of influence factor be necessary. 
for this purpose a cutting operation with a linear cutting motion like orthogonal cutting be beneficial. 
such an experimental setup require suitable tool workpiece and measurement system. 
the experimental assessment of a develop modular design be present in this publication. 
in addition to orthogonal cut oblique cut which be representative for machine operation with respect to the helix angle be investigate. 
to analyze process dynamic interrupt cut include a specifically compliant tool system be perform. 
case study of real manufacturing system improve through simulation model. 
the paper deal with a real manufacturing system improve through simulation model creation. 
the aim of the paper be to present the possibility of simulation model as a tool for optimization and quantification of proposal to improve production line in engineering production. 
the research be carry out as a case study of a production plant in a slovak machine build company deal with the component for the automotive sector production. 
the paper present the creation of simulation model of the original line as well as the simulation model of improve line where robotic arm be use for material handling. 
output statistic compare the performance of the original line and its improved variant be part of the paper. 
we expect that in the come year there will be an increase demand for creation of simulation model of manufacturing system by modern enterprise that will try to implement the industry 4.0 strategy and thus increase its competitiveness. 
3d print belt wheel for use in design of bicycle. 
the article describe how it be possible to use 3d printing for print belt wheel for bicycle. 
new category of bike keep appear in the market. 
for the use specially city that be bike that use belt instead of a traditional chain. 
with new generation of belt this power transmission can be use on mountain bike. 
but a belt drive bike must have a special frame because the belt can not be disconnect like a classic chain. 
even with modern 3d cad application a company need to make a prototype and check their design. 
that be not only important for the function of the bicycle but also to prove the assembly or maintenance process. 
in comparison with a chain the belt drive system be more expensive. 
for small company it be then difficult to buy different gearing combination just for check the design. 
in this case the 3d printing come in handy because it can produce very quickly cheap belt wheel with different tooth combination or design of the belt wheel. 
with more advanced method like the selective laser sintering of 3d printing it be possible to produce even functional belt wheel that have the same ore even well property compare to traditional injection molding. 
this article show the possibility in the prototyping of belt wheel with different 3d printing method. 
modification of cutting tools by drag finishing. 
the paper deal with a progressive method of modification of cut tool by drag finishing process. 
the subject of the research be the dependence of the drag finish time on the size of the cutting edge radius. 
the mill tool solid cement carbide mill be make on a tool grinder reinecker wzs 60. 
the cut tool be drag finish on the otec df three tools drag finish machine. 
the measurement of cut edge radius be perform on two device 3d optical microscope alicona infinite focus g5 and contour and surface measure machine zeiss surfcom 5000. 
the result of the measurement be evaluate at the end of the paper. 
optimization coating of cylindrical tools with fixture for increasing machine capacity. 
the coating technology be integral part of industrial production. 
in the tooling field coating be an essential part. 
for the vast majority of tooling material today a coating that have abrasion resistance high hardness high temperature stability as well as overall wear resistance of the cutting edge be a matter of course and necessity. 
however coating machine be design for a maximum predetermined number of tool. 
it would be possible to increase the capacity of the coating machine by mean of a jig design specifically for the give machine with give kinematic. 
the topic of this article be the design of the jig for increase the capacity of the coat pvd machine. 
the main part be the design and construction of the jig where the construction of the movement system be describe. 
then follow the design of the material and description of the main principle operation of the product. 
the jig will be design for coat cylindrical tool the monolithic milling cutter and drill make mostly of cement carbide. 
when coat such tool with the pvd method care must be take to avoid so call shadow effect. 
this fact must also be reflect in the design of the fixture. 
increase the capacity of the pvd of the machine will lead to an increase in the production batch and thus an increase in profit. 
model partial discharge phenomena. 
measurement of partial discharge pd activity be a commonly use technique to diagnose the health of insulation material within high voltage plant. 
the definition of pd be relatively broad it be generally define as a localized or confine discharge within an insulate medium. 
due to the high electric breakdown strength of insulation material pd typically occur within low density defect in the system. 
one family of defect which have receive significant research attention be air fill void typically spherical or cylindrical surround by solid dielectric material. 
experiment have typically use a sandwich technique to fabricate cylindrical void use three slab of material with a circular hole drill into the central slab. 
the slab be then press together and place between parallel plate electrode. 
a common dielectric material use to fabricate cylindrical voids be ldpe. 
by inject air through a syringe before the curing process spherical void have be fabricate in epoxy resin and silicone rubber. 
contractguard defend ethereum smart contracts with embedded intrusion detection. 
ethereum smart contract be program that can be collectively execute by a network of mutually untrusted node. 
smart contract handle and transfer asset of value offer strong incentive for malicious attack. 
intrusion attack be a popular type of malicious attack. 
in this article we propose contractguard the first intrusion detection system ids to defend ethereum smart contract against such attack. 
like ids for conventional program contractguard detect intrusion attempt as abnormal control flow. 
however exist ids technique tool be inapplicable to ethereum smart contract due to ethereum s decentralize nature and its highly restrictive execution environment. 
to address these issue we design contractguard by embed it in the contract to profile context tag acyclic path and optimize it under the ethereum gas orient performance model. 
the main goal be to minimize the overhead to which the user will be extremely sensitive since the cost need to be pay upfront in digital concurrency. 
empirical investigation use real life contract deploy in the ethereum mainnet show that on average contractguard only add to 36.14 percent of the deployment overhead and 28.27 percent of the runtime overhead. 
furthermore we conduct control experiment and show that contractguard successfully guard against attack on all real world vulnerability and 83 percent of the seeded vulnerability. 
facilitate application aware bandwidth allocation in the cloud with one step ahead traffic information. 
bandwidth allocation to virtual machine vm have a significant impact on the performance of communication intensive big datum application host in vm. 
it be crucial to accurately determine how much bandwidth to be reserve for vm and when to adjust it. 
past approach typically resort to predict the long term network demand of application for bandwidth allocation. 
however lack of prediction accuracy these method lead to the unpredictable application performance. 
recently it be concede that the network demand of application can only be accurately derive right before each of their execution phase. 
hence it be challenge to timely allocate the bandwidth to vm with limited information. 
in this paper we design and implement appbag an application aware bandwidth guarantee framework which allocate the accurate bandwidth to vm with one step ahead traffic information. 
we propose an algorithm to allocate the bandwidth to vm and map they onto feasible host. 
to reduce the overhead when adjust the allocation an efficient lazy migration lm algorithm be propose with bound performance. 
we conduct extensive evaluation use real world application show that appbag can handle the bandwidth request at run time while reduce the execution time of application by 47.3 percent and the global traffic by 36.7 percent compare to the state of the art method. 
analysis of features dataset for ddos detection by use asvm method on software defined network. 
the impact of distributed denial of service ddos attack be one of the major concern for software defined networking sdn environment. 
support vector machine svm have be use in a ddos attack detection mechanism on sdn. 
the advantage of svm algorithm in ddos attack detection be high accuracy and low false positive rate. 
however svm algorithm take too long for training and testing time. 
a large number of literature have be try to get well result in a svm base ddos attack detection. 
they propose various kind of svm base detection method. 
their result be measure and evaluate by use various evaluation metric. 
as a result a svm base detection performance depend on the nature of traffic dataset. 
in this paper our focus be to analyze the extract feature from the sdn traffic dataset result on a reduction of bias datum from the dataset. 
sdn traffic feature dataset be validate by use 10 fold cross validation method. 
the effectiveness of our create dataset be validate by compare with other dataset knowledge discovery and data mining tools competition kddcup 99 dataset. 
in conclusion our propose dataset can be use effectively for svm on sdn. 
c 2020 the authors. 
publish by atlantis press sarl. 
multiple internet of robotic things robot base on lidar and camera sensor. 
a combination of internet of thing and multiple robot with sensor have be an attractive research topic over the past year. 
this article propose an internet of robotic things system structure to monitor event fuse sensor datum use local robot to determine a good action and then act to control multiple mobile robot. 
the internet of robotic things system include two main layer the host controller layer and the multiple robot layer. 
the controller layer communicate with the multiple robot layer by wi fi module. 
the internet of robotic things system help finish five task localize robot planning path avoid obstacle move to waypoint stable and create a map. 
base on depth datum from depth camera and robot posture a mapping algorithm be propose to create map. 
base on light detection and range sensor datum and google cartographer simultaneously localization and mapping slam be also process in this article. 
the fuzzy slide mode tracking control method be propose for each robot to guarantee the robot stable move. 
simulation result show the effectiveness of the propose algorithm and be use to compare with the experiment result. 
in the experiment one host computer and two kobuki mobile robot with light detection and range and depth camera sensor be integrate as an internet of robotic things system. 
two robot successfully localize themselves and avoid obstacle. 
the follower robot simultaneously build a map. 
a comprehensive load flow approach for grid connect and islande ac microgrid. 
this paper propose a comprehensive load flow algorithm for balanced and unbalanced distribution system consider the effect of a multi grounded neutral conductor. 
the method be base on the implicit z(bus method present fast convergence and robustness regardless of the r x ratio of the line. 
its distinct feature be its ability to handle all network configuration include highly mesh distribution system that operate in either islande or grid connect mode. 
furthermore an algorithm be propose for overcome the limitation of implicit z(bus method to treat pv node. 
additionally the concept of virtual impedance be incorporate into the propose algorithm to accurately simulate the behavior of distribute generator dgs during the islanded operation. 
numerical simulation be conduct in 33 bus and 38 bus balanced network as well as in 25 bus and 30 bus unbalanced network to verify the validity of the propose load flow algorithm. 
a homotopy base method for robust computation of controlling unstable equilibrium point. 
this paper propose a homotopy base method for efficiently compute and precisely determine control unstable equilibrium point cueps in transient stability analysis and screen use direct method. 
the propose method be intend to overcome potential numerical convergence problem associate with compute cuep. 
these convergence problem be mostly due to irregularity in the region of convergence of cuep which make it difficult to determine suitable initial point. 
the most commonly use initial point in compute cuep be minimum gradient point mgps on the stability boundary which in turn rely on the determination of exit point ep point at which sustain fault trajectory exit system stability boundary. 
however determination of mgps and ep be computationally involve and sophisticated numerical method have be introduce such as stability boundary follow procedure and shadowing method to correct the solution trajectory. 
the propose method do not depend on mgps and also do not require accurate ep. 
the propose method map the solution from ep to the cuep. 
the propose method be apply on several know system include the ne 39 bus system and the reduce wecc system and the result be provide. 
the result be compare with the traditional method such as boundary of stability region base cuep method bcu method. 
a proposal of the event relate potential method to effectively identify kansei word for assess product design feature in kansei engineering research. 
the effective acquisition of kansei word for assess product design feature play a decisive role in knasei engineering research whereas previous study rarely give a full understanding of how to effectively grasp the relate kansei word. 
the exist finding reveal that traditional method base on questionnaire survey might have trouble and limitation in kansei word acquisition. 
the process require the active involvement of user which could be time consume expensive knowledge and labor intensive. 
hence there still remain a need for an efficient method that can effectively identify kansei word for assess product design feature in kansei engineering study. 
the n400 an event relate potential erp can be trigger by semantic violation in visual stimulus material. 
the present study investigate whether n400 can be use as an electrophysiological measurement to effectively identify kansei word for assess product design feature in kansei engineering research. 
this study take the suv picture as the prime stimulus and two relatedness match level of kansei word from a high level to a low level as the target stimulus include the unrelated kansei word and related kansei word. 
it be show that the relate kansei word elicit a short n400 amplitude than the unrelated kansei word. 
moreover the n400 exhibit the different scalp distribution between related and unrelated kansei word. 
these finding indicate that the n400 could be use to compensate limitation of conventional questionnaire survey in kansei word acquisition for assess product design feature. 
relevance to industry with the assistance of n400 neural measurement in kansei word acquisition kansei engineering will advance far as a modernized technology in kansei product design. 
the method propose in this study use n400 to effectively identify kansei word which can be apply to kansei engineering research and improve the product development process. 
adaptive null broadening algorithm base on sidelobes cancellation. 
in exist null broaden algorithm the taper matrix do not contain phase information and when it be use to against strong directional and large deviation angle interference the null depth become shallow and the interference suppression performance drop seriously. 
an adaptive null broaden algorithm for sidelobe canceller be propose base on dense disturbance in virtual airspace. 
the algorithm reconstruct the self covariance matrix of the auxiliary array datum and the co covariance matrix of the main and auxiliary array datum at the same time to realize the adaptive control of the null region. 
the taper matrix be only relate to the position and width of the array element and it can be generate offline without disturb information and occupy no compute resource of the system. 
the simulation result show that this method can achieve adaptive broadening of the null region and improve the robustness of non stationary interference suppression. 
the method of virtual machine live migration base on hashgraph. 
live migration of virtual machines(vms across wan be an important support for multi datacenter cloud computing environment. 
the current live migration of vm across wan face many technical challenge due to the limitation of small bandwidth and no share storage such as ensure the security and consistency of image datum migration. 
therefore a method for vm live migration across datum center base on hashgraph be propose in this paper decentralize idea be use to achieve reliable and efficient image distribution between datum center. 
the merkle dag of hashgraph improve the deficiency of deduplication when migrating image across datum center. 
compare with exist method it can reduce total migration time. 
exponential stabilization control of delayed quaternion value memristive neural networks vector ordering approach. 
the stabilization control of the quaternion value memristive system be investigate in this paper. 
by start from the basic quaternion value algorithm the memristive system describe by quaternion value connection weight be derive. 
subsequently a comprehensive set of result to ensure the existence of the equilibrium point and its stability analysis have be develop. 
particularly vector ordering approach be propose in this paper which can be employ to determine the magnitude of two different quaternion value and thus the close convex hull derive by two different quaternion value connection can be obtain correspondingly. 
in the end the propose method be substantiate with two numerical example. 
stabilization of a class of hybrid systems by switch controllers with input constraints. 
in this paper a hybrid control strategy use appropriate switching between a set of linear controller be present for stabilization of a class of hybrid system with input constraint. 
the input constraint under consideration be novel reverse polytopic constraint avoid a set of specify input value. 
the design procedure of the switch controller be perform by solve a set of linear matrix inequality for the full state feedback case and by solve a set of bilinear matrix inequality for the output feedback case. 
under the design controller the closed loop system be show to be globally uniformly pre asymptotically stable if a specific set of matrix inequality ensure the existence of a common lyapunov function be satisfied. 
to avoid the zeno behavior a tunable parameter relate to the controller gain be introduce and assess. 
it be show that the propose switching control be superior to continuous state feedback control with input constraint. 
in addition besides continuous linear system the propose control strategy be applicable to hybrid or impulsive system. 
numerical example be include to illustrate the propose result. 
a survey on modeling and improve reliability of dnn algorithm and accelerator. 
as dnn become increasingly common in mission critical application ensure their reliable operation have become crucial. 
conventional resilience technique fail to account for the unique characteristic of dnn algorithm accelerator and hence they be infeasible or ineffective. 
in this paper we present a survey of technique for study and optimize the reliability of dnn accelerator and architecture. 
the reliability issue we cover include soft hard error arise due to process variation voltage scaling time error dram error due to refresh rate scaling and thermal effect etc. 
we organize the research project on several category to bring out their key attribute. 
this paper underscore the importance of design for reliability as the first principle and not merely retrofit for it. 
designing observer type controller for containment of discrete time linear mas over sign graph. 
in this brief we aim to solve the containment problem for a class of discrete time linear multi agent system mass with multiple interaction leader. 
agent in the consider mass will communicate with their neighbor through a signed digraph the relationship between neighboring agent in the present mass model may be cooperative or antagonistic which differ from most previous research on containment of linear mas. 
to achieve containment in such an mas model reduce order observer type containment controller use the relative output of neighboring agent be develop. 
by utilize stability theory of discrete time linear system it be prove that the state trajectory of follower can enter eventually the convex hull form by the trajectory of leader and their symmetric trajectory provide that the inherent linear dynamic of each agent be stabilizable and detectable and each follower could receive information directly or indirectly from at least one leader. 
finally a numerical example be present to verify the achievement of containment under the propose controller. 
scheduling resources to multiple pipelines of one query in a main memory database cluster. 
to fully utilize the resource of a main memory database cluster we additionally take the independent parallelism into account to parallelize multiple pipeline of one query. 
however scheduling resource to multiple pipeline be an intractable problem. 
traditional static approach to this problem may lead to a serious waste of resource and suboptimal execution order of pipeline because it be hard to predict the actual data distribution and fluctuate workload at compile time. 
in response we propose a dynamic scheduling algorithm list with filling and preemption lfp base on two novel technique. 
one adaptive filling improve resource utilization by issue more extra pipeline to adaptively fill idle resource hole during execution. 
two rank base preemption strictly guarantee schedule the pipeline on the critical path first at run time. 
interestingly the latter facilitate the former fill idle hole with good effort to finish multiple pipeline as soon as possible. 
we implement lfp in our prototype database system. 
under the workload of tpc h experiment show our work improve the finish time of parallelizable pipeline from one query up to 2.5x than a static approach and 2.1x than a serialized execution. 
a 135 150 ghz frequency tripler use su eight micromachined wr five waveguide. 
this article present a 135 150 ghz schottky diode base bias less frequency tripler base on su eight micromachine wr five waveguide. 
the waveguide consist of five 432  mu m thick silver plate su eight layer which house the diode chip and form the output matching network. 
the input matching circuit be realize in a computer numerical control cnc mill waveguide filter which also provide support and thermal sink to the su eight waveguide. 
consider the low thermal conductivity of the su eight material auxiliary metallic thermal path be design and the impact of these be discuss through thermal modeling. 
the thermal simulation show that under 50 mw power dissipation in the diode anode the maximum temperature of the su eight tripler be predict to be 346 k at the diode junction only seven k high than in an entirely metal equivalent. 
the tripler be measure to have a conversion loss of 16 18 db and the input return loss be well than 18 db. 
this work demonstrate that su eight micromachined waveguide can be use to package high frequency semiconductor component which like other photolithography base process such as silicon deep reactive ion etch si drie have the potential for submicrometer feature resolution. 
ctdroid leverage a corpus of technical blogs for android malware analysis. 
the rapid growth of android malware result in a large body of approach devote to malware analysis by leverage machine learning algorithm. 
however the effectiveness of these approach primarily depend on the manual feature engineering process which be time consume and labor intensive base on expert knowledge and intuition. 
in this paper we propose an automatic approach that engineer informative feature from a corpus of android malware relate technical blog which be write in a way that mirror the human feature engineering process. 
however there be two main challenge. 
first it be difficult to recognize useful knowledge in the magnanimity information of thousand of blog. 
to this end we leverage natural language processing technique to process the blog and extract a set of sensitive behavior that might do harmful activity to user potentially. 
second there exist a semantic gap between the extract sensitive behavior and the programming language. 
to this end we propose two semantic matching rule to match the behavior with concrete code snippet such that the app can be test experimentally. 
we design and implement a system call ctdroid for malware analysis include malware detection md and familial classification fc. 
after the evaluation of ctdroid on a large scale of real malware and benign app the experimental result demonstrate that ctdroid can achieve 95.8 true positive rate with only one false positive rate for md and 97.9 accuracy for fc. 
furthermore our propose feature be more informative than those of state of the art approach. 
a reliability allocation method for mechanical product base on meta action. 
for a long time the machinery s reliability allocation method have follow the electronic and thus all of the interaction among move component and part in machine be neglect. 
in fact the allocate result be not reasonable for mechanical product even the allocation granularity be not appropriate to guide the reliability design. 
to overcome these problem this paper propose an allocation method base on meta action. 
by use the function movement action method we decompose the mechanical product into meta action. 
an action be use as the basic unit of reliability control and all the part contribute to the action be treat as a whole. 
the interaction of the part which contribute to the same action be treat as the internal force of meta action and other be consider as the interaction between meta action by the consideration of common part in different unit. 
an illustrative example show the propose method make the result more reasonable and more convenient to guide mechanical product design. 
combinatorial optimization of graphical user interface designs. 
the graphical user interface gui have become the prime mean for interact with computing system. 
it leverage human perceptual and motor capability for elementary task such as command exploration and invocation information search and multitaske. 
for design a gui numerous interconnect decision must be make such that the outcome strike a balance between human factor and technical objective. 
normally design choice be specify manually and code within the software by professional designer and developer. 
this article survey combinatorial optimization as a flexible and powerful tool for computational generation and adaptation of gui. 
as recently as 15 year ago application be limit to keyboard and widget layout. 
the obstacle have be the mathematical definition of design task on the one hand and the lack of objective function that capture essential aspect of human behavior on the other. 
this article present definition of layout design problem as integer programming task a coherent formalism that permit identification of problem type analysis of their complexity and exploitation of know algorithmic solution. 
it then survey advance in formulate evaluative function for common design goal focus such as user performance and experience. 
the convergence of these two advance have expand the range of solvable problem. 
approach to practical deployment be outline with a wide spectrum of application. 
this article conclude by discuss the position of this application area within optimization and human computer interaction research and outline challenge for future work. 
fad or trend rethink the sustainability of connected health. 
ypolicymaker academic and industry player have be focus on determine whether connected health ch be a fad or a trend by look at its sustainability. 
although the significance of innovation in healthcare be gradually rise a definitive identification and systematic comprehension of the core driver structure content and pattern of innovation in ch be miss. 
to bridge this gap this study re examine and analyse ch from the perspective of its industrial chain and structure to assess its future prospect and sustainability by focus on how its structure and participant act in the ecosystem. 
this study involve an inductive theory building approach base on multi stage semi structured interview n 60 in total. 
the result indicate that the core driver constituent and component of ch need to be identify and restructure. 
a valid discourse which be miss in the current literature should be propose with regard to the sustainability of ch. 
a sustainable business model innovation bmi system and the method employ to achieve sustainability be suggest to discover indicator for future success. 
this study enrich the current ch understanding from a technology perspective and suggest some implication for practitioner as well as policymaker to enhance sustainable development in the healthcare sector. 
an innovative industry 4.0 cloud data transfer method for an automated waste collection system. 
move to industry 4.0 involve the collection of massive amount of datum and the development of big datum application that can ensure a quick data flow between different system include massive amount of datum and information collection from smart sensor and send they to cloud application that allow real time datum monitoring and processing. 
securing and protect the transmit datum represent a big issue to be discuss and resolve. 
in the paper we propose a new method of datum encoding and encryption for cloud application use png format image. 
the propose method be describe in comparison with one of the classical method of datum encoding and transmission use currently. 
the paper include a case study in which the propose method be use to collect and transmit datum from an automate waste collection system. 
the result show that the propose method represent a secure fast and efficient way to send and store the datum in the cloud compare to the method currently use. 
the propose method be not limit to be use only in waste management but can be use successfully for any type of manufacture system from smart factory. 
social impact innovations and market activity of social enterprises comparison of european countries. 
the purpose of this article be to provide an insight into the specific of social entrepreneurship in different business environment. 
the article therefore examine select characteristic of social enterprise namely social value innovation and market activity. 
in addition difference in the start up and operational phase of social enterprise be measure. 
social enterprise must operate in a specific business context which essentially hinder or promote social entrepreneurship. 
as culture differ between north western and south eastern europe it be important to examine the difference in social entrepreneurship between these two group of country. 
to analyze the propose characteristic we use the late datum from the global entrepreneurship monitor special report on social entrepreneurship. 
the result indicate that there exist difference in social impact measurement between observed group of country. 
additionally we confirm difference between the observed group of country in term of innovation and market activity of social enterprise in the operational phase. 
our result also suggest that social entrepreneurship be more develop in north western european country than in south eastern one with some element in the north western country be more noticeable in the operational phase compare to the start up phase. 
social sustainability satisfying owners and communities by multilevel strategies of contractor. 
in sustainable construction production the social dimension regard owner and community satisfaction have receive the least focus. 
to promote social sustainability the multilevel strategy of contractor should be develop for owner and community satisfaction. 
however a literature review show that there be few study on how multilevel strategy influence such satisfaction. 
hence this study aim to analyze such influence. 
a survey be conduct to gather datum from the thai construction industry and these datum be then analyze by a structural equation model sem. 
the result for the first time highlight that corporate strategy influence business strategy direct influence 0.98 which in turn influence functional strategy direct influence 0.93. 
additionally only functional strategy influence owner direct influence 0.84 and community satisfaction direct influence 0.66. 
furthermore parenting cooperation and equipment machinery substrategie obtain the high weight within the management level of corporation business and function regression weight 0.49 0.48 and 0.55 respectively. 
the work productivity and site organization indicator have the large weight for owner and community satisfaction regression weight 0.47 and 0.57 respectively. 
the finding provide a guideline that help contractor allocate their available resource to substrategie accord to their regression weight enhance owner and community satisfaction. 
spatial relations between the standards of living and the financial capacity of polish district level local government. 
the objective of the present article be the identification of spatial relation between the inhabitant standard of living and the district financial capacity base on datum for 2017. 
the investigation comprise all of the 380 polish district. 
in regard to the multidimensionality of economic occurrence analyze the topsis the technique for order of preference by similarity to ideal solution approach to measure the inhabitant standard of living and the financial ability of district be apply in the research. 
a spatial autocorrelation analysis between the taxonomic synthetic index be perform use local and global moran s i statistic in order to determine the district cluster demonstrate a comparable degree of occurrence analyze. 
a spatial regression analysis be conduct to find the strength of spatial relation between the taxonomic index of the standard of living and the district financial ability. 
diagnostic variable be choose accord to substantive statistical and formal criterion. 
the outcome of the spatial regression analysis allow it to be conclude that about one increase of the taxonomic indicator of the district financial ability be reflect in about 0.4 growth of the taxonomic index of the standard of living of the inhabitant of different district other thing be equal. 
the result of analysis can be apply indirectly by a number of stakeholder local authority responsible for local and regional development when create the development strategy at local government unit lgu level. 
the knowledge on spatial development structure can enhance the formation of the strategic management process for instance redefine the objective and task set out in local strategy restructure the expenditure to meet the local population s need. 
review of the effect of developments with low parking requirement. 
parking management and planning can be use to address several issue relate to sustainable urban development. 
for example parking availability affect both car ownership and usage and parking planning can affect both land use and building cost. 
a tool use in several country be minimum parking requirement mpr and lower these could be a pathway to more sustainable mobility. 
however the actual effect of low mpr have not systematically be study. 
in this paper we present the result of a review of sixteen development with low mpr in sweden austria germany switzerland and the uk. 
exist research and report have be analyze to compare these and draw conclusion on the effect of mpr on mobility pattern and mobility service. 
in addition interview be conduct with representative from municipality and developer. 
our result indicate that the mobility pattern of individual in the studied project be more sustainable than in nearby project. 
however the causality of mpr and mobility be hard to establish due to the risk of self selection and that all of the studied project have good prerequisite for sustainable mobility practice. 
many of the study evaluation be also of poor quality with for example lack of appropriate control group. 
tkrm a formal knowledge representation method for typhoon event. 
typhoon event can cause serious environmental damage and economic loss. 
understand the development of typhoon event will provide valuable knowledge for disaster prevention and mitigation. 
in the age of big datum the sharp contrast between the sudden increase of mass information and the lack of a knowledge appreciation mechanism appear. 
there be an urgent need to promote the transformation of information service to knowledge service in the field of hazard management. 
knowledge representation as a strategy for symbolizing and formalizing knowledge affect knowledge acquisition storage management and application and be the basis and prerequisite for the implementation of knowledge service. 
base on the evolution law of typhoon event and human cognitive habit a formal knowledge representation method for typhoon event tkrm be propose in this paper. 
first by analyze the evolution characteristic of typhoon event the tkrm framework with three layer consist of event process state be construct which be use to describe the knowledge composition and relationship of the different granularity of typhoon event. 
second the formal representation of the tkrm framework be form by use a finite state machine fsm as a reference take time and location as the basic condition and extend the hierarchical and parallel representation mechanism. 
finally the rationality and practical value of the tkrm be verify use a case study. 
study on the influence of air tightness of the building envelope on indoor particle concentration. 
in order to grasp the building palisade structure tightness of indoor particulate matter mass concentration base on the particle penetration mechanism and settlement characteristic this article analyze the measurement of two different type of build air tightness of a shenyang university office building in term of indoor and outdoor particulate matter mass concentration level from 2016 one 09 to one 22 2016 seven 18 to eight 03 and 2017 two 28 to three 13. 
the building outside the closed window that have no indoor source condition the indoor office building and outdoor particle mass concentration and the aperture size and shape of the envelope be analyze to carry on the numerical simulation research by fluent software which be then analyze the result reveal that the measuring point of the i o ratio be less than point b of the i o ratio measurement point of a linear regression fitting degree be low than the fit of the measure point b and the cause for the measuring point a tightness level 8) be superior to the measure point b level four. 
when the gap height h be great than 0.5 mm the penetration rate of particle within the range of 0.25 2.5 mu m particle size be close to one. 
in different gap depth the penetration rate of particle within the range of 0.1 one mu m particle size be close to one. 
in diverse pressure difference the 0.25 2.5 mu m particle within the scope of penetration rate p be close to one the gap on both side of the differential value delta p the great the particle the high penetration rate. 
the large the right angle number of gap n the low the penetration rate of particle. 
the l shape gap and u shape gap have significantly well barrier effect in large and small particle than the rectangular gap. 
the research result in this paper can help people understand and effectively control the influence of outdoor particle on the indoor air quality and provide reference datum for the prediction of indoor particle mass concentration in building which have theoretical basis and practical significance. 
design and implementation of a connection between augmented reality and sensor. 
wireless sensor network wsn be use by engineer to record the behavior of structure. 
the sensor provide datum to be use by engineer to make informed choice and prioritize decision concern maintenance procedure require repair and potential infrastructure replacement. 
however reliable datum collection in the field remain a challenge. 
the information obtain by the sensor in the field frequently need further processing either at the decision make headquarters or in the office. 
although wsn allow data collection and analysis there be often a gap between wsn datum analysis result and the way decision be make in industry. 
the industry depend on inspector decision so it be of vital necessity to improve the inspector access in the field to datum collect from sensor. 
this paper present the result of an experiment that show the way augmented reality ar may improve the availability of wsn datum to inspector. 
ar be a tool which overlay the know attribute of an object with the correspond position on the headset screen. 
in this way it allow the integration of reality with a virtual representation provide by a computer in real time. 
these additional synthetic overlay supply datum that may be unavailable otherwise but it may also display additional contextual information. 
the experiment report in this paper involve the application of a smart strain gauge platform which automatically measure strain for different application use a wireless sensor. 
in this experiment an ar headset be use to improve actionable data visualization. 
the result of the report experiment indicate that since the ar headset make it possible to visualize information collect from the sensor in a graphic form in real time it enable automatic effective reliable and instant communication from a smart low cost sensor strain gauge to a database. 
moreover it allow inspector to observe augmented datum and compare it across time and space which then lead to appropriate prioritization of infrastructure management decision base on accurate observation. 
control liquid slosh by apply optimal operating speed dependent motion profiles. 
in this paper an investigation be present that demonstrate the application of a new approach for enable the reduction of liquid slosh by implement optimize motion profile over a continuous range of operating speed. 
liquid slosh occur in the packaging process of beverage. 
start by create a dynamic process model optimal control theory be apply for calculate optimal motion profile that minimize residual vibration. 
subsequently the difficulty of operate speed dependency of the herewith synthesize motion profile be examine. 
an approach in which the optimal motion profile be consolidate into a characteristic map of motion specification which can be execute by a programmable logic controller in real time be discuss. 
eventually the success of this novel approach be demonstrate by the comparison with state of the art motion profile and conventional motion implementation. 
research and development of monitor system and datum monitoring system and datum acquisition of cnc machine tool in intelligent manufacturing. 
intelligent manufacturing as the development direction of the new generation manufacturing system have become a hot research topic. 
computer numerical control cnc machine tool be the core manufacturing equipment in discrete manufacture enterprise collect and monitor the data be an important part of intelligent manufacturing workshop. 
it have a great significance to improve the production efficiency of enterprise and eliminate information island. 
the purpose of this article be to solve the problem of datum acquisition and monitoring of cnc machine tool in the manufacturing workshop of enterprise. 
this article use focas datum acquisition method to research and develop the datum acquisition and monitoring system of cnc machine tool in intelligent manufacturing workshop. 
the research result show that the equipment information model base on mtconnect protocol and focas can solve the datum acquisition and storage function of cnc machine tool well. 
use the object orient petri net model it can solve various uncertain factor in numerical control nc machining task and realize the monitoring function of cnc machining task in the workshop. 
base on the nc program analysis the calculation method of machine time in the nc program can determine the preventive maintenance cycle of the machine base on the machine fault information. 
base on vs2013 development environment qt application framework and sql server 2012 database the numerical control machine tool datum acquisition and monitoring prototype system be develop and the system be verify in the workshop to prove the effectiveness of the system. 
calculation of gear meshing stiffness consider lubrication. 
gear meshing stiffness be the key parameter to study the gear dynamic performance. 
however the study on the calculation of gear meshing stiffness consider lubrication especially mixed lubrication be still insufficient. 
base on the three dimensional linear contact mix elastohydrodynamic lubrication model and the contact stiffness calculation method of rough surface a method for calculate the gear meshing stiffness under mixed lubrication be propose in this paper. 
accord to the propose calculation method the effect of speed external load and roughness amplitude on gear meshing stiffness be far explore. 
the method can take into account the real rough surface topography and lubrication in the meshing process so it may be more advantageous than the conventional method to some extent. 
industrial design of kansei engineering based sensor for industry. 
up to date workload and worker performance in small medium sized enterprise sme be assess manually. 
kesan kansei engineering base sensor for agroindustry be develop as a tool to assess worker workload and performance. 
the late prototype of kesan be establish. 
as the final step prior to the full scale mass production an industrial design be require and must be design base on the validation to user need. 
this research propose an industrial design for mass production of kesan use kano model and quality function deployment qfd. 
the user need be extract from attributive analysis of kano model. 
the matrix of house of quality hoq be utilize to connect the user need and technical requirement. 
the research result validate thirteen 13 user need attribute. 
the most important attribute be desktop application as an integrate decision support system. 
fourteen 14 technical requirement attribute be identify to fulfil the user need. 
finally a prototype be develop base on product final specification and prioritize technical requirement. 
the sme s manager could use the prototype for workplace environmental management. 
ensure the economic efficiency of enterprise by multi criteria selection of the optimal manufacturing process. 
technological assurance and improvement of the economic efficiency of production be the first priority issue for the modern manufacturing engineering area. 
it be possible to achieve a high value of economic efficiency in multiproduct manufacturing by multicriteria optimization. 
a set of optimality criterion base on technological and economic indicator be define with the aim of select the optimal manufacturing process. 
competitive variant and a system of optimization be develop and investigate. 
a comparative analysis of the optimality criterion and their influence on the choice of optimal machining process be carry out. 
it be determine that the batch of part make an impact on the selection of the manufacturing process. 
six sigma methodology use to improve the mechanical property for friction stir weld of aluminum pipes. 
this paper present a new welding quality evaluation approach depend on the analysis by the fuzzy logic and control the process capability of the friction stir weld of pipe fswop. 
this technique have be apply in an experimental work develop by alternate the fsw of pipe process major parameter rotation speed pipe wall thickness and travel speed. 
variable sample be friction stir weld of pipe use from 485 to 1800 rpm four 10 mm min and two four mm for the rotation speed the travel speed and the pipe wall thickness respectively. 
dmaic methodology define measuring analyzing improving control have be use as an approach to analyze the fsw of pipe it depend on the attachment potency and technical commonplace demand of the fsw of pipe process. 
the analysis control the al 6061 friction stir weld joint tensile strength. 
to obtain the good tensile strength the study determine the optimum value for the parameter from the corresponding range. 
goal orient obstacle avoidance with deep reinforcement learning in continuous action space. 
in this paper we propose a goal orient obstacle avoidance navigation system base on deep reinforcement learning that use depth information in scene as well as goal position in polar coordinate as state input. 
the control signal for robot motion be output in a continuous action space. 
we devise a deep deterministic policy gradient network with the inclusion of depth wise separable convolution layer to process the large amount of sequential depth image information. 
the goal orient obstacle avoidance navigation be perform without prior knowledge of the environment or a map. 
we show that through the propose deep reinforcement learn network a goal orient collision avoidance model can be train end to end without manual tuning or supervision by a human operator. 
we train our model in a simulation and the result network be directly transfer to other environment. 
experiment show the capability of the train network to navigate safely around obstacle and arrive at the designate goal position in the simulation as well as in the real world. 
the propose method exhibit high reliability than the compare approach when navigate around obstacle with complex shape. 
the experiment show that the approach be capable of avoid not only static but also dynamic obstacle. 
bacombo bandwidth aware decentralize federated learning. 
the emerge concern about datum privacy and security have motivate the proposal of federated learning. 
federated learning allow compute node to only synchronize the locally  train model instead of their original datum in distributed training. 
conventional federated learn architecture inherit from the parameter server design rely on highly centralized typology and large node to server bandwidth. 
however in real world federated learn scenario the network capacity between node be highly uniformly distribute and small than that in datum center. 
as a result how to efficiently utilize network capacity between compute node be crucial for conventional federated learning. 
in this paper we propose bandwidth aware combo bacombo a model segment level decentralize federated learning to tackle this problem. 
in bacombo we propose a segment gossip aggregation mechanism that make full use of node to node bandwidth for speed up the communication time. 
besides a bandwidth aware worker selection model far reduce the transmission delay by greedily choose the bandwidth sufficient worker. 
the convergence guarantee be provide for bacombo. 
the experimental result on various dataset demonstrate that the training time be reduce by up to 18 time that of baseline without accuracy degrade. 
framework for delay guarantee in multi domain network base on interleaved regulators. 
the key to the asynchronous traffic shaping ats technology be standardize in ieee 802.1 time sensitive network tsn task group tg be the theorem that a minimal interleaved regulator ir attach to a fifo system do not increase delay upper bind while suppress the burst accumulation. 
in this work it be observe that the fifo system can be a network for flow that share same input output port and same queue of the network and be treat with a scheduling scheme that guarantee the fifo property within a queue. 
base on this observation a framework for delay bind guarantee be far propose in which the network with flow aggregate fas scheduling and minimal irs per fa attach at the network edge be interconnect. 
the framework guarantee the end to end delay bind with reduce complexity compare to the traditional flow base approach. 
numerical analysis show that the framework yield small bind than both the flow base framework such as the integrate service intserv and the class base ats at least in the network with identical flow and symmetrical topology. 
q function base traffic  and thermal aware adaptive routing for 3d network on chip. 
die stack technology be expand the space diversity of on chip communication by leverage through silicon via tsv integration and wafer bonding. 
the 3d network on chip noc a combination of die stack technology and systematic on chip communication infrastructure suffer from increase thermal density and unbalanced heat dissipation across multi stacked layer significantly affect chip performance and reliability. 
recent study have focus on runtime thermal management rtm technique for improve the heat distribution balance but performance degradation owe to rtm mechanism and unbalanced inter layer traffic distribution remain unresolved. 
in this study we present a q function base traffic  and thermal aware adaptive routing algorithm utilize a reinforcement machine learning technique that gradually incorporate update information into an rtm base 3d noc route path. 
the propose algorithm initially collect deadlock free direction base on the rtm and topology information. 
subsequently q learn base decision making through the learning of regional traffic information be deploy for performance improvement with more balanced inter layer traffic. 
the simulation result show that the propose routing algorithm can improve throughput by 14.0% 28.2 with a 24.9 more balanced inter layer traffic load and a 30.6 more distribute inter layer thermal dissipation on average compare with those obtain in previous study of a 3d noc with an eight x eight x four mesh topology. 
lorawan network for fire monitoring in rural environments. 
the number of forest fire that occur in recent year in different part of the world be cause increase concern in the population as the consequence of these fire expand beyond the destruction of the ecosystem. 
however with the proliferation of the internet of things iot industry solution for early fire detection should be develop. 
the assessment of the fire risk of an area and the communication of this fact to the population could reduce the number of fire originate by accident or due to the carelessness of the user. 
this paper present a low cost network base on long range lora technology to autonomously evaluate the level of fire risk and the presence of a forest fire in rural area. 
the system be comprise of several lora node with sensor to measure the temperature relative humidity wind speed and co2 of the environment. 
the datum from the node be store and process in a the things network ttn server that send the datum to a website for the graphic visualization of the collected datum. 
the system be test in a real environment and the result show that it be possible to cover a circular area of a radius of four km with a single gateway. 
optimization design and experimental testing of a laser receiver for use in a laser levelling control system. 
the elevation detection accuracy of the laser receiver in the laser level control system directly affect land level operation. 
to effectively improve the effect of level operation and meet the requirement for the accuracy of elevation detection in different industry this study optimization design a multilevel adjustable laser receiver. 
first we examine the laser signal detection technology and processing circuit design the photoelectric conversion array for the detection of the rotate laser and convert it into a photocurrent signal. 
we also design the filter amplifier and shape and stretch circuit for analogue to digital conversion of the photocurrent signal. 
the digital signal be calculate base on the deviation of the elevation by use a microprocessor and be output by a controller area network can bus. 
the laser beam spot diameter transmission and diffusion be then study and with the detectable spot diameter be compare and analyze. 
accordingly an algorithm be propose to calculate the deviation of laser receiver elevation. 
the resolution of the elevation deviation be set to three mm however this value could be adjust to six mm nine mm 12 mm and 15 mm accord to the requirement. 
finally the laser receiver be test and analyze and the test result of the elevation detection accuracy show that when the laser receiver be within a radius of 90 m the elevation detection accuracy be within the three mm range. 
the outcome of the farmland level test show that the standard deviation sd of the field surface decrease from 9.54 cm before level to 2.42 cm after levelling and the percentage of sample point associate with absolute error of three cm be 84.06. 
these outcome meet the requirement of high standard farmland construction. 
the test result of concrete levelling show that within a radius of 30 m the standard deviation sd of the elevation adjustment of the left laser receiver be 1.389 mm and the standard deviation sd of the elevation adjustment of the right laser receiver be 1.316 mm. 
furthermore the percentage of the sample point associate with absolute elevation adjustment error of three mm in the case of the two laser receiver be 100 after level whereas the standard deviation sd of the sand bed surface be 0.881 mm. 
additionally the percentage of the sample point associate with absolute error of three mm be 100. 
this meet the construction standard of the concrete industry. 
object detection algorithm base on improve yolov3. 
the you only look once v3 yolov3 method be among the most widely use deep learning base object detection method. 
it use the k means cluster method to estimate the initial width and height of the predicted bounding box. 
with this method the estimate width and height be sensitive to the initial cluster center and the processing of large scale dataset be time consume. 
in order to address these problem a new cluster method for estimate the initial width and height of the predict bounding box have be develop. 
firstly it randomly select a couple of width and height value as one initial cluster center separate from the width and height of the ground truth box. 
secondly it construct markov chain base on the select initial cluster and use the final point of every markov chain as the other initial center. 
in the construction of markov chain the intersection over union method be use to compute the distance between the select initial cluster and each candidate point instead of the square root method. 
finally this method can be use to continually update the cluster center with each new set of width and height value which be only a part of the datum select from the dataset. 
our simulation result show that the new method have fast convergence speed for initialize the width and height of the predict bounding box and that it can select more representative initial width and height of the predicted bounding box. 
our propose method achieve well performance than the yolov3 method in term of recall mean average precision and f1 score. 
research on ship intelligent manufacturing datum monitoring and quality control system base on industrial internet of thing. 
the paper analyze several key technology of datum monitoring and quality control system base on the internet of thing technology from the perspective of system integration include web database access real time display of dynamic datum dynamic drawing of curve etc and give technical difficulty. 
route and improvement have solve the problem of the system in term of real time and security. 
the zigbee wireless sensor network be use as the datum acquisition end and the server receive the datum collect by the wireless sensor network through the serial communication to connect the cc2530 wireless communication module. 
at the same time the paper combine the actual need of user and design the server system accord to the software engineering development process. 
while realize the normal pc browser access to the server the android application of the mobile terminal be develop and the mobile be realize. 
in terminal access to the server user can access the server by access computer on the network and mobile phone with android system. 
view the running status of the device authorize user can also make judgment base on real time datum and can send control command and adjust the environment. 
a method of garment factory worker performance monitoring use control chart base on rfid system. 
massive production datum of front line worker be record every day by rfid system in garment factory which be mainly in multiple variety and small batch production. 
to maintain productivity and consistency of front worker a technique be propose to monitor the mean and variance of front line worker production time base on the recorded datum to avoid bottleneck operation. 
result of monitoring can be use to schedule allocation and worker performance assessment. 
two front line worker spc control chart be make as example and procedure be give simultaneously change batch datum to daily datum find critical point of the process after the critical point the process be stable make spc control chart to monitor both mean and variance of worker. 
the first seven to 10 day datum be utilize to build optimal hyperbolic curve model to find critical point for the process mean of monitor variable be forecast after about 10 day of production. 
stable datum after critical point be utilize to make control chart to monitor both mean and variance of monitor variable. 
research on the overall architecture of internet of thing middleware for intelligent industrial park. 
with the continuous development of the internet of thing technology and the proposal of make in china 2025 the construction of iot application model for intelligent production line intelligent workshop smart factory and other manufacturing industry have attract more and more attention. 
in the smart industry there be many type of device connect to the internet of thing and the data format of the device be not uniform. 
therefore when the upper layer application collect device datum and manage the device it be necessary to introduce middleware to solve these problem. 
a service orient iot middleware model be design. 
this middleware be build on the background of the smart campus with the above characteristic. 
the middleware be responsible for realize the information interaction between the front end sense device and the upper layer application send the command of the upper layer application to the device to implement real time management of the device and provide a heterogeneous intelligent device for access the internet of things application environment an effective solution. 
and through an application example the work principle and implementation of this middleware be far illustrate. 
an improved pso algorithm for time optimal trajectory planning of delta robot in intelligent packaging. 
with the advancement of the time robotic technology be also develop rapidly. 
some large enterprise in china use robot to work in manufacturing and handle position and also make robot more and more widely use. 
this paper focus on the trajectory planning strategy for three degree of freedom high speed parallel manipulator of delta robot in cartesian space under high speed operation handling the point to point door type handling operation trajectory under the condition of ensure control accuracy and increase productivity in intelligent packaging be establish base on the inverse kinematic model of the manipulator. 
the four three 3 four degree polynomial interpolation be present to control height of obstacle avoidance and trajectory length on this basis the mapping relationship between the motion feature in operation space and those in joint space be establish. 
take into account the complexity of trajectory optimization due to multiple constraint in order to reduce the difficulty of trajectory optimization it be necessary to ensure smoothness and constrain of angular displacement angular velocity and angular acceleration of each joint in space an improved particle swarm optimization algorithm be propose to optimize trajectory run time of the four three 3 four degree polynomial interpolation. 
the simulation result by use matlab indicate that the accurate and stable time optimal trajectory planning of four three 3 four degree polynomial interpolation can be achieve by mean of the improved particle swarm optimization algorithm. 
compare with other trajectory planning algorithm the propose algorithm be easy to implement which not only improve the local convergence of particle swarm optimization algorithm achieve the time optimal trajectory planning of delta robot but also realize the controllability of obstacle avoidance height therefore which realize the fast accurate and safe operation in intelligent packaging. 
less interference tool path correction model for half revolution penetration and retraction trajectory in internal straight thread side mill. 
unreasonable tool path generation in the penetration and retraction process of the internal thread milling can easily result in severe interference error therefore this study propose a less interference tool path correction model for the half revolution penetration and retraction trajectory to far reduce the tool path interference error. 
firstly the parametric equation of the initial penetration and retraction trajectory be derive from the half revolution penetration and retraction angle alpha. 
then an offset coefficient e be define to adjust the x coordinate component of the starting point of the penetration trajectory and the end point of the retraction trajectory the z coordinate component of the penetration and retraction trajectory be calculate by substitute the angle alpha with the cutter spiral rotation angle theta. 
as a result the correction parametric equation for adjust the penetration and retraction trajectory with the e be establish. 
finally accord to the influence of e on the interference error the appropriate value of the e be determined to control the interference error within the allowable tolerance range. 
take the milling of m16 x 1.5 thread hole with m8 x 1.5 thread milling cutter as an experimental example the experimental result show that the maximum interference error of the propose correction model e 0.9 can be reduce by 73.6 and 33.82 compare with the initial uncorrection model and the exist optimization method respectively. 
this study indicate the propose model can significantly decrease the interference occur in internal thread mill and smoothly achieve the demand of more precision thread connection. 
manufacturing of bent tube with non uniform curvature and cross section use a novel hydroforme die experimental finite element analysis and optimization. 
produce non uniformly curved tube with sharp corner use the common experimental method in hydroforming process be difficult. 
a common approach be to increase the internal pressure as high as possible which may lead to excessive thinning and fracture on the corner of the tube. 
to manufacture this type of tube the current study have propose a new hydroforming die to perform such a process by take two general step initial bulging and form. 
the propose die facilitated with two movable bush be able to produce bended stainless steel tube with non uniform curvature and cross section. 
to find the optimum pressure and axial feed profile finite element simulation be perform and the result be validate with experiment. 
the main advantage of this die be that by move the bush inside the die cavity the friction between die and bush can be reduce considerably while axial feeding be provide properly lead to produce a tube with a uniform thickness distribution and maximum achievable corner filling. 
optimization method for systematically improve non contact r test accuracy. 
non contact r test be an instrument to measure the synchronous error of five axis machine tool. 
however there be still some deficiency in its research such as the difficult and laborious calibration. 
how to systematically improve the measurement accuracy with a good balance to minimum cost be a real problem in guide practice. 
this paper propose a new systematic optimization method to solve this problem base on a comprehensive understanding of the non contact r test in term of structure parameter and relation. 
firstly the algorithm for sphere center coordinate be establish base on the self adaptive differential evolution algorithm to obtain the definite computational accuracy and efficiency. 
secondly the parameter of the fixture structure be optimize to maximize the measurement stability measure space and non interference space. 
thirdly the on machine calibration be perform to replace pre calibration and re calibration and to establish the positional relationship between sensor the fixture and the machine tool simultaneously. 
it can reduce the difficulty of manufacture maintenance and application. 
fourthly the measurement accuracy can be evaluate to determine whether the iterative optimization achieve the goal. 
the propose method have be verify with case study to support the setting up of the optimize non contact r test lead to a cost effective and accurate test on five axis machine tool. 
investigation of chatter stability of cut process with a rotate tapered cutter bar consider internal and external damp. 
the damping of cut system be an important factor influence stability in boring and milling process. 
however systematical and thorough study of the influence mechanism of damp especially on the chatter stability of rotate cutter bar be still absent. 
the damping of a cut system mainly consist of external damping and internal damping. 
this study focus on these damp effect on chatter stability of the cut system with a rotate tapered cutter bar. 
the partial differential equation of motion of the cutter bar be derive base on the hamilton principle combine with the euler bernoulli beam theory. 
it be assume that the cutter bar be taper and its free end act on a two dimensional regenerative cut force with time delay effect. 
the damp mechanism of external and internal be describe by the viscous damp model and the strain rate dependent kelvin voigt model respectively. 
the partial differential equation of motion be discretized as an ordinary differential equation use the galerkin method. 
the campbell diagram and the decay rate plot include critical rotate speed and instability threshold of the cutter bar be obtain by free vibration analysis. 
also the chatter stability lob in the cutting process be plot and the predict result of stability in frequency domain be compare with those in time domain. 
the result indicate that the structural parameter of a cutter bar include the rotation the ratio of internal and total damp damp ratio and taper and aspect ratio have significant effect on cutter bar dynamic and chatter stability of cut process. 
in particular a new chatter instability be observe for the cut system in high rotate speed range due to the effect of rotation and internal damping. 
the onset rotate speed of the new chatter instability equal to the instability threshold of rotor system of cutter bar. 
finally the present model be validate by compare both stability prediction give by previous study and natural frequency and decay rate by ansys fe code. 
tool condition monitoring in mill use a force singularity analysis approach. 
tool condition monitoring tcm be extremely important to ensure production efficiency and workpiece quality. 
it be crucial to extract and select suitable feature from raw signal to improve the robustness and feasibility of tcm system. 
this paper introduce a cut force singularity analysis approach for tcm in mill which correlate tool wear state with force waveform variation. 
the holder exponent hes be select as the index of singularity. 
hes be calculate by wavelet transform modulus maxima wtmm. 
the raw signal be de noise base on wtmm estimation which can effectively preserve singularity compare with traditional filter. 
fisher s discriminant ratio fdr be employ to rank the discriminant capability of statistical feature of he. 
it be find that mean of he and quantity of singular point estimate from feed force f x show the strong class discriminant ability. 
then these feature be choose as training sample to propose a tcm approach base on the support vector machine svm. 
experimental result indicate that this approach provide reliable and effective advice for tool change. 
a novel approach to springback control of high strength steel in cold roll form. 
to high precision control the springback of high strength steel hss in cold roll form the 3d finite element analysis fea model of hat shape sectional hss roll forming process be build with the professional roll form software copra. 
two conventional angle adjusting method for hss the namaste type and the platform type apply widely for complex sectional normal steel easily lead to the edge wave and asymmetric behavior respectively especially high springback that be difficult to control by the fea simulation and practical production of hss cold roll forming process. 
the roll design of the udt ustb durable t) type angle adjusting method be develop to significantly reduce springback with the improvement of the edge wave and asymmetric behavior in the hat shape sectional hss roll form process by the fea simulation. 
the propose angle compensation method base on udt type angle adjusting method achieve high precision springback control by the fea simulation which provide a novel approach for springback control effectively in complex sectional hss roll forming process. 
the industrial application give remarkable result that the hat shape sectional hss product can strictly meet market requirement of less than 0.5 degree by the propose angle compensation method base on udt type angle adjusting method. 
on prolongation of discharge regime during ecdm by titrated flow of electrolyte. 
in electrochemical discharge machining ecdm the drilling of micro hole have be establish through two regime i.e. discharge and hydrodynamic regime. 
in discharge regime the material removal mechanism be directly control by the number of spark discharge and it allow fast penetration of tool electrode inside the work material whereas in hydrodynamic regime the accumulation of bubble at hole entrance and inadequate supply of electrolyte toward tool tip limit the penetration rate during deep hole drilling. 
in order to achieve consistent machining condition particularly during deep hole drilling the prolongation of discharge regime be essential. 
thus in the present research endeavor a ecdm with titrated flow of electrolyte be attempt. 
the application of titrated flow of electrolyte in ecdm process drill micro through hole in 1350 mu m thick work material in approximately 30 s. 
in comparison to the conventional ecdm process the present method reduce the machining time by seven time and also improve the machining accuracy by reduce the hole entrance diameter by 1.25 time. 
the consistency obtain in discharge characteristic as well as in penetration rate be evident in the prolongation of discharge regime during ecdm with titrated flow of electrolyte. 
the underlie material removal mechanism have also be present. 
multicriteria optimization mco be also perform to predict the suitable parametric combination for high penetration rate and low hole entrance diameter of the machine micro hole. 
the result obtain from the current investigation present titrate flow of electrolyte as a one of the fast machining strategy that provide a penetration rate of 45 mu m s to drill the micro hole by ecdm process. 
research on the drum suppression method for long distance reverse thinning spinning of the ultra thin walled cylinder. 
to address the instability phenomenon cause by the continuous increase in the drum height during the long distance spinning of ultra thin cylindrical part the evolution and influence factor of the drum height during the spinning process be study by combine both theory and experiment. 
the parameter that can be use to restrain the increase in the drum height be obtain and successfully apply to the long distance thinning spinning process of ultra thin cylindrical part. 
first combine with the spinning model the constraint boundary metal flow and stress field of the spin contact zone be analyse and the formation mechanism and influence parameter of the drum shape during the spinning of the thin walled cylinder be obtain. 
next by perform a numerical simulation the influence law of the parameter thinning rate and feed rate on the height of the drum be obtain and an experimental verification be perform. 
base on the change rate of the drum height as the selection basis of the parameter interval the method of reduce the thinning rate of each pass and increase the spinning pass be select to suppress the continuous increase in the drum height during the long distance spinning of thin walled cylinder. 
finally through the fine tuning of the parameter the long range stability spinning of a thin walled cylinder with a diameter of phi 398 mm be realize the wall thickness be reduce from two to 0.53 mm and the spinning length be extend from 1030 to 3800 mm. 
the result show that the thinning rate be the main parameter affect the change in the drum height when the parameter of the machine tool mandrel workpiece and rotate wheel be fix. 
the spinning pass and reduction in each pass can be determine with the thinning rate not exceed 45 which can effectively control the increase rate of the drum height and prevent the instability phenomenon cause by the continuous increase in the drum height during the long range spinning of the ultra thin cylindrical part. 
the finding provide theoretical and experimental guidance for the long distance stability spinning of ultra thin cylindrical part. 
stir tank design for powder mix edm sic al and solid liquid suspension uniformity research. 
in order to solve the problem of non uniform powder concentration in electrical discharge machining edm working fluid a mathematical model of powder particle movement in stirred tank be establish and the flow field and solid liquid suspension uniformity be simulate in this paper. 
the factor of slot shape depth diameter ratio blade angle blade installation height and solid particle volume fraction which affect flow field distribution solid suspension particle uniformity and power consumption be research and the stir tank structure be optimize. 
when the ratio of spherical stir tank depth to diameter be 0.8 the blade design angle be 45 degree and the installation height of impeller blade be 120 mm the suspension uniformity of solid particle be the good and the power consumption be the small. 
under the condition of al powder concentration four g l pulse width 175 mu s and pulse interval 75 mu s the powder mix edm experiment of sic al functionally gradient material be carry out with this optimize stir device. 
the result show that the material removal rate of powder mix edm increase by 24.82 and the surface roughness decrease by 27.28 than that of the conventional edm. 
six dimensional b spline fitting method for five axis tool path. 
piecewise linear segment present by a sequence of g01 g codes be the widely adopt tool path format for five axis computer numerical control cnc machining. 
nevertheless the g01 tool path have only g(0 continuity which may lead to feedrate and acceleration fluctuation and produce machinery vibration and unexpected slowdown during the process. 
thus tool path smoothing method such as b spline fitting be develop to increase the continuity of the tool path. 
this work propose a six dimensional b spline fitting method with arc length parameterization and quality evaluation refinement for five axis tool path. 
first establish the relationship of cutter contact cc error and cutter location cl error and tool axis error to ensure that the cc error of five axis b spline tool path can be accurately compute. 
second six dimensional b spline tool path generate by three axis b spline fitting method in six dimensional space be parameterize with arc length satisfy the stability condition of tool axis. 
third the chord error of the fit six dimensional b spline tool path be compute use the hausdorff distance. 
the chord error computation smoothness assessment and refinement algorithm be perform together to ensure the fitting quality. 
the simulation result demonstrate that the propose six dimensional fitting method be effective and suitable for five axis blade machining and the evaluation refinement algorithm can ensure that the five axis b spline tool path be shape preserve strictly and satisfy the chord error constraint. 
the experimental result show that the propose six dimensional fitting method improve the machine quality and be suitable for industrial application. 
study on the critical negative rake angle of the negative rake angle tool base on the stagnant characteristic in micro cut. 
the critical negative rake angle of negative rake angle tool be the critical criterion for the state of cut and plow in micro cut. 
it affect the flow characteristic of cut material the deformation state of chip the quality of the machine surface and the amount of tool wear. 
meanwhile a stagnant region often appear in front of the tool surface when a negative rake tool be use to cut the plastic metal material which would increase the actual negative rake angle. 
therefore base on the stagnant characteristic and the infinite shear strain approach this paper construct a critical negative rake angle model and the orthogonal cutting experiment and the finite element model be use to verify the correctness of the model. 
by analyze the deviation of the effective critical negative rake angle theoretical value and critical negative rake angle experimental value it can be know that the theoretical value be 0.36 4.15 large than the experimental value which indicate that the model consider the existence of stagnant region be close to the actual critical negative rake angle. 
in addition the relationship between the stagnant region the deviation and the multi cut factor can provide experimental basis of angle for solve the effective critical negative rake angle when the critical negative rake angle be know. 
global tool axis vector optimization base on the minimum angular acceleration of rotary axis. 
the part with complex surface be widespread application for industrial manufacturing field and five axis machining with ball end cutter be a common measure for surface machining. 
in order to achieve high quality surface machining it be especially important to optimize the pose of the tool and the workpiece. 
the local tool axis vector optimization can effectively reduce the machining error of the complex surface part with abrupt curvature. 
however when tool axis vector optimize interval be overmuch the local tool axis vector optimization be time consume and ineffective. 
to solve this defect aim at the minimum angular acceleration a global tool axis vector control method be propose in this research. 
firstly the feasible space of the tool axis vector at the cc cutter contact point be obtain. 
then the toolpath be divide by the property of concavity or convexity for the toolpath curve and the key tool axis vector on the toolpath curve be determine. 
finally tool axis vector be adjust base on the minimum rotary axis angular acceleration in each interval and the tool axis vector at the joint position of the adjacent segment be adjust to smooth tool axis vector for the entire toolpath. 
through the simulation and experiment on the test part the validity of the method be prove and the global optimization method can effectively decrease the machining error and promote the machining quality of the complex surface. 
influence of chisel edge axial rake angle on the drilling performance of helical point micro drill. 
the chisel edge axial rake angle have an important effect on the processing performance of helical point micro drill. 
in this research the mathematical modeling for the spiral groove helical flank and cross shaped chisel edge be conduct and then three type of helical point micro drill each have a thin chisel edge with an unequal axial rake angle be design and fabricate. 
then the finite element simulation and processing experiment of micro drilling be perform separately and the thrust force torque chip morphology tool wear and micro hole machining quality be measure and evaluate. 
with the rise of the axial rake angle of the chisel edge the curl degree of the chip and the thrust force be find to decrease owe to the increase of the rake angle along the inner cutting edge. 
the angle between the tool axis and chip axis be find to gradually decrease due to the reduction of the rake angle gradient along the cutting edge. 
additionally the thickness and width of the uncut chip of the inner cutting edge be find to increase bring about the rise in the torque. 
the wear degree of the micro drill with a zero degree axial rake angle type ii be the small due to their medium thrust force and torque and a well micro hole entrance morphology and minimum roundness be obtain. 
when drill to the 30th hole compare with the micro drill with a 10 degree axial rake angle type i and 10 degree axial rake angle type iii the chisel edge maximum wear width of type ii delta zero degree be respectively reduce by 82.43 and 19.69 and the micro hole roundness respectively decrease by 26.7 and 11.33. 
the thrust force of type i delta 10 degree be the large so it cause great tool wear and poor micro hole quality. 
the large torque and low rigidity of the inner cutting edge of type iii delta 10 degree lead to poor drilling performance. 
thus helical point micro drill have the zero degree chisel edge axial rake angle be suitable for drill 304 austenitic stainless steel. 
early detection and identification of fatigue damage in thrust ball bearings by an acoustic emission technique. 
as rolling bearing be widely use in various machine there be a strong need to detect any problem as early as possible. 
although vibration analysis be commonly use in the diagnosis of rolling bearing it be possible that the failure of such bearing might be detect early by an acoustic emission ae technique. 
method for detect potential fatigue damage in a thrust ball bearing by ae signal analysis and by vibration analysis be compare. 
for the ae signal analysis the maximum amplitude and the frequency spectrum be use to detect and identify fatigue damage in the bearing. 
feature of ae signal detect when a defect be artificially form on the raceway surface of a bearing by use a vickers hardness tester be also examine. 
the ae technique detect initial crack due to fatigue damage early than the vibration technique. 
additionally ae signal be always detect during bear fatigue test but the ae signal detect during the running in process crack initiation crack propagation and flake all contain different frequency component. 
furthermore the correlation map between the frequency spectra of ae signal and deformation and fracture phenomenon friction and wear mode be update by add the new finding of this study. 
friction and wear monitoring method for journal bearings of geared turbofans base on acoustic emission signals and machine learning. 
in this work effective method for monitor friction and wear of journal bearing integrate in future ultrafan(r jet engine contain a gearbox be present. 
these method be base on machine learning algorithm apply to acoustic emission ae signal. 
the three friction state dry boundary mixed and fluid friction of journal bearing be classify by pre process the ae signal with windowe and high pass filtering extract separation effective feature from time frequency and time frequency domain use continuous wavelet transform cwt and a support vector machine svm as the classifier. 
furthermore it be show that journal bear friction classification be not only possible under variable rotational speed and load but also under different oil viscosity generate by vary oil inlet temperature. 
a method use to identify the location of occur mixed friction event over the journal bear circumference be show in this paper. 
the time base ae signal be fuse with the phase shift information of an incremental encoder to achieve an ae signal base on the angle domain. 
the possibility of monitor the run in wear of journal bearing be investigate by use the extract separation effective ae feature. 
validation be do by tactile roughness measurement of the surface. 
there be an obvious ae feature change visible with increase run in wear. 
furthermore these investigation show also the opportunity to determine the friction intensity. 
long term wear investigation be do by carry out long term wear test under constant rotational speed load and oil inlet temperature. 
roughness and roundness measurement be do in order to calculate the wear volume for validation. 
the integrate ae root mean square rms show a good correlation with the journal bear wear volume. 
investigation of galling wear use acoustic emission frequency characteristic. 
in the sheet metal stamping process during slide contact between the tool and sheet it be expect that severe event such as tool wear or fracture on the sheet generate acoustic emission ae burst waveform. 
attempt have be make in the literature to correlate the ae burst waveform with the wear mechanism. 
however there be a need for additional study to understand the frequency characteristic of the ae burst waveform due to the severity and progression of the galling wear. 
this paper will determine the ae frequency characteristic that can be use to monitor galling wear independent of the experimental process examine. 
the ae burst waveform generate during the stamping and scratch test be analyse in this paper to understand the change in the ae frequency characteristic with the gall severity. 
these ae burst waveform be investigate use the hilbert huang transform hht time frequency technique band power and mean frequency. 
subsequently these ae frequency feature be correlate with the wear behaviour observe via high resolution profilometer image of the stamped part and scratch surface. 
initially the hht technique be apply to the ae burst waveform to understand the influence of wear severity in the power distribution over the wide ae frequency range. 
later the ae bandpower feature be use to quantitatively analyse the power in each frequency interval during the unworn and worn tool condition. 
finally the mean frequency of ae signal be identify to be able to determine the onset of gall wear. 
the new knowledge define in this paper be the ae frequency feature and wear measurement feature that can be use to indicate the onset of gall wear irrespective of the process examine. 
performance verification of a flexible vibration monitoring system. 
the performance of measurement or manufacturing system in high precision application be dependent upon the dynamic of the system as vibration can be a significant contributor to the measurement uncertainty and process variability. 
technology make use of accelerometer and laser vibrometer be available to rapidly measure and process structural dynamic datum but the software infrastructure be yet to be available in an open source or standardised format to allow rapid inter platform use. 
in this paper we present a novel condition monitoring system which use commercially available accelerometer in combination with a control monitor infrastructure to allow for the appraisal of the performance of a measurement or manufacturing system. 
a field programmable gate array fpga) based control system be implement for high speed datum acquisition and signal processing of six triaxial accelerometer with a frequency range of one hz to 6000 hz a sensitivity of 102.5 mv ms( two and a maximum sample rate of 12,800 sample per second per channel. 
the system include two method of operation real time performance monitoring and detailed measurement manufacture verification. 
a lathe condition monitoring investigation be undertake to demonstrate the utility of this system and acquire typical machining performance parameter in order to monitor the health of the system. 
comparative study of ar versus video tutorial for minor maintenance operation. 
augmented reality ar have become a mainstream technology in the development of solution for repair and maintenance operation. 
although most of the ar solution be still limited to specific context in industry some consumer electronic company have start to offer pre package ar solution as alternative to video base tutorial vt for minor maintenance operation. 
in this paper we present a comparative study of the acquire knowledge and user perception achieve with ar and vt solution in some maintenance task of it equipment. 
the result indicate that both system help user to acquire knowledge in various aspect of equipment maintenance. 
although no statistically significant difference be find between ar and vt solution user score higher on the ar version in all case. 
moreover the user explicitly prefer the ar version when evaluate three different usability and satisfaction criterion. 
for the ar version a strong and significant correlation be find between the satisfaction and the achieve knowledge. 
since the ar solution achieve similar learning result with high usability score than the video base tutorial these result suggest that ar solution be the most effective approach to substitute the typical paper base instruction in consumer electronic. 
spacecraft formation fly in the port hamiltonian framework. 
the problem of control the relative position and velocity in multi spacecraft formation fly in the planetary orbit be an enable technology for current and future research. 
this paper propose a family of track controller for different dynamic of spacecraft formation flying sff in the framework of port hamiltonian ph system through application of timed interconnection and damping assignment passivity base control ida pbc. 
the leader multi follower architecture be use to address this problem. 
in this regard first we model the spacecraft motion in the ph framework in the earth center inertial frame and then transform it to the hill frame which be a special local coordinate system. 
by this technique we may present a unified structure which encompass linear nonlinear dynamic with without perturbation. 
then use the time ida pbc method and the contraction analysis a new method for control a family of sff dynamic be develop. 
the numerical simulation show the efficiency of the approach in two different case of mission. 
adaptive smooth control for nonlinear uncertain system. 
this paper present an adaptive smooth controller for a class of nonlinear dynamical system in the presence of bound uncertainty with unknown bound. 
motivate by the concept of slide mode control a continuous control law that drive the slide variable to a user specify small domain in a finite time be develop. 
also an adaptation law be obtain to ensure that the gain update be perform in real time and the error be always bound within a desire range without a priori knowledge of the uncertainty. 
only the magnitude of the control input be require for online gain adaptation and hence the gain update be readily implement in real time which greatly ease the application of the suggest algorithm to real world system. 
in addition by add nonlinear term in the slide manifold the reach phase vanishe and the transient performance of the control system be considerably improve. 
numerical example serve to demonstrate the effectiveness and the robustness of the control methodology propose herein. 
exertrack towards smart surfaces to track exercise. 
the concept of the quantify self have gain popularity in recent year with the hype of miniaturized gadget to monitor vital fitness level. 
smartwatche or smartphone app and other fitness tracker be overwhelm the market. 
most aerobic exercise such as walk running or cycling can be accurately recognize use wearable device. 
however whole body exercise such as push up bridge and sit up be perform on the ground and thus can not be precisely recognize by wear only one accelerometer. 
thus a floor base approach be prefer for recognize whole body activity. 
computer vision technique on image datum also report high recognition accuracy however the presence of a camera tend to raise privacy issue in public area. 
therefore we focus on combine the advantage of ubiquitous proximity sensing with non optical sensor to preserve privacy in public area and maintain low computation cost with a sparse sensor implementation. 
our solution be the exertrack an off the shelf sport mat equip with eight sparsely distribute capacitive proximity sensor to recognize eight whole body fitness exercise with a user independent recognition accuracy of 93.5 and a user dependent recognition accuracy of 95.1 base on a test study with nine participant each perform two full session. 
we adopt a template base approach to count repetition and reach a user independent counting accuracy of 93.6. 
the final model can run on a raspberry pi three in real time. 
this work include data processing of our propose system and model selection to improve the recognition accuracy and data augmentation technique to regularize the network. 
complementary ensemble adaptive sparse narrow band decomposition method and its application to the gear crack fault diagnosis. 
adaptive sparsest narrow band decomposition be the most sparse solution to search for signal in the over complete dictionary library contain intrinsic mode function which transform the signal decomposition into an optimization problem but the calculation accuracy must be improve in the case of strong noise interference. 
therefore in combination with the algorithm of the complementary ensemble empirical mode decomposition a new method of the complementary ensemble adaptive sparse narrow band decomposition be obtain. 
in the complementary ensemble adaptive sparse narrow band decomposition the white noise opposite to the paired symbol be add to the target signal to reduce the reconstruction error and realize the adaptive decomposition of the signal in the process of optimize the filter parameter. 
the analysis result of the simulation and experimental datum show this method be superior to complementary ensemble empirical mode decomposition and adaptive sparse narrow band decomposition in inhibit the mode confusion endpoint effect improve the component orthogonality and accuracy and effectively identify the gear fault type. 
data drive product design toward intelligent manufacturing a review. 
with the arrival of the big datum era a lot of valuable datum have be generate in the entire product life cycle. 
the gather product datum contain a lot of design knowledge which bring new opportunity to enhance the production efficiency and product competitiveness. 
data drive product design be an effective and popular design method which can provide sufficient support for designer to make smart decision. 
this article focus on a comprehensive review of the exist research in data drive product design. 
base on the product design process this article summarize the data drive design method into the follow aspect customer requirement analysis conceptual design detailed design and design knowledge support tool. 
in the customer requirement analysis stage through datum mining and transformation method customer requirement be predict and then map to obtain accurate requirement expression for aid designer to explore the design space. 
in the conceptual design stage the intelligent algorithm and data warehouse technology be discuss in detail for function reasoning and scheme decision making to achieve the iterative mapping from customer space to solution space. 
in the detailed design stage datum modeling language and method be introduce to support the simulation verification of the design process. 
for the design knowledge support tool the method of extract knowledge from product datum be discuss in detail and the realization of computer aid conceptual design be assist through the development of knowledge orient design tool. 
finally this article summarize the key point of data drive product design research and provide an outlook for future research direction. 
fault diagnosis method of mechanical power system base on image processing technology. 
fault detection and diagnosis become one of today s hot spot which describe that image information be an important form of fault information it can quickly through the image processing technique and can accurately extract the characteristic signal. 
this article select the color of the particle image the integrate use of digital image processing pattern recognition theory the characteristic parameter of tribology knowledge as well as the extraction optimization and digital verify the feasibility of iron spectrum of abrasive fault recognition and provide a new efficient ferrographic wear particle image recognition method. 
firstly the grindstone image of the original color diesel engine be preprocesse and the grindstone image of the ferrograph be identify by directly select grindstone from the preprocessed ferrograph image and select the target grindstone. 
accord to the two type of abrasive particle the characteristic parameter be first classified and then the value of the characteristic parameter be obtain through the training and learning of the sample abrasive particle. 
in view of the large number of characteristic parameter of ferro spectrum abrasive particle this article determine the characteristic parameter suitable for the identification of abrasive particle in this article through the feature optimization and prove the correctness of the identification of characteristic parameter of abrasive particle through the test. 
the blade surface performance and its robotic machining. 
through numerical calculation it could be find that when the blade surface quality reach a certain level the surface quality of the blade be continuously improve and the guarantee effect on its performance would be weaken. 
under this circumstance continue to improve the surface quality of the blade have no positive effect on the performance of the blade. 
study have show that when the blade surface equivalent grit roughness k s reach 4.96 about r a 0.8 mu m the blade performance be close to the smooth surface of the blade and no further processing be require to improve the surface roughness. 
when the surface equivalent grit k s be great than 4.96 mu m the surface roughness have a great influence on the blade performance. 
when k s be large than 40 mu m the negative effect be significantly increase. 
for the different characteristic of the blade and different processing condition four kind of robot base blade surface grind scheme be propose of which the core content be the robot layout. 
base on the robot group s fitting to the spatial surface and the path planning the experimental verification be carry out. 
comparison of measured and model residual stress in a weld p91 steel pipe undergo post weld heat treatment. 
the process of fusion arc welding of steel pipe in power generation plant induce residual stress which may be detrimental to the integrity and endurance of plant pipeline. 
p91 be high grade steel use in the construction of pipeline carry hot steam at high pressure condition which cause creep during service. 
welded p91 pipe be usually subject to post weld heat treatment pwht to mitigate the magnitude of residual stress and temper the material hence improve its resistance to creep. 
in this paper the finite element fe method of model residual stress due to pwht in a circumferentially butt weld p91 pipe be present. 
the pwht hold temperature be 760 degree c. 
the paper describe the x ray diffraction xrd and deep hole drilling dhd experimental technique and how they be apply to measure residual stress in the weld p91 pipe after pwht. 
the material property datum necessary for the fe simulation of pwht have be obtain from stress relaxation test on p91 uniaxial tensile specimen at 760 degree c. 
good agreement have be achieve between the result of the fe method and the two set of experimentally measure residual stress. 
switch reluctance motor drive with low speed performance improvement. 
this paper deal with the analysis and implementation of a switch reluctance motor drive feature good performance even at low speed. 
the combination of a suitable design and current control strategy can lead to a significant improvement of the motor drive performance. 
after having identify the electrical parameter of the consider motor in term of stator resistance and inductance different current control structure have be compare by numerical simulation and experimental test highlight their advantage and disadvantage. 
torque measurement be also include to enable analysis of current regulation on the developed electromagnetic torque. 
also a new current controller be propose base on a modification of a pd controller. 
from the study carry out on a traction drive it be find that some control strategy can provide a good transient response while preserve low computational requirement. 
this be important not only for efficient and reliable drive operation but also for torque ripple minimization. 
a model reference base adaptive pss4b stabilizer for the multi machines power system. 
two input adaptive ieee multi bands power system stabilizer pss4b be develop for oscillation damp control in power system. 
two supplementary loop base on model reference mr adaptive control be add to the typical pss4b design. 
the mr have the same loop parameter of the typical pss4b and hence avoid a complex tuning process. 
the propose pss have a self tune gain reduction block to avoid any negative impact due to the high gain value during the disturbance time. 
the propose pss be apply on the four machine benchmark power system. 
to evaluate the robustness of the propose pss it be test in comparison with the delta w pss one input multi bands pss4b 1imb and two input multi band pss4b 2imb stabilizer. 
the integration of the propose pss be demonstrate use different study case. 
these case consider the small signal stability sss large signal stability lss and the coordination test for the local and inter area excited power mode. 
the propose pss demonstrate robust and superior response in all case. 
robust model reconstruction for intelligent health monitoring of tunnel structure. 
advanced robotic system will encounter a rapid breakthrough opportunity and become increasingly important especially with the aid of the accelerated development of artificial intelligence technology. 
nowadays advanced robotic system be widely use in various field. 
however the development of artificial intelligence base robot system for structural health monitoring of tunnel need to be far investigate especially for data modeling and intelligent processing for noise. 
this research focus on integrate b spline approximation with a nonparametric rank method and reveal its advantage of high efficiency and noise resistance for the automatic health monitoring of tunnel structure. 
furthermore the root mean square error and time consumption of the rank base and huber s m estimator method be compare base on various profile. 
the result imply that the rank base method to model point cloud datum have a comparative advantage in the monitoring of tunnel as well as the large area structure which require high degree of efficiency and robustness. 
a novel time frequency space method with parallel factor theory for big datum analysis in condition monitoring of complex system. 
the spatial information of the signal be neglect by the conventional frequency time decomposition such as the fast fourier transformation principal component analysis and independent component analysis. 
frame of the datum be as a three way array index by channel frequency and time allow the application of parallel factor analysis which be know as a unique multi way decomposition. 
the parallel factor analysis be use to decompose the wavelet transform ongoing diagnostic channel frequency time signal and each atom be trilinearly decompose into spatial spectral and temporal signature. 
the time frequency space characteristic of the single source fault signal be extract from the multi source dynamic feature recognition of mechanical nonlinear multi failure mode and the correspond relationship between the nonlinear variable multi fault mode and multi source fault feature in time frequency and space be obtain. 
in this article a new method for the multi fault condition monitoring of slurry pump base on parallel factor analysis and continuous wavelet transform be develop to meet the requirement of automatic monitoring and fault diagnosis of industrial process production line. 
the multi scale parallel factorization theory be study and a three dimensional time frequency space model reconstruction algorithm for multi source feature factor that improve the accuracy of mechanical fault detection and intelligent level be propose. 
fast solution of rotor losses in inverter fed cage induction motors with skewed slot. 
the conventional calculation of rotor loss in cage induction motor by the time step finite element method require the full slip wave of the rotor flux density and current. 
the calculation of the full slip wave be extremely expensive in cpu time memory and hard disk space for the induction motor with skewed slot and pulsewidth modulate supply. 
this article propose a technique that reproduce those full slip wave by utilize both the time vary and the spatial information of the rotor electromagnetic quantity and hence significantly save the calculation cost. 
the more rotor bar per pair of pole the induction motor have the more calculation cost this technique save. 
the calculation cost of the propose and conventional method be compare for the rotor loss of a 5.5 kw inverter feed skewed induction motor under load condition and the calculated loss be validate by test. 
analysis of inter turn short fault in an fscw ipm type brushless motor consider effect of control drive. 
a comprehensive analysis of inter turn short fault itsf in a fractional slot concentrate wind fscw interior permanent magnet synchronous motor ipmsm be present in this article. 
during online fault detection the fault signature can be influence by the controller action in a closed loop control system. 
therefore this study focus on the comparison of the itsf characteristic in an ipmsm use open loop and closed loop control drive. 
the variation rate in various parameter such as flux density input current circulate current torque ripple and vibration under healthy and itsf condition be compare. 
conventional six step square wave control ssc and field orient control foc drive be respectively use for open loop and closed loop analysis of itsf. 
furthermore this study also focus on mitigate the capability of the control drive for achieve extended postfault life of the motor. 
base on our analysis a fault mitigating strategy for the benchmark ipmsm be also suggest. 
a multidomain cosimulation technique be use to integrate the finite element method base model of ipmsm with the control drive under different severity of itsf for the simulation. 
finally experiment on a three phase 400 w ipmsm be perform for verification. 
the result show that in the fscw machine the itsf can be mitigate and foc have a well capability of itsf mitigation than ssc. 
new stator construction and simulation of high efficiency wind turbine generator. 
this article describe generator with high efficiency wind construction apply to small scale and large scale wind turbine. 
electromechanical converter base on these compact winding generator be promise for all type of stand alone installation. 
here a squirrel cage induction generator with innovative stator be study. 
stator winding construction feature reduce cross section of connection spot between rectangular slot and overhang part of winding turn. 
this compact construction be expect to be beneficial for different type of electric motors and generator. 
a new design methodic of induction generator for wind turbine provide by author consider construction feature of compact winding. 
resistance and end wind leakage calculation peculiarity be describe and compact winding s influence on size and efficiency of generator be estimate. 
research result of electromagnetic field which be give in this article should be consider in design of generator. 
calculation have show that compact winding construction result reduce the size and improved efficiency of the propose induction generator. 
reduce end winding of generator allow place power electronic unit on the stator core inside the machine housing. 
direction of further research be point in the article induction generator design technology improvement in particular. 
partially couple d q zero components of magnetically isolate fscw ipm machines with open end wind drive. 
fractional slot concentrated winding interior permanent magnet fscw ipm machine have be design with very low winding mutual inductance for magnetic isolation feature require for improve their fault tolerant capability. 
these magnetically isolate fscw ipm machine no long adhere to the precondition require for a conventional abc to dq0 transformation. 
as a result it be find in this article that d q axis could couple with zero axis in magnetically isolate fscw ipm machine. 
consider the second order reluctance component this phenomenon lead to third harmonic injection in phase voltage during normal operation which can be cancel out in term of line to line voltage for y connect three phase system. 
however for open end wind machine drive without wind neutral point constraint these voltage harmonic will show up in the winding voltage waveform. 
study show that the amplitude of these extra harmonic be determine by both saliency ratio and zero axis current. 
the bandwidth of the proportional integral pi current regulator as well as switch frequency should be carefully determined to be able to take into account the major harmonic inject in phase voltage. 
experimental verification on a 12 slot/10 pole prototype machine with speak pms have be carry out to show the impact of this phenomenon. 
electromagnetic performance comparison between 12 phase switch flux and surface mounted pm machines for direct drive wind power generation. 
in this article the 12 phase switch flux permanent magnet pm sfpm machine and three surface mount pm spm machine design for direct drive wind power generation be comparatively analyze. 
first feasible stator slot rotor pole combination for symmetrical 12 phase wind layout be investigate for both machine topology. 
second the key design parameter of the pm generator include the split ratio and stator tooth width ratio be optimize by finite element analysis to achieve a high phase fundamental emf per turn and a low cog torque both of which be desire by the direct drive wind power generator. 
third electromagnetic performance include air gap field cog torque static torque inductance output voltage and its regulation factor output power and efficiency of the generator be compare. 
a 10 kw 24 slot/22 pole sfpm prototype be build and test to validate the fe predict result. 
electrical monitoring of damper bar condition in salient pole synchronous motors without motor disassembly. 
the damper or amortisseur wind of synchronous motor sms be a critical component require for start the motor. 
several case of the force outage of industrial process due to the start failure of salient pole sm cause by damper bar failure have recently be report. 
the detection of broken damper bar be difficult since they be active only during rotor acceleration and offline visual inspection be the only mean of testing available in the field. 
it be recently show that the broken damper bar can be detect from the airgap flux but this require the installation of airgap flux sensor inside the motor. 
in this article a method base on the analysis of the stator start current be propose for detect broken damper bar. 
in addition an electrical detection method base on signal injection from the motor terminal be propose. 
the new method have be devise to provide remote testing from the motor control center without motor disassembly require in exist test. 
finite element analysis one mw and experimental testing 30 kw perform on salient pole sm with emulate break damper bar show that the propose method can provide the sensitive and reliable detection of damper bar failure. 
the relationship between the fusion temperature and dimensional accuracy of 3d print parts. 
the aim of this study be to investigate the relationship between the fusion temperature and dimensional accuracy of the 3d print component. 
the computer aided design cad model of specimen be prepare use autodesk inventor software. 
then the model be export to stl file format for rapid prototype. 
prusa i3 desktop type 3d printer with 90 300 micron layer height manufacturing capacity be use to produce the sample. 
the printer setting be prepare with simplified3d software. 
infill density and layer height of specimen be determine as 2o% and 200 micron respectively. 
the heated bed temperature be select as 60 degree c to increase the bonding and surface quality. 
the specimen be produce as sphere with the diameter of 10 mm. 
the sample be manufacture with five different extruder temperature 185 195 205 215 and 220 degree c that directly affect the fuse temperature and process. 
three sample sphere be produce for each fusion temperature. 
after the design and manufacturing process the dimension of produce sample be measure with image processing technique. 
the obtain result be compare with each other to find the relationship between the dimensional accuracy and fusion temperature. 
the result show that the minimum dimensional error be obtain from the fusion temperature of 185 degree c with the value of 0.290797 mm and percentage of three. 
a decision support system for cross docking center with different objective. 
the truck scheduling problem be an important problem that consist of assign each inbound and outbound truck to a door at the dock and then determine the sequence of truck at each door. 
truck scheduling in multi door cross docking center be essential for both customer and cross docking facility. 
in this study a decision support system dss be design for the truck scheduling problem for multi door cross docking center. 
the scheduling model of the dss use simulated annealing sa meta heuristic. 
in the solution process each schedule be establish for several different objective such as the minimization of the maximum completion time and the total earliness and tardiness maximization of the total number of shipping product within a work period. 
the design dss provide alternative schedule to decision maker and enable the choice of an appropriate schedule by monitor the sequence and trade off between alternative solution for the cross docking center and the customer. 
ascend the waste hierarchy re use potential in swedish recycling centres. 
accord to the waste hierarchy principle which constitute the basis of european waste legislation waste prevention and re use be consider most of the time well waste management option than recycle. 
however prevention and re use activity be difficult to operationalise and measure without a monitoring framework in place. 
this contribution investigate the potential of re use end of life product that have be dispose at recycling centre in sweden. 
recycling centre receive a wide variety of material for recycling of which a portion could be re use instead. 
the aim be to identify what product group can be re use the share of these potentially re usable product in the recycling centre and under what condition their re use be feasible. 
a literature review of similar study site visit at recycling centre in sweden and semi structured interview with relevant stakeholder be use to analyse the potential for re use in private recycling centre in sweden. 
the most suitable product group for re use identify be build material furniture and electrical equipment mainly white good as other material type be mostly handle by charity organisation e.g. 
textile. 
there be significant potential for increase re use operation in recycling centre but in order to be economically profitable it be important to identify the most suitable material fraction or product group and engage in strategic partnership that will allow more effective organisation of re use process. 
influence of throughput rate and input composition on sensor based sorting efficiency. 
accord to the directive eu 2018/851 of the european union high recycling rate for municipal waste will have to be meet in the near future. 
beside improvement to the collection system the efficiency of mechanical processing and sorting will have to be increase to reach the eu s target. 
sensor base sorting sbs plant constitute an integral part of today s sorting process. 
two main factor determine the sort performance throughput rate and input composition. 
to improve recycling efficiency especially sbs machine need to be optimize. 
three evaluation criterion be use to describe the performance of these process recovery content of input material both eject and reject material discharge into the product fraction or product quantity amount of product generate via sort within a specific interval calculate by multiply throughput rate and yield yield amount of eject material discharge into the product fraction and product purity. 
for this study 160 sorting experiment each with 1,000 red and white low density polyethylene ldpe chip be conduct to investigate the effect of throughput rate and input composition on sort process. 
this simplified approach reduce the influence of other factor on the sort performance give precise information on the effect of throughput rate and input composition. 
the testing result can enter process optimization. 
with increase throughput rate product quantity rise follow a saturation graph despite exponential decrease in recovery. 
in the experiment a high throughput rate also result in an exponential decrease of the yield while a change to the input composition have no such effect. 
the third evaluation criterion product purity decrease linearly with increase occupation density. 
the slope of this function depend on the input composition. 
optimization of drilling process parameter on delamination factor of jute reinforce unsaturated polyester composite use box behnken design of experiment. 
this paper present an investigation on the influence of the drilling parameter such as feed rate spindle speed and drill tool diameter onto the delamination factor of the jute reinforce unsaturated polyester composite. 
natural fibre base composite be mostly use for commodity application and often subject to drill during application and may generate delamination of drill hole on the workpiece. 
the composite be fabricate use weave jute fibre via vacuum bagging method follow a high temperature cure use hot press. 
the fibre be keep at 40 vol. 
the main effect and the interaction between the specify factor of feed rate 20 100mm min spindle speed 500 1500 rpm and drill tool diameter four 8 mm with delamination factor as corresponding respond be structure via the response surface methodology rsm base on three level box behnken design of experiment and the anova. 
the level of importance of the process parameter on flexural property be determine by use analysis of variance anova. 
the optimise drilling process parameter obtain as 24.38 mm min of feed rate 1146.14 rpm of spindle speed and 5.51 mm drill tool diameter achieve the most minimal delamination factor. 
the feed rate and spindle speed be perceive as the most influential drilling parameter on the delamination factor of the jute reinforce unsaturated polyester composite. 
analysis of tool vibration and surface roughness with tool wear progression in hard turning an experimental and statistical approach. 
the machine surface quality and dimensional accuracy obtain during hard turning be prominently gets affect due to tool wear and cut tool vibration. 
with this view the result of tool wear progression on surface quality and acceleration amplitude be present while machine aisi 52100 hard steel. 
central composite rotatable design ccrd be employ to develop experimental plan. 
the result report that vibration signal sense in a tangential direction v z be most sensitive and find high than the vibration in the feed direction v x and depth of cut direction v y. 
the acceleration signal in all three direction be observe to increase with the advancement of tool wear and good surface finish be observe as tool wear progress up to 0.136 mm. 
the vibration amplitude be discover high in the range three khz 10 khz within selected cutting parameter range cut speed 60 180mm min feed 0.1 0.5mm rev depth of cut 0.1 0.5 mm. 
the investigation be extend for the development of multiple regression model with regression coefficient value 0.9. 
these model find statically significant and give dependable estimate between a tool vibration and cut parameter. 
finite time consensus for linear multiagent systems via event trigger strategy without continuous communication. 
take into account multiagent system with general linear dynamic and direct topology the issue of achieve finite time consensus in a distribute event trigger fashion be discuss in this paper. 
a novel model base triggering function which depend only on local information be adopt. 
to ensure the finite time convergence of the disagreement vector and the trigger error a dynamic threshold which be guarantee to converge to zero in finite time be adopt in the propose triggering function design. 
by employ a novel distribute event trigger controller for each agent finite time consensus of multiagent system can be achieve. 
in the propose approach no continuous communication be need in either controller update or trigger detection. 
furthermore the trigger number be significantly reduce and the high frequency triggering be restrain. 
in addition the feasibility of the propose approach be guarantee by the comprehensive theoretical demonstration of the finite time consensus stability and the analysis of the zeno behavior. 
finally numerical simulation be carry out to illustrate the effectiveness of our result. 
observation driven scheduling for remote estimation of two gaussian random variables. 
joint estimation and scheduling for sensor network be consider in a system form by two sensor a scheduler and a remote estimator. 
each sensor observe distinct gaussian random variable which may be correlate. 
this system can be analyze as a team decision problem with two agent the scheduler and the remote estimator. 
the scheduler observe the output of both sensor and choose which of the two be reveal to the remote estimator. 
the goal be to jointly design scheduling and estimation policy that minimize a mean square estimation error criterion. 
the person by person optimality of a policy pair call max schedule mean estimation be establish where the measurement with the large absolute value be reveal to the estimator which use a correspond conditional mean operator. 
this result be obtain for independent gaussian random variable and correlate gaussian random variable with symmetric variance. 
finally the joint design of scheduling and linear estimation policy for any two gaussian random variable with an arbitrary correlation structure be consider. 
in this case the optimization problem be recast as a difference of convex program and locally optimal solution can be find use a simple numerical procedure. 
differential privacy for network identification. 
we consider a multiagent linear time invariant system whose dynamical model may change from one disturbance event to another. 
the system be monitor by a control center that collect output measurement from the agent after every event and estimate the eigenvalue of the model to keep track of any adverse impact of the disturbance on its spectral characteristic. 
share measurement in this way however can be susceptible to privacy breach. 
if an intruder gain access to these measurement she may estimate the value of sensitive model parameter and launch more severe attack. 
to prevent this we employ a differential privacy framework by which agent can add synthetic noise to their measurement before send they to the control center. 
the noise be design carefully by characterize the sensitivity of the system so that it limit the intruder from infer any incremental change in the sensitive parameter thereby protect their privacy. 
our numerical result show that the propose design result in marginal degradation in eigenvalue estimation when compare to the error incur by the intruder in identify the sensitive parameter. 
sensor placement for optimal control of infinite dimensional systems. 
an important challenge in control distributed parameter system be implement feedback control law over an infinite dimensional space. 
one widely study approach be to place sensor at a set of discrete location and then approximate the state feedback use the sensor output. 
this approach naturally raise the question of where the sensor should be locate. 
in this paper we investigate the problem of place a set of sensor on the unit interval in order to minimize the mean square deviation between a desire infinite dimensional control law and an approximate finite dimensional controller obtain by apply state feedback at the choose sensor position. 
we propose a greedy algorithm and derive optimality bound on the select set of sensor. 
we also present a simplified greedy algorithm in which the incremental improvement from add each sensor be not update at each step. 
we analyze the performance of the approach under two scenario. 
in the case where the sensor placement be constrain such that each of the detection radius of each pair of sensor do not overlap we show that the two algorithm be equivalent and achieve a 1/2+\epsilon$ optimality guarantee where \epsilon$ can be make arbitrarily small at the cost of increase computational overhead. 
when overlap exist between sensor detection area we derive an optimality bind for the simplified algorithm. 
the value of the optimality bind be determine by the sensor model cardinality of sensor set and the allow minimum sensor distance. 
our approach be illustrate through numerical study in which we compare our propose greedy algorithm the current state of the art approach and the true optimum obtain from exhaustive search. 
resilient consensus through event base communication. 
we consider resilient version of discrete time multiagent consensus in the presence of faulty or even malicious agent in the network. 
in particular we develop event trigger update rule that can mitigate the influence of the malicious agent and at the same time reduce the communication. 
each regular agent update its state base on a give rule use its neighbor information. 
only when the triggering condition be satisfied the regular agent send their current state to their neighbor. 
otherwise the neighbor will continue to use the state receive the last time. 
assume that a bound on the number of malicious node be know we propose two update rule with event trigger communication. 
they follow the so call mean subsequence reduce type algorithm and ignore value receive from potentially malicious neighbor. 
we characterize the necessary connectivity in the network for the algorithm to perform correctly which be state in term of the notion of graph robustness. 
a numerical example be provide to demonstrate the effectiveness of the propose approach. 
tool wear model and wear mechanism when machine tialn ball end mill with high thermal conductivity steel htcs 150. 
the intent of this research be to develop the regression model and optimization focus on the relationship between the cut parameter and wear performance when machine htcs 150 by use response surface methodology experimental design. 
microscopy analysis be employ to identify surface characteristic. 
experimental process be carry out use computer numerical control mill machine with range of cut speed of 484 553 m min feed rate of 0.31 0.36 mm tooth axial depth of cut of 0.1 0.5 mm and constant radial depth of cut of 0.01 mm. 
the result show that the model that develop adequately represent the process with modeling validation run within the 90 prediction interval. 
the combination of cut parameter for low tool wear record as 553 m min cut speed 0.36 mm tooth feed rate and 0.1 mm axial depth of cut. 
the wear on the cut tool start at the centre of the flank face before generate to the near upper contact zone. 
dominant wear mechanism appear to be coat delamination abrasion wear chipping and adhesion wear. 
friction and wear analysis of ceramic cutting tool make from alumina zirconia chromia. 
this research focus on the friction and wear analysis of ceramic cutting tool make from al2o3 zro2 and cr2o3. 
80 wt% of al2o3 and 20 wt% of zro2 compact be prepare by ball milling process with cr2o3 addition at the variation of 0.2 0.4 0.6 and 0.8 wt%. 
each sample be press by cold isostatic press at 350 mpa before sinter at the constant temperature of 1400oc and nine hour soaking time. 
relative density hardness flexural strength and pin on disc tribotest be perform for each sample. 
the sample with desire mechanical property be far machine with aisi 1045 at the cut speed of 200 m min 0.175 mm rev feed rate and 0.5 mm depth of cut. 
the result show the sample with composition ratio of al2o3 zro2 cr2o3 at 80 20 0.6 wt% demonstrate low coefficient of friction cof of 0.23 with hardness and relative density record at 71.3 hrc and 95.81 respectively. 
microstructure of al2o3 zro2 cr2o3 present significant grain compaction as compare to al2o3 zro2 and single al2o3 that show significant appearance of porosity. 
in term of tool wear al2o3 zro2 cr2o3 perform 51 and 800 well tool life than al2o3 zro2 and al2o3 cut tool. 
influence of rounded cutting edge radius and machine parameter on surface roughness and tool wear in mill aisi h13 steel under dry and cryogenic machining. 
rounded cutting edge radius have a significant influence on tool life of cut tool and consequently on the machining performance. 
thus this study present an experimental investigation to investigate the effect of rounded cutting edge radius and machine parameter on surface roughness and tool wear in milling of aisi h13 tool steel 52hrc in dry and cryogenic machining. 
uncoated four flute cement carbide cut tool of six mm diameter with cutting edge radius of 0.03 and 0.05 mm be prepared to be use in the study. 
the machining parameter apply be 0.03 and 0.06mm tooth of feed rate and axial depth of cut of 0.1 and 0.2 mm. 
cut speed be keep constant at 200m min. 
the obtain result show that the combination of low feed rate depth of cut and cutting edge radius in dry and cryogenic machining give the surface quality value of 0.158 and 0.146 mu m respectively and machine time of 4.429 and 8.652 min correspondingly. 
furthermore cryogenic machining significantly contribute to improve the machine surface and tool life by 2.46 7.59 and 48.81 84.62 respectively compare to dry machining. 
consider all factor cut tool of 0.03 mm edge radius show well performance in term of surface quality and tool wear under both machining condition. 
the morphological and surface roughness of magnetorheological polished aisi 6010 surface. 
this paper discuss the morphological and surface roughness produce on aisi 6010 aluminium surface with microgroove use the magnetorheological polishing method. 
initially the 17 sample be prepare with micro v groove feature use cnc computer numerical control mill machine. 
box behnken design of experiment doe be use to vary the polishing process factor namely speed voltage and magnetic field. 
the doe allow a relationship on morphological and surface roughness to be study. 
the mrp process be carry out use fabricate one axis two d.o.f mrp rig mount on a cnc machine. 
abrasive add mrp fluid be use during the polishing process. 
the surface roughness ra of the sample be measure under an olympus 3d laser microscope. 
from morphology study the irregularity on v groove and the flat surface of 17 sample after mrp be reduce. 
the magnetorheological polishing process reduce surface roughness from 10 mu m to as low as 0.4 mu m with a constant polishing time of 10 minute. 
this study show that the mrp method be capable to replace the conventional polishing process to polish complex micro feature on al 6010 surface. 
evaluation of tool wear and machining performance by analyze vibration signal in friction drilling. 
tool condition play an important role in machine performance. 
in machining process multiple phenomenon occur during material cutting. 
to improve their robustness the reliability pattern recognition technique have be implement in tool condition monitoring system. 
this study demonstrate a tool condition monitor approach in a friction drilling operation base on the vibration signal collect through accelerometer sensor. 
the experiment have be carry out on a cnc milling machine. 
in this present work an optimal parameter in friction drilling have be use on medium carbon steel aisi 1045. 
the signal be collect by accelerometer sensor and low pass filter be utilize to filter the raw datum. 
pattern recognition be identify and categorize into one of three cluster which be tool at good half life and wear out condition. 
the result find that the vibration amplitude be directly proportional to tool wear and friction which support the nature of tool wear in drilling process. 
the hole size reduction on the workpiece can also be see clearly with the increase vibration on the process due to the tool wear. 
with the effectiveness of pattern recognition the damage of the machine tool can be avoid to control the product quality consistently. 
safety practices in requirements engineering the uni repm safety module. 
context software be an important part in safety critical system scs development since it be become a major source of hazard. 
requirements relate hazard have be associate with many accident and safety incident. 
requirement issue tend to be mitigate in company with high process maturity level since they do their business in a systematic consistent and proactive approach. 
however requirement engineer need systematic guidance to consider safety concern early in the development process. 
goal the paper investigate which safety practice be suitable to be use in the requirements engineering re process for scs and how to design a safety maturity model for this area. 
method we follow the design science methodology to propose uni repm scs a safety module for unified requirements engineering process maturity model uni repm. 
we also conduct a static validation with two practitioner and nine academic expert to evaluate its coverage correctness usefulness and applicability. 
result the module have seven main process fourteen sub process and 148 practice that form the basis of safety process maturity. 
moreover we describe its usage through a tool. 
conclusion the validation indicate a good coverage of practice and well receptivity by the expert. 
finally the module can help company in evaluate their current practice. 
efficient robust design for thermoacoustic instability analysis a gaussian process approach. 
in the preliminary phase of analyze the thermoacoustic characteristic of a gas turbine combustor implement robust design principle be essential to minimize detrimental variation of its thermoacoustic performance under various source of uncertainty. 
in this study we systematically explore different aspect of robust design in thermoacoustic instability analysis include risk analysis control design and inverse tolerance design. 
we simultaneously take into account multiple thermoacoustic mode and uncertainty source from both the flame and acoustic boundary parameter. 
in addition we introduce the concept of a risk diagram base on specific statistical description of the underlie uncertain parameter which allow practitioner to conveniently visualize the distribution of the modal instability risk over the entire parameter space. 
throughout this study a machine learning method call gaussian process gp modeling approach be employ to efficiently tackle the challenge pose by the large parameter variational range various statistical description of the parameter as well as the multifaceted nature of robust design analysis. 
for each of the investigate robust design task we propose an efficient solution strategy and benchmark the accuracy of the result deliver by gp model. 
we demonstrate that gp model can be flexibly adjust to various task while only require one time training. 
their adaptability and efficiency make this modeling approach very appealing for industrial practice. 
vibration base condition monitoring of helicopter gearboxes base on cyclostationary analysis. 
the core of a helicopter drivetrain be a complex planetary main gearbox mgb which reduce the high input speed generate by the engine in order to provide the appropriate torque to the main rotor and to other auxiliary system. 
the gearbox consist of various shaft planetary gear and bearing and operate under vary condition under excessive friction heat and high mechanical force. 
the component be vulnerable to fatigue defect and therefore health and usage monitoring system hums have be develop in order to monitor the health condition of the gearbox focus toward early accurate and on time fault detection with limited false alarm and miss detection. 
the main aim of a hums be by health monitoring to enhance the helicopter operational reliability to support the maintenance decision making and to reduce the overall maintenance cost. 
the importance and the need for more advanced and accurate hums have be emphasize recently by the postaccident analysis of the helicopter ln ojf which crash in norway in 2016. 
during the last few decade various methodology and diagnostic indicator feature have be propose for the monitoring of rotate machinery operate under steady condition but still there be no global solution for complex structure. 
a new tool call improve envelope spectrum via feature optimization gram iesfogram have be recently propose by the author base on cyclostationary analysis focus on the accurate selection of a filter band under steady and vary speed condition. 
moreover the cyclic spectral coherence cscoh be integrate along the select frequency band lead to an improved envelope spectrum ies. 
in this paper the performance of the tool be test on a complex planetary gearbox with several vibration source. 
the method be test evaluate and compare to state of the art method on a dataset capture during experimental test under various operating condition on a category a super puma sa330 main planetary gearbox present seeded bear defect of different size. 
experiment on a large flexure pivot journal bearing summary of test results and comparison with prediction. 
flexure pivot(r journal bearing fpjbs have typically be use in small high speed application such as integrally gear compressor and multistage high speed compressor where the temperature management and the rotordynamic stability of the machine be the main target. 
nevertheless the need for high speed application may also be applicable to large compressor and for this reason a large 280 mm diameter four pad fpjb with l d 0.7 have be design build and test by the author. 
the test facility be a novel rig setup at the university of pisa that include a float test bearing and a rigid rotor support by two stiff rolling element bearing. 
both static and dynamic load be apply through hydraulic actuator capable of 270 kn static and 40 kn overall dynamic load. 
the instrumentation can measure all the relevant test boundary condition as well as the static and dynamic quantity that characterize the bearing performance. 
this paper present the result from a test campaign conceive to explore not only the design condition 7000 rpm rotational speed and 0.75 mpa unit load but also the sensitivity to the unit load from 0.2 mpa minimum load up to 2.2 mpa maximum load as well as the oil flow. 
the result be discuss and compare with prediction from an exist numerical code. 
reinforcement neural fuzzy surrogate assisted multiobjective evolutionary fuzzy systems with robot learning control application. 
this paper propose a new reinforcement neural fuzzy surrogate rnfs) assiste multiobjective evolutionary optimization rnfs meo algorithm to boost the learn efficiency of data drive fuzzy controller fcs. 
the rnfs meo be apply to evolve a population of fcs in a multiobjective robot wall follow control problem in order to reduce the number of time consume control trial and the implementation time of learn. 
in the rnfs meo the rnfs be incorporate into a typical multiobjective continuous ant colony optimization algorithm to improve its learn efficiency. 
the rnfs estimate the accumulate multiobjective function value of the fc in a colony without apply they to control a process which help reduce the number of control trial. 
the rnfs be train online through structure and parameter learning base on the reinforcement signal from control a process. 
consider the influence of the current control signal on the future state of a control process the temporal difference technique be use in the rnfs training so that it estimate not only the current but also the future objective function value. 
the colony of fcs in the rnfs meo be repeatedly evolve base on the rnfs estimate value or the objective function value from real evaluation until a colony of successful fcs be find. 
the rnfs meo base fc learning approach be apply to a robot wall follow control problem. 
simulation and experiment on the robot control application be perform to verify the effectiveness and efficiency of the rnfs meo. 
extract lpv and qlpv structure from state space functions a tp model transformation based framework. 
this paper propose a tensor product tp model transformation base framework require minimal human intuition to numerically reconstruct linear time invariant takagi sugeno t s fuzzy model base linear parameter vary and quasi linear parameter vary representation of state space model. 
the propose framework facilitate the manipulation of the structure of the system matrix the parameter vector include state element and the vertex system. 
the motivation behind this capability be that all of these structural component strongly influence the control design and the result control performance. 
an important feature of the framework be that it be agnostic towards the formulation of the state space model whether it be give use soft computing base technique or close formulae. 
the propose approach be an extension of the tp model base control design framework and inherit all of its advantageous property it can be easily use to find minimal representation include the high order singular value base canonical form and it support the clear formulation of complexity accuracy tradeoff and allow for conversion to various type of convex representation make for a flexible way to manipulate the weighting and antecedent function. 
this paper give example to show how the framework can be use in a routine like fashion and to highlight how it can be apply to the problem of find useful t s fuzzy model variation of a give model. 
pid like adaptive fuzzy controller design base on absolute stability criterion. 
this paper describe a method of pid like adaptive fuzzy controller design for a linear time invariant single input and single output dynamic plant. 
the plant transfer function be assume to be partially know. 
the controller operate in the direct adaptation mode with the output feedback and a nonlinear reference model which provide well closed loop response parameter than the system with a pid linear controller. 
the closed loop stability be guarantee during the adaptation process. 
the fuzzy controller be assume to be a nonlinearity in a bound sector and be define by highly interpretable fuzzy rule. 
the absolute stability criterion for the system contain pid like fuzzy controller be deliver. 
a design procedure that generalize and significantly extend result report so far in the literature and considerably automate the search process of a nonlinear adaptive fuzzy controller be provide. 
adaptive neural output feedback decentralize control for large scale nonlinear systems with stochastic disturbance. 
this paper address the problem of adaptive neural output feedback decentralized control for a class of strongly interconnect nonlinear system suffer stochastic disturbance. 
an state observer be design to approximate the unmeasurable state signal. 
use the approximation capability of radial basis function neural network nns and employ classic adaptive control strategy an observer base adaptive backstepping decentralize controller be develop. 
in the control design process nn be apply to model the uncertain nonlinear function and adaptive control and backstepping be combine to construct the controller. 
the develop control scheme can guarantee that all signal in the closed loop system be semiglobally uniformly ultimately bound in fourth moment. 
the simulation result demonstrate the effectiveness of the present control scheme. 
neural networks base distributed adaptive control of nonlinear multiagent systems. 
the cooperative control problem of nonlinear multiagent system be study in this paper. 
the follower in the communication network be subject to unmodeled dynamic. 
a fully distribute neural network base adaptive control strategy be design to guarantee that all the follower be asymptotically synchronize to the leader and the synchronization error be within a prescribed level where some global information such as minimum and maximum singular value of graph adjacency matrix be not necessarily to be know. 
base on the lyapunov stability theory and algebraic graph theory the stability analysis of the result closed loop system be provide. 
finally an numerical example illustrate the effectiveness and potential of the propose new design technique. 
consensus tracking control of switched stochastic nonlinear multiagent systems via event trigger strategy. 
in this paper the consensus tracking problem be investigate for a class of continuous switch stochastic nonlinear multiagent system with an event trigger control strategy. 
for continuous stochastic multiagent system via event trigger protocol it be rather difficult to avoid the zeno behavior by the exist method. 
thus we propose a new protocol design framework for the underlie system. 
it be prove that follower agent can almost surely track the give leader signal with bound error and no agent exhibit the zeno behavior by the give control scheme. 
finally two numerical example be give to illustrate the effectiveness and advantage of the new design technique. 
an ensemble integrate security system with cross breed algorithm. 
blockchain and iot be two technology be most widely popular in present scenario but technology be more complicated. 
the blockchain use to transform storage and datum analysis. 
in recent year the blockchain be at the heart of computer technology. 
it be a cryptographically secure distribute database technology for store and transmit information. 
various attack be do in many network. 
many research article discuss about the security issue over the iot base secure use block chain technology. 
in this paper an ensemble integrated security system eiss be introduce to improve the security for the heterogeneous network which consist of normal and abnormal node which be process with the block chain iot. 
result show the performance of the ouath two and eiss algorithm. 
robotics rolls into high gear with signal processing a robotic revolution promise to transform global industry and service and signal processing be at the forefront. 
resource optimize combinational binary neural network circuit. 
design efficient machine learning algorithm for near sensor datum processing on the edge have be at the research forefront in recent year. 
to achieve the required edge processing constraint massively parallel binary neural network bnns have be develop. 
bnn implement in purely combinational circuit provide resource utilization efficiency and performance. 
this paper propose novel resource optimize architecture of hard wire combinational bnn target field programmable gate array fpga edge deployment. 
the propose architecture require few adder and overall operation for parallel neuron activation computation. 
a high level synthesis toolchain be design which enable user to produce the hardware description language model of optimize combinational bnn circuit directly from application dataset. 
standard and optimize combinational architecture be build for different edge processing application by use this toolchain. 
the propose optimize architecture reach a 39.9 improvement in term of fpga slice usage a 28.2 improvement in net use and a 51.9 reduction in power consumption which enable deployment possibility for the state of the art fpga classification system. 
application of machine learning and big data in doubly fed induction generator base stability analysis of multi machine system use substantial transformative optimization algorithm. 
with the increase in the amount of datum capture during the manufacturing process surveillance system be the most important decision make decision. 
current technology such as internet of things iot can be consider a solution to provide efficient monitoring of productivity. 
in this study it have suggest a real time monitoring system that use an iot big datum processing and an offshore wind farm owf model be propose. 
the offshore wind farm owf be an extended level invasion in modern power electronic system in this propose work doubly fed induction generator dfig base multi machine owf be design and power stability be analyze use substantial transformative optimization algorithm stoa. 
the voltage source converter vsc and high voltage direct current hvdc system be combine with onshore network. 
the terminal voltage of onshore network be control through onshore side converter osc active and reactive power be regulate separately use vsc. 
the performance of the onshore network be evaluate under renewable network error total harmonics distortion and steady state error beside with owe. 
the owf dfig active and reactive power be control smoothly with in the limit of hvdc and the power framework security can be update by control the active power of the osc to help its terminal voltage use stoa methodology. 
from the voltage control mode the electrical fault be recover rapidly with minimum fluctuation. 
the dynamic simulation come about additionally demonstrate that onshore network fault can t impact owf behind hvdc transmission system. 
because of the specialized favorable circumstance vsc hvdc innovation the constancy in owf be very much ensure against the onshore grid fault. 
the propose stoa base system have validate through simulation in matlab simulink environment. 
general 97 effectiveness accomplish at full load condition in light of the propose system. 
the result show that the iot system and the propose large datum processing system be sufficiently competent to monitor the manufacturing process. 
c 2019 elsevier b.v. 
all right reserve. 
measurement of image degradation a no reference approach. 
in modern communication system transmission of datum particularly that of image be very important. 
unfortunately the process be prone to different kind of degradation. 
for instance the large traffic on the network make the reduction of datum volume and storage imperative. 
this be achieve through compression technique such as jpeg and jpeg2000 at the expense of image quality unfortunately. 
image quality also deteriorate on account of the state of the transmission channel and the amount of loss occur. 
another common type of image degradation be blur. 
at the receiving end identify the degradation be an important requirement for application like blind image denoise so that appropriate technique for removal may be adopt. 
since the undegraded original image be usually not available no reference method be not only attractive but also essential. 
this article propose a novel no reference method which can clearly distinguish between noise compression and blur. 
this be achieve in two stage the first distinguishe between noise and compression blurring while the second distinguishe between compression and blur. 
finally a quantification of the degradation suffer be also carry out which form another important contribution of the approach. 
the primary tool employ be the discrete wavelet transform dwt and the differential behaviour of the image dwt coefficient to noise compression and blurring at various level of resolution. 
the use of the property of the inter level coefficient make this approach unique in nature. 
these property have be explore and analyze in detail. 
a large number of simulation use image from popular database establish the usefulness of the approach. 
a system for semantic segmentation of tv news broadcast video. 
tv news channel present rich and complete experience of various event through audio visual content. 
this make television news an influential medium to affect masse and thus persuade various social scientist and regulator to monitor and analyze the content of broadcast video. 
an organized archive of newscast be a prerequisite for any such analysis. 
create such archive require segmentation of continuous news video into suitable logical unit. 
base on the application these logical unit may be one of channel content obtain after advertisement removal different show news story or video shot. 
in this work we propose an end to end system with software architecture for segment the tv broadcast video at all these four granularity. 
the video be segment into shot. 
video shot be use as basic unit for all further processing. 
video shot be first subject to advertisement detection and removal to obtain the non commercial channel content. 
this channel content be far process to identify various program boundary. 
we propose to identify three type of show base on the presentation format viz. 
news bulletin interview and debate. 
news bulletin so obtain be process far to obtain news story. 
we propose a modular and scalable framework and software architecture for the broadcast segmentation system for deployment on a computation cluster. 
this involve scheduler base recording module and broadcast segmentation module. 
we have present the detailed software architecture for individual module automation of entire processing pipeline along with resource and database management system. 
we have implement and verify the software architecture by deploy the propose system on a cluster of nine desktop and one workstation. 
the deployed system be use for round the clock processing of three indian english news channel. 
an integrated fuzzy carbon management base model for suppliers performance evaluation and selection in green supply chain management. 
assess supplier base on green focus attribute be a critical issue recently implement by industry due to increase community knowledge about global warming and climate change. 
carbon management be a new branch of green supplier selection which focus on other aspect of environmental issue. 
this study integrate a new fuzzy modification of analytical hierarchy process ahp know as fuzzy preference programming fpp with fuzzy vlsekriterijumska optimizacija i kompromisno resenje fvikor to assess supplier performance with respect to carbon management criterion. 
four dimension and twelve criterion have be select base on previous study and expert opinion. 
linguistic variable be employ to gather the expert opinion about the importance degree of the dimension and correspond attribute. 
subsequently the importance weight of each dimension and its corresponding criterion be compute by use fpp. 
the performance rating of the supplier base on the determined criterion be collect under a fuzzy environment use linguistic variable. 
then fvikor be apply to obtain the overall environmental performance with respect to carbon management attribute. 
through a case study in a textile company the performance score of its supplier be elicit in accordance with this procedure. 
finally validation and managerial implication show that the developed model be robust and applicable. 
grid base indexing with expansion of resident domain for monitor move object. 
continuous range query crqs for move object monitor the designate spatial region and report their up to date query result. 
in such query query region be more static than when compare to move object. 
therefore create an index structure for query region to process crq require low maintenance cost of the server than that of move object. 
to relieve the workload of the server each move object can be assign with a resident domain where the object monitor the overlapped query region and inform the server if any update occur. 
in this paper we propose a grid base indexing with expansion of resident domain for monitor crq in the mobile ubiquitous computing environment. 
the propose method expand resident domain for move object as large as possible so that they have less chance to inform the server about update. 
comprehensive experiment with various setting have verify that our propose method outperform the qr* tree. 
empirical decision analytic approach of advanced granularity base model for identify performance measure of erps application. 
there be four motivation in this study. 
first recent machine learning technique such as decision tree multi layer perceptron and bayesian method for empirical decision analytic approach be span a wide research interest to understand and solve a real world complex problem and thus attract significant concern for identify performance measure of extensive application domain. 
second integrate circuit design ic industry in taiwan play a prominent bellwether in trigger world s economic market particularly for taiwan semiconductor manufacturing company. 
third enterprise resource planning system erps have be one of the most popular tool in total solution management across industry and its relevant decision rule attract current trend in use an advanced soft computing approach. 
lastly with limited literature review there be scarce investigation on pick right erps with effective decision rule base knowledge for the ic design industry from application perspective and this research be first to bridge such a study gap for technical and managerial application. 
thus this research synthesize and propose an advanced hybrid procedure to organize multi expert granularity base model with comprehensible decision rule base wisdom to experience the erps selection and identify its determinant. 
the study finding imply that the determinant be varied from the class type and benefit interested party useful reference to facilitate positive migration of inter industry. 
this research significantly contribute clear motivation and originality with good application value for an advanced hybrid analysis. 
research and development of laser engraving and material cutting machine from 3d printer. 
this article deal with the adjustment of a 3d printer for laser engraving and material cutting. 
the print head can be fit with a solid laser diode module which achieve a compact size while retain its useful power. 
two path lead to the use of such a concept. 
it be possible to equip the exist print head with a module which also bring a number of disadvantage such as for example the reduction of the printing space or the need for a suitable mount design. 
a more elegant solution be to consider this in the design of a 3d printer and design a system to exchange the print head for 3d printing and laser engraving. 
such a solution allow full utilization of the workspace and simple installation of the effector for the required type of work. 
accord to the instal power of the laser diode it be possible not only to engrave but also cut material such as thin wood veneer or acrylic glass. 
the use of such a machine be not only for graphic element but for the creation of various stencil box or simple model which can be make up of plastic burn piece. 
the laser module be control by a driver which be design for the device. 
this be connect to a 3d printer control board. 
it be therefore necessary for the control board to have at least two pin which can be control after adjust the control firmware. 
most laser module be normally equip with an adjustable lens which be use to concentrate the focus of a laser for the give distance against the worktop. 
thus the modify 3d printer can perform its function as a multi purpose cnc machine while a basic platform similar for both device be use. 
qt adaptation engine adaptive qos aware scheduling and govern in thermally constrain mobile device. 
modern mobile device be equip with heterogeneous multicore processor which integrate asymmetric cpu core and gpu. 
more core require additional power consumption and produce more heat which can result in performance degradation due to thermal throttling. 
to address this issue this paper propose a qt adaptation engine to monitor current temperature and quality of service qos and derive a qos temperature model qt model through a run time learning mechanism qt learning to balance dynamic workload and dynamic thermal behavior. 
base on the derive qt model the qt adaptation engine migrate thread among core use the propose critical thread aware scheduler to ensure high qos and use a self adapt governor to meet the temperature constraint for system robustness. 
the concept be implement on a commercial lg nexus 5x and evaluate use real world application. 
result show the propose approach increase the frame per second rate by up to 25 compare to other current method while meet temperature constraint. 
hierarchical symbol base health status analysis use time series data in a core router system. 
to ensure high reliability and rapid error recovery in commercial core router system a health status analyzer be essential to monitor the different feature of core router. 
however traditional health analyzer need to store a large amount of historical datum in order to identify health status. 
the storage requirement become prohibitively high when we attempt to carry out long term health status analysis for a large number of core router. 
we describe the design of a symbol base health status analyzer that first encode as a symbol sequence the long term complex time series collect from a number of core router and then utilize the symbol sequence to do health analysis. 
the symbolic aggregation approximation sax 1d sax move average base trend approximation and nonparametric symbolic approximation representation method be implement to encode complex time series in a hierarchical way. 
hierarchical agglomerative clustering and sequitur rule discovery be implement to learn important global and local pattern. 
three classification method include a vector space model base approach be then utilize to identify the health status of core router. 
datum collect from a set of commercial core router system be use to validate the propose health status analyzer. 
the experimental result show that our symbol base health status analyzer require much low storage than traditional method but can still maintain comparable diagnosis accuracy. 
connect the dots privacy leakage via write access pattern to the main memory. 
data dependent access pattern of an application to an untrusted storage system be notorious for leak sensitive information about the user s datum. 
previous research have show how an adversary capable of monitor both read and write request issue to the memory can correlate they with the application to learn its sensitive datum. 
however information leakage through only the write access pattern be less obvious and not well study in the current literature. 
in this work we demonstrate an actual attack on power side channel resistant montgomery s ladder base modular exponentiation algorithm commonly use in public key cryptography. 
we infer the complete 512 bit secret exponent in \mathbf{\sim 3.5}$similar to 3.5 minute by virtue of just the write access pattern of the algorithm to the main memory. 
in order to learn the victim algorithm s write access pattern under realistic setting we exploit a compromise dma device to take frequent snapshot of the application s address space and then run a simple differential analysis on these snapshot to find the write access sequence. 
the attack have be show on an intel core(tm i7 4790 3.60ghz processor base system. 
we far discuss a possible attack on mceliece public key cryptosystem that also exploit the write access pattern to learn the secret key. 
simulation and evaluation of production factors in manufacturing of fireplace. 
the paper present quantitative approach for management decision of the manufacturing system for production of fireplace relate to evaluation of key parameter productivity and throughput which most author and methodology consider to be substantial. 
methodology be base on create the simulation model of the fireplace production line in software witness optimize the production capacity by select constraint base on result from simulation model evaluate the simulation experiment with the goal to increase productivity set production to maximize sale profit use simplex method. 
simulation model be build accord to a technological process of fireplace in a semi automated production. 
improvement in a production process within theory of constraint philosophy be complement by mathematical modelling simplex method that estimate profit maximization in case the company management decide to produce more product variant. 
experimental assessment of effect of backlash control parameters on quadrant protrusions of circular tests for cnc machine tools. 
backlash friction and servo lag factor often result in protrusion or segment difference phenomenon in the move speed reversal of a machine tool s move table. 
this phenomenon can be improve by adjust the backlash control parameter of the machine tool controller but the control parameter must vary with the feed rate and payload of the move table. 
therefore this study perform the circular test process for cnc machine tool and use different feed rate radius and payload motion condition to discuss the effect of backlash control parameter on quadrant protrusion. 
first this study use parameter range reduction combine with the taguchi method and the binary search algorithm to search for the optimal backlash control parameter in the parameter set range so that the machine tool could have preferable quadrant protrusion performance when execute circular test. 
afterward the correlation of the move table feed rate radius and payload to the quadrant protrusion be analyze accord to the experimental result. 
the result indicate that the machine tool move table feed rate have the most apparent effect on quadrant protrusion and the relationship between the payload and quadrant protrusion be influence by the move table feed rate and circular radius simultaneously. 
machining and characterization of micro channels generate on phosphor bronze use mu edm. 
micro electro discharge machining mu edm be one of the nonconventional micro machining process in which electrical discharge be produce between the micro sized electrode tool and workpiece immerse in dielectric fluid. 
the electrical discharge thus produce remove the workpiece material through melting and vaporization process and result in the creation of micro crater. 
this paper focus on machining of micro channel on copper alloy phosphor bronze plate use mu edm. 
various micro channel have be machine on phosphor bronze with input parameter voltage capacitance and pulse on time varied at four level. 
the experimental layout plan be design with robust design technique taguchi base l 16 orthogonal array and the process parameter be optimize use optimization technique grey relational analysis gra. 
the dimensional aspect depth width profile and surface roughness of machine channel be select as output response. 
the experimental result show that the parameter have individual and combined effect on response. 
analysis of variance anova technique have be use to explore the effect of parameter on response. 
detailed surface morphology of the machine feature have also be analyze use scan electron microscope sem and noncontact optical profiler image. 
as an extension of machine channel y shape channel have be machine on copper alloy which can be use for micro fluidic application. 
investigation of gfrp gear accuracy and surface roughness use taguchi and grey relational analysis. 
glass fiber reinforce polymer gfrp composite gear be use in a number of application where fine motion transmission and silent rotation be require. 
in order to increase its usage there be a need to increase the quality of gear. 
shrinkage problem be associate with injection mold gear. 
in present case blank be prepare by injection molding and tooth be cut on gear shaper by which metrology can be control by optimize the machining parameter. 
an analysis of variance be apply on 27 experiment to validate the process and find out that rotary feed be at rank one which be 0.15 mm stroke cut fluid ratio be at rank two which be 12 cut speed be at rank three which be 240 stroke min fluid flow rate be at rank four which be 30 ml min. 
by use these parameter optimum performance obtain be 0.213 mm root diameter deviation rd 0.165 mm tooth thickness variation tt and one mu m roughness average ra with grey relational grade of 0.8318. 
the optimum response provide the good value of rd tt and ra for the range include in experimental result which be 0.138 to 0.416 mm 0.012 to 0.187 mm and 1.2 to 2.43 mu m respectively. 
surface roughness improvement in this work be 49.8 high as compare to result available in literature. 
error estimation of bilinear galerkin finite element method for 2d thermal problems. 
this study demonstrate a two dimensional steady state heat conduction laplace partial differential equation solution use the bilinear galerkin finite element method. 
heat transfer analysis be of vital importance in many engineering application and devise computationally inexpensive numerical method while maintain accuracy be one of the primary concern. 
the method use structure mesh grid over a two dimensional rectangular domain and solve use a stiffness matrix for the bilinear element calculate use the propose modify numerical scheme. 
several numerical experiment be conduct by control the number of node and change element size of the present scheme and comparison make between analytical solution and software generate solution. 
a 60 m range 6.16 mw laser power linear mode lidar system with multiplex adc tdc in 65 nm cmos. 
this paper present a linear mode light detection and range lidar analog front end architecture with multiplex analog to digital converter time to digital converter adc tdc. 
an add voltage to time converter vtc and a reuse tdc be simultaneously use to implement the adc and tdc function thus replace discrete adc and tdc save hardware cost and reduce power consumption. 
a three stage inverter base transimpedance amplifier tia with ultra low power low noise and high low gain mode long short range mode be propose to reduce its influence to optical signal to noise ratio osnr. 
the prototype tia and adc tdc be fabricate in the 65 nm cmos technology and integrate into the single line apd base lidar system. 
the receiver front end of tia and adc tdc only consume 12.44 mw. 
the minimum detection current of the receiver front end be less than 238 na with bandwidth of 150mhz for long range and weak light detection. 
lidar achieve a measurement range of 60 m with a 70 klx direct sunlight and only 6.16 mw average laser power. 
experimental result show that this architecture be suitable for low cost multi line integrate lidar application compare to conventional architecture use adc tdc adc+tdc architecture. 
comparative analysis of tree meta learning and function classifiers to predict the atmospheric concentration of no2. 
the concentration of airborne pollutant be rise in recent year. 
due to serious health effect of no2 so2 etc. 
their constant monitoring be important for the policy maker as it provide early pollution estimate before it cross permissible limit set by the state. 
for air quality modelling several statistical technique base on artificial neural networks have be apply however tree and meta learn base classifier have rarely be adopt for air pollution prediction purpose. 
thus for this study tree random forest reduces error pruning rep tree meta learn bagging random subspace and function multilayer perceptron and support vector machine base classifier have be employ to predict atmospheric concentration of nitrogen dioxide no2. 
the study use three atmospheric pollutant sulphur dioxide so2 carbon monoxide co and hydrochloric acid hcl and five meteorological parameter temperature humidity wind speed wind direction and atmospheric pressure. 
moreover for validation of prediction model the performance of different classifier be compare. 
the result obtain suggest that tree classifier in general and random forest in particular can outperform function mlp and svm and meta learn bagging and random subspace classifier to predict the atmospheric concentration of no2. 
c 2020 l&h scientific publishing llc. 
all right reserve. 
machine learning techniques for satellite fault diagnosis. 
satellite be know as a remotely operate system with high degree of complexity due to large number of interconnect device onboard the satellite. 
consequently it have correspond significant number of telemetry parameter to allow operator and designer have full control and monitor of satellite mode of operation. 
the tremendous amount of telemetry datum receive from the satellite during its lifetime have to be analyze in order to monitor and control subsystem health for well decision making and fast responsively. 
in this research we address the topic of use machine learn technique to diagnose fault of satellite subsystem use its telemetry parameter. 
the case study and source of telemetry be acquire from egyptsat one satellite which have be launch april 2007 and lose communication with ground station last 2010. 
we apply machine learning technique in order to identify operating mode and correspond telemetry parameter. 
we use support vector machine for regression to analyze the satellite performance then a fault diagnosis approach be apply to determine the most probable reason of this satellite failure. 
telemetry datum be cluster use k mean cluster algorithm in combination with t distribute stochastic neighbor embed t sne function for dimensionality reduction. 
we classify datum use logical analysis of data lad in order to generate positive pattern for each failure class which be use to determine probability failure cause for each telemetry parameter. 
these probability enable fault tree analysis fta to get the most probable cause that lead to satellite failure. 
c 2019 the authors. 
publish by elsevi b.v. 
on behalf of faculty of engineering ain shams university. 
this be an open access article under the cc by nc nd license http://creativecommons.org/licenses/by nc nd/4.0/. 
solve the motion planning problem use learn experience through case base reasoning and machine learning algorithm. 
this article present two novel methodology for solve the motion planning problem through retain experience. 
both approach employ ai s case base reasoning cbr technique. 
case base reasoning be an expert system development methodology which reuse past solution to solve new problem. 
the first approach use cbr to retain k similar case to solve the motion planning problem by merge those solution into a set. 
afterwards it pick from this set base on a heuristic function to assemble a final solution. 
regard the second approach it employ the retain k similar case differently. 
it use those solution to build a graph which can be query use traditional graph search algorithm. 
result prove the success of such approach concern solution quality and success rate compare to different experience base algorithm. 
such utilization for cbr system develop new research direction for building system that can solve np problem base on retain experience exclusively. 
c 2019 the authors. 
publish by elsevi b.v. 
on behalf of faculty of engineering ain shams university. 
this be an open access article under the cc by nc nd license http://creativecommons.org/licenses/by nc nd/4.0/. 
coordination of pricing and order quantity for two replaceable and seasonal products. 
this paper deal with the coordination of pricing and order quantity decision for two seasonal and substitutable good in one firm. 
we assume that the customer be price sensitive and they be willing to buy the cheap product which be know as one way and customer base price drive substitution. 
first a mathematical model be develop for one firm which contain two replaceable product consider seasonality. 
the model aim to maximize the profit by determine optimal dynamic price order quantity and the number of period for both of the product. 
then we show that the objective function be strictly concave of price and have a unique maximum solution. 
next an exact algorithm base on the karush kuhn tucker kkt condition be present to determine the optimal decision. 
finally a numerical example accompany by sensitivity analysis on key parameter be develop to illustrate the efficiency of solution procedure and the algorithm. 
experimental evaluation of surface alterations induce in machining of ti 6al 4v alloy. 
surface integrity of workpiece after machine process be one of the most essential requirement of engineer in advanced industry since it have significant effect on performance and service life of the component. 
base on this thermal and mechanical load generate by machining be responsible for change in mechanical property of the machined workpiece and consequently they should be control. 
among they ti 6al 4v be utilize extensively by engineer because of its excellent property. 
therefore at the present study extensive experiment be conduct to characterize the performance of machine operation regard the surface integrity of ti 6al 4v super alloy. 
hence the effect of experimental condition on microhardness profile surface roughness grain size and maximum machining temperature be study. 
the result indicate that cut speed be a predominant parameter for enhancement of surface microhardness and increase in feed rate have the striking influence on thermal load enhancement. 
the result also demonstrate that increase depth of cut have the low influence on grain size variation. 
balanced scorecard for evaluate the performance of supply chain a bibliometric study. 
as supply chain management involve several criterion its performance evaluation be a challenge for industrial manager. 
researcher have propose several approach for such evaluation among they be balanced scorecard bsc highlight. 
academic paper on bsc application for evaluate supply chain performance have be expressively increase in recent year. 
consider that examine publish paper on a topic be a way of monitor the emergence of a new field this study aim to explore through bibliometrics paper publish in indexed journal scopus and web of science database. 
this paper weave an overview of academic production and study trend on bsc for performance evaluation of supply chain finding help researcher and manager understand the state of the art to identify gap and to identify future trend. 
the result also show the maturation of study over the year. 
the predominance of publication in journal with impact factor thomson reuters also have be notice. 
the development of the theme in emerge country can be useful for increase the competitiveness of their company. 
in summary this study be helpful for influence future study and publication of researcher interested in performance evaluation of supply chain base on bsc and may orient new researcher so that they directly know which journal to consult and which technical procedure to explore. 
iepe accelerometer fault diagnosis for maintenance management system information integration in a heavy industry. 
with the increase demand for reliable production facility the design of a health condition monitor system with the implementation of automatic diagnosis as well as software solution be one of the main issue for a smart factory. 
among many industrial application accelerometer be one of the most frequently use sensor for facility vibration monitoring. 
thus the health condition of the sensor itself be a critical factor for a correct diagnosis. 
failure to monitor the sensor s health condition would potentially cause a false alarm which may lead to a wrong decision making make by field operator. 
in this research a preprocessing method of synthetic datum and a gaussian mixture model gmm classifier be develop to classify the health condition of the online integrate electronic piezoelectric iepe accelerometer. 
the propose method be integrate into a product line and the test result achieve 99 of accuracy in determine five different health condition of the accelerometer. 
with the aid of the propose method the time of human inspection can be significantly reduce and the field safety can also be improve. 
moreover false alarm cause by sensor failure can be prevent. 
this lead to increase in reliability of the facility monitoring system. 
three feature to represent 99 three feature to represent 99. 
risk of modular integrated construction a review and future research direction. 
stakeholder remain skeptical in adopt modular integrate construction mic because of the associated risk and uncertainty although its benefit have be extensively document. 
the unique business model of mic nurture several risk and uncertainty different from those of the conventional construction approach. 
despite the grow attention on mic with its market expansion no systematic evaluation be in place to monitor its risk research progress. 
accordingly this research review publish literature address the risk associate with mic from 1992 to 2019. 
analysis reveal that the research publication on risk of mic witness a steady growth with considerable progress occur in the last decade. 
result imply that the risk of mic have gain extra attention in the construction engineering and management domain in recent time. 
exist empirical study have focus heavily on perceive implementation risk supply chain risk schedule risk investment risk structural risk ergonomic risk and mic risk management strategy which indicate that mic be associate with a host of risk event. 
the research far identify the critical risk event cres in the application of mic base on frequency of occurrence. 
the identify cre contribute to the checklist of risk event in the implementation of offsite construction osc. 
the latter may be useful in risk planning especially where the mic be less develop and few or no bespoke risk assessment exist. 
research gap in exist study be highlight in this research and area for further study be then propose. 
thus it make a useful contribution to the scholarly literature on the risk of osc and may prove useful to offsite construction researcher industry practitioner and project manager. 
identify stakeholder role and relevant project document for 4d base collaborative decision make. 
to fully understand and effectively implement 4d building information model bim model and method we need to develop a precise knowledge of which project digital document should be use and how they influence the decision make dm process. 
this article study the convergence between use of 4d bim and digital project document. 
we hypothesize that a clear visualization of the construction simulation through a 4d model be a useful source of information and a support for dm at collaborative meeting. 
through this research we continue to progress toward a new 4d base collective decision device so these element will contribute to propose 4d bim as dm support on architecture engineering construction aec project. 
far the present research will be complement by result from questionnaire give at a later research stage. 
the article present a brief review of bim context to consider way of foster the implementation of all 4d bim use not only visualization. 
it then introduce a proposition for 4d bim use implementation by the project development phase. 
it conclude by summarize stakeholder role and document relevant to 4d bim use. 
a 1.8 ghz near field dielectric plethysmography heart rate sensor with time base edge sampling. 
this article present a near field dielectric plethysmography dpg heart rate sensor for low power operation. 
by interrogate the contracting and expand blood vessel with gigahertz frequency fringe electric field from the on board coplanar waveguide cpw transmission line pulse heart rate signal be detect use a phase sensitive interface circuit through change permittivity at the fingertip. 
signal analysis frequency response measurement and variability study be provide to demonstrate the robustness of dpg for heart rate detection. 
the readout circuit employ a highly digital time base edge sample with the rail to rail signal and double integration chopper stabilization technique to maximize the electronic sensitivity and to minimize the flicker noise. 
implement in the 0.18  cmos technology the phase sensitive readout circuit exhibit a limit of detection of 0.0033 degree and consume 20.1 under a sampling and duty cycling rate of 100 hz and 0.0256 respectively. 
with the integration of cpw sensor in a low cost fr four print circuit board pcb the 1.8 ghz dpg heart rate sensor achieve an rm inaccuracy of 1.64 bpm. 
a bi directional zero latency adaptive clocking circuit in a 28 nm wide avfs system. 
resilient circuit base on in situ timing monitor adaptive voltage frequency scaling avfs eliminate excess time margin cause by process voltage and temperature pvt variation but suffer from 50 throughput loss during error recovery when operate at a half frequency. 
we propose a bi directional adaptive clocking circuit to provide fine frequency tuning with zero latency for avfs system. 
it can either stretch the clock cycle when there be time error to ensure correct function or compress the cycle when there be excess timing margin. 
to support a wide frequency range we generate multiple phase clock base on two delay line and select one appropriate phase clock to obtain a stretched output clock where balanced clock path be obtain by a time to digital converter and dynamic or gate. 
apply to a wide operate range avfs system of an sha 256 accelerator with transition detector td latch the whole avfs system be able to respond to error in one clock cycle with dynamic or gate collect all the error in half a cycle and adaptive clocking circuit stretching at the current cycle. 
fabricate in 28 nm cmos chip measurement show that it achieve 38.6% 69.4 power gain at near threshold while reduce throughput loss during error recovery. 
adaptive harmonic control for rejection of sinusoidal disturbances act on an unknown system. 
we present a sample datum adaptive harmonic control algorithm that reject sinusoid with know frequency that act on a completely unknown asymptotically stable linear time invariant system. 
we analyze the stability and closed loop performance for system with at least as many control as performance measurement. 
we show that the closed loop system be uniformly lyapunov stable and the adaptive controller asymptotically reject the disturbance. 
we present numerical simulation compare the new sample datum adaptive controller with an exist sinusoidal disturbance rejection approach i.e. high harmonic control. 
we also present result from an active disturbance rejection experiment in an acoustic environment. 
these experimental result demonstrate the practical effectiveness of the adaptive harmonic controller. 
sparsity exploit anytime algorithms for model predictive control a relaxed barrier approach. 
we present and analyze a novel class of stabilize and numerically efficient model predictive control mpc algorithm for discrete time linear system subject to polytopic input and state constraint. 
the propose approach combine the previously present concept of relaxed barrier function base mpc with suitable warm starting and sparsity exploit factorization technique and allow to rigorously prove important stability and constraint satisfaction property of the result closed loop system independently of the number of perform newton iteration. 
the effectiveness of the propose approach be demonstrate by mean of a numerical benchmark example. 
formation control with multiplex information network. 
current distribute control method have a lack of information exchange infrastructure to enable spatially evolve multiagent formation. 
specifically these method be design base on information exchange rule represent by a network have a single layer where they lead to multiagent formation with fix nonevolve spatial property. 
for situation where capable agent have to control the result formation through these method they can often do so if such agent have global information exchange ability. 
yet global information exchange be not practical for case that have large number of agent and low bandwidth peer to peer communication. 
motivated from this standpoint the contribution of this paper be to show how information exchange rule which be represent by a network have multiple layer multiplex information network can be design for enable spatially evolve multiagent formation. 
in particular we first consider the formation assignment problem and then the formation track problem and introduce new distribute control architecture that allow capable agent to spatially alter the size and the orientation of the result formation without require global information exchange ability. 
in addition tool and method from differential potential field be far utilize in order to generalize the propose distribute control architecture for the formation track problem to allow for connectivity maintenance and collision avoidance need in real world application. 
stability of the propose architecture be theoretically analyze and their efficacy be illustrate on numerical example and on multiagent formation experiment. 
a process monitoring scheme for uneven duration batch process base on sequential moving principal component analysis. 
the batch process contain complicated production mechanism which have pose a huge challenge for condition monitoring. 
motivate by the problem of multiphase mp partition in time sequence uneven duration batch with out of sync trajectory this brief present a novel process monitor scheme of mp partition modular modeling and online monitoring. 
the sequential move principal component analysis smpca be first propose to perform the mp partition of uneven duration batch in time sequence. 
the update of the smpca exactly explain the dynamic mp characteristic of the sample datum and the immediacy of the local smpca model. 
moreover the essential trend of process change be also explain by extract the local smpca model feature space and establish the similarity evolution index for critical variable. 
subsequently the modular modeling base on the subphase partition be conduct to solve the modeling problem of uneven duration batch with out of sync trajectory. 
then a monitoring technique include the differentiated monitoring and secondary monitoring be introduce to far effectively abate fault alarm rate of the monitoring. 
the performance and advantage of the process monitoring scheme propose be explain through a typical case and comparative experimental analysis. 
hierarchical bayesian network modeling framework for large scale process monitoring and decision making. 
in this brief a hierarchical bayesian network modeling framework be formulate for large scale process monitoring and decision making which include a basic layer and a functional layer. 
first the whole process be decompose into different unit where local bayesian network be construct provide monitor information and decision make capability for the upper layer. 
the network structure be determine automatically base on the process datum in each local unit of the basic layer. 
then through incorporate the topological structure of the process a functional bayesian network be far construct to infer the information from the basic layer which can be customize accord to user demand such as fault detection fault diagnosis and classification of operating status. 
the performance of the propose method be evaluate through a benchmark process. 
merit tensor transform for memory efficient vision processing on parallel architectures. 
computationally intensive deep neural network dnn be well  suited to run on gpu but newly develop algorithm usually require the heavily optimize dnn routine to work efficiently and this problem could be even more difficult for specialized dnn architecture. 
in this article we propose a mathematical formulation that can be useful for transfer the algorithm optimization knowledge across compute platform. 
we discover that datum movement and storage inside parallel processor architecture can be view as tensor transform across memory hierarchy make it possible to describe many memory optimization technique mathematically. 
such transform which we call memory efficient range inner product tensor merit transform can be apply to not only dnn task but also many traditional machine learning and computer vision computation. 
moreover the tensor transform can be readily map to exist vector processor architecture. 
in this article we demonstrate that many popular application can be convert to a succinct merit notation on gpu speed up gpu kernel up to 20 time while use only half as many code token. 
we also use the principle of the propose transform to design a specialized hardware unit call merit z processor. 
this processor can be apply to a variety of dnn task as well as other computer vision task while provide comparable area and power efficiency to dedicated dnn application specific integrate circuit asic. 
support vector regression to correct motor current of machine tool drive. 
nonlinear friction be the limiting factor in use motor current signal to estimate the load of machine tool. 
the inertia of the axis and the positional dependency of the friction add another degree of complexity. 
the work focus on industrial machining center with ball screw drive stage as they be use in metal cutting. 
the approach use internal low frequency signal from the nc controller to keep the barrier for an industrial application at a minimum. 
the contribution of this study be twofold first it extend conventional analytic friction model so that they incorporate positional dependency of friction as well as the contribution of the inertia of the axis. 
second it propose how to model the both effect jointly through support vector regression. 
this data drive model outperform the extended stribeck and the generalize maxwell slip friction model which serve as a representative benchmark for static and dynamic friction model respectively. 
however this come with the need for a careful selection of the datum on which the support vector machine be train in order to obtain an accurate and general model. 
genetic algorithm apply to integration and optimization of billing and pick process. 
this article intend to provide a computational tool that integrate and provide optimize solution to two interdependent problem call optimized billing sequencing obs and optimized picking sequence ops. 
these problem be address separately by the exist literature and refer respectively to the optimization of billing and pick process in a typical warehouse with low level picker to part system. 
integration literature be therefore limited and there be a demand for more robust obs ops optimization method. 
this approach will deal with practical dilemma that have not be address by researcher yet to propose an extension to the obs model by pinto et al. 
j intell manuf 29(2):405 422 2018 along with a specific variation of the order batch and sequencing problem. 
the premise be to prove to manager the possibility of make more consistent decision about the trade off between the level of customer service and the warehouse efficiency. 
the propose tool be formulate by the integration of two genetic algorithms call ga obs and ga ops where ga obs maximize the order portfolio billing and generate the pick order to the ops whereas ga ops comprise the iteration of batch and route algorithm to minimize pick total time and cost to the ops. 
experiment with problem with different complexity level show that the propose tool produce solution of satisfactory quality to obs ops. 
the approach propose fill a gap in the literature and make innovative contribution to the development of more suitable optimization method to the reality of warehouse. 
a modular factory testbe for the rapid reconfiguration of manufacturing system. 
the recent manufacturing trend toward mass customization and further personalization of product require factory to be smart than ever before in order to one quickly respond to customer requirement two resiliently retool machinery and adjust operational parameter for unforeseen system failure and product quality problem and three retrofit old system with upcoming new technology. 
furthermore product lifecycle be become short due to unbounded and unpredictable customer requirement thereby require reconfigurable and versatile manufacturing system that underpin the basic building block of smart factory. 
this study introduce a modular factory testbe emphasize transformability and modularity under a distribute shop floor control architecture. 
the main technology and method be develop and verify through the testbed be present from the four aspect of rapid factory transformation self layout recognition rapid workstation and robot reprogramming inter layer information sharing and configurable software for shop floor monitoring. 
research on adaptive cnc machine arithmetic and process for near net shape jet engine blade. 
near net shape jet engine blade machining process have well performance on both reduce material waste during production and improve work reliability in service while precision machining of this blade be very challengeable and difficult due to its positioning difficulty and low stiffness. 
this paper propose that reasonable fixture and adaptive cnc machining technology can provide a systematic solution for the machining of near net shape blade tenon root tip and lead edge and trail edge lte. 
firstly process characteristic difficulty and requirement of near net shape blade be analyze. 
secondly adaptive cnc machining process and its key technical principle be introduce and optimize and propose measure bad point cull algorithm of simultaneously use distance relationship angle relationship and radius relationship and propose camber line calculation algorithm of equidistant offset and optimize the iterative close point icp algorithm base on point to line icp algorithm with six control point and realize the reconstruction of processing model. 
finally the feasibility of the propose adaptive cnc machining process and the design polyetheretherketone peek gf30 material and multi point support rigid flexible coupling fixture be verify by a typical near net shape blade lte and tenon root adaptive cnc machining process experiment. 
the result show that the propose process scheme of reasonable fixture and adaptive cnc machining process can solve two problem of near net shape blade manufacturing of position difficulty and low stiffness. 
the design fixture of peek gf30 material and multi point support rigid flexible coupling and the optimize adaptive cnc machining process algorithm can realize high precision manufacturing of near net shape jet engine blade. 
a convolutional approach to quality monitoring for laser manufacturing. 
the extraction of meaningful feature from the monitoring of laser process be the foundation of new non destructive quality inspection method for the manufacture piece which have be and remain a grow interest in industry. 
we present convlbm a novel approach to monitor laser based manufacturing process in real time. 
convlbm use a convolutional neural network model to extract feature and quality indicator from raw medium wavelength infrare coaxial image. 
we demonstrate the ability of convlbm to represent process dynamic and predict quality indicator in two scenario dilution estimation in laser metal deposition and location of defect in laser welding process. 
obtain result represent a breakthrough in the 3d printing of large metal part and in the quality control of welding process. 
we be also release the first large dataset of annotated image of laser manufacturing. 
probabilistic kalman filter for move object tracking. 
kalman filter have be successfully apply to track move object in real time situation. 
however the filter can not take into account the exist prior knowledge to improve its prediction. 
in the move object tracking the trajectory of multiple target in the same environment could be available which can be view as the prior knowledge for the tracking procedure. 
this paper present the probabilistic kalman filter pkf that be able to take into account the store trajectory to improve track estimation. 
the pkf have an extra stage after two step of the kalman filter to refine the estimate position of the target. 
the refinement be obtain by apply the viterbi algorithm to a probabilistic graph that be construct base on the observed trajectory. 
the graph be build in the offline situation and could be adapt in the online tracking. 
the propose tracker have high accuracy compare to the standard kalman filter and could handle widespread problem such as occlusion. 
another significant achievement of the propose tracker be to track an object with anomalous behavior by draw an inference base on the construct probabilistic graph. 
the pkf be apply to several manually build video and several other video basis contain severe occlusion which demonstrate a significant performance in comparison with other state of the art tracker. 
an intelligent object detection and measurement system base on trinocular vision. 
the exist size measurement system can not meet the requirement of non contact measurement task and the main challenge be how to detect various object and improve measurement accuracy. 
in order to solve these problem a novel measurement system be propose in this paper. 
in the system a three camera model with variable baseline be design base on the trinocular vision. 
three binocular vision subsystem be compose of the three camera which be use to obtain the depth information from different shooting angle and the baseline between the camera could be adjust accord to the different object. 
in the measurement process the target object be detect automatically base on the visual saliency feature and spatial information. 
finally the size of the target object be compute by the cooperative analysis of the three binocular vision subsystem. 
the experimental result demonstrate that the propose system be accurate and stable in various object detection and measurement task. 
steady state simulation for combined transmission and distribution systems. 
the future electric grid will consist of significant penetration of renewable and distribute generation that be likely to create a homogenous transmission and distribution t&d system require tool that can model and robustly simulate the combine t&d network. 
exist tool use disparate model and formulation for simulation of transmission versus distribution grid and solve for the steady state solution of the combine t&d network often lack convergence robustness and scalability to large system. 
in this paper we show that model both the t&d grid element in term of current and voltage use an equivalent circuit framework enable simulation of combine positive sequence network of the transmission grid with three phase network of the distribution grid without loss of generality. 
we far demonstrate that we can ensure robust convergence for these result large scale complex t&d system when the circuit simulation method be apply to they. 
our result illustrate robust convergence of combine t&d network use a direct newton raphson solver on a single machine for small sized system and use a parallel gauss seidel newton solver on multiple machine for large sized system with great than million node. 
a fast algorithm for optimal power scheduling of large scale appliances with temporally spatially couple constraint. 
optimally scheduling power consumption of appliance be the essential feature of smart grid which enable demand response management drm and help to shape the power usage profile. 
this problem be often require to be solve in face of a large number of appliance and many time slot thus the computational efficiency of solve a large scale optimal power scheduling problem with limited computational resource become the major concern of algorithm design. 
to this end a novel algorithm be propose base on karush kuhn tucker kkt condition to solve the optimal power scheduling problem with temporally spatially couple constraint in a distribute manner. 
the propose algorithm convert the original problem into equivalently solve an optimal kkt operator in a much low dimension thus the computation speed be greatly enhance. 
in addition the propose method dose not require a step size in the iteration process thus avoid the oscillation of numerical solution cause by problem parameter change. 
compare with the widely use conventional algorithm interior point method and dual decomposition the high computational speed and less sensitivity to the problem parameter setting be observe in numerical simulation. 
modeling and stability analysis of inverter base microgrid under harmonic condition. 
microgrid mgs operate under harmonic condition due to the integration of nonlinear load. 
the autonomous harmonic compensation control of inverter interface dg have be propose to successfully mitigate the harmonic. 
however the small signal analysis of harmonic compensation control have not be investigate in the microgrid with multiple inverter. 
this paper develop the modeling and analysis of the inverter base mg under harmonic condition. 
the concept of dynamic phasor dp be use to describe the fundamental and harmonic component of an ac waveform via dc variable. 
the developed model consist of droop control distribute generator dgs diode rectifier work as nonlinear load and resistance load. 
virtual impedance control be consider in the droop control dg for the autonomous harmonic compensation. 
base on the develop dp model the dynamic behavior of the microgrid be investigate via small signal analysis. 
it be observe that the virtual impedance for harmonic compensation bring inter inverter oscillation on harmonic domain. 
participation and eigenlocus analysis be perform to investigate the influence of parameter tuning of harmonic compensation on microgrid stability. 
numerical simulation be carry out to validate the effectiveness of the propose modeling method and the analysis result. 
correlation clustering imputation for diagnosing attacks and fault with missing power grid data. 
while the quality of the synchronize measurement be of paramount importance for real time monitoring and protection of the power grid collect measurement often contain missing value. 
this paper propose a scheme for diagnose attack and fault in the presence of miss measurement in power grid datum. 
the propose scheme contain four module for clustering miss datum imputation decision making and optimization. 
this paper develop a novel technique for miss datum imputation base on the correlation connect cluster that consider local correlation among the measurement in estimate miss datum handle high dimensional datum and tolerate high miss ratio. 
the optimization module tie the imputation process to diagnostic performance. 
the propose novel imputation technique be compare with other state of the art technique within the diagnostic scheme. 
the achieve result show that the propose technique significantly outperform other competitor. 
automate the verification of the low voltage network cables and topology. 
low voltage lv network be increasingly require to cope with challenge they be not design for require for more active network management anm. 
crucially anm solution require the availability of accurate network information. 
in practice available datum on lv network can be incomplete a problem often overlook in prior anm research. 
for example in the u.k. 
and many developed country the lifetime of distribution network asset span several decade with some of the available asset datum gather and maintain over many year. 
this can often lead to incomplete cable datum be available to network operator. 
to overcome this we propose a novel machine learning technique to autonomously approximate the miss cable information in lv network. 
our propose algorithm use a tree base search methodology which approximate the miss cable s cross section area xsa datum base on rule engineer use when design the lv network. 
we validate our approach use a large database of real lv network where some of the cable xsa be treat as unknown and use as ground truth to evaluate the accuracy of the prediction. 
moreover we propose a mechanism that score the confidence level of the prediction information which be then present to the human network planner. 
designing reactive power control rules for smart inverters use support vector machines. 
smart inverter have be advocate as a fast respond mechanism for voltage regulation in distribution grid. 
nevertheless optimal inverter coordination can be computationally demand and preset local control rule be know to be subpar. 
leverage tool from machine learning the design of customize inverter control rule be pose here as a multi task learning problem. 
each inverter control rule be model as a possibly nonlinear function of local and/or remote control input. 
give the electric coupling the function output interact to yield the feeder voltage profile. 
use an approximate grid model inverter rule be design jointly to minimize a voltage deviation objective base on anticipated load and solar generation scenario. 
each control rule be describe by a set of coefficient one for each training scenario. 
to reduce the communication overhead between the grid operator and the inverter we devise a voltage regulation objective that be show to promote parsimonious description for inverter control rule. 
numerical test use real world datum on a benchmark feeder demonstrate the advantage of the novel nonlinear rule and explore the trade off between voltage regulation and sparsity in rule description. 
design of elastic metasurface for control shear vertical wave use uniaxial scaling transformation method. 
control wave propagation be a popular research field however progress with regard to the study of elastic wave be slow because of the coupling of different type of wave. 
in this paper we report a novel approach to design elastic metasurface for control elastic shear vertical sv wave in solid. 
the metasurface be compose of separate parallel thin plate connect at both end to half space solid. 
the elastic sv wave in solid be control by manipulate the induce flexural wave in the thin plate of the metasurface. 
base on the form invariance of the govern equation for flexural wave in a thin plate under linear coordinate transformation the uniaxial scaling transformation method ustm have be put forward to alter the material to constitute the thin plate of the metasurface. 
the transformed material be transversely isotropic which greatly reduce implementation difficulty. 
to tune the travel time of the flexural wave in the thin plate different value of the scaling parameter a and plate thickness h be assign for different thin plate base on the kirchhoff plate theory. 
by combine the plate thickness variation approach with the ustm the plate length of the metasurface could be effectively control to be small than the wavelength at the work frequency. 
to demonstrate the performance of the propose approach two design of elastic metasurface for wave focus and abnormal refraction be describe in detail and full numerical simulation be conduct. 
the present approach open a promising avenue toward the realization of metasurface for control elastic wave. 
real time feedback control for knee prosthesis use motion fusion algorithm in six dof imu. 
stump angle measurement sam system be develop and test for its use in the development of a low cost electronic knee prosthesis use an accelerometer to measure tilt angle of the residual stump during various phase of gait. 
this system provide real time feedback to control the actuator position for cover a wide range of mobility for the above knee amputee. 
however this system be prone to high frequency noise result from gait event. 
these noise spike trigger false threshold value result in incorrect operation of the actuator. 
in the propose design a six degree of freedom six dof sensor replace the accelerometer from previous design. 
the modified algorithm use complimentary filter to process the datum from inertial measurement unit imu. 
this new system produce sensitive yet smooth output remove the drawback of the early system. 
this paper report the comparative analysis of the sam system use six dof and accelerometer. 
these result use six dof sensor will assist in the further development of an intelligent feedback system for low cost active prosthetic leg. 
effect of machining parameters on surface finish and noise patterns for machining en 19 steel with pvd tin coated mixed ceramic inserts in cnc turning operation. 
this paper present a relationship between the surface finish machining condition and the noise level generate by the turning operation for machining of en 19 alloy steel use pvd tin coat mixed ceramic al2o3+ticn insert on a cnc turning centre under wet lubrication condition. 
the machining parameter consider in this study include cut velocity feed rate and depth of cut. 
the level of machine parameter for the experimental investigation be determine use full factorial experiment model and anova be apply to find the effect of machine parameter on surface roughness. 
additionally noise generate during the cutting operation for all set of experiment trial be record to determine the relationship between machining condition and the surface finish. 
a security requirement model language for cloud computing environment. 
this paper present a novel security modelling language and a set of original analysis technique for capture and analyse security requirement for cloud computing environment. 
the novelty of the language lie in the integration of concept from cloud computing with concept from security and goal orient requirement engineer to elicit model and analyse security requirement for cloud infrastructure. 
we then propose three analysis technique which support an automate process where give a model of a cloud computing system develop with the propose language will enhance the model with new security knowledge for example threat and vulnerability mitigation strategy and asset and actor responsibility. 
this be to the good of our knowledge the first attempt in the literature to develop a language for cloud compute security modelling and analysis base on such integration and support it with a set of automate technique that enhance the stakeholder create model with security knowledge. 
the propose modelling language and technique be illustrate through walk example and a case study base on our work in the vision european project. 
ultra wideband complementary metal oxide semiconductor low noise amplifier use cs cg noise cancellation and dual resonance network technique. 
in this paper a low power ultra wideband uwb low noise amplifier lna with high and flat voltage gain be propose use cs cg noise cancellation and dual resonance network technique base on tsmc 180 nm technology. 
the cs cg noise cancellation technique reduce the noise figure in three 10.6 ghz frequency band and the dual resonance network technique be apply to reach an acceptable input matching. 
in order to reduce the number of inductor the active inductor be use in the noise cancellation stage. 
also to control voltage gain and input return loss a resistor be connect in parallel to channel length modulation resistance of the transistor in the first stage. 
the developed lna circuit provide a high and flat voltage gain of 12.75 db with 0.65 db variation which be the result of use two stage common source topology. 
an average noise figure of two db with its maximum value of 2.3 db an iip3 of  eight dbm be obtain from three to 10.6 ghz respectively. 
the obtain input and output matching value be well than  10 db. 
the layout of propose lna occupy an area of 0.55 mm2 include ring pad and this structure consume 11.56 mw from one v dc supply. 
study of the applicability of 22mnb5 sheet metal as protective mask to improve tool life in hot forging process. 
low boron steel be the only class of steel capable of form a fully martensitic microstructure after hot stamping when a cooled tool be use and the maximum stress can reach 1500 mpa. 
the purpose of this work be to study the applicability of 22mnb5 sheet metal as protective mask in hot forging die. 
sheet that be 1.3 mm thick be cut in sample of 110 mm diameter and heat treat in condition similar to direct hot stamping and place on the hot forging die. 
cycle of 25 50 75 and 100 forging be perform and at each cycle the metallic mask be replace for characterization. 
microhardness profile micrographic analysis by optical and electron microscopy and profilometry profile be use to determine the occurrence of surface wear on the mask after each forge cycle. 
the main type of superficial wear be abrasive and plastic deformation. 
however the mask show high resistance to wear and do not present failure that would make they unusable until the studied condition of a cycle of 100 forging. 
a data drive model for weld bead monitor during the laser weld assist by magnetic field. 
in this research a data drive model be develop to monitor the seam during the laser beam weld under the influence of an external magnetic field lbw amf. 
firstly a visible lbw amf system be build for track the laser melt pool and keyhole. 
then the feature of the laser melt pool and keyhole be extract with image processing technique. 
the approach for an ensemble of different neural network which include radial basis function neural network back propagation neural network and generalize regression neural network be propose to establish the correlation of the characteristic of the laser melt pool and keyhole and the welding seam. 
finally lbw amf experimental result be obtain to validate the performance of the propose data drive model. 
result illustrate that the developed model can provide a reliable result for monitor the weld bead which could give guidance for control the processing parameter in real time to improve the weld quality for practical lbw amf. 
new droplet removal polishing method for diamond like carbon with carbon fiber brush. 
in this paper we propose a new polishing method for diamond like carbon dlc coating use a carbon fiber brush cfb. 
surface finishing be an important process for dlc coating application. 
a lapping process be widely use for attain tetrahedral amorphous carbon ta c coating which be a type of dlc coating contain many droplet to obtain fine flat surface. 
the lapping process remove protuberant part of droplet rather than the entire droplet. 
in this paper we propose a new polish brush material make of carbon fiber call cfb. 
carbon fiber have both mechanical strength due to its hard carbonaceous material and flexibility due to its fiber structure. 
in polish test cfb remove droplet from ta c coating and the removal effect increase with the shortening of the brush length. 
the surface profile of the polished surface indicate that a short brush length yield deep scratch mark on ta c surface. 
consequently the arithmetic average surface roughness of the polished ta c surface s a have almost the same value as that of a non polished surface. 
here we show the ability of cfb to remove the droplet without an increase in the surface roughness. 
the cfb with the long brush length in the present study 12 mm show a ten point average roughness s zjis 75 nm and s a 4.7 nm which be 59 and 22 low than those of the non polished surface respectively. 
furthermore the long cfb remove the entire droplet whereas a short cfb merely remove the protuberant part of the droplet. 
the result indicate that cfb polishing can remove entire droplet which result in abrasive wear or deterioration. 
from other polishing test the optimum polishing distance be determine. 
short polish distance could not remove droplet sufficiently whereas long polish distance cause deep scratch on ta c surface due to the material transfer to the cfb. 
accordingly the polishing distance of 600 m show the good surface finish with s zjin 25 nm and r a 0.43 nm which be 86 low than and similar to those of the non polished ta c surface respectively. 
fabrication of optimally micro textured copper substrates by plasma printing for plastic mold packaging. 
micro emboss use plasma print micro punch be propose to form micro groove texture into the copper substrate for plastic packaging of hollowed gan hemt chip. 
in particular the micro groove network on the copper substrate be optimize to attain uniform stress distribution with maximum stress level be as low as possible. 
three dimensional finite element analysis be employ to investigate the optimum micro grooving texture topology and to attain the uniform stress distribution on the joined interface between the plastic mold and the textured copper substrate. 
thereafter plasma printing be utilize to fabricate the micro punch for micro embossing of the micro grooving network into the copper substrate as a design optimum micro texture. 
this plasma printing mainly consist of three step. 
two dimensional micro pattern be screen print onto the aisi316 die surface as a negative pattern of the optimum cad datum. 
the screen print die be plasma nitride at 673 k for 14.4 k at 70 pa under the hydrogen nitrogen mixture for selective nitrogen supersaturation onto the unprinted die surface. 
a micro punch be develop by mechanically remove the print part of die material. 
then fine computer numerical control cnc stamping be use to yield the micro embossed copper substrate specimen. 
twelve micro textured substrate be mold into package specimen by plastic molding. 
finally gross leak testing be employ to evaluate the integrity of the joined interface. 
the takt time require to yield the micro grooved copper substrate by the present method be compare to the picosecond laser micro grooving the former show high productivity base on this parameter. 
development of surface roughness generation model for cfrtp manufactured by lft d. 
in this study we propose a new surface generation model for carbon fiber reinforce thermoplastic cfrtp manufacture by the long fiber thermoplastic direct lft d method. 
cfrtp be consider to be a next generation structural material because of their high productivity as well as high mechanical strength and lightness. 
conversely cfrtp have a rough surface which do not meet the automotive outer panel standard of a class a surface. 
in the present study we establish a surface roughness generation model base on a thermal shrinkage mismatch of thermoplastic resin to carbon fiber and non uniform carbon fiber distribution. 
furthermore we construct a surface roughness estimation formula base on the model. 
in the calculation a cross sectional image of cfrtp be divide into many vertical segment. 
subsequently the thermal shrinkage of each segment be calculate with a standard deviation an average and a probability density of the amount of carbon fiber in each segment. 
the surface roughness of the manufacture cfrtp be measure use a surface profilometer. 
the result show that the arithmetic surface roughness increase with the volume fraction of carbon fiber. 
we apply the surface roughness calculation to cross sectional image of the specimen. 
consequently the estimate surface roughness show the same tendency in which the surface roughness increase with the volume fraction of carbon fiber. 
the slope of a regression line of the estimate surface roughness with respect to the volume fraction be 0.010 which be almost the same 0.011 as the slope of a regression line of the measure surface roughness. 
furthermore the estimation formula use a thermal shrinkage effective depth of 395 mu m be able to estimate the surface roughness within a three average error. 
use the estimation formula it be predict that the surface roughness increase with the standard deviation of the amount of carbon fiber in a segment. 
to confirm the reliability of the model and the formula we measure the standard deviation of the amount of carbon fiber in cfrtp specimen show that the trend for cfrtp specimen match the estimate value. 
predict surface roughness of dry cut grey cast iron base on cut parameter and vibration signals from different sensor positions in cnc turning. 
during the turning process cast iron be directly shatter to become particle. 
this mechanism mean the surface roughness can not be predict use the kinematic equation. 
this paper provide surface roughness prediction use two method the multiple regression model mrm and artificial neural network ann. 
cut parameter and vibration signal be consider input variable in both method. 
this work also overcome the common sensor position limitation tool shank and provide a safe and efficient solution. 
the prediction value from mrm and ann show accurate result compare to the measure surface roughness with the average error of less than eight. 
furthermore the propose sensor position at the turret bed also exhibit similar prediction accuracy to a sensor at the tool shank hence promise feasible industrial application. 
ultrasonic assist face milling for fabricate hierarchical microstructure. 
surface microstructure can provide various functionality and wettability be a typical surface property that can be control by the surface texture. 
this study attempt to fabricate hierarchical microstructure through ultrasonic assist face mill uafm to change the surface functionality by specifically focus on the wettability. 
the fabrication involve the use of an ultrasonic generating spindle and a self design diamond tool. 
the locus of the tip of the diamond tool be compute base on the equation of motion and the micro  and macrostructure be illustrate in this paper. 
the structure be confirm through observation use a white light interferometer. 
the wettability on six zone of the process area be measure and the result indicate that the central zone of the uafm surface become hydrophobic whereas the edge zone become hydrophilic. 
surface formation behaviors in wavy microgroove cutting on various workpiece materials. 
functional film with multi directional wavy microgroove can be apply to reduce fluid drag in turbulent flow application. 
for high efficiency mass production of functional film through polymer imprinting it be necessary to machine wavy microgroove on the surface of metal roll mold. 
when wavy groove be cut to reduce the follow up error of machine tool a very low cutting speed be normally use but the mechanism of this cutting be still unclear. 
in this study microgroove experiment be conduct on three different workpiece material brass oxygen free copper and aluminum alloy and their cut mechanism be investigate. 
distinct difference in chip formation behavior and machine surface integrity be identify among these material. 
aluminum alloy be choose as the most suitable material for roll mold fabrication. 
two directional wavy microgroove with form accuracy on one mu m level and surface roughness of less than 10 nm ra be obtain. 
effect of tool rake angle and crystal orientation on ductile mode cutting of hard brittle materials. 
the effect of negative rake angle on the ductile mode cutting of soda glass and sapphire be study. 
in addition the machining mechanism be study use a groove cut model base on the orthogonal cutting theory. 
it be find that the specific cut force in ductile mode cutting increase on both the soda glass speciman and on the sapphire speciman when the rake angle of the tool become negative. 
the difference between the experimental datum and theoretical datum of the specific cutting force become large when the tool have a high rake angle on the negative side. 
this be attribute to effect of the roundness of the edge the effect of the roundness of the nose and the plowing mechanism which cause plastic flow of the work material to both side of the groove. 
the specific cutting force of sapphire depend on the cut direction against the crystal orientation. 
the specific cutting force of sapphire depend on the cut direction in term of the crystal orientation. 
the anisotropy of the cut force of sapphire also depend on the rake angle of the tool. 
special issue on advanced material driven design of machine tools. 
evaluation of dynamic characteristics of a hybrid guideway system. 
this paper present the dynamic characteristic of a hybrid guideway system that employ slide guide as the primary support and roll guide to decrease the friction force and improve servo response. 
a drive table with a linear motor be fabricate and the dynamic response of the propose hybrid guideway to command input and disturbance be measure. 
the result indicate that the develop guideway system provide high dynamic stiffness without sacrifice the accuracy of servo response. 
furthermore the float action of the table influence the dynamic compliance of the guide in the horizontal direction. 
drive performance of natural fiber gears make only from bamboo fibers extract with a machining center. 
plastic gear be light and can be use without any lubricant but they have low strength and an adverse effect on the environment. 
therefore a new gear that maintain these advantage while mitigate the disadvantage have be propose. 
the development of sustainable and reproducible natural material be desire to address these environmental problem. 
therefore in this study a method be devise to extract high quality and precise bamboo fiber use a machining center. 
then the hot press method be use to produce a novel spur gear make from only bamboo fiber which be a green and organic machine element with a complicated shape. 
the present paper describe the characteristic of the propose bamboo fiber gear consider experimental result include the hot press molding condition and the influence of fiber length on tooth bend strength root strain and vibration due to meshing tooth. 
late machine tool structural design technology for ultra precision machining. 
most machine tool comprise a combination of square block and plate for each body structure which be not fully optimize. 
one reason for the nonoptimal design be that machine tool designer face difficulty in introduce curve structure to fulfill functional requirement. 
in this paper completely new structure of the surface profile grind machine have be develop pursue the ideal structure by defy fundamental design rule as well as by utilize topology and shape optimization method. 
the combination of fundamental technique and state of art technique enable lightweight structure that can achieve two time high resonance frequency 40 50 space saving and 60 100 productivity improvement compare to those with the conventional design. 
utilization of cfrp in high speed stamping press and its gigacycle fatigue testing at resonance frequency. 
carbon fiber reinforce polymer cfrp utilization meet the requirement of stiffness damp and light weight for enhance performance of machine tool. 
stamp press be expect to function for billion of cycle result in the fatigue of the employ material and part. 
high speed stamping press such as the bruderer bsta 200 should fulfil the increase customer requirement of enhance both quality and quantity of the deliver part. 
among the quick press currently available in the market these bsta press can reach speed up to 2000 stroke per minute spm with a stroke of eight mm and still continue operate for many decade. 
for this project new requirement be define a 25 increase of the stamp speed reach up to 2500 spm while maintain the same stroke of eight mm. 
the ram be redesign by make use of cfrp and because of its high stiffness and strength it enable a weight reduction of 65. 
owe to the stamp force of 200 kn and the impact of the stamping process the material of the ram be highly strained. 
a major concern in utilize cfrp in machine tool be the fatigue and change in material property with increase stress cycle. 
therefore the fatigue behavior of cfrp have to be validate in the very high cycle fatigue vhcf range. 
this be perform use a newly develop fatigue test bench. 
to complete 10(9 cycle within a few week the testing occur at the speciman s resonance frequency with a constant and control strain of 0.1. 
aspect such as resonance frequency testing heating of the speciman and an accurate measuring system be consider. 
the specimen have to be design and optimize for this type of testing thus result in a cylindrical tube shape with a unidimensional ud arrangement of the fiber in longitudinal and transverse direction. 
a novel retractable stiffener base disk shape active compliant polish tool. 
a novel active variable compliance polish tool be propose to improve the control over the area of contact and pressure distribution during polish. 
this active compliance be achieve by employ a retractable stiffener base design. 
this novel tool can provide a continuous range of compliance as per the polishing requirement. 
the design fabrication and testing of this newly develop tool be report. 
static pressure distribution test and material removal study be conduct for three different compliance value by change the stiffener position. 
appreciable change in static contact pressure and material removal depth be observe as the stiffener position be change. 
far numerical pressure distribution and load displacement response simulate use a finite element model show good agreement with the experimental measurement. 
this study pave the way for well control of polish condition in an automate environment. 
distribute and parallel processing for real time and dynamic spatio temporal graph. 
as a non linear datum structure consist of node and edge the graph datum span many different domain. 
in the real world application base on such data structure be always time sensitive that is the value of graph datum tend to decrease with time. 
furthermore the application base on spatio temporal graph be one of the typical representative of time sensitive since the time dimension be an inherent feature of spatio temporal datum. 
the distributed stream processing engine dspe seem an excellent choice for the above requirement which be commonly partition and concurrently process by a number of thread to maximize the throughput. 
however it be not feasible to do such mission directly use the traditional dspe. 
in this paper we propose a computational model suitable for handle the spatio temporal graph in dspe by reconstruct the dspe s parallel processing slot. 
specifically our proposal include a general processing framework to deal with the datum structure of the spatio temporal graph a state information compensation mechanism to ensure the correctness of process such stateful operation in dspe a lightweight summary information calculation method to ensure the performance of the system. 
empirical study on real world stream application validate the usefulness of our proposal and prove the considerable advantage of our approach over state of the art solution in the literature. 
from crowdsource to crowdmine use implicit human intelligence for well understanding of crowdsourced datum. 
with the development of mobile social network more and more crowdsourced datum be generate on the web or collect from real world sense. 
the fragment heterogeneous and noisy nature of online offline crowdsourced datum however make it difficult to be understand. 
traditional content base analyzing method suffer from potential issue such as computational intensiveness and poor performance. 
to address they this paper present crowdmine. 
in particular we observe that the knowledge hide in the process of datum generation regard individual crowd behavior pattern e.g. mobility pattern community contexts such as social tie and structure and crowd object interaction pattern flicker or tweet pattern be neglect in crowdsourced datum mining. 
therefore a novel approach that leverage implicit human intelligence implicit hi for crowdsourced datum mining and understanding be propose. 
two study title crowdevent and crowdroute be present to showcase its usage where implicit his be extract either from online or offline crowdsourced datum. 
a generic model for crowdmining be far propose base on a set of exist study. 
experiment base on real world dataset demonstrate the effectiveness of crowdmining. 
a lightweight and cost effective edge intelligence architecture base on containerization technology. 
the integration of cloud computing and internet of thing lead to rapid growth in the edge computing field. 
this would not be achievable without combine the datum center manage system with much more restrain technology. 
one significantly effective and lightweight solution to this issue be present by the docker technology. 
it be able to manage virtualization process and can therefore be use to distribute deploy and manage cloud and edge application assign into the cluster. 
in our study this technology be represent by the raspberry pi device which be convenient thank to their low cost robust applicability and lightweight nature. 
our application scenario focus on identification of the human activity. 
in this paper we suggest and evaluate an architecture on the basis of the distribute edge cloud integration paradigm. 
we explain all of its advantage which lie in the combination of affordability and several other benefit provide by the fact that datum processing be conduct by the edge device instead of the central server. 
to recognize and identify human activity the regularized extreme leaning machine relm be engage in our architecture. 
our study present detailed information about our use case scenario and the experimental simulation we perform. 
a projection base controller for fast spacecraft detumble use magnetic actuation. 
magnetic control have be use for decade for spacecraft detumbling to bring a spacecraft to a final condition with a sufficiently small angular momentum after separation from the launcher. 
this task be typically achieve by controller base on the so call b dot principle which stand out thank to its simplicity reliability and ease of on board implementation. 
in this paper we first review exist control method and study their convergence property with tool borrow from general averaging theory which allow address in an accurate manner the time vary nature of magnetic actuation. 
then some effort be devote to show the performance limitation of exist controller for which increase the gain too much deteriorate the convergence rate. 
to overcome this issue a novel projection base control law with a state dependent time vary gain be present. 
by mean of lyapunov argument for non autonomous system we prove that the propose controller guarantee that the spacecraft angular momentum converge exponentially fast to zero for all initial condition robustly with respect to sufficiently small uncertainty in the inertia matrix and that the closed loop solution be globally uniformly ultimately bound in the presence of exogenous bound disturbance. 
several numerical simulation have be carry out by refer to realistic detumble scenario to show the performance improvement with respect to exist controller. 
c 2019 elsevier ltd. 
all right reserve. 
boundary state feedback exponential stabilization for a one dimensional wave equation with velocity recirculation. 
in this paper we consider boundary state feedback stabilization of a one dimensional wave equation with in domain feedback recirculation of an intermediate point velocity. 
we firstly construct an auxiliary control system which have a nonlocal term of the displacement at the same intermediate point. 
then by choose a well know exponentially stable wave equation as its target system we find one backstepping transformation from which a state feedback law for this auxiliary system be propose. 
finally take the result closed loop of the auxiliary system as a new target system we obtain another backstepping transformation from which a boundary state feedback controller for the original system be design. 
by the equivalence of three system the closed loop of original system be prove to be well pose and exponentially stable. 
some numerical simulation be present to validate the theoretical result. 
c 2019 elsevier ltd. 
all right reserve. 
vertical hierarchical mpc for constrain linear system. 
a hierarchical model predictive control mpc formulation be present for discrete time linear system with state and input constraint. 
a vertical hierarchical controller with one controller per level reduce the computational burden associate with the solution of centralized mpc have long prediction horizon and short time step. 
to guarantee satisfaction of state and input constraint in the presence of both know and unknown disturbance a robust mpc formulation be use at each level while wayset be use as a novel coordination mechanism between controller at different level. 
these wayset be implement as terminal state constraint on low level controller and be compute on line base on the optimal state trajectory of upper level controller. 
to achieve the computational efficiency necessary for on line calculation wayset be represent as constrain zonotope. 
state and input constraint satisfaction be prove for a hierarchical controller with an arbitrary number of level and two numerical example demonstrate the key feature performance and scalability of the approach. 
c 2020 elsevier ltd. 
all right reserve. 
stability analysis of linear system with time vary delay via intermediate polynomial base function. 
this note be devote to stability analysis for linear system with time vary delay. 
by advisably introduce slack matrix novel fractional order intermediate polynomial base function ipf be propose. 
then the stability condition be derive for the time delay system. 
from configuration on fractional order polynomial the relationship among system state be take into account and consolidate via slack variable and the characteristic for integral inequality be synthetically consider while avoid high order time delay. 
more remarkably adjust tunable parameter also contribute to reduction of conservatism. 
the comparison of computational complexity and stability region on a well know numerical example be provide to validate the advantage of the result stability criterion. 
c 2019 elsevier ltd. 
all right reserve. 
fbstab a proximally stabilize semismooth algorithm for convex quadratic programming. 
this paper introduce the proximally stabilize fischer burmeister method fbstab a new algorithm for convex quadratic programming that synergistically combine the proximal point algorithm with a primal dual semismooth newton type method. 
fbstab be numerically robust easy to warmstart handle degenerate primal dual solution detect infeasibility unboundedness and require only that the hessian matrix be positive semidefinite. 
we outline the algorithm provide convergence and convergence rate proof and report some numerical result from model predictive control benchmark and from the maros meszaros test set. 
we show that fbstab be competitive with state of the art method and be especially promise for model predictive control and other parameterized problem. 
c 2020 elsevier ltd. 
all right reserve. 
high dimensional kuramoto model on stiefel manifold synchronize complex network almost globally. 
the kuramoto model of couple phase oscillator be often use to describe synchronization phenomenon in nature. 
some application quantum synchronization and rigid body attitude synchronization involve high dimensional kuramoto model where each oscillator live on the n sphere or so(n. 
these manifold be special case of the compact real stiefel manifold st(p n. 
use tool from optimization and control theory we prove that the generalized kuramoto model on st(p n converge to a synchronize state for any connected graph and from almost all initial condition provide p n satisfie p 2/3 n one and all oscillator frequency be equal. 
this result could not have be predict base on knowledge of the kuramoto model in complex network over the circle. 
in that case almost global synchronization be graph dependent it apply if the network be acyclic or sufficiently dense. 
this paper hence identify a property that distinguish many high dimensional generalization of the kuramoto model from the original model. 
c 2019 elsevier ltd. 
all right reserve. 
clot norm minimization for continuous hand off control. 
in this paper we propose optimal control that be both sparse and continuous unlike previously propose alternative to maximum hand off control. 
the maximum hand off control be the l zero optimal or sparse control among all feasible control that be bound by a specify value and transfer the state from a give initial state to the origin within a fix time duration. 
the propose control be obtain via minimization of the clot combined l one and two norm of the control input along with the constraint on the state variable. 
the constraint on the state variable ensure that the state be not blow up while achieve the optimal control. 
by use the non smooth maximum principle we prove that the clot norm optimal control be unique and it be continuous in the time variable. 
we show by numerical simulation that the clot control be continuous unlike l zero optimal control or maximum hand off control and much sparser i.e. 
have long time duration on which the control equal zero than the conventional en elastic net control which be a convex combination of l one and squared l two norm. 
c 2019 elsevier ltd. 
all right reserve. 
analytical convergence region of accelerate gradient descent in nonconvex optimization under regularity condition. 
there be a grow interest in use robust control theory to analyze and design optimization and machine learning algorithm. 
this paper study a class of nonconvex optimization problem whose cost function satisfy the so call regularity condition rc. 
empirical study show that accelerate gradient descent agd algorithm e.g. 
nesterov s acceleration and heavy ball with proper initialization often work well in practice. 
however the convergence of such agd algorithm be largely unknown in the literature. 
the main contribution of this paper be the analytical characterization of the convergence region of agd under rc via robust control tool. 
since such optimization problem arise frequently in many application such as phase retrieval training of neural network and matrix sensing our result show promise of robust control theory in these area. 
c 2019 elsevier ltd. 
all right reserve. 
a relaxed quadratic function negative determination lemma and its application to time delay system. 
the quadratic function with respect to the time vary delay have often be introduce for the analysis of system with time vary delay. 
to determine the negative definiteness of such function this paper develop a parameter adjustable base lemma which contain the lemma popularly use in literature as a special case and have potential to reduce the conservatism without require extra decision variable. 
a stability criterion for a linear time delay system be establish by use the propose lemma whose advantage be demonstrate via a numerical example and the criterion be finally apply to analyze the stability of load frequency control scheme for a single area power system. 
c 2019 elsevier ltd. 
all right reserve. 
fix time attitude track control for rigid spacecraft. 
the problem of fix time attitude track control for rigid spacecraft be address in this paper. 
base on the backstepping technique and the idea of add a power integrator a novel fix time attitude control law be propose. 
the control scheme derive here be continuous and nonsingular and can guarantee the attitude track error converge to the origin within fix time if there be no uncertainty and measurement noise and to a small bound region around zero if there be uncertainty and measurement noise. 
finally numerical simulation be present to demonstrate the effectiveness of the propose scheme. 
c 2020 elsevier ltd. 
all right reserve. 
estimation use l one adaptive descriptor observer for multivariable system with nonlinear uncertainty and measurement noise. 
in this paper an l one adaptive descriptor observer be design for multivariable system with nonlinear uncertainty and measurement noise. 
if the system be detectable noise be bound and some rank condition be satisfied an l one adaptive descriptor observer be construct to asymptotically estimate state nonlinear uncertainty and measurement noise at the same time. 
the original system be augment with all the system state and measurement noise two design parameter provide additional degree of freedom. 
the freedom of select these parameter allow we to choose the derivative gain to reduce the noise amplification the proportional gain to ensure the stability of the estimate error dynamic. 
an adaptive law will update the adaptive parameter which represent the uncertainty estimate such that the estimation error between the predict state and the real state be drive to zero at every integration time step. 
of course neglection of the unknown for solve the error dynamic equation will introduce an estimation error in the adaptive parameter. 
the magnitude of this error can be lessen by choose the time step as small as possible meanwhile the picking up of time step should satisfy the hardware requirement. 
the two design parameter and adaptive law guarantee the performance bound for the estimation error both state and nonlinear uncertainty. 
numerical example be give to illustrate the design procedure and the simulation result demonstrate the satisfactory tracking performance. 
publish by elsevier ltd on behalf of european control association. 
robust output regulation for state feedback descriptor system with nonovershoote behavior. 
in this paper the design of robust non overshooting no controller for output regulation be present for a continuous linear time invariant lti multi input multi output mimo state feedback base descriptor system. 
in this method of controller design for descriptor system the integral slide mode ism technique along with generalise moore s eigen structure assignment method and output regulation theory for descriptor system be invoke to ensure robust output regulation with no behavior. 
the efficiency of the propose controller be also demonstrate with the help of a numerical example and simulation result present at the end. 
c 2019 european control association. 
publish by elsevier ltd. 
all right reserve. 
one step ahead robust mpc for lpv model with bound disturbance. 
the on line model predictive control mpc approach usually assume that with the system information be collect at each sample instant the control action can be calculate instantaneously. 
however the practicality of this approach be limit by its ability to solve the optimization problem in real time. 
in this paper an improved on line approach be propose where the controller parameter optimize from the previous sampling interval be utilize to calculate the current control action the control action be implement in a one step ahead fashion. 
this one step ahead approach solve the optimization problem during the sampling interval which mean that the controller and the real system be run in a concurrent manner. 
we first introduce the one step ahead approach to state measurable case. 
then we extend this approach to state unmeasurable case where the system output be utilize to estimate the system state. 
furthermore the recursive feasibility and stability be guarantee for both case. 
a numerical example be give to show the effectiveness of the propose approach. 
c 2019 european control association. 
publish by elsevier ltd. 
all right reserve. 
robust control of temperature during local hyperthermia of cancerous tumor. 
local hyperthermia be one of the most common method to treat cancerous tumor near the skin surface or natural body orifice. 
in order to study the problem of temperature control during local hyperthermia firstly the heat conduction process during this therapy be analytically model by a time delay fractional order transfer function parametrize with respect to the body temperature. 
since the body temperature may vary under the influence of patient physiological reaction and heat source a robustness criterion be propose to achieve the phase margin invariance despite of the temperature variation. 
afterwards an analytical method be propose to tune stabilize fo pi pd controller for desirably adjust the value of phase margin and gain crossover frequency where the suggest robustness feature be satisfied in temperature control during the treatment. 
finally to validate the effectiveness of the paper achievement by use practical parameter numerical simulation result be present. 
c 2019 european control association. 
publish by elsevier ltd. 
all right reserve. 
scanning micro electrochemical machining process for v shape groove. 
microstructure determine flow property of microfluidic chip. 
micromold form be an effective method to realize mass manufacturing of microfluidic chip. 
this require to machine some kind of special microstructure of high surface quality on a metal alloy workpiece. 
micro v shape groove be the typical microstructure of the chip micromold use for control microfluid or weld packaging. 
in this research a scan micro electrochemical machining ecm process of v shape groove be propose use a tool electrode fabricate by micro electrical discharge machining edm on machine. 
theoretical and experimental research be conduct for achieve the v shape groove with a give angle on die steel. 
a long distance v shape groove with the give angle of 67 deg and the depth of 125 mu m be successfully machine. 
an ensemble model for statistical monitoring of pattern in bivariate process base on multiple artificial neuronal network. 
multivariate control graphic detect signal out of control of the process. 
these signal be special pattern of joint variation but they do not allow to determine what type of variation pattern take place in the individual variable. 
the refer problem have be treat through model of pattern recognition pr by artificial neural networks ann. 
there be important advance in solve the problem to univariate case but not so in multivariate case. 
there be no research which affirm that a single ann can identify a multivariate out of control signal and recognize the special variation type of the variable individually. 
this research present a model of pr of special variation in bivariate process and be base on an organized assembly of different type of ann which be activate sequentially. 
with this work it be possible to obtain a diagnosis of the bivariate process control that simultaneously recognize the type of variation of the variable involve. 
this novel model provide the basis of new knowledge about statistical control of bivariate process by pr through ann. 
the model have two stage of training experimental and industrial. 
the first one work with datum generate by montecarlo simulation and the second one with datum from a process that perform manufacture operation on metal bar use in the speed system in automobile. 
displacement measurement of a concrete bridge under traffic load with fibre reinforce polymer package optical fibre sensor. 
current displacement measurement method can not cope with the demand of the long term measurement of small  or medium span concrete bridge because of some technology or economic challenge. 
in this article a displacement measurement method be propose for concrete bridge base on fibre reinforce polymer package optical fibre sensor. 
the sense principle and manufacture process of the propose sensor be introduce as well as the strain sense property. 
then a relationship be establish between the strain and the displacement base on the distribute strain monitor. 
finally some field test be implement use a simply support concrete bridge. 
the test include static loading test dynamic loading test with specific speed and dynamic random traffic loading test. 
the field test result show that the propose method can measure the displacement of concrete bridge under traffic load with reasonable accuracy. 
moreover different type of sensor distribution be propose to investigate the displacement measurement effect to optimise the sensor installation. 
although the sensor cover only some key part of the girder the result also verify the accuracy of the propose method. 
therefore the propose method can be implement in concrete bridge in future. 
gear machining make easy tnc cycles for skiving. 
scatter search with path relinke for multiprocessor open shop scheduling. 
maintenance and health care diagnostic system be generally compose of different workstation pertain to technologically different process. 
a workstation be compose of one or more parallel machine. 
in such system the multiprocessor open shop scheduling problem be commonly encounter. 
it be concern with assign processing interval for each job on machine that need to be select in each request workstation. 
meanwhile job do not require a specific order for visit workstation. 
this paper consider a static deterministic version of the problem in which job do not have to visit all workstation the workstation do not necessarily have identical machine and the processing time depend on both the job and the machine. 
the objective be to minimize the maximum completion time makespan which be commensurate with maximize the utilization of the available machine. 
to the good of our knowledge this problem structure have not be consider in the literature before despite its existence in real life application. 
since it be np hard problem efficient heuristic be need to generate near optimal solution in practically acceptable computational time. 
in this paper two neighborhood search function and two solution combination function be develop and use within a scatter search with path relinke metaheuristic along with a new distance definition between solution. 
computational experiment be conduct first to select the good level of the metaheuristic parameter. 
then computational experiment be conduct on specially design instance that take into consideration different setting of the studied problem. 
this be follow by computational experiment on a set of benchmark instance of the proportionate multiprocessor open shop scheduling problem which be a special rase of the studied problem for which other metaheuristic have be develop in the literature. 
result show that the develop metaheuristic be capable of generate optimal or near optimal solution for different configuration of the studied problem. 
in addition it generate competitive result for the proportionate raw compare to the available metaheuristic with 18 new upper bound among they seven be optimal. 
cost base text understanding to improve maintenance knowledge intelligence in manufacture enterprise. 
improve maintenance knowledge intelligence use text datum have not be largely explore in the literature of production and engineering management. 
the state of the art approach and solution mainly focus on either clustering and classification of maintenance log or extract additional meta )data failure time datum from maintenance text report operator workbook and digital logbook. 
knowledge discovery from text kdt enable find undetected causality hide pattern frequency associative relation and sentiment in maintenance text repository. 
apply kdt may enhance understand the content of text datum syntactically and semantically. 
however advanced kdt approach do not significantly provide meaningful and explainable outcome due to certain barrier in manufacture enterprise namely availability and quality of longitudinal maintenance text datum. 
to overcome these barrier in real world industrial maintenance generate add value in industrial maintenance and lie the ground for autonomous maintenance decision support in the context of industry 4.0 the first step be to adopt kdt method and accordingly provide maintenance specific solution consider practical challenge and possibility. 
this paper discuss the lack of understand maintenance text datum and examine its effect on maintenance knowledge intelligence in manufacture enterprise. 
a compositional framework for text understanding textplan be introduce. 
textplan explore quantification of text datum in both syntax and semantic level how to vectorize an annotated maintenance report into numeric value which represent cost datum hide association and sentiment. 
a prominent feature of textplan be cost base text analysis which decompose a maintenance text report into separate cost item and then re )compose the finding to estimate the total maintenance cost associate with the give report. 
finally yet importantly textplan consolidate the finding into a text understanding map for assist maintenance planner base on three propose measure of text comprehension namely association measuring index ami opinion index oi and cost vector cv. 
design of a testbed for hybrid flow shop scheduling with identical machine. 
in this paper we present two extensive set of instance for the hybrid flow shop scheduling problem. 
the first set be compose of 240 instance with a small number of job while in the second set 240 instance with a large number of job be consider. 
a rigorous methodology to develop these testbed be propose so the instance comply with the requirement of empirical hardness adequacy to the problem exhaustiveness and amenity for statistical analysis. 
a total of 57,600 instance have be randomly generate for different processing time and distribution of machine. 
out of these instance the 240 one with well characteristic accord to a number of indicator have be select in each set. 
the extensive experimentation carry out prof that the propose set of instance you all previous requirement and outperform in this regard all previous set of instance use in the literature. 
an artificial bee colony with division for distribute unrelated parallel machine scheduling with preventive maintenance. 
distribute scheduling problem have attract much attention in recent year however some practical processing constraint such as preventive maintenance pm be seldom consider in distribute scheduling case. 
in this study distribute unrelated parallel machine scheduling problem dupmsp with pm be investigate and an artificial bee colony with division dabc be propose to minimize makespan. 
to generate high quality solution the whole warm be divide into one employ bee colony and three onlooker bee colony four colony differ from each other in search strategy a novel method be use to handle scout and swarm be update by use optimization datum. 
extensive experiment be conduct to test the performance of dabc and computational result show that dabc have promise advantage on dup msp with pm. 
optimal condition base maintenance with general repair and two dependent failure mode. 
this paper propose a condition base maintenance cbm policy for a system subject to dependent soft and hard failure. 
when the deterioration exceed a predetermined level the system experience a soft failure that can be rectify by corrective general repair or corrective replacement. 
three possible action namely no maintenance preventive general repair and preventive replacement be consider at each inspection epoch. 
the hard failure rate depend on both age and deterioration be describe by a proportional hazard model with the covariate characterize by a gamma process. 
the hard failure can be correct by minimal repair general repair or by replacement. 
different from previous cbm policy no threshold be use to define maintenance action. 
the objective be to determine the optimal maintenance policy that minimize the long run expect average cost per unit time. 
the optimization problem be formulate in the semi markov decision process smdp framework and solve by the policy iteration algorithm. 
two practical numerical example be provide to illustrate the propose policy. 
the comparison with other cbm policy show an outstanding performance of the propose policy as well as the significance of minimal repair and general repair in cbm decision making. 
new control method for vsc mtdc station in the abnormal condition of power system. 
low complexity insensitivity on the system parameter less number of electrical sensor fast and accurate dynamic response the ability of connection to weak ac system and high power quality be some of the major criterion for selection of control method of the voltage source converter vsc. 
consider these issue in this paper a new control method be present for application in the vsc station. 
this control method be base on recursive least square with variable forget factor vff rls which be a numerical estimator. 
estimation of fundamental component of distort ac grid voltage and their symmetric positive component be do by vff rls estimator. 
desire power injection by the propose control method be do with correspond to estimate signal. 
simulation result in the matlab simulink platform and experimental result use tms320f2812 digital signal processor validate the superiority of the propose control method. 
multivariable extremum seeking by periodic switching function with application to raman optical amplifier. 
a periodic switching function base extremum seek slide mode control strategy be address for uncertain nonlinear system. 
we generalize previous result to a more challenging multivariable scenario where the diagonal dominance condition be relaxed and can now be understand as a triangular dominance condition which be significantly less restrictive. 
as an essential advantage over early result in the literature the complete global convergence proof with respect to the closed loop initial condition of the overall multi input multi output mimo closed loop system be provide rather than local stability result. 
the practical application of the propose multivariable controller be exemplify through the optimization problem of the output signal power spectrum of raman optical amplifier. 
from a practical point of view the extremum seek scheme enable the automatic adjustment of the control pump power signal in the presence of plant uncertainty guarantee a flat power spectrum of the downstream data signal. 
use a multi objective approach we develop the optimization algorithm to achieve this goal by simultaneously minimize the output ripple and the deviation from some desire power level. 
the convergence analysis and control design be carry out in the presence of uncertainty and the algorithm performance be test through numerical example where a particular optical communication system with 32 channel be consider. 
this numerical example use model parameter acquire experimentally and a representative fiber model such that the result be close to what be expect to find in a practical implementation. 
hierarchical density decomposition for abnormal event diagnosis in serially correlate non gaussian system. 
process in industrial practice often represent dynamic system which be a result of controller feedback the presence of process noise and measured or unmeasured disturbance. 
to monitor dynamic system that produce serially time base correlate datum record the literature have propose numerous multivariate technique that rely on i time lag arrangement of the record variable and ii subspace base approach. 
propose technique however may not accurately and reliably describe to what extent process variable be affect by abnormal event which compromise the identification of potential root cause. 
to address this this paper employ a state space model to describe the inherent serial correlation and introduce a joint probability density function for this model. 
the density function can be hierarchically decompose into the product of multiple low dimensional conditional density to reduce complexity and to detect and preanalyze anomalous behavior. 
use the low dimensional density a correction scheme to optimally describe the effect of an abnormal event upon particular process variable be propose. 
a second important benefit of the hierarchical decomposition be that no assumption be impose on the distribution of the random error component of the state space model. 
application study to a simulation process and record datum from two industrial process demonstrate that compare to conventional method the hierarchical decomposition can substantially improve the diagnosis of abnormal process behavior. 
smart reckoning reduce the traffic of online multiplayer game use machine learning for movement prediction. 
massively multiplayer online game mmog player maintain consistent view of the position of each other by periodically exchange message. 
besides the fact that these message can suffer delay that cause render inconsistency they also represent an overhead on the network. 
this overhead can be significant as the number of mmog player be very large but reduce the number of message be not trivial. 
the classic strategy to predict movement avoid message exchange be base on the dead reckoning algorithm which have several limitation. 
other strategy have be propose more recently that improve the result but rely on expert knowledge. 
in this work we propose smart reckoning a movement prediction strategy base on machine learning. 
the strategy consist of two phase. 
in the first phase a learn model classifie whether the classical dead reckoning algorithm be able to predict the new avatar position correctly or not. 
in case the conclusion be negative another learning model be use to predict the new direction. 
the propose strategy be apply to the world of warcraft game. 
the learning model be implement with the weka tool use real game trace datum and result be present for the accuracy of multiple algorithm. 
development of a novel spindle shape coil base wireless power transfer system for frequency splitting elimination. 
to eliminate frequency splitting in wireless power transfer a novel spindle shape coil base wireless power transfer system be introduce and design. 
base on the equivalent circuit model the transmission coefficient and the input impedance be calculate. 
a comparative analysis be perform between the traditional and the propose system. 
it be find that the frequency splitting be suppress by utilize spindle shape transmit and receive coil in the propose system because of the large mutual inductance between the source coil load coil and transmit coil receive coil and the small mutual inductance between the transmitting and the receiving coil in comparison with the traditional system. 
in the overcoupled region the transmission coefficient of the propose system almost remain unchanged and keep at a high value. 
the input impedance be characterize with high amplitude and small argument which be beneficial for efficient power transfer. 
experimental setup be establish to validate the performance of the propose wireless power transfer system. 
the result indicate that the propose system be superior to the traditional one in eliminate the frequency splitting which be well consistent with the simulation analysis. 
diagnosability analysis of intermittent faults in discrete event systems use a twin plant structure. 
most research in fault diagnosis of discrete event system have be focus on permanent failure. 
however experience with monitoring of dynamic system show that intermittent fault be predominant and that their diagnosis constitute one of the most challenging task for surveillance activity. 
among the main exist approach to deal with permanent fault two be widely investigate while consider different setting the diagnoser base approach and the twin plant base approach. 
the latter be develop to cope with some complexity limitation of the former. 
in the present paper we propose a twin plant base approach to deal with diagnosability of intermittent fault. 
firstly we discuss various notion of diagnosability while consider the occurrence of fault their recovery and the identification of the system status. 
then we establish the necessary and sufficient condition for each notion and develop on the fly algorithm to check these property. 
the discuss approach be implement in a prototype tool that be use to conduct experiment on a railway control benchmark. 
stability of stochastic functional differential systems with semi markovian switching and levy noise and its application. 
this paper investigate the general decay stability on system represent by stochastic functional differential equation with semi markovian switching and levy noise sfdes sms ln. 
base on generalized multidimensional ito s formula and multiple lyapunov function a new pth moment stability criterion with general decay rate be establish. 
meanwhile as an application of the present stability criterion we consider the stabilization problem of stochastic delay neural network with semi markovian switching and levy noise sdnn sms ln. 
a vertex approach be propose to design the controller in term of binary diagonal matrix bdms and linear matrix inequality lmis. 
finally a numerical example be present to demonstrate the effectiveness of the propose result. 
invariant kalman filter for correlated wide band noises. 
kalman filtering be a powerful estimation method. 
one of its weakness be relate to the white or coloured nature of the disturbing noise in the kalman filter model. 
at the same time real noise be rarely white or colour. 
they be mostly wide band. 
in this regard white or coloured noise kalman filtering make concession on adequacy. 
this push system scientist to develop mathematical method of estimation for system corrupt by wide band noise. 
in application wide band noise be detect by their autocovariance and cross covariance function which do not allow to model they uniquely. 
therefore it become important to develop estimation method which be independent of a class of wide band noise but dependent on the unique autocovariance and cross covariance function. 
such result be call invariant result. 
in this paper we prove a complete set of invariant equation for kalman type filter for a linear signal observation system corrupt by correlate wide band noise. 
this filter have a ready form to be use in application just respective numerical method must be develop. 
finite time guarantee cost control of caputo fractional order neural network. 
in this paper we investigate the problem of finite time guarantee cost control of uncertain fractional order neural network. 
firstly a new cost function be define. 
then by use linear matrix inequality lmis approach some new sufficient condition for the design of a state feedback controller which make the closed loop system finite time stable and guarantee an adequate cost level of performance be derive. 
these condition be in the form of linear matrix inequality which therefore can be efficiently solve by use exist convex algorithm. 
finally two numerical example be give to illustrate the effectiveness of the propose method. 
multi variable direct self organize fuzzy neural network control for wastewater treatment process. 
a multi variable direct self organize fuzzy neural network control m dsnnc method be propose for the multi variable control of the wastewater treatment process wwtp. 
in this paper the propose control system be an essential multi variable control method for the wwtp. 
no exact plant model be require which avoid the difficulty of establish the mathematic model of wwtp. 
the m dsnnc system be comprise of a fuzzy neural network controller and a compensation controller. 
the fuzzy neural network be use for approximate the ideal control law under a general nonlinear system. 
moreover the neural network be design in a self organize mode to adapt the uncertainty environment. 
simulation result base on the international benchmark simulation model no.1 bsm1 demonstrate that the control accuracy be improve under the propose m dsnnc method and the controller have a much strong decouple ability. 
mixed event trigger mechanism modeling and controlling for networked control systems with time vary delay and uncertainty. 
this paper be concern with modeling and control under the mixed event trigger mechanism etm for networked control system ncs with time vary delay and uncertainty. 
firstly an event trigger threshold be set by use both state and state independent information in the mixed etm. 
then the event trigger ncs with network induce time vary delay which exist in both sensor to controller and controller to actuator channel be model as a general time delay system. 
base on the piecewise differentiable characteristic of the time vary delay and by use the approach of free weighting matrix and reciprocally convex a less conservative criterion to be globally uniformly ultimately bound guub stability and a controller design method be derive. 
furthermore an algorithm be propose to obtain the desire mixed etm and state feedback controller which can render the network load and control performance to reach an expect level. 
compare with the relative and absolute etm the propose mechanism can effectively improve the transmission efficiency during the whole working time. 
finally a numerical example be give to show the effectiveness of the propose approach. 
bifurcation control of small world network with delay via pid controller. 
in this paper the problem of bifurcation control for a small world network model with time delay be study. 
we first put forward a proportional integral derivative pid feedback scheme to control the hopf bifurcation of the network. 
the time delay be select as the bifurcation parameter. 
the condition of the stability and hopf bifurcation be give for the control network. 
by use the center manifold theorem and the normal form theory the direction and stability of bifurcate periodic solution be confirm. 
the feasible region of the parameter of the controller be determine. 
it be find that the bifurcation dynamic of the small world network be optimize by adjust the parameter of the pid controller. 
finally a numerical example verifie the effectiveness of the design pid controller and the relationship between the onset of the hopf bifurcation and the control parameter be obtain. 
novel mpc base fault tolerant tracking control against sensor fault. 
the problem of active fault tolerant tracking control with control input and system output constraint be study for a class of discrete time system subject to sensor fault. 
a time vary fault tolerant observer be first develop to estimate the real system state from the faulty sensor output and control input signal. 
then by use the estimate state at each time step a model predictive control mpc) base fault tolerant tracking control scheme be present to guarantee the desire tracking performance and the give input and output constraint on the faulty system. 
in comparison with many exist fault tolerant mpc method its main contribution be that the propose state estimator be design by the simple and online numerical computation to tolerate the possible sensor fault so that the regular mpc algorithm without fault information can be adopt for the online calculation of fault tolerant control signal. 
the potential recursive infeasibility and computational complexity due to the fault be avoid in the scheme. 
additionally the closed loop stability of the post fault system be discuss. 
simulative result of an electric throttle control system verify the effectiveness of the propose method. 
boundary control for a flexible string system with input saturation constraint. 
in this study we focus on the boundary control problem for a vibrate string system with saturate input under the condition of external disturbance. 
base on the backstepping approach a boundary vibration control scheme be propose to globally stabilize the string around the equilibrium position. 
a smooth hyperbolic tangent function be exploit to restrict the control input an auxiliary system and a nussbaum function be adopt to cope with the nonlinear term derive from the input saturation and a disturbance observer be employ to tackle the boundary disturbance. 
the developed controller can assure the convergence of the closed loop system state to a small neighbourhood of zero. 
by the appropriate choice of control design parameter numerical simulation be conduct to show the effectiveness of the derive control. 
guarantee cost control of distribute parameter networked control system with time vary delay. 
distribute parameter networked control system mean distribute parameter system be control through a network where the control loop be close. 
in this paper the problem of guarantee cost and state feedback controller design be investigate for a class of distribute parameter networked control system. 
with the network factor such as transmission delay datum packet dropout consider the distribute parameter networked control system be model as a linear closed loop system with time vary delay and uncertain parameter. 
by select an appropriate lyapunov krasovskii function and use linear matrix inequality lmi approach the controller be design to render the system stable and it can keep the cost function less than a certain upper value. 
in addition numerical simulation be include to demonstrate the theoretical result. 
fault tolerant control base on augmented state estimator and pdf. 
a new fault tolerant control base on augmented state estimator and probability density function pdf be propose for a stochastic distribution system sds with time delay and additive fault. 
first a system model base on a pdf with the additive fault be construct by use square root rational b spline neural network. 
second an augmented system be obtain by convert the additive fault as an auxiliary state variable. 
in this framework a robust augmented state estimator be design to estimate the original state and the additive fault simultaneously. 
then base on the obtain estimation of fault a delay dependent fault tolerant control be design to compensate the fault. 
finally the numerical simulation show the effectiveness of the propose method. 
stabilization of switch neural network with time vary delay via bumpless transfer control. 
this paper investigate the stabilization of switch neural network with time vary delay. 
in order to overcome the drawback that the classical switching state feedback controller may generate the bump at switch time a new switch feedback controller which can smooth effectively the bump be propose. 
accord to mode dependent average dwell time new exponential stabilization result be deduce for switch neural network under the propose feedback controller. 
base on a simple corollary the procedure which be use to calculate the feedback control gain matrix be also obtain. 
two simple numerical example be employ to demonstrate the effectiveness of the propose result. 
event trigger stabilization for continuous time saturate markov jump system with generally uncertain transition rate. 
this paper be concern with the stabilization for continuous time saturate markov jump system with generally uncertain transition rate gutrs under event trigger strategy. 
in the gutrs model the transition rate could be unknown or only its estimate value and estimate error bind be know. 
in practical system actuator saturation commonly exist which may lead to instability. 
event trigger strategy be introduce in markov jump system to save communication resource. 
a stochastic stabilization condition be derive for the underlie system consider event trigger control and the lower bind of the inter event time interval be calculate to avoid zeno behavior. 
to obtain the big domain of attraction an optimization algorithm be formulate. 
finally numerical example be provide to illustrate the application of the give result. 
track control for general second order multi agent systems with communication delay and variable topology. 
this article study the consensus problem for a class of general second order multi agent system mass with communication delay and variable topology. 
we first consider the case with time delay but un variable topology and obtain sufficient condition for exponential consensus. 
then base on the obtain condition for the un variable topology case the condition of the consensus for the case with time delay and variable topology be analyze. 
finally the effectiveness of the derive consensus condition be illustrate by numerical example. 
multiple performance characteristic optimization in end milling of thin walled part use desirability function. 
with the development of high performance cnc machine tool milling have be establish as one of the main mean of machine thin walled part. 
thus the selection of process parameter for mill operation be an important issue in end milling of thin walled part to assure product quality and increase productivity. 
the current study explore three machining parameter namely wall thickness feed and machining strategy that influence dimensional and form error surface roughness and machine time mill of 7075 t6 aluminum alloy thin walled part. 
the effect of machine parameter on each of the response variable be analyze use graph of the main effect and three dimensional surface plot. 
analysis of the result show that the most influential factor for wall thickness deviation dimension deviation perpendicularity deviation flatness deviation surface roughness of inner wall surface roughness of outer wall and surface roughness of reference plane be machine strategy while feed be the most influential parameter affect the machine time follow by the machining strategy. 
the desirability concept have be use for simultaneous optimization in term of machine parameter of the thin walled part machining process. 
finally a confirmation test with the optimal parameter setting be carry out to validate the result. 
a thermomechanical modeling and experimental validation of the gear finish hobbing process. 
the current research work aim at develop an analytical modelling of the gear finish hobbing process when the uncut chip thickness may be very small. 
numerical model and particularly finite element simulation of this complex material removal process be often limit to one tooth because of the high require computational time. 
to analyze the performance characteristic of this process a predictive approach for finish gear hobbing base on an analytical model of orthogonal cutting operation be propose. 
to reduce the computational time a new calculation strategy have be develop. 
this allow to examine the local parameter which change significantly for each tooth. 
during the finish hobbing process of large gear six m diameter 16 m the industrial condition require low cutting speed less than one m s with lubrication. 
therefore in order to consider the effect of lubrication cut speed and uncut thickness on the friction coefficient an appropriate friction law be identify from orthogonal cutting test. 
the cut model have be experimentally validate for different cutting condition. 
finally the effect of hobbing process on the cut force and the tool chip contact parameter contact length pressure frictional stress and temperature have be investigate and deeply analyze use the develop model. 
the distribution of these local parameter at each tooth rake face may be use as a process signature for the result condition of the machine surface and subsurface layer. 
design of prepreg compression molding for manufacturing of cfrtp b pillar reinforcement with equivalent mechanical properties to existing steel part. 
prepreg compression mold pcm be a well know process for manufacturing of carbon fiber reinforce thermo plastic cfrtp product with high quality and production rate. 
however the design method use for the development of automotive part have not be clearly present. 
in this paper we propose a process chain that can satisfy the stiffness of exist steel product. 
first the cfrtp product of a b pillar reinforcement to satisfy the bend deformation of an exist product be design use a structural analysis and genetic algorithm. 
next form condition of the product be determine by a form analysis. 
to investigate the feasibility regard the mass production of the pcm process a rapid heating and cool system be apply to pcm mold. 
the heating and cool time of the mold be calculate use a computational fluid dynamic analysis. 
finally a cfrtp product be fabricate and its bend deformation dimensional accuracy and weight be evaluate. 
real time ufir parameter identification. 
an unbiased finite impulse response filter ufir filter be use for parameter identification. 
the algorithm be equivalent to the recede horizon least square method. 
but it do not require initial condition and the horizon length be optimise to guarantee a minimal error covariance if there be parameter and measurement noise. 
a smart sensor generate a sequence of measurement. 
this sequence be send to the ufir estimator via a network base on the transmission control protocol tcp. 
the effect of package dropout be investigate. 
furthermore a convergence and stability analysis be carry out and approve within numerical study. 
traffic signal control reinforcement learning approach for continuous time markov game. 
traffic signal control tsc model have be transform from simple pre timed isolated indication to a more complex form of actuated and coordinated tsc model for highway railroad etc. 
however exist tsc model can not always manage inconvenience like over saturation delay by incident congestion by weather condition among other which be why this be still an open area of research. 
an important challenge be to propose a tsc solution model for multiple intersection which adapt traffic signal timing accord to real time traffic. 
this paper introduce a novel reinforcement learning rl approach for solve the traffic signal control problem for multiple intersection use continuous time markov games ctmg. 
the rl model be base on a temporal difference method. 
for estimate the transition rate of the markov model we use non degenerate randomize markov law be be use such that the connected chain be show to be ergodic and to visit all state infinitely often use all the control in every state. 
our reinforcement learning model suppose to have complete information. 
the estimation of the transition rate be obtain by the number of transition on an interval of time divide by the total value of the hold time. 
the estimation of the reward be define as the arithmetic mean of the observed reward. 
we consider a non cooperative game model for solve the multiple intersection problem. 
for compute the nash equilibrium we employ an iterative proximal gradient method. 
as our final contribution we present a numerical example for validate our model and concretely measure the benefit of the tsc model. 
machine tool condition monitor with gaussian mixture model base dynamic probabilistic clustering. 
the combination of artificial intelligence with datum computing power and new algorithm can provide important tool for solve engineering problem such as machine tool condition monitoring. 
however many of these problem require algorithm that can perform in highly dynamic scenario where the datum stream have extremely high sampling rate from different type of variable. 
the unsupervised learn algorithm base on gaussian mixture model call gaussian base dynamic probabilistic clustering gdpc be one of these tool. 
however this algorithm may have major limitation if a large amount of concept drift associate with transient occur within the data stream. 
gdpc become unstable under these condition so we propose a new algorithm call gdpc+ to increase its robustness. 
gdpc+ represent an important improvement because we introduce a automatic selection of the number of mixture component base on the bayesian information criterion bic and b concept drift transition stabilization base on cauchy schwarz divergence integrate with the dickey fuller test. 
thus gdpc+ can perform well in highly dynamic scenario than gdpc in term of the number of false positive. 
the behavior of gdpc+ be investigate use random synthetic datum stream and in a real data stream base condition monitoring obtain from a machine tool that produce engine crankshaft at high speed. 
we find that the initial temporal window size can be use to adapt the algorithm to different analytical requirement. 
the cluster result be also investigate by induction of the rule generate by the repeat incremental pruning to produce error reduction ripper algorithm in order to provide insight from the underlying monitor process and its associate concept drift. 
data drive orient optimization of resource allocation in the forging process use bi objective evolutionary algorithm. 
resource allocation in the forge process of the steel production industry be an important element of the material supply in upstream process and the subsequent processing of semi finished product downstream. 
however the exist literature rarely discuss issue relate to this problem. 
in this study the information flow be build by refer to specification and process logic which be a kind of pre processing in datum analysis flow in order to break the initial barrier of resource allocation in forge. 
in addition bi objective evolutionary algorithm boea be propose to optimize the resource allocation in the forging process. 
use the build information flow the available multiple forging process resource can be effectively connect and information of available resource combination can be establish for order. 
since real user have preference for different objective in practice experiment result show that the propose boea can deal with these preference by effectively optimize both the remnant the remain material and the execution cost and the profit contribution be also prove by effective cost saving. 
a fitting model base intuitionistic fuzzy rough feature selection. 
feature subset selection be an essential machine learning approach aim at the process of dimensionality reduction of the input space. 
by remove irrelevant and/or redundant variable not only it enhance model performance but also facilitate its improved interpretability. 
the fuzzy set and the rough set be two different but complementary theory that apply the fuzzy rough dependency as a criterion for perform feature subset selection. 
however this concept can only maintain a maximal dependency function. 
it can not preferably illustrate the difference in object classification and do not fit a particular dataset well. 
this problem be handle by use a fitting model for feature selection with fuzzy rough set. 
however intuitionistic fuzzy set theory can deal with uncertainty in a much well way when compare to fuzzy set theory as it consider positive negative and hesitancy degree of an object simultaneously to belong to a particular set. 
therefore in the current study a novel intuitionistic fuzzy rough set model be propose for handle above mention problem. 
this model fit the datum well and prevent misclassification. 
firstly intuitionistic fuzzy decision of a sample be introduce use neighborhood concept. 
then intuitionistic fuzzy low and upper approximation be construct use intuitionistic fuzzy decision and parameterized intuitionistic fuzzy granule. 
furthermore a new dependency function be establish. 
moreover a greedy forward algorithm be give use the propose concept to calculate reduct set. 
finally this algorithm be apply to the benchmark dataset and a comparative study with the exist algorithm be present. 
from the experimental result it can be observe that the propose model provide more accurate reduct set than exist model. 
new mix code pso algorithm for a self adaptive and automatic learning of mamdani fuzzy rule. 
thank to its algorithmic performance pso algorithm become a popular tune tool for fuzzy system in literature. 
however it still encounter many complication especially when deal with mamdani fuzzy system type because of its nature. 
the mamdani fuzzy system be know as a linguistic model where the semantic meaning of the fuzzy rule be an intrinsic characteristic that must be retain during the learning process while seek for high accuracy. 
therefore to tune the mamdani fuzzy system it be very crucial to well represent each rule in a way that preserve this characteristic firstly and to look for a search mechanism to optimize they throughout this topic secondly. 
in this paper we introduce a new and promising approach to optimize the mamdani fuzzy system without a need of any prior knowledge. 
to the good of our knowledge this approach be the first to optimize simultaneously the membership function the scaling factor parameter and the fuzzy rule conclusion with a mix code pso algorithm by combine a special monitoring function and a self adaptive threshold. 
the propose approach be validate by a comparative study with other design strategy take from box jenkins gas furnace system literature and two theoretical example in addition to a real time control of the inverted pendulum feedback 33 200. 
the obtain result prove the potential and the effectiveness of the propose approach. 
combinatorial search for select the structure of model of dynamical system with equation discovery. 
automated modeling aim at the induction of mathematical model both their structure and parameter value from time series measurement of observed system variable. 
in this paper we address the task of model structure selection select an optimal structure from a user specify finite set of alternative model structure use various approach to combinatorial search. 
we propose a mapping of the set of candidate model structure to a fix length vector representation allow the use of an arbitrary search algorithm as a solver of the structure selection task. 
we perform a comparative analysis of the performance of thirteen variant of several search algorithm range from one with high intensification focus on neighborhood of the good candidate solution to one with high diversification focus on cover the entire search space. 
the empirical analysis involve eight task of reconstruct know model of dynamical system from synthetic and measure datum. 
the result of the analysis show that search algorithm involve moderate diversification method have superior performance on the structure selection task. 
the empirical analysis also reveal that this finding be relate to specific property of the search space of candidate model structure. 
analysis and prediction for spindle thermal bending deformation of a vertical milling machine. 
to understand the thermal behavior of the spindle the radial thermal drift error rtde of the spindle be test in this paper. 
to analyze the influence of environmental temperature to the rtde the rtde be test at zero r min. 
afterward the rtde of the spindle and the temperature value of key point be test at different speed. 
the thermal deformation process of the spindle be analyze and verify by thermal imaging testing. 
the rtde model of ten thermal deformation be establish. 
also the relationship between compensation value and tool length determination criterion of thermal deformation algorithm flow and parameter identification process be present by use an inverse model. 
the compensation effect be verify use both simulation and experimental datum. 
the result indicate that high accuracy can be achieve for all rotate speed with parameter identify use datum of one speed. 
the strong robustness of the propose model be prove. 
a new demagnetization fault recognition and classification method for dpmslm. 
this paper investigate a new method for the demagnetization fault recognition and classification in double sided permanent magnet synchronous linear motor that be use in linear motion application. 
this method be base on time time transform tt couple with extreme learning machine elm which be especially suitable for the industrial occasion such as motor batch demagnetization inspection before delivery and periodic maintenance. 
first a finite element analysis model with demagnetization fault be build to extract three line up line center line and down line magnetic flux density signal. 
second tt be first apply to conduct magnetic signal waveform transformation and digital picture processing technology be innovatively use to extract the pixel rate of its diagonal element contour surface as the fault feature. 
then machine learn algorithm call elm be utilize as a classifier to obtain the unique fault label that can represent the demagnetization occur position side and severity type in detail. 
the validity and superiority of elm be verify through comparison with back propagation neural network and probabilistic neural network. 
finally prototype motor experimental platform be design to confirm the correctness and effectiveness of this propose method. 
data base iterative dynamic decoupling control for precision mimo motion systems. 
decouple control be still an important research topic for precision multiple input multiple output mimo motion system involve in computer numerically control cnc machine tool wafer scanner etc. 
in this paper to minimize internal coupling and improve servo performance a data base iterative dynamic decouple control iddc approach be synthesize. 
specifically a mimo dynamic decouple controller structure with finite impulse response filter be use as an add on to a static decouple part. 
then a data base parameter optimization algorithm be develop such that the optimal parameter can be iteratively solve base entirely on the input output datum by minimize the coupling induce error. 
unlike pre exist iddc approach the propose approach can achieve an unbiased estimate of the optimal parameter combine with a small estimate variance that be illustrate through numerical simulation. 
finally application to an ultraprecision wafer stage confirm that the propose approach significantly decrease the coupling induce error and achieve enhance performance compare to pre existing approach. 
finite gaussian mixture model based multimodele for nonlinear distributed parameter systems. 
complex nonlinear distribute parameter system dps widely exist in real industrial thermal process. 
modeling of such system often lead to the follow challenge strong nonlinearitie time vary dynamic and large operating range with multiple working point. 
therefore traditional single spatiotemporal model will become ill suit. 
motivate by the idea of multimodeling integration of finite gaussian mixture model fgmm and principle component regression pcr base multiple spatiotemporal modeling be propose in this paper for complex nonlinear dps. 
the main idea of the propose method can be summarize as the follow three part fgmm base operating space separation karhunen loeve base local spatiotemporal modeling and pcr base local spatiotemporal model integration. 
to evaluate the generalization bind of the propose method the rademacher complexity be also develop here theoretically. 
since multimodele can reduce the nonlinear complexity the propose model have strong ability to track and handle the complex nonlinear dynamic. 
simulation on a two dimensional cure thermal process demonstrate the superior model performance of the propose model. 
a distribute deep learning system for web attack detection on edge device. 
with the development of internet of thing iot and cloud technology numerous iot device and sensor transmit huge amount of datum to cloud datum center for further processing. 
while provide we considerable convenience cloud base computing and storage also bring we many security problem such as the abuse of information collection and concentrated web server in the cloud. 
traditional intrusion detection system and web application firewall be become incompatible with the new network environment and related system with machine learning or deep learning be emerge. 
however cloud iot system increase attack against web server since datum centralization carry a more attractive reward. 
in this article base on distributed deep learning we propose a web attack detection system that take advantage of analyze url. 
the system be design to detect web attack and be deploy on edge device. 
the cloud handle the above challenge in the paradigm of the edge of thing. 
multiple concurrent deep model be use to enhance the stability of the system and the convenience in update. 
we implement experiment on the system with two concurrent deep model and compare the system with exist system by use several dataset. 
the experimental result with 99.410 in accuracy 98.91 in true positive rate tpr and 99.55 in detection rate of normal request drn demonstrate the system be competitive in detect web attack. 
tool wear and hole quality evaluation in cryogenic drilling of inconel 718 superalloy. 
in this paper the research efffort have be make to discover the potential of cryogenic machining as a sustainable manufacturing process for drilling of inconel 718 superalloy. 
the drilling performance be investigate in term of thrust force torque tool wear chip morphology and hole quality circularity  cir cylindricity  cyl and surface roughness r a value. 
the experimental result show temperature dependent tool wear drastically reduce under cryogenic drilling as compare to dry drilling and this lead to a reduction in torque value up to 30. 
furthermore the cryogenic drilling improve tool life up to 87.50 and produce well quality hole due to a decrease in cir deviation up to 51 cyl deviation up to 77 and r a value up to 48. 
experimental investigation on material removal mechanism during rail grind at different forward speed. 
the study focus on the removal behaviour of rail material during grind at different forward speed which provide a well understanding for improve the grind efficiency and quality. 
the result indicate that the rise in forward speed lead the grind efficiency to increase and then decrease and the grind process be the most efficient at the forward speed of three km h. 
on the other hand with the forward speed increase the grind quality be improve surface burn surface hardness and white layer thickness decline. 
the wear form of a grind wheel consist of rail material adhesion abrasive fracture and abrasion wear. 
it be suggest that the forward speed should be high than four km h in the field. 
design of rank one modification feedback controller for second order system with time delay use frequency response method. 
in this note a novel approach to design rank one single input feedback controller for second order system with time delay be present. 
the versatile well know receptance modeling be combine with classical frequency response method of control design and the feedback gain be compute in order to achieve a give stability margin base on sensitivity specification. 
the system under study be assume to be stable in open loop. 
a heuristic optimization technique namely genetic algorithm be employ to impose a minimal distance from the nyquist plot of the control system to the critical point guarantee thereby a predefined margin of robust stability. 
in addition to the well know advantage of the receptance method in obtain experimental model the propose design approach bring the possibility of consider time delay without approximation by use frequency response calculation avoid thereby the drawback inherent to the a posteriori stability verification when pole assignment technique be use. 
numerical example help to enlighten the merit of the propose approach. 
c 2019 elsevier ltd. 
all right reserve. 
genetically optimize parameter estimation of mathematical model for multi joints hip knee exoskeleton. 
achieve precise parameter of multi joint actuator for hip knee exoskeleton hke be a crucial process due to its non linear characteristic. 
in this paper a genetic algorithm ga base optimization be use for parameter estimation of the mathematical model for a four degree of freedom dof multi joint hke which be a type of lower limb exoskeleton lle. 
mathematical model for electromechanical mechanical and electrical component of the hke have be formulate and its parameter be estimate use ga and experimental method. 
an objective function be determine base on the difference between the simulated and actual angular trajectory for each joint. 
the performance of the mathematical model be examine with different voltage under the range of four v to eight v for hip and knee respectively. 
furthermore the performance of the estimate model be compare with particle swarm optimization pso. 
the result and numerical analysis demonstrate that the estimate model by ga and pso with vary voltage predict the actual angular trajectory with acceptable error while ga provide the more accurate model. 
it can be ascertain that the propose method of estimation for mathematical model of the hke be applicable to identify its parameter and useful for design a control system. 
c 2020 elsevi b.v. 
all right reserve. 
an effective approach for the probabilistic and deterministic multistage pmu placement use cuckoo search iran s national power system. 
in recent year phasor measurement unit pmu as vital element have be widely increase in control monitoring and protection of power system. 
in practice as the size of a power system be large it be not possible to install all pmu over a short period of time mainly due to the financial and technical barrier. 
one solution would be instal the pmu over different stage. 
accordingly the paper present an effective approach for multistage pmu placement mspp in power system call dynamic mspp. 
furthermore since the probabilistic concept of observability reflect a more realistic image of power system observability compare to deterministic one this paper unlike most of the exist mspp model investigate the mspp model in both probabilistic and deterministic framework. 
compare to the exist approach and result the obtain one in this paper show a considerable improvement in the observability level during pmu installation period. 
in the propose approach pmu be instal at intermediate stage aim at maximize the cumulative network observability in a single optimization process instead of several subsidiary optimization in conventional approach. 
briefly the propose approach offer a complete search space for the problem while the exist model lead to limited one. 
moreover because of the nonlinearity pose by the probabilistic concept of observability as well as the propose mspp cuckoo search optimization algorithm be use to handle the complexity and a new problem encoding decode technique for the propose mspp be utilize. 
eventually the suggested framework be implement on different case study as well as iranian transmission network to reveal the performance of the present model. 
control of the cedra brachiation robot use combination of controlled lagrangians method and particle swarm optimization algorithm. 
this paper study the control of a brachiate robot imitate the locomotion of a long armed ape. 
the robot have two revolute joint but only one of they be actuate. 
in this paper after derive dynamic model of the robot the controlled lagrangians cl method be use to design a controller for point to point locomotion. 
the cl method involve satisfy a number of equation call matching condition. 
the matching condition be derive use the extended lambda method in the form of a set of partial differential equation pde. 
solve the pde a class of controller be find that satisfy the matching condition. 
the fit controller in the class of controller be then choose by particle swarm optimization algorithm. 
performance of the develop controller be investigate by numerical simulation. 
finally experiment be perform to validate theoretical result. 
a machine learning base ensemble method for anti patterns detection. 
anti pattern be poor solution to recur design problem. 
several empirical study have highlight their negative impact on program comprehension maintainability as well as fault proneness. 
a variety of detection approach have be propose to identify their occurrence in source code. 
however these approach can identify only a subset of the occurrence and report large number of false positive and miss. 
furthermore a low agreement be generally observe among different approach. 
recent study have show the potential of machine learn model to improve this situation. 
however such algorithm require large set of manually produce training datum which often limit their application in practice. 
in this paper we present smad smart aggregation of anti pattern detectors a machine learning base ensemble method to aggregate various anti patterns detection approach on the basis of their internal detection rule. 
thus our method use several detection tool to produce an improved prediction from a reasonable number of training example. 
we implement smad for the detection of two well know anti pattern god class and feature envy. 
with the result of our experiment conduct on eight java project we show that one our method clearly improve the so aggregated tool two smad significantly outperform other ensemble method. 
c 2019 elsevier inc. 
all right reserve. 
augment ant colony optimization with adaptive random testing to cover prime path. 
test datum generation have a notable impact on the performance of software testing. 
a well know approach to automate this activity be search base test datum generation. 
most study in this area use branch coverage as the test criterion. 
since the prime path coverage criterion include branch coverage it have high probability to detect software failure than the branch coverage criterion. 
this paper customize and improve ant colony optimization aco to provide a test datum generation approach for cover prime path. 
the propose approach incorporate the notion of input space partition to maintain pheromone value in the search space. 
in addition it employ the idea of adaptive random testing in the local search. 
at last it use the information of program predicate in order to make a relation between the logic of the program and pheromone value in the search space. 
the experimental result confirm the positive effect of the mention contribution especially for program with complex predicate. 
furthermore they represent that on average test suite generate by the propose approach have nine well mutation score in comparison to test suite produce by evosuite a well know test datum generation tool. 
c 2019 elsevier inc. 
all right reserve. 
performance evaluation of web service response time probability distribution model for business process cycle time simulation. 
context the adoption of business process management bpm be enable company to improve the pace of build new capability enhance exist one and measure process performance to identify bottleneck. 
it be essential to compute the cycle time of the process to assess the performance of a business process. 
the cycle time typically form part of service level agreement slas and be a crucial contributor to the overall user experience and productivity. 
the simulation technique be versatile and have broad applicability for determine realistic cycle time use historical datum of web service response time. 
bpm tool offer inadequate support for model input datum use in simulation in the form of descriptive statistic or standard probability distribution like normal lognormal which result in inaccurate simulation result. 
objective we evaluate the effectiveness of different parametric and non parametric probability distribution for model datum of web service response time. 
we far assess how the choice of probability distribution impact the accuracy of the simulated cycle time of a business process. 
the work be the first of such a study use real world datum for encourage business process simulation specification bpsim standard setter and bpm tool to enhance their support for such distribution in their simulation engine. 
method we consider several parametric and non parametric distribution and explore how well these distribution fit web service response time from extensive public and a real world dataset. 
the cycle time of the business process of a real world system be simulate use the identify distribution to model the underlie web service datum. 
result our result show that kernel distribution be the most suitable choice follow by burr. 
kernel outperform burr by 86.63 for the public and 84.21 for the real world dataset. 
the choice of distribution affect the percentile rank like 90 and above than the median. 
the use of single point value underestimate cycle time value at high percentile. 
conclusion base on our empirical result we recommend the addition of kernel and burr to the current list of distribution support by bpsim and bpm tool. 
c 2019 elsevier inc. 
all right reserve. 
laura architecture towards a simple way of build situation aware and business aware iot application. 
the explosion of smart object make company rethink their business model bm use wireless sensor networks wsn and the internet of things iot aim to improve their business processes bp to achieve competitiveness. 
business environment be complex due to the wide variety of technology hardware and software solution that compose heterogeneous enterprise environment. 
on the other hand put real world iot scenario into practice be still a challenge for even experienced developer because it require low level programming skill and at the same time specific domain knowledge of a company s bm. 
this research paper propose laura lean automatic code generation for situation aware and business aware applications a flexible service orient and general open source conceptual architecture design to support the deployment of decouple iot application. 
empirical evaluation have show that laura simplify the development of final situation aware or business aware application reduce the need for specialize iot low level knowledge while show an acceptable performance. 
laura also provide the freedom and independence to modify adapt or integrate its architecture accord to specific need of the stakeholder. 
c 2019 elsevier inc. 
all right reserve. 
air couple ultrasonic testing to estimate internal defect in composite panel use for boat and luxury yacht. 
in construction of boat and luxury yacht glass fiber reinforced polymer gfrp composite material be widely employ owe to their high mechanical performance light weight and flexibility in manufacture complex shape. 
however gfrp composite material can be affect by several intrinsic defect e.g. 
inclusion delamination resin excess or lack because of both wrong production process and post production handling. 
although conventional ultrasonic testing be the most apply method to enhance the structural safety and quality it present a strong limitation in achieve an efficient contact between the transducer and the testing surface. 
air couple ultrasonic testing can be use as a valid alternative overcome the previous disadvantage. 
aim of this study be to demonstrate the ability of air couple ultrasonic testing acut for qualitatively and quantitatively evaluation of internal defect in gfrp composite panel as those typically use for boat and luxury yacht construction. 
simulated delamination of different size have be analyse as well as excess and lack of resin. 
result highlight that a good signal to noise ratio can be achieve for delamination great than 15 mm with correct defect shape recover hence make acut an appropriate choice for the interactive engineering design and manufacturing of boat. 
augmented reality technology selection base on integrated qfd ahp model. 
in the last decade augmented reality have become increasingly popular. 
as improve performance be gather in term of mature hardware and software tool we be observe the stemming of a huge number of application of this technology both in the entertainment and in the industrial domain. 
on the one hand such application be usually claim to bring benefit in term of productivity or enhancement of the human s capability to perform task. 
on the other hand researcher and developer seem not to adequately consider the different meaning that ar assume when implement through visualization device that can differ significantly in nature and in their capability to provide a mixed real virtual scenario. 
in this paper we describe a user centre method base on an integrated qfd ahp approach to select the good visualization display technology with regard to a specific application context. 
the aim be to establish a repeatable and document process for the identification of the technology that good suit and mitigate the acceptability risk of the transition from a legacy work environment to an ar base operational environment. 
the method have be develop in the framework of the retina resilient synthetic vision for advanced control tower air navigation service provision project involve the end user in this case air traffic controller. 
nevertheless it can be generalise and apply to other context of use. 
furthermore in order to be resilient to the fast technological development in ar it can be use to update the result as improvement arise in the performance level of the display device in a specific technology. 
interactive optimization of the resin transfer molding use a general purpose tool a case study. 
simulation tool for liquid composite molding process be a key to predict and solve manufacturing issue of composite material. 
numerical process be commonly use to analyse and predict mould fill consider also resin cure and exothermic reaction. 
these evaluation be usually perform through dedicated software tool that require highly specialized operator and purchasing cost. 
the present study relate to a multi objective optimization approach for evaluate the effect of different process parameter of the resin transfer mold rtm process use a multi purpose tool. 
start from a simple case useful for analyse the effect of mesh type and size on the simulation and then increase the complexity of the model virtual simulation have be validate through real test. 
afterward this approach have be use for the optimization of the rtm process for the manufacturing of an automotive component. 
gate position injection pressure and resin temperature have be optimize use finite volume analysis with a multi objective genetic algorithm. 
finally the parameter have be use in real experiment in order to validate the efficiency and the reliability of multi purpose tool in simulate rtm process. 
comparison of development methodology in web application. 
context web application development be at its peak due to the advance of technological trend and the constant dependence of the internet. 
as a result of the need of developer new development methodology have emerge. 
however that do not mean that company always implement an optimal development process instead there be several disadvantage present by an inadequate and not versatile methodology. 
objective the aim be to compare web development methodology base on dynamic feature present during the life cycle to identify their use relevance and characteristic. 
the process employing be an slr and field research to ecuadorian development company. 
method the method use be a systematic literature review slr for the identification of characteristic and process of development methodology. 
additionally a survey of ecuadorian web application developer be implement to assess the importance of use a method during the project. 
result the literature review exhibit as a result that uwe and oohdm have great flexibility than other methodology before dynamic environment during the web development process. 
on the other hand within field research be obtain that company use different software development method than those assess in the study hybrid methodology. 
however within the range of company use the compare methodology uwe be the most select. 
conclusion each methodology hold particular feature and employment environment which make they useful in specific condition. 
through the field research it be possible to conclude that most of the company use different methodology than the evaluate one thus the process be guide by hybrid method or model base on experience. 
on the other hand through the slr we identify uwe as the most suitable methodology for web development under dynamic environment such as the size of the company the need to modify the requirement or the knowledge that the development team have about the process. 
an empirically evaluate checklist for survey in software engineering. 
context over the past decade software engineering research have see a steady increase in survey base study and there be several guideline provide support for those willing to carry out survey. 
the need for auditing survey research have be raise in the literature. 
checklist have be use both to conduct and to assess different type of empirical study such as experiment and case study. 
objective to operationalize the assessment of survey study by mean of a checklist. 
to fulfill such goal we aim to derive a checklist from standard for survey research and far evaluate the appropriateness of the checklist in the context of software engineering research. 
method we systematically aggregate knowledge from 12 methodological study support survey base research in software engineering. 
we identify the key stage of the survey process and its recommend practice through thematic analysis and vote counting. 
we evaluate the checklist by apply it to exist survey and analyze the result. 
thereafter we gather the feedback of expert the survey author on our analysis and use the feedback to improve the survey checklist. 
result the evaluation provide insight regard limitation of the checklist in relation to its understanding and objectivity. 
in particular 19 of the 38 checklist item be improve accord to the feedback receive from expert. 
conclusion the propose checklist be appropriate for auditing survey report as well as a support tool to guide ongoing research with regard to the survey design process. 
a discussion on how to use the checklist and what its implication be for research practice be also provide. 
intelligent software engineering in the context of agile software development a systematic literature review. 
context intelligent software engineering ise refer to the application of intelligent technique to software engineering. 
we define an intelligent technique as a technique that explore datum from digital artifact or domain expert for knowledge discovery reasoning learning planning natural language processing perception or support decision making. 
objective the purpose of this study be to synthesize and analyze the state of the art of the field of apply intelligent technique to agile software development asd. 
furthermore we assess its maturity and identify adoption risk. 
method use a systematic literature review we identify 104 primary study result in 93 unique study. 
result we identify that there be a positive trend in the number of study apply intelligent technique to asd. 
also we determine that reasoning under uncertainty mainly bayesian network search base solution and machine learning be the most popular intelligent technique in the context of asd. 
in term of purpose the most popular one be effort estimation requirement prioritization resource allocation requirement selection and requirement management. 
furthermore we discover that the primary goal of apply intelligent technique be to support decision making. 
as a consequence the adoption risk in term of the safety of the current solution be low. 
finally we highlight the trend of use explainable intelligent technique. 
conclusion overall although the topic area be up and come for many area of application it be still in its infancy. 
so this mean that there be a need for more empirical study and there be a plethora of new opportunity for researcher. 
sensemake in critical situations and in relation to resilience a review. 
accident and incident such as the capsizing of the anchor handle vessel bourbon dolphin in 2007 and the unintended list of the drilling rig scarabeo eight in 2012 underline the need for address sensemake in safety critical situation in the maritime domain to reduce risk. 
sensemake and risk must be understand as a part of the organizational context of the incident. 
this paper present the result of a comprehensive qualitative literature review conduct to establish more knowledge on sensemake in the context of safety critical situation and on the relation between the concept of sensemaking and resilience. 
in the obtain literature sensemaking be use as a frame of reference for understand accident it be use in relation to critical situation or complex operation in general it be describe by some as a process create situational awareness and it be explain by other mainly in term of how it relate to resilience. 
sensemaking create the context for be resilient at the same time source of resilience help to make sense of the situation. 
few author provide explicit characteristic of sensemake in safety critical situation where discrepancy can be support by redundant system or by training to ensure the needed questioning attitude. 
there be a lack of literature regard sensemake in safety critical situation and in relation to resilience that also address important aspect of training and system design. 
analysis and estimation of human errors from major accident investigation report. 
risk analysis require proper consideration and quantification of the interaction between human organization and technology in high hazard industry. 
quantitative human reliability analysis approach require the estimation of human error probability heps often obtain from human performance datum on different task in specific context also know as performance shaping factor psfs. 
datum on human error be often collect from simulated scenario near miss report system and expert with operational knowledge. 
however these technique usually miss the realistic context where human error occur. 
the present research propose a realistic and innovative approach for estimate hep use datum from major accident investigation report. 
the approach be base on bayesian network use to model the relationship between performance shaping factor and human error. 
the propose methodology allow minimize the expert judgment of heps by use a strategy that be able to accommodate the possibility of have no information to represent some conditional dependency within some variable. 
therefore the approach increase the transparency about the uncertainty of the human error probability estimation. 
the approach also allow identify the most influential performance shaping factor support assessor to recommend improvement or extra control in risk assessment. 
formal verification and validation process be also present. 
an analytical framework for resilience exemplified with a real time operational center. 
integrated operation io be an ongoing change process in the oil and gas industry. 
new technological opportunity enable work in new way that involve an integration of onshore and offshore personnel. 
this paper analyze the result of two round of datum gathering in an onshore drilling support center in term of the development of resilience. 
the first round take place in 2004/2005 and the second in 2012. 
this study present a framework for the analysis of resilience and have use the case company as a mean of test the framework. 
our finding indicate that the support center have take a huge step in the direction of become more resilient. 
the drilling company have test a number of design and size of support center each of which have different pro and con. 
for the drilling discipline to develop resilience it be essential that the number of rig support by a center be not too large as they must not become involved in too many rig and drilling operation. 
our finding also indicate that the suggested framework provide a good overall picture of the development of resilience in the case company. 
the impact of weighting methods and behavioral attitudes on the weighting process in decision making. 
the determination of weight in decision make problem can be deduce as a complex process of preference formation. 
preference be expression of behavioral attitude and be affect by external circumstance such as risk and ambiguity. 
the objective of this research be to examine the impact of both the human factor and the weighting method on the weighting process in decision make problem. 
base on relevant literature a new methodology be propose and apply to identify with the use of a psychometric function the behavioral attitude of decision make analyst against risk and ambiguity. 
furthermore the examination of process relate feature such as the weighting method the weighting scale and the weighting problem s presentation provide additional knowledge on the understanding of the weighting process in decision make problem. 
thus an original survey be design aim at a the identification of the respondent attitudinal preference base on multiple personality test and b the elicitation of weight assignment through the use of different weighting task and subtask. 
the finding reveal that the weighting and their consistency be significantly affect by the elicitation method the nature of the weighting scale and the problem s frame. 
it be also interesting that the decision analyst behavioral trait in association with the problem s methodological aspect affect the weight assignment thus provide evidence for the potential to predict weighting in the decision making process. 
chilled air system and size effect in micro milling of nickel titanium shape memory alloys. 
although nickel titanium shape memory alloys niti sma be use in a variety of application due to their shape memory and superelasticity property their feature of high ductility temperature sensitivity and strong work hardening render these material difficult to machine. 
the viability of a new approach in improve the machinability through temperature control use chill air system application be investigate. 
differential scan calorimetry be use to characterise material response to thermal load. 
microstructure phase identification be evaluate with x ray diffraction. 
micro mill test be perform use chill air system and benchmarke to dry cutting and the use of minimum quantity lubricant mql. 
to augment lubrication chill air be also apply concurrently with mql. 
result indicate that the application of chill air reduce cut temperature and minimise burr height while their simultaneous application with mql far improve the machinability. 
further investigation be conduct to explore the influence of the ploughing mechanism on machine performance and product quality. 
the result point to high feed per tooth produce well outcome. 
this paper put forward a new hypothesis that the machinability could be improve by inhibit or lock in phase transformation through temperature control and optimise chip thickness one of the principal parameter of size effect. 
extract core requirement for software product line. 
software product line engineering sple be a promising paradigm for reuse knowledge and artifact among similar software product. 
however sple method and technique require a high up front investment and hence be profitable if several similar software product be develop. 
thus in practice adoption of sple commonly take a bottom up approach in which analyze the commonality and variability of exist product and transform they into reusable one term core asset be need. 
these time consume and error prone task call for automation. 
the literature partially deal with solution for early software development stage mainly in the form of variability analysis. 
we aim for further creation of core requirement reusable requirement that can be adapt for different software product. 
to this end we introduce an automate extractive method name corereq to generate core requirement from product requirement write in a natural language. 
the approach cluster similar requirement capture variable part utilize natural language processing technique and generate core requirement follow an ontological variability framework. 
focus on clone scenario we evaluate corereq through example and a control experiment. 
base on the result we claim that core requirement generation with corereq be feasible and usable for specify requirement of new similar product in clone scenario. 
a novel slide mode control for a class of stochastic polynomial fuzzy systems base on sos method. 
in this paper a novel robust controller for continuous stochastic polynomial fuzzy system be investigate. 
the aim of the propose method be to eliminate the restrictive assumption that the local input matrix bi must be uniform and the slide mode surface propose do not consider the stochastic perturbation which be require in most exist result. 
at the same time the propose method could handle the system with matched external disturbance. 
first a novel vector integral slide mode surface visms be construct accord to the basis matrix b(x. 
the slide mode surface parameter matrix k(x can be obtain through the provide sum of square condition. 
second by use an improve lyapunov method and a new propose lemma a novel slide mode control law be design to keep the state of the closed loop system on the visms approximately since the initial time. 
third a practical example and a numerical one be provide to illustrate the validity of the propose approach. 
mhtn modal adversarial hybrid transfer network for cross modal retrieval. 
cross modal retrieval have draw wide interest for retrieval across different modality such as text image video audio and three d model. 
however exist method base on a deep neural network often face the challenge of insufficient cross modal training datum which limit the training effectiveness and easily lead to overfitte. 
transfer learning be usually adopt for relieve the problem of insufficient training datum but it mainly focus on knowledge transfer only from large scale dataset as a single modal source domain such as imagenet to a single modal target domain. 
in fact such large scale single modal dataset also contain rich modal independent semantic knowledge that can be share across different modality. 
besides large scale cross modal dataset be very labor consuming to collect and label so it be significant to fully exploit the knowledge in single modal dataset for boost cross modal retrieval. 
to achieve the above goal this paper propose a modal adversarial hybrid transfer network mhtn which aim to realize knowledge transfer from a single modal source domain to a cross modal target domain and learn cross modal common representation. 
it be an end to end architecture with two subnetwork. 
first a modal share knowledge transfer subnetwork be propose to jointly transfer knowledge from a single modality in the source domain to all modality in the target domain with a star network structure which distill modal independent supplementary knowledge for promote cross modal common representation learn. 
second a modal adversarial semantic learning subnetwork be propose to construct an adversarial training mechanism between the common representation generator and modality discriminator make the common representation discriminative for semantic but indiscriminative for modality to enhance cross modal semantic consistency during the transfer process. 
comprehensive experiment on four widely use dataset show the effectiveness of mhtn. 
distribute event trigger estimation over sensor network a survey. 
an event trigger mechanism be of great efficiency in reduce unnecessary sensor sampling transmission and thus resource consumption such as sensor power and network bandwidth which make distribute event trigger estimation a promising resource aware solution for sensor network base monitoring system. 
this paper provide a survey of recent advance in distribute event trigger estimation for dynamical system operate over resource constrain sensor network. 
local estimate of an unavailable state signal be calculate in a distribute and collaborative fashion base on only invoke sensor datum. 
first several fundamental issue associate with the design of distribute estimator be discuss in detail such as estimator structure communication constraint and design method. 
second an emphasis be lay on recent development of distribute event trigger estimation that have receive considerable attention in the past few year. 
then the principle of an event trigger mechanism be outline and recent result in this subject be sort out in accordance with different event trigger condition. 
third application of distribute event trigger estimation in practical sensor network base monitoring system include distribute grid connect generation system and target tracking system be provide. 
finally several challenging issue worthy of further research be envision. 
topic base exploration and embedded visualizations for research idea generation. 
this work analyze sensemake framework and experiment with an iteratively design visual analysis tool to identify design implication for facilitate research idea generation use visualization. 
our tool thoughtflow structure and visualize literature collection use topic model to bridge the information gap between core activity during research ideation. 
to help user stay focused on a topic while discover relevant document we design and analyze usage pattern for two type of embed visualization that help determine document relevance while minimize distraction. 
we analyze how research ideation outcome and process differ when use thoughtflow and conventional search engine by augment insight base evaluation with concept map analysis. 
our result suggest that operation afford by topic model match well with later ideation stage when coherent topic have emerge but not with early stage when user be still rely heavily on individual keyword to gather background knowledge. 
we also present qualitative evidence that citation sparkline encourage more exploration of recommend reference and that a preference for paper thumbnail may depend on the consistency between the evidence and the current mental frame. 
cutensor tubal efficient primitives for tubal rank tensor learning operations on gpu. 
tensor be the cornerstone datum structure in high performance computing big datum analysis and machine learning. 
however tensor computation be compute intensive and the run time increase rapidly with the tensor size. 
therefore design high performance primitive on parallel architecture such as gpu be critical for the efficiency of ever grow datum processing demand. 
exist gpu basic linear algebra subroutine blas library e.g. nvidia cublas do not provide tensor primitive. 
researcher have to implement and optimize their own tensor algorithm in a case by case manner which be inefficient and error prone. 
in this paper we develop the cutensor tubal library of seven key primitive for the tubal rank tensor model on gpu t fft inverse t fft t product t svd t qr t inverse and t normalization. 
cutensor tubal adopt a frequency domain computation scheme to expose the separability in the frequency domain then map the tube wise and slice wise parallelism onto the single instruction multiple thread simt gpu architecture. 
to achieve good performance we optimize the datum transfer memory access and design the batched and stream parallelization scheme for tensor operation with data independent and data dependent computation pattern respectively. 
in the evaluation of t product t svd t qr t inverse and t normalization cutensor tubal achieve maximum 16.91 \time 27.03 \time 38.97 \time 22.36 \time 15.43 \times$16.91,27.03,38.97,22.36,15.43 speedup respectively over the cpu implementation run on dual 10 core xeon cpu. 
two application namely t svd base video compression and low tubal rank tensor completion be test use our library and achieve maximum 9.80 \times$9.80 and 269.26 \times$269.26 speedup over multi core cpu implementation. 
a novel method for closed loop topology modification of helical gear use internal meshing gear honing. 
the internal meshing honing process allow excellent machining efficiency for the tooth crowning of helical gear. 
a gear with double crown tooth flank be well than that with longitudinal crown tooth flank because the tooth edge contact be prevent and the contact load distribution be improve more effectively. 
this study propose a numerical approach for the closed loop topology modification on cylindrical gear that have double crown and anti twist tooth flank for a cnc internal meshing gear honing machine. 
ad ditional motion be add in form of polynomial to three machine axis include the radial feed of hone wheel the swivel angle of hone wheel and the rotational angle of work gear. 
a sensitivity matrix combine with the levenberg marquardt lm algorithm be employ to obtain the polynomial coefficient of additional motion for desire tooth sur face. 
the amount of crowning on the work gear tooth surface can be specify use the propose method. 
the result in the present numerical example verify the advantage of the propose method. 
c 2019 elsevier ltd. 
all right reserve. 
modeling and experimental assessment of the emi characteristics of switching converters with power semiconductor filter. 
an input filter technology name power semiconductor filter psf have be propose recently. 
its operate principle be base on use a series pass device spd to profile the wave shape and magnitude of the input current of converter. 
the voltage across the spd be regulate around the knee point of the current voltage characteristic of the spd to minimize the power dissipation of the spd. 
this paper report the conduct electromagnetic interference emi performance of the converter with the psf. 
to suppress differential mode dm emi a fast current regulation circuit be propose to tightly regulate the current through the spd. 
to suppress common mode cm emi a single cm noise bypass capacitor be propose. 
detailed mathematical model for describe the frequency response of the spd and main component in the drive network be formulate. 
a set of selection guideline for the component will be give. 
the derive model will be validate by compare the theoretical prediction with the measurement result of a 100 w 90 264 vac led driver use a buck boost converter. 
result reveal that the psf reduce the dm noise level by 47.47dbv. 
the cm noise level be reduce by 21.4dbv with the bypass capacitor. 
an integrate circuit for the controller be illustrate to demonstrate the feasibility of reduce the form factor of the filter section. 
an online global fault tolerant control strategy for symmetrical multiphase machines with minimum losses in full torque production range. 
the high fault tolerant ability of multiphase drive be favor in safety critical application. 
under open phase fault to guarantee ripple free torque stator current reference should be revise. 
in this paper a global fault tolerant control strategy base on an online current optimization algorithm ocoa be propose for symmetrical multiphase machine smms to achieve both the maximal torque production range tpr and minimal stator winding loss under all possible opf. 
the ocoa can calculate the minimum loss current reference cover the full tpr online regardless of the number and location of faulty phase. 
with the online optimize reference ripple free torque and minimum loss in full tpr can be achieve under faulty condition. 
additionally the propose method can be adopt to smm with arbitrary phase number. 
simulation and experiment demonstrate that the online optimization can be complete in a short time meanwhile achieve the same tpr and loss reduction compare with an exist offline strategy base on prestore look up table. 
due to the flexible online calculation ability and excellent extensibility the propose method be especially favor in modular multiphase converter and machine with high phase number where converter can adapt to machine with different phase number or the number of possible faulty condition can be extremely large. 
hydrogen loss in fuel station operation. 
this paper describe an engineering approach for hydrogen accounting from production to dispense at cal state los angeles hydrogen research and fueling facility equip with an electrolyzer for on site production. 
particularly the accounting process have be carry out by take an in depth look at current practice and database and its analysis have be base on datum from quarterly report of hydrogen production and dispense related parameter and from its datum acquisition system. 
it be describe how the station address this analysis investigate several station area. 
follow there be an assessment of the possible critical point flank by consideration calculation mathematical modeling and analysis of the database. 
the analysis lead to a marked improvement on the station operation know how. 
for most of the analyzed month the current average percentage of loss be find to be between two and 10 whereas before it be between 30 and 35. 
this current range of percentage two 10)% include all experiment do defuele the buffer tank reboot the dispenser vent the line the uncertainty of the mass flow meter inside the dispenser five and the inherent uncertainty of faraday s law for hydrogen production estimate. 
among all area analyze maintenance activity reveal themselves as the most critical one lead to datum mismatching in hydrogen accounting. 
the paper aim also to provide a guideline with recommend practice base on our experience deduce for station operator and builder include several step for leakage monitoring prevention and troubleshoot. 
c 2019 elsevier ltd. 
all right reserve. 
the impact of green credit policy on manufacturer effort to reduce supplier pollution. 
green credit policy gcp in south korea be an environmentally friendly regulation that enable manufacturer to reduce pollution by cooperate with supplier. 
the main objective of this study be to investigate the impact of the gcp on manufacturer effort to reduce pollution in the supply chain. 
this study adopt an optimal control model that reflect the gcp s incentive scheme as well as consumer environmental awareness. 
a numerical analysis be illustrate to demonstrate the applicability of our model. 
we find that manufacturer can create additional value by reduce their supplier pollution at the desirable level. 
furthermore our finding suggest that manufacturer should strengthen their capability to reduce pollution to obtain more incentive under the gcp. 
c 2019 elsevier ltd. 
all right reserve. 
toward a holistic view on lean sustainable construction a literature review. 
the need for sustainable build environment be press an urgency that span environmental economic and social value of sustainability. 
since late 1980s the lean philosophy have be adopt in the construction sector with a focus on efficiency predominantly as a function of economic competence. 
more recently however the lean principle and practice have be revisit and increasingly use to create and preserve social and environmental value as well. 
the result be a grow but disperse body of knowledge on sustainability and lean construction and hence equivocal about how lean contribute to sustainability. 
by mean of a systematic literature review slr base on 118 journal article from 1998 to 2017 this article aim to provide a comprehensive understanding of how lean helps achieve and maintain sustainability in construction sector. 
the finding be structure into a holistic framework which underline a multidimensional approach toward sustainability focus on stakeholder across various construction phase while simultaneously be heedful of concern regard people planet and profit. 
it become clear that the current body of knowledge be mainly skew toward economic value which call for more research in the social and environmental aspect of construction. 
this study assemble a palette of exist good practice base on which scholar and practitioner can balance their effort across three dimension of sustainability. 
moreover it identify several under research area of lean sustainable construction that have the potential to be expand in by future researcher. 
c 2019 the authors. 
publish by elsevier ltd. 
this be an open access article under the cc by nc nd license http://creativecommons.org/licenses/by nc nd/4.0/. 
automatic detection of erythemato squamous disease use pso svm base on association rule. 
in this paper we develop a diagnosis model base on particle swarm optimization pso support vector machine svm and association rule ar to diagnose erythemato squamous disease. 
the propose model consist of two stage first ar be use to select the optimal feature subset from the original feature set then a pso base approach for parameter determination of svm be develop to find the good parameter of kernel function base on the fact that kernel parameter set in the svm training procedure significantly influence the classification accuracy and pso be a promising tool for global searching. 
experimental result show that the propose ar_pso svm model achieve 98.91 classification accuracy use 24 feature of the erythemato squamous disease dataset take from uci university of california at irvine machine learning database. 
therefore we can conclude that our propose method be very promising compare to the previously report result. 
c 2012 elsevier ltd. 
all right reserve. 
startrack the next generation of product review management tools. 
online product review be increasingly be recognize as a gold mine of information for determine product and brand positioning and more and more company look for way of dig this gold mine for nugget of knowledge that they can then bring to bear in decision making. 
we present a software system call startrack that automatically rate a product review accord to a number of star accord to how positive it be. 
in other word give a text only review i.e. one with no explicit star rating attach startrack attempt to guess the star rating that the reviewer would have attach to the review. 
startrack be thus useful for analyse unstructured word of mouth on product such as the comment and review about product that be to be find in spontaneous discussion forum such as newsgroup blog and the like. 
startrack be base on machine learning technology and as such do not require any re program for port it from one product domain to another. 
base on the star rating it attribute to review startrack can subsequently rank the product in a give set accord to how favourably they have be review by consumer. 
we present control experiment in which we evaluate on two large set of product review crawl from the web the accuracy of startrack at i star rating review and ii rank the review product base on the automatically attribute star rating. 
safeguard labour in distant factory health and safety governance in an electronics global production network. 
one of the many concern over worker in the electronics industry be their health and safety condition in factory. 
lead firm in the electronic industry use a variety of self regulatory private standard and code of conduct to govern health and safety in factory of their supplier. 
global supplier in turn implement these private measure within their firm which include manufacture site locate in distant location. 
how these health and safety governance system be implement across border in the electronic industry gpn be the focus of this paper. 
the discussion and analysis connect the gpn framework with the governmentality literature to understand how private governance system be implement from a micro lens of day to day action of health and safety manager. 
it aim to show how the self regulatory nature of standard and code of conduct produce self disciplinary effect on safety and health manager which enable the spread of corporate lead governance programme throughout a global industry. 
the analysis be base on a case study of print circuit board manufacturing site of supplier to hewlett packard locate in penang malaysia. 
c 2012 elsevier ltd. 
all right reserve. 
a novel visual modeling system for time series forecast application to the domain of hydrology. 
accurate and reliable forecast of key hydrological variable such as stream flow be of importance due to their profound impact on real world water resource application. 
data drive method have prove their applicability to model complex and non linear hydrological process. 
this paper present a novel visual modeling system that have be develop to overcome the problem involve in implementation of data drive model for hydrological forecast use conventional programming language problem such as the effort and skill need to program the model the lack of reusability of exist model and the lack of share tool to perform tedious task such as preprocesse datum. 
the system provide an integrate visual modeling environment within which user be able to graphically design and verify specific forecasting model for particular problem without write code. 
a set of popular data drive model be offer by the system. 
plug in model create by wrap exist code be also allow to run within the system due to the system s open architecture. 
the system s feasibility and capability be demonstrate through a case study of forecast one day ahead flow in a river basin locate in china. 
the encouraging simulation result show that the system can simplify the process of implement hydrological forecast. 
support system of system hazard analysis use multi agent simulation. 
when engineer create a safety critical system they need to perform an adequate hazard analysis. 
for systems of systems soss however hazard analysis be difficult because of the complexity of sos and the environment they inhabit. 
traditional hazard analysis technique often rely upon static model of component interaction and have difficulty explore the effect of multiple coincident failure. 
they can not be rely on therefore to provide adequate hazard analysis of sos. 
this paper present a hazard analysis technique simhazan that use multi agent modelling and simulation to explore the effect of deviant node behaviour within a sos. 
it define a systematic process for develop multi agent model of sos start from exist model in the modaf architecture framework and proceed to implement simulation model. 
it then describe a process for run these simulation in an exploratory way bound by estimate probability. 
this process generate extensive log of simulated event in order to extract the cause of accident from these log this paper present a tool support analysis technique that use machine learning and agent behaviour trace. 
the approach be evaluate by comparison to some explicit requirement for sos hazard analysis and by apply it to a case study. 
base on the case study it appear that simhazan have the potential to reveal hazard that be difficult to discover when use traditional technique. 
c 2012 elsevier ltd. 
all right reserve. 
a control strategy with motion smoothness and machining precision for multi axis coordinate motion cnc machine tool. 
the advanced manufacture technology require that multi axis coordinate motion computer numerical control cnc machine tool have the capability of high smoothness and high precision. 
at present the study of the motion smoothness mainly concentrate on the acceleration and deceleration control method and the look ahead process of velocity planning in the interpolation stage. 
the control strategy of the contouring error mainly focus on track error control cross coupling control and optimal control. 
in order to improve the motion smoothness and contouring precision for multi axis high speed cnc machine tool a multi axis modify generalize predictive control approach be present in this paper. 
in the control strategy the estimation model of track error contouring error velocity error and acceleration error be structure separately. 
a new improve quadratic performance index be propose to guarantee the minimum of these error. 
generalize predictive control be also introduce a multi axis generalize predictive control model be deduce for motion smoothness and machining precision for multi axis coordinate motion cnc system and an approve multi axis generalize predictive controller base on the model be design in this paper. 
the propose predict control approach be evaluate by simulation and experiment of circular noncircular and space line trajectory respectively. 
these simulative and experimental result demonstrate that the propose control strategy can significantly improve the motion smoothness and contouring precision. 
therefore the new position control method can be use for the servo control system of multi axis coordinate motion cnc system which increase motion smoothness and machining precision of cnc machine tool. 
automatic knowledge base recognition of low level task in ophthalmological procedure. 
surgical process model spms have recently be create for situation aware computer assist system in the operating room. 
one important challenge in this area be the automatic acquisition of spm. 
the purpose of this study be to present a new method for the automatic detection of low level surgical task that is the sequence of activity in a surgical procedure from microscope video image only. 
the level of granularity that we address in this work be symbolize by activity formalize by triplet action surgical tool anatomical structure. 
use the result of our late work on the recognition of surgical phase in cataract surgery and base on the hypothesis that most activity occur in one or two phase only we create a light weight ontology formalize as a hierarchical decomposition into phase and activity. 
information concern the surgical tool the area where tool be use and three other visual cue be detect through an image base approach and combine with the information of the current surgical phase within a knowledge base recognition system. 
know the surgical phase before the activity recognition allow supervised classification to be adapt to the phase. 
multiclass support vector machines be choose as a classification algorithm. 
use a dataset of 20 cataract surgery and identify 25 possible pair of activity a frame by frame recognition rate of 64.5 be achieve with the propose system. 
the addition of human knowledge to traditional bottom up approach base on image analysis appear to be promise for low level task detection. 
the result of this work could be use for the automatic indexation of post operative video. 
on line prediction of micro turn multi response variable by machine vision system use adaptive neuro fuzzy inference system anfis. 
in this paper a new attempt have be make in the area of tool base micromachining for automate non contact and flexible prediction of quality response such as average surface roughness r a tool wear ratio twr and metal removal rate mrr of micro turn miniaturized part through a machine vision system mvs which be integrate with an adaptive neuro fuzzy inference system anfis. 
the image of machine surface grab by the mvs could be extract use the algorithm develop in this work to get the feature of image texture average gray level g a. 
this work present an area base surface characterization technique which apply the basic light scattering principle use in other optimal optical measurement system. 
these principle be apply in a novel fashion which be especially suitable for in process prediction and control. 
the main objective of this study be to design an anfis for estimation of r a twr and mrr in micro turning process. 
cut speed s feed rate f depth of cut d g a be take as input parameter and r a twr mrr as the output parameter. 
the result obtain from the anfis model be compare with experimental value. 
it be find that the predict value of the response be in good agreement with the experimental value. 
msdetector toward a standard computational tool for dna microsatellite detection. 
microsatellite mss be dna region consist of repeat short motif(s. 
mss be link to several disease and have important biomedical application. 
thus researcher have develop several computational tool to detect mss. 
however the currently available tool require adjust many parameter or depend on a list of motif or on a library of know mss. 
therefore two laboratory analyze the same sequence with the same computational tool may obtain different result due to the user adjustable parameter. 
recent study have indicate the need for a standard computational tool for detect mss. 
to this end we apply machine learn algorithm to develop a tool call msdetector. 
the system be base on a hide markov model and a general linear model. 
the user be not obligate to optimize the parameter of msdetector. 
neither a list of motif nor a library of know mss be require. 
msdetector be memory and time efficient. 
we apply msdetector to several specie. 
msdetector locate the majority of mss find by other widely use tool. 
in addition msdetector identify novel mss. 
furthermore the system have a very low false positive rate result in a precision of up to 99. 
msdetector be expect to produce consistent result across study analyze the same sequence. 
predict the accuracy of multiple sequence alignment algorithm by use computational intelligent technique. 
multiple sequence alignment msa have become one of the most studied approach in bioinformatic to perform other outstanding task such as structure prediction biological function analysis or next generation sequence. 
however current msa algorithm do not always provide consistent solution since alignment become increasingly difficult when deal with low similarity sequence. 
as widely know these algorithm directly depend on specific feature of the sequence cause relevant influence on the alignment accuracy. 
many msa tool have be recently design but it be not possible to know in advance which one be the most suitable for a particular set of sequence. 
in this work we analyze some of the most use algorithm present in the bibliography and their dependence on several feature. 
a novel intelligent algorithm base on least square support vector machine be then develop to predict how accurate each alignment could be depend on its analyzed feature. 
this algorithm be perform with a dataset of 2180 msa. 
the propose system first estimate the accuracy of possible alignment. 
the most promising methodology be then select in order to align each set of sequence. 
since only one select algorithm be run the computational time be not excessively increase. 
error correction modelling of wind speed through hydro meteorological parameters and mesoscale model a hybrid approach. 
accurate estimation of wind speed be essential for many hydrological application. 
one way to generate wind velocity be from the fifth generation penn ncar mm5 mesoscale model. 
however there be a problem in use wind speed datum in hydrological process due to large error obtain from the mesoscale model mm5. 
the theme of this article have be focus on hybridization of mm5 with four mathematical model two regression models  the multiple linear regression mlr and the nonlinear regression nlr and two artificial intelligence model the artificial neural network ann and the support vector machine svm in such a way so that the properly model scheme reduce the wind speed error with the information from other mm5 derive hydro meteorological parameter. 
the forward selection method be employ as an input variable selection procedure to examine the model generalization error. 
the input variable of this statistical analysis include wind speed temperature relative humidity pressure solar radiation and rainfall from the mm5. 
the propose conjunction structure be calibrate and validate at the brue catchment southwest of england. 
the study result show that relatively simple model like mlr be useful tool for positively alter the wind speed time series obtain from the mm5 model. 
the svm base hybrid scheme could make a well robust modelling framework capable of capture the non linear nature than that of the ann base scheme. 
although the propose hybrid scheme be apply on error correction modelling in this study there be further scope for application in a wide range of area in conjunction with any high end model. 
do industry self regulation reduce pollution responsible care in the chemical industry. 
self regulation program in which industry association set membership code beyond government regulation be prevalent despite scarce evidence on their effectiveness. 
we examine responsible care rc in the us chemical manufacturing sub sector whose membership code include pollution prevention use our author construct panel database of 3,278 plant own by 1,759 firm between 1988 and 2001. 
we apply two set of instrumental variable to address a plant s parent firm s self selection into the program use i the characteristic of other plant belong to the same firm in our multi plant sample and ii firm participation in the industry association before the establishment of rc and industry level rc participation in our full sample. 
we find that on average plant own by rc participate firm raise their toxicity weight pollution by 15.9 relative to statistically equivalent plant own by non rc participate firm. 
this estimate increase be large relative to the yearly four reduction in pollution among all plant in our sample between 1988 and 2001. 
moreover rc raise plant level pollution intensity by 15.1. 
these result caution against reliance on self regulation program model on the pre 2002 rc program that do not require third party certification and in those sector that lack independent third party certification. 
experimental comparison between a counter rotate axial flow fan and a conventional rotor stator stage. 
base on the requirement of energy consumption level and weight and dimension restriction compact axial machine be highly demand in many industrial field. 
the counter rotate axial flow fan could be a promising way to achieve these requirement. 
because of the reduction of rotational speed and a well homogenization of the flow downstream of the rear rotor these machine may have very good aerodynamic performance. 
however they be rarely use in subsonic application mainly due to poor knowledge of the aerodynamic in the mix area between the two rotor where very complex structure be produce by the interaction of highly unsteady flow. 
the purpose of the present work be to compare the global performance static pressure rise and static efficiency and the wall pressure fluctuation downstream of the first rotor for three different stage operate at the same point a single subsonic axial flow fan a conventional rotor stator stage and a counter rotate system that have be design with in house tool. 
the counter rotate system allow large saving of energy with respect to the other two system for low rotation rate and by adjust the distance between the two rotor a solution with comparable wall pressure fluctuation level for the three system be find. 
computer support programming of control system sinumerik 840d for e learning education. 
modern information and communication technology bring into the educational system the massive change in the whole world. 
the expansion of computer technique and new computer aid technology give very power tool for education enhancement to university teacher. 
the paper be focus on actual information and communication technology implementation in e learn educational process at the faculty of mechanical engineering university of zilina department of automation and production systems for the study branch automation of production systems. 
the article present apply aid method course and educational software from the area of technological production preparation give the current information about solution of task specify for the field of cnc machine programming of the control system sinumerik 840d.. 
the speech recognition virtual kitchen. 
this paper describe the speech recognition virtual kitchen environment which have the goal to promote community sharing of research technique foster innovative experimentation and provide solid reference system as a tool for education research and evaluation with a focus on but not restrict to speech and language research. 
the core of the research infrastructure be the use of virtual machines vms that provide a consistent environment for experimentation. 
we liken the virtual machine to a kitchen because they provide the infrastructure into which one can install appliance e.g. speech recognition tool kit recipe script for create state of the art system and ingredient language data. 
a web base community platform complement the vm to allow physically disconnect user to jointly explore vm learn from each other and collaborate in research. 
in this demo we present initial vm that be mostly use for teach class at carnegie mellon and ohio state university and solicit feedback for an initial hub  style web site. 
simulation of distortion due to machining of thin walled components. 
the distortion of component be strongly related to the residual stress state induce by manufacture process like heat treatment form or machining. 
each process step affect the initial stress state of the follow process step. 
when remove material during machining the component establish a new stress equilibrium. 
stress be redistribute cause the component geometry to adjust. 
especially for thin walled component distortion potential be high. 
gain knowledge about the influence of initial load and the release of distortion during machine process help to increase product quality and efficiency. 
the influence of different initial stress state and different machining parameter on the amount of distortion be examine use both fem simulation and experiment. 
a thin walled t profile make of aluminum alloy al 7075 t6 serve as test speciman. 
a bend process apply a load to initialize a repeatable and define residual stress state. 
a groove be machine afterwards into the plastically deform work piece to trigger stress redistribution and a release of distortion. 
different load with 35 to 45 kn and two different geometry of a groove be use. 
the amount of initial stress have a significant effect on the distortion potential which could be quantify in the study. 
simulation show the same behavior as the experiment and the result match very well especially for a high load. 
c 2013 the authors. 
publish by elsevier b.v.. 
study of the influences of laser parameters on laser assisted machining process. 
hybrid machining process use additional energy source such as laser assist machine lam have increase considerably during the last year. 
the benefit of lam for reduce tool wear and cut force be well know especially for superalloy. 
however optimal machining result depend on both the laser parameter and the cutting process parameter. 
it be difficult to find optimal lam setting due to the complexity of the influence parameter and their mutual interaction. 
the aim of the paper be to characterize the laser heating process by detect how the individual lam parameter influence work temperature heat affect zone haz extension and laser track width. 
a reliable application require a localized and control continuous heating of the material within the machining zone directly in front of the tool contact area. 
in this research statistical and technological knowledge be fully involve in the experimental activity. 
therefore a statistical study base on design of experiment doe be carry out in order to investigate the effect of laser process parameter and their interaction. 
in practice two level fractional factorial design and analysis of variance anova be apply. 
the follow process parameter be examine laser power scan speed defocus the distance between focal point and workpiece surface temperature control by pyrometer and surface roughness. 
furthermore a finite element fe model be develop base on experimental result in order to find out the optimal parameter for model the laser heating process. 
future fe simulation of the laser assist cut process will be carry out use this model of the move laser source. 
c 2013 the authors. 
publish by elsevier b.v.. 
modeling and simulation of the electrochemical machining ecm material removal process for the manufacture of aero engine components. 
in order to increase the efficiency of jet engine hard to machine nickel base and titanium base alloy be in common use for aero engine component such as blade and blisk blade integrate disk. 
here electrochemical machining ecm be a promising alternative to mill operation. 
due to lack of appropriate process modeling capability beforehand still knowledge base and a cost intensive cathode design process be pass through. 
therefore this paper present a multi physical approach for model the ecm material removal process by couple all relevant conservation equation. 
the result simulation model be validate by the example of a compressor blade. 
finally a new approach for an inverted cathode design process be introduce and discuss. 
c 2013 the authors. 
publish by elsevier b.v.. 
local approach of wear in drill ti6al4v cfrp for stack modelling. 
the drilling of stack make of carbon fibre composite material cfrp and metal aluminium or titanium alloy be an operation more and more common in aerospace industry. 
however this critical machining operation be not yet fully control. 
the knowledge of the cut force and the wear phenomenon be an important issue to assure a good quality of the hole. 
the study on the stack drilling usually do not break down the operation on both material cfrp and metallic alloy which do not allow a full understanding of the impact of each part of the stack on the behaviour of tool especially regard its wear. 
nevertheless a study of the drilling of a single material do not lead we to the understanding of the stack drilling because of the influence of a piece toward another. 
this study firstly discuss the drilling of each material of the stack titanium alloy ti6al4v and cfrp individually. 
the impact of the local wear be assess by investigate the variation of the cut force along the cutting edge the computation be make by the decomposition of the thrust force and the torque during the progressive engagement of the drill point. 
furthermore this study explain the drilling of an alternation of titanium alloy and cfrp in order to model its effect on a stack while allow the analysis of the wear for each material. 
c 2013 the authors. 
publish by elsevier b.v.. 
reliability assessment of cut tool life base on advanced approximation method. 
cut tool reliability influence the whole manufacturing efficiency. 
however in most case the same cutting tool may be use for different operation with different processing parameter make thus difficult to estimate the remain life of the tool precisely. 
the present study propose a new reliability estimation approach to the cutting tool base on advanced approximation method. 
reliability base design operation be a technique extensively employ for problem of structural reliability assess the performance of critical infrastructure under stochastic design parameter. 
due to the complexity of machine process which involve a significant number of hidden or difficult to statistically model variable advanced approximation method such as response surface or surrogate modelling method may be apply start from a few sample point obtain through fundamental experiment and extend they to model able to predict estimate the value of control value indicator as a function of the key design variable often refer to as limit state. 
having construct such model and accord to the level of probability that need to be measure different reliability analysis method can be employ such as monte carlo simulations or first order reliability methods form. 
in the present study these two reliability analysis method be assess for estimate the reliability of cut tool. 
c 2013 the authors. 
publish by elsevier b.v.. 
modelling of process force in broach inconel 718. 
broaching be the standard machining process for fir tree slot in turbine disc. 
due to the fact that inconel 718 turbine disc belong to the safety critical component of aero engine there be high demand on dimensional accuracy and surface quality. 
the cut parameter as well as tool fixture and machine tool be critical factor to fulfill these high requirement. 
within the next year the process have to be design for the need of new turbine disc geometry disc material and tool material. 
therefore detailed knowledge about process force be an essential prerequisite. 
modern 2d fem simulation enable calculation of the thermomechanical load collective in the chip tool interface. 
a 2d chip formation model of the broaching process have be design to calculate cut force for process relevant parameter as the rake angle rise per tooth and cut speed. 
depend on these parameter a multivariate regression model have be develop. 
the chip formation and the multivariate regression model have be validate on a test bench for fundamental cutting investigation simultaneous process force be measure and high speed film be record. 
this paper thoroughly discuss the result and evaluate the application potential. 
c 2013 the authors. 
publish by elsevier b.v.. 
monitoring and control of manufacturing process a review. 
online processing optimization through adaptive control can provide significant advance in process efficiency tool life and product quality. 
this paper describe conventional and enhance method for the monitoring and control of manufacturing process. 
the difference between the available method architecture and the correspond equipment be identify and evaluate. 
a systematic analysis of current and future system and their component be make focus on adaptive control system implementation into manufacturing process. 
c 2013 the authors. 
publish by elsevier b.v.. 
microcutte force prediction by mean of a slip line field force model. 
mechanical micromachining be a very flexible and widely exploit process but its knowledge should still be improve since several typical phenomenon play a role on the microscale chip removal e.g. 
minimum chip thickness effect microstructure influence on cut force stable build up edge etc. 
several model have be develop to describe the machining process but only some of they take into account a round edge tool which be a typical condition in micromachine. 
among these model the slip line field model develop by waldorf for the macroscale allow to separately evaluate shear and plough force component in orthogonal cutting condition therefore it be suitable to predict the cut force when a large ploughing action occur as in micromachine. 
the present work aim at objectively verify the cutting and feed force prediction performance of the waldorf model within typical microscale cutting condition uncut chip thickness low than 50 mu m and comparable in size to cut edge radius in its original version and in a modify version consider the partial effective rake angle. 
a suitable set up especially design for microturne condition have be use in this research to measure force and chip thickness. 
test have be carry out on c38500 brass cuzn39pb3 with different cutting speed and different ratio between uncut chip thickness and cut edge radius. 
c 2013 the authors. 
publish by elsevier b.v.. 
use multi agent systems to pursue autonomy with automated components. 
human have use tool to transform raw resource into value output ever since society harness fire. 
the type of tool amount of effort and form of energy require depend on the output or object be create. 
as tool evolve into machine they enhance operator productivity. 
hence industry continue to invest heavily in machine to assist people to do more with less physical control and/or interaction. 
this involve automate function previously complete manually. 
taylorism and the hawthorn experiment all contribute to optimise industrial output and value engineer continue to promote a mechanized workforce in order to minimise business variation in human performance and their behaviour. 
researcher have also pursue this goal use computational intelligence ci technique. 
this process of transform cognitive functionality into machine actionable form have encompass many career. 
machine intelligence mi be become more aspirational with artificial intelligence ai enable the achievement of numerous goal. 
more recently multi agent systems mass have be employ to provide a flexible framework for research and development. 
these framework facilitate the development of component interoperability with coordination and cooperation technique need to solve real world problem. 
however problem typically manifest in complex dynamic and often hostile environment. 
base on the effort to seek or facilitate human like decision make within machine it be clear that further research be require. 
this paper discuss one possible avenue. 
it involve future research aim at achieve a cognitive sub system for use on board platform. 
the framework be introduce by describe the human machine relationship follow by the theoretic background into cognitive architecture and a conceptual mechanism that could be use to implement a virtual mind. 
one which could be use to improve automation achieve great independence and enable more autonomous behaviour within control system. 
c 2013 the authors. 
publish by elsevier b.v.. 
scale out beyond map reduce. 
the amount and variety of datum be collect in the enterprise be grow at a staggering pace. 
the default now be to capture and store any and all datum in anticipation of potential future strategic value and vast amount of datum be be generate by instrument key customer and system touch point. 
until recently datum be gather for well define objective such as auditing forensic reporting and line of business operation now exploratory and predictive analysis be become ubiquitous. 
these difference in datum heterogeneity scale and usage be lead to a new generation of datum management and analytic system where the emphasis be on support a wide range of large dataset to be store uniformly and analyze seamlessly use whatever technique be most appropriate include traditional tool like sql and bi and new tool for machine learning. 
these new system be necessarily base on scale out architecture for both storage and computation. 
the term big data and datum science be often use to refer to this class of system and application. 
hadoop have become a key building block in the new generation of scale out system. 
early version of analytic tool over hadoop such as hive and pig for sql like query be implement by translation into map reduce computation. 
this approach have inherent limitation and the emergence of resource manager such as yarn and mesos have open the door for new analytic tool to bypass the map reduce layer. 
this trend be especially significant for iterative computation such as graph analytic and machine learning for which map reduce be widely recognize to be a poor fit. 
in fact the website of the machine learn toolkit apache mahout explicitly warn about the slow performance of some of the algorithm on hadoop. 
in this talk i will examine this architectural trend and argue that resource manager be a first step in re factor the early implementation of map reduce and that more work be need if we wish to support a variety of analytic tool on a common scale out computational fabric. 
i will then present reef which run on top of resource manager like yarn and provide support for task monitoring and restart datum movement and communication and distribute state management. 
finally i will illustrate the value of use reef to implement iterative algorithm for graph analytic and machine learning. 
a time dependent enhanced support vector machine for time series regression. 
support vector machines svm be a lead tool in machine learning and have be use with considerable success for the task of time series forecasting. 
however a key challenge when use svm for time series be the question of how to deeply integrate time clement into the learning process. 
to address this challenge we investigate the distribution of error in the forecast deliver by standard svm. 
once we identify the sample that produce the large error we observe their correlation with distribution shift that occur in the time series. 
this motivate we to propose a time dependent loss function which allow the inclusion of the information about the distribution shift in the series directly into the svm learning process. 
we present experimental result which indicate that use a time dependent loss function be highly promising reduce the overall variance of the error as well as deliver more accurate prediction. 
aid intrusion analysis use machine learning. 
intrusion analysis the process of comb through ids alert and audit log to identify real successful and attempt attack remain a difficult problem in practical network security defense. 
the major contributing cause to this problem be the high false positive rate in the sensor use by ids system to detect malicious activity. 
the goal of our work be to examine whether a machine learn classifier can help a human analyst filter out non interesting scenario report by an ids alert correlator so that analyst time can be save. 
this research be conduct in the open source snips intrusion analysis framework. 
throughout observe the output of snips run on our departmental network we find that an analyst would need to perform repetitive task in prune out the false positive in the correlation graph produce by it. 
we hypothesize that such repetitive task can yield limited label datum that can enable the use of a machine learning base approach to prune snips output base on the human analyst feedback much similar to spam filter that can learn from user past judgment to prune email. 
our goal be to classify the correlation graph produce from snip into interesting and non interesting where interesting mean that a human analyst would want to conduct further analysis on the event. 
we spend significant amount of time manually label snips output correlation base on this criterion and build prediction model use both supervised and semi supervised learning approach. 
our experiment reveal a number of interesting observation that give insight into the pitfall and challenge of apply machine learning in intrusion analysis. 
the experimentation result also indicate that semi supervised learning be a promising approach towards practical machine learning base tool that can aid human analyst when a limited amount of label datum be available. 
ensemble feature selection method for a well regularization of the lasso estimate in p n gene expression dataset. 
the problem of variable selection from a large number of candidate predictor have recently be address in the machine learning of bioinformatics field. 
this be due to advance in high throughput microarray technique such as affymetrix genechips and illumina microarray that allow for study thousand of gene in a single experiment. 
however the resultant datum from such genomic tool suffer from an p n problem where the number of gene p to be examine be much large than the number of sample n. 
in such a model selection the learning be consider hard and the goal be to achieve accurate prediction from the infer model alongside with their interpretability. 
towards this goal this work will experiment with feature selection method and show how to improve the choice of the tuning parameter s in the lasso estimate feature selection method by add an extra layer of filter feature selection method to the lasso estimate path when learn from p n gene expression dataset. 
the result show that when the lasso estimate be ensemble with filter feature selection method the prediction accuracy for the choose predictor for each target variable have improve. 
method and applications for distance based ann training. 
feature learning have the aim to take away the hassle of hand design feature for machine learning task. 
since the feature design process be tedious and require a lot of experience an automate solution be of great interest. 
however an important problem in this field be that usually no objective value be available to fit a feature learning function to. 
artificial neural networks be a sufficiently flexible tool for function approximation to be able to avoid this problem. 
we show how the error function of an ann can be modify such that it work solely with objective distance instead of objective value. 
we derive the adjust rule for backpropagation through network with arbitrary depth and include practical consideration that must be take into account to apply difference base learn successfully. 
on all three benchmark dataset we use linear svm train on automatically learn ann feature outperform rbf kernel svm train on the raw datum. 
this can be achieve in a feature space with up to only a tenth of dimension of the number of original datum dimension. 
we conclude our work with two experiment on distance base ann training in two further field datum visualization and outlier detection. 
virtual metrology in semiconductor manufacturing by mean of predictive machine learning models. 
advanced process control apc be an important research area in semiconductor manufacturing sm to improve process stability crucial for product quality. 
in low volume high mixture fabrication plant fab knowledge discovery in databases be extremely challenging due to complex technology mixture and reduce availability of datum for comparable process step. 
high density plasma chemical vapor deposition hdp cvd appear to be a process area in sm predestinate for application of data mining dm. 
enhance physical metrology by predictive model lead to smart future fab. 
actual research focus on virtual metrology vm use high sophisticated machine learning ml method to model unknown functional interrelation and to predict the thickness of dielectric layer deposit onto a metallization layer of the manufactured wafer. 
decision trees dt neural networks nn and support vector regression svr have be investigate to maximize the accuracy of the regression. 
for datum of various logistical granularity promise result have be achieve by implement these statistical model. 
development and implementation of a biomanipulation system with magnetic drive microrobot. 
recently biomanipulation microrobot have attract much attention in both academia and industry since they have become a promising tool to perform the practical biological micromanipulation task. 
in this field biological micromanipulation on micro fluidic chip emerge as a new focus since it can be use to improve the biomanipulation efficiency and stability. 
this study aim to develop a micromanipulation system with magnetic drive microrobot to implement the practical biomanipulation on a micro fluidic chip. 
a novel flexure base micromanipulator with large workspace and micro nano scale motion accuracy be propose in this paper. 
after a series of mechanism optimal design and analytic modeling the positioning performance of the micromanipulator be evaluate by use the ansys workbench platform. 
after the mechanism fabrication with the consideration of rate dependent hysteresis effect inherent in piezoelectric ceramic pzt actuator a novel hybrid visual servo control hvsc strategy combine with the extreme learning machine elm and the artificial neural network ann be propose. 
afterwards a series of practical biomanipulation experiment be successfully implement by use the design control strategy. 
both theoretical analysis and visual tracking result uniformly demonstrate the satisfactory performance of the develop system. 
classify breast cancer types base on fine needle aspiration biopsy data use random forest classifier. 
breast cancer be a complex and heterogeneous disease due to its diverse morphological feature as well as different clinical outcome. 
as a result breast cancer patient may response to different therapeutic option. 
currently difficulty in recognize the breast cancer type lead to inefficient treatment. 
generally there be two type of breast cancer know as malignant and benign. 
therefore it be necessary to devise a clinically meaningful classification of the disease that can accurately classify breast cancer tissue into relevant class. 
this study aim to classify breast cancer lesion which have be obtain from fine needle aspiration fna procedure use random forest. 
random forest be a classifier build base on the combination of decision tree and have be identify to perform well in comparison to other machine learning technique. 
this method have be test on approximately 700 datum which consist of 458 instance from benign case and 241 instance belong to malignant case. 
the performance of propose method be measure base on sensitivity specificity and accuracy. 
the experimental result show that random forest achieve sensitivity of 75 specificity of 70 and accuracy about 72. 
thus it can be conclude that random forest can accurately classify breast cancer type give a small number of feature and it work as a promising tool to differentiate malignant from benign tumor at early stage. 
mesh learning for object classification use fmri measurement. 
machine learning algorithm have be widely use as reliable method for modeling and classify cognitive process use functional magnetic resonance imaging fmri datum. 
in this study we aim to classify fmri measurement record during an object recognition experiment. 
previous study focus on multi voxel pattern analysis mvpa which feed a set of active voxel in a concatenate vector form to a machine learn algorithm to train and classify the cognitive process. 
in most of the mvpa method after an image preprocessing step the voxel intensity value be feed to a classifier to train and recognize the underlie cognitive process. 
sometimes the fmri data be far process for de noising or feature selection where technique such as generalized linear model glm independent component analysis ica or principal component analysis be employ. 
although these technique be prove to be useful in mvpa they do not model the spatial connectivity among the voxel. 
in this study we attempt to represent the local relation among the voxel intensity value by form a mesh network around each voxel to model the relationship of a voxel and its surrounding. 
the degree of connectivity of a voxel to its surrounding be represent by the arc weight of each mesh. 
the arc weight which be estimate by a linear regression model be feed to a classifier to discriminate the brain state during an object recognition task. 
this approach call mesh learning provide a powerful tool to analyze various cognitive state use fmri datum. 
compare to traditional study which focus either merely on multi voxel pattern vector or their reduce dimension version the suggested mesh learning provide a well representation of object recognition task. 
various machine learning algorithm be test to compare the suggested mesh learning to the state of the art mvpa technique. 
the performance of the mesh learning be show to be high than that of the available mvpa technique. 
masif machine learning guided auto tuning of parallel skeletons. 
parallel skeleton provide a predefined set of parallel template that can be combine nest and parameterize with sequential code to produce complex parallel program. 
the implementation of each skeleton include parameter that have a significant effect on performance so carefully tune they be vital. 
the optimization space form by these parameter be complex non linear exhibit multiple local optima and be program dependent. 
this make manual tune impractical. 
effective automatic tuning be therefore essential for the performance of parallel skeleton program. 
in this paper we present masif a novel tool to auto tune the parallelization parameter of skeleton parallel program. 
it reduce the size of the parameter space use a combination of machine learning via near neighbor classification and linear dimensionality reduction use principal components analysis. 
to auto tune a new program a set of program feature be determine statically and use to compute k near neighbor from a set of training program. 
previously collect performance datum for the near neighbor be use to reduce the size of the search space use principal components analysis. 
good parallelization parameter be find quickly by search this small search space. 
we evaluate masif for two exist parallel framework threading building blocks and fastflow. 
masif achieve 89 of the performance of the oracle on average. 
this exploration require just 45 parameter value on average which be similar to 0.05 of the optimization space. 
in contrast a state of theart machine learning approach achieve 51. 
masif achieve an average speedup of 1.32 x over parallelization parameter choose by human expert. 
a knowledge management system base on jspwiki. 
with the research of the knowledge base economy and the bloom growth of e business knowledge management be be an important research subject and highly value in the business management area. 
jspwiki an open source wiki engine be base on standard j2ee component and have rich function about knowledge management. 
it be very popular in the java open source community. 
but the jspwiki have some disadvantage as an available knowledge management system. 
it lack of the basic knowledge audit and log function and it need to be improve in some exist function. 
in this paper it propose a knowledge system base on jspwiki and add the java business process management jbpm to the system for audit the knowledge process. 
it also add the hibernate framework to support oracle database and store all the log in the database. 
besides it add some humanize feature in the system for high available. 
the real system that we implement have be use by shenyang machine tool co. ltd and the feedback be positive. 
electrical engineering teaching and distance learning use a desktop virtual reality system. 
high education have evolve in the last decade with the use of information technology. 
this change be call distance education a teaching method in which the student do not need to meet with the teacher on a certain day and time. 
the student may be either at home or at work and may have no interaction with the other part either the teacher or other student. 
it have allow the institution to resolve geographical gap in order to reach the large number of student. 
on the other hand it pave the way for the non traditional university orient for adult work in a narrow range of graduation program compatible with the current demand from industry. 
it be also important to mention that distance education be become increasingly appropriate for non academic study such as corporate training environment. 
this paper address circuit theory system more specifically laboratory practice gear towards teaching and learn. 
the choice be make from observe the need in the specific context of a measure and instrumentation laboratory mainly relate with access to the mean and equipment to carry out laboratory practice. 
the purpose of the work be the use of virtual experimentation to carry out laboratory practice and also as an alternative tool to meet the need of access to the mean and equipment of the laboratory. 
in the present case the basis of the project be the construction of a 3d lab environment measures and instrumentation where the equipment and the component can be see and manipulate. 
the project involve simple electrical schematic which later can be change in value present new result and display a set of menu and submenus to support experiment. 
the virtual laboratory can accommodate new device and scenario be adapt to new subject such as electric machine and power system analysis of the electrical engineering program. 
this work be develop to demonstrate how a desktop vr prototype virtual electric manual vema can be apply to an engineering unit and use to enhance security and resourcefulness in use electrical equipment. 
several interactive scene be develop to illustrate the idea use a measurement and instrumentation laboratory as virtual environment. 
the add value of these various feature in the educational context be that they contribute to the construction of new virtual environment able to benefit the communication between teacher and student and among themselves thus create new opportunity for each student to participate more actively in his her own learn construction process. 
rather than be see as mere information file these e learn platform should be perceive as a means to promote interaction and experimentation through technological resource. 
diabetes mellitus forecast use different data mining techniques. 
in this paper with the improvement in expert system and ml tool the effect of these innovation be enter to more application domain day by day and medical field be one of they. 
decision making in medical field can sometimes be a trouble. 
classification system that be use in medical decision make provide medical datum to be examine in short time and in a more detailed manner. 
in this particular work four different approach have be propose for the classification of subject into two class namely diabetic non diabetic. 
the technique undertake be anfis pca anfis neural networks pca neural network. 
the result obtain be very interesting and show improvement from the previous work. 
there be enough scope for improvement in this field and with the advent of fast and more accurate learning technique the result can surely be improve considerably. 
again the application on live subject rather than rely on store dataset can lead to breakthrough research in the field of diabetes. 
an approach for classification of network traffic on semi supervised datum use clustering technique. 
classification of network traffic be extensively require mainly for many network management task such as flow prioritization traffic shaping policing and diagnostic monitoring. 
many approach have be evolve for this purpose. 
the classical approach such as port number or payload analyis method have their own limitation. 
for example some application use dynamic port number and encryption technique make these technique ineffective. 
to overcome these limitation machine learning approach be propose. 
but these approach also have problem of label instance in supervised learning and tedious manual work in unsupervised learning. 
our aim be to implement an approach for classification of network traffic on semi supervised datum which overcome the shortcoming of other two approach. 
in this approach flow instance statistic be use to classify the traffic. 
these flow statistic contain few label and many unlabeled instance constitute a training datum set which be use for the training(learning of classifier. 
then we use two process the clustering use k medoids which divide the training datum into different group and classification in which the labeling to the group be do. 
to build the model we use the matlab tool. 
to test the build model we use kdd cup 99 intrusion detection datum set which include both attack datum and normal datum. 
automatic classification of nosema pathogenic agents through machine vision technique and kernel base vector machines. 
over the past few year the microscopic image analysis have become increasingly important for the diagnosis and classification of disease in natural and health science. 
although some computational tool be available for image processing on those area their efficiency be limit by lack of adaptation to the specific problem. 
this work present a simple and direct method to identify and classify spore with the use of machine vision and supervised learning technique in order to detect disease in bee colony. 
the method make use of segmentation technique to identify spore which be subsequently classify by mean of multi class kernel base vector machine. 
different computer vision tool have be combine and apply to enhance the image and get the relevant information. 
the result be encouraging and be also applicable to the diagnosis of other parasitic disease. 
serious game based on visual interactive simulation for dynamic workers assignment. 
assign worker to machine dynamically so as to achieve production objective be know as a difficult problem which must be address in several manufacturing system. 
in fact production manager must determine when and where to assign worker which be a very difficult task because of the complexity induce by the dynamic change and the stochastic behavior of these system. 
the current scientific literature be mainly orient towards static assignment problem only few dynamic heuristic be publish. 
we propose a new approach whose aim be to help the manager in improve their knowledge about how to assign worker in real time. 
it be base on serious games build use visual interactive simulation discrete event. 
our experiment show that an appropriate training use the propose game can improve the user ability to make good decision about dynamic worker assignment and that human decision can become more efficient than exist worker assignment rule find in the literature. 
gain ratio as attribute selection measure in elegant decision tree to predict precipitation. 
prediction of precipitation be a necessary tool in meteorology. 
to date it be technologically and scientifically a challenging task for scientist and researcher around the globe. 
rainfall be a liquid form of precipitation that depend primarily on humidity temperature pressure wind speed dew point and so on. 
because rainfall depend on several parameter its prediction become very complex. 
approach such as the back propagation linear regression support vector machine bayesian network and fuzzy logic can be apply but their rate of prediction be very low which lead to unpredictable result. 
this paper aim at improve the prediction of precipitation compare to supervised learning in quest sliq decision tree especially when dataset be large. 
because sliq decision tree take more computational step to find split point they consume more time and thus can not be apply to huge dataset. 
an elegant decision tree use gain ratio as an attribute selection measure be adopt which increase the accuracy rate and decrease the computation time. 
this approach provide an average accuracy of 76.93 with a reduction of 63 in computational time over sliq decision tree. 
music classification use extreme learning machines. 
over the last year automatic music classification have become a standard benchmark problem in the machine learn community. 
this be partly due to its inherent difficulty and also to the impact that a fully automate classification system can have in a commercial application. 
in this paper we test the efficiency of a relatively new learn tool extreme learning machines elm for several classification task on publicly available song dataset. 
elm be gain increase attention due to its versatility and speed in adapt its internal parameter. 
since both of these attribute be fundamental in music classification elm provide a good alternative to standard learning model. 
our result support this claim show a sustained gain of elm over a feedforward neural network architecture. 
in particular elm provide a great decrease in computational training time and have always high or comparable result in term of efficiency. 
fast saliency map extraction from video a hardware approach. 
saliency map be a central part of many visual attention system particularly during learning and control of bottom up attention. 
in this research we develop a hardware tool to extract saliency map from a video sequence. 
saliency map be obtain by aggregate primary feature of each frame such as intensity color and line orientation along with temporal difference. 
the system be design to provide both high speed and acceptable accuracy for real time application such as machine vision and robotic. 
a versatile verilog model for realization of the video processing system be develop which can easily be map and synthesize on various fpga or asic platform. 
the propose parallel hardware can process over 50 million pixel in a second which be about 2x fast than the state of the art design. 
experimental result on sample image justify the applicability and efficiency of the develop system in real time application. 
machine learning based internet traffic recognition with statistical approach. 
the researcher have start look for internet traffic recognition technique that be independent of well know tcp or udp port number or interpret the content of packet payload. 
newer approach classify traffic by recognize statistical pattern in externally observable attribute of the traffic such as typical packet length and inter arrival time. 
the main goal be to cluster or classify the internet traffic flow into group that have identical statistical property. 
the need to deal with traffic pattern large dataset and multidimensional space of flow and packet attribute be one of the reason for the introduction of machine learning ml technique in this field. 
ml technique be subset of artificial intelligence use for traffic recognition. 
far there be four type of machine learning classification supervised learning cluster un supervised learning numeric prediction and association. 
in this research paper ip traffic recognition through classification process be implement. 
different researcher be call this process as ip traffic recognition ip traffic identification and sometimes ip traffic classification. 
here real time internet traffic have be capture use packet capture tool and dataset have be develop. 
also few standard dataset have be use in this research work. 
then use standard attribute selection algorithm a reduced statistical feature dataset have be develop. 
after that six ml algorithm adaboostm1 c4.5 random forest tree mlp rbf and svm with polykernel function classifier be use for ip traffic classification. 
this implementation and analysis show that tree base algorithm be effective ml technique for internet traffic classification with accuracy up to of 99.7616. 
computer aided reverse engineering of a toy car. 
this paper focus on a three d solid modeling technique employ in reverse engineering of a toy car. 
engineering graphics and cad cam be two of the core course teach in our manufacturing engineering program in sophomore and junior year respectively. 
the engineering graphics curriculum familiarize student with two d drafting and three d solid modeling and assembly of simple product. 
in continuation both computer aid design and manufacturing as well as rapid prototyping application be cover in the cad cam course. 
furthermore application of computer aid technology in manufacture simulation and engineering analysis as well as other area of the student interest be practice in under graduate research and/or individual study. 
early a team of two student have be engage in a project title as computer aided reverse engineering of a toy car. 
one of the main objective of this project be for the student to extend their knowledge of reverse engineering and to also gain a hand on experience in the field of solid modeling of complicated product. 
coordinates measurement machine cmm a caliper and a micrometer be use to measure the main dimension of the toy car. 
a solid modeling program be then use for create the model and manufacturing analysis. 
this paper report the re engineering methodology and process of the toy car model body as a manufacturing design project. 
develop authentic projects for a senior level design class. 
at murray state university product and tooling design class be offer as a core course in the engineering graphics and design program. 
the objective of the course be to enable student to integrate their design knowledge and skill to solve engineering design problem. 
since the class be a senior level course all of the student be expect to have acquire a set of skill and knowledge in manufacturing process industrial material engineering drawing tolerance stack up solid modeling motion analysis and static analysis prior to this class. 
the course be build on four design problem with different goal and emphasis on each problem. 
the first design problem be concentrate on engineering design process. 
student practice how to start and finish a design project by follow a proper methodology. 
the second project be a three dimensional static problem for practice finite element analysis. 
the third project require integration of motion analysis and simulation tool to address a specific engineering problem. 
the focus of the last assignment be tool design and machining principle. 
for all four assignment computer generate three dimensional model of part and assembly engineering drawing and a report be common required deliverable. 
in addition second and third assignment require the result of analysis and simulation. 
this paper explain how to set up an authentic problem set for each assignment to create authentic learning task. 
an itemized scoring rubric be present with the rationale behind each item. 
student common mistake be share with example as well. 
at the end student evaluation of the course be provide. 
it be believe that authenticity meaningfulness and completeness of the assignment increase student involvement and motivation for success. 
integrate liberal studies at the assignment level a case study. 
the definition of liberal art have evolve from its roman origin and its renaissance expansion. 
while there be many modern interpretation of what constitute a liberal art curriculum one distinction have remain throughout a focus on and value of intellectual rather than vocational skill. 
this paper demonstrate an approach to integrate those intellectual skill to enhance vocational one. 
as a result of industry feedback a community college adopt four workforce skills to be integrate into the entire curriculum. 
multiple way of measure each competency be also identify for each competency. 
the skill identify be communication skills communicate effectively through speak listen and write. 
critical thinking use critical thinking to analyze and solve problem. 
technical skills demonstrate knowledge and competence in academic and technical field of study. 
interpersonal skills demonstrate positive effective and appropriate interpersonal skill. 
with the exception of technical skill these fall within the modern definition of liberal study. 
this case study describe how one technical program integrate these skill into its laboratory intensive program. 
the subject of this study be a tool die and mold making program lead to an associate of applied science degree. 
identify linkage to outcome such as these be fairly common at the program and course level. 
in this study the relevant skill be integrate at the assignment level as well. 
in course where assignment do not support these skill assignment be add or modify as appropriate. 
for example communication critical thinking and teamwork be integrate into laboratory machining section through the use of individual and team base project. 
these project require write plan write evaluation at the conclusion a reflective paper to cement learning and a presentation to the class and other. 
this paper will provide a detailed description of how this integration and the demonstration of these competency be achieve. 
linkage between all assignment and the relevant liberal study item workforce skills will be identify. 
the paper will also discuss the how the integration of each of these liberal study skill enhance the application of technical skill and job readiness. 
use a virtual platform for teaching electrical machines and power systems courses. 
study of electrical power system and electric machine require a good background on advanced calculus and electromagnetic. 
but many engineering and engineering technology student lack the require background and as a result they have difficulty to learn these subject. 
another issue for electric power system or electric machine student be find the textbook problem solution through the use of routine problem solve technique such as equation and formulae. 
but the student reliance on formulae and routine use of technique in problem solve too often lead to poor performance in real world scenario. 
on the other hand the laboratory session in any engineering program particularly in electrical power engineering be critical as these lab be design for student in accordance with theoretical course work. 
set and run electric machine energy conversion and power system laboratory put several challenge and requirement such as cost space limited equipment access equipment size and similarity with real equipment safety student supervision etc. 
virtual laboratory can become important component of the teaching process because use they some of the above challenge can be avoid while several experiment orient problem can be solve easily and also from the distance. 
software base laboratory experiment have become current day need due to its impact on flexible learning of student and understand ability. 
also the student lack of solid comprehension of mathematical and/or physics concept result in waste time during laboratory experiment misinterpretation of experiment result and datum etc. 
this motivation deal with simulation of electric machine and power system experiment which be part of lab work at undergraduate electrical engineering level use laboratory labview and matlab simulink software package. 
the selection of these software package among other be base in part on their strong graphical interface capability symbolic computation user friendly tool and highly understandable approach. 
moreover labview and matlab base electric machine and power system laboratory and simulation experiment be economical and user friendly. 
we strongly believe that graduate train in such virtual laboratory be well train when they enter the job market. 
this paper will discuss design and development of interactive instructional virtual instrument vi module for study the most common experiment in electric machine and power system laboratory. 
assessment of active learning modules an update of research findings. 
the landscape of contemporary engineering education be ever change adapt and evolve. 
as an example finite element theory and application have often be include in graduate level course in engineering program however current industry need bachelor s level engineering graduate with skill in apply this essential analysis and design technique. 
engineering education be also change to include more active learning. 
in response to the need to introduce undergrad to the finite element method as well as the need for engineering curriculum to include more active learning we have develop implement and assess a suite of active learning module alms. 
the alms be design to improve student learning of difficult engineering concept while student gain essential knowledge of finite element analysis. 
we have use the kolb learning cycle as a conceptual framework to guide our design of the alms. 
originally develop use msc nastran follow by development effort in solidworks simulation ansoft ansys and other commercial fea software package a team of researcher with national science foundation support have create over twenty eight active learning module. 
we will discuss the implementation of these learn module which have be incorporate into undergraduate course that cover topic such as machine design mechanical vibration heat transfer bioelectrical engineering electromagnetic field analysis structural fatigue analysis computational fluid dynamic rocket design chip formation during manufacturing and large scale deformation in machine. 
this update on research finding include statistical result for each module which compare performance on pre and post learning module quiz to gauge change in student knowledge relate to the difficult engineering concept that each module address. 
statistically significant student performance gain provide evidence of module effectiveness. 
in addition we present statistical comparison between different personality type base on myers briggs type indicator mbti subgroup and different learning style base on felder solomon ils subgroup in regard to the average gain each group of student have make on quiz performance. 
although exploratory and generally base on small sample size at this point in our multi year effort the module for which subgroup difference be find be be carefully review in an attempt to determine whether modification should be make to well ensure equitable impact of the module across student from specific personality and /or learn style subgroup e.g. mbti intuitive versus sensing ils sequential versus global. 
machine design experience in a manufacturing engineering technology program. 
program an industrial robot by use a teach pendent be a tedious and time consume task that require a considerable amount of work relate skill robotic knowledge and experience. 
robot application design also require a tremendous amount of programming skill and input output control to make they useful. 
obviously a good robot programmer be a key factor of successful robot application. 
in order to teach manufacture engineering technology met student to program industrial robot we propose an effective learning approach for industrial robot programming in our curriculum. 
research indicate that the use of off line programming olp method for learn industrial robot programming have a positive impact on reduce the robotic lab programming time ex. 
only two robot be available for 20 student reduce the downtime of equipment when program new workpiece variant and accelerate program complex path. 
this paper describe the development of off line programming method to help student learn industrial robot programming. 
the off line programming method be base on example from industry and illustrate several good robot program design. 
overall the olp method provide not only our student an excellent learning environment but also a powerful teaching tool for met instructor. 
our result indicate that the student have the following competence to one study multiple scenario of a robotic workcell before any decision be commit two determine the cycle time for a sequence of manufacture operation three use library of pre defined high level command for certain type of robotic application four minimize production interruption and help meet flexible automation goal and five ensure that a robotic system will do the function that an end user need it to do. 
we also recognize that the student who understand both robotic hardware and offline programming olp software in combination be a challenge for many other college and university. 
not many student be proficient at both but our student be. 
quick return mechanism revisit. 
in this paper the teaching and learn experience of the author with two summer intern at one of the educational institution in india be present. 
these be the senior mechanical engineering student from two different engineering college in india who spend nearly two month at the institute where the author spend a three month sabbatical as a visit faculty. 
although these two student take the theory of machines course at their college a complete understanding of kinematic and dynamic analysis of mechanism such as a quick return linkage seem to be not realize well by they. 
in addition to the student from india there be other mechanical engineering student who be take a design and analysis of mechanical systems and assemblies course as a directed study. 
the student be teach the basic of loop closure equation pertain to the kinematic and dynamic analysis of an example quick return and other planar mechanism. 
all these student develop an excel base program to perform calculation and plot the various characteristic such as variation of quick return ratio as a function of the critical link length kinematic and dynamic characteristic of the linkage. 
study relate to partially balance the system be also under way mostly use a cae tool. 
the student model the linkage use the motion simulation application that be commonly available in any cae tool such as catia ug nx nx i deas or solidwork. 
other math tool such as matlab simulink maplesim etc be also available to study planar mechanism kinematic. 
finally the student in india use the available laboratory experimental apparatus to verify some of the theoretical calculation. 
the performance metric be a final report that include the learn outcome and recommendation for further work. 
virtual three d laboratory for cnc machining and automation curriculum. 
global competition and technological advance be force manufacturer designer and engineer to constantly innovate new product manufacturing strategy in reduce product development cost and time. 
contemporary manufacturer have the option of select optimum technology or process to suit their manufacturing environment. 
when these technology be judiciously combine to address a specific manufacturing challenge such as the one present in the paper rapid product development for quantity production will produce suitable result in term of cost quality and time. 
equip engineering student with the skill and knowledge require to be successful global engineer in the 21st century be one of the primary objective of undergraduate educator. 
the key to unlock the full potential of the computer numerical control cnc programmer and engineer lie in the ability to use the full range of the productivity tool incorporate into the cnc equipment and software while provide realistic operation part programming and maintenance environment. 
use actual cnc equipment or machine tool to deliver the hand on experience that be vital to acquire and demonstrate competence might be too expensive especially when multiple location be use for training purpose. 
software simulator and hardware emulator can mimic the actual lathe machining center and compound application while lower the overall instructional cost enable student to acquire the required skill in a safe environment. 
the fundamental challenging problem in manufacture education be relate to a improve the student instructional technology interface to incorporate the required learning tool b improve teaching and learn effectiveness in online course and training. 
therefore the 24 hour access to intensive and informative training tool be desire. 
the paper discuss the development of a virtual three d laboratory set of activity consist of learn module and tutorial that will provide student with a realistic interaction with cnc machine. 
the simulator use enable development of complex machine troubleshoot scenario that be not feasible on real equipment. 
these simulator provide a realistic operation part programming and maintenance environment at a fraction of the cost of use a real cnc hardware or a production machine tool therefore lower the training cost. 
these simulation tool be basically mean of optimize part machining process and tool design. 
hardware and software simulator allow the user to learn how to program and operate the cnc machine in a virtual environment while the goal of the tutor system be to enhance student learning when the instructor be not available. 
incorporate 3d animation allow student to visualize the machining process and provide great understanding of the challenge and operate characteristic. 
machine simulation include real component like coolant sound for machine operation and chip generation. 
simulation software have over fifty different control model so that not only will our student get familiar with the haas cnc mill machine that exist in our laboratory but also other universal control model such as fanuc fanuc usa or sinumerik siemens. 
interdisciplinary senior design project to develop a teaching tool mini cnc mill. 
the desire current set of skill require of modern engineer and technologist have be steadily expand. 
in addition to familiarity with manual machining and fabrication technique master cad cam computer numerical control cnc and automation method be increasingly become essential tool in the design prototype and manufacturing of complex system. 
in this paper an inter disciplinary design project towards the development of a mini cnc milling machine be present. 
since purchase and instal traditional cnc equipment be not an option for every campus of drexel university or similar engineering school an alternative solution to provide hand on experience with cnc equipment be desirable. 
a cnc machine with a desktop form factor which would be easily transport between campus would eliminate the need for multiple traditional cnc machine and would improve the quality of the met316 cnc course by provide more hand on lab experience. 
the desktop cnc machine which be develop by student design team fit on a standard desktop or table would interface with commonly available cnc computer aided manufacturing cam software would be power by a standard ac outlet would be easy to use and robust enough for educational use and would not be cost prohibitive. 
student in the mechanical electrical and industrial field along with many other can learn many new skill from multi disciplinary project such as the design and development of a desktop cnc mill. 
such project show student how to use different type of technology and demonstrate how advanced technology can be use in an actual application. 
this project teach future engineer and technologist various advanced skill that can be use in their career. 
overall many different field of engineering can benefit from this application enable the development of skill and knowledge in many different engineering aspect and process. 
as this capstone design project provide opportunity for student to design manufacture it stimulate the student interest in real world product realization. 
as manufacture laboratory be very expensive to develop this project can also be adapt at other institution that have limit funding to improve manufacturing process facility. 
quickly building students confidence in their fabrication ability. 
undergraduate mechanical engineering education usually place a high priority on design experience. 
such course serve to enhance student interest in engineering improve retention and improve result in later course. 
a challenge to implement early design experience in engineering program be the readiness of the student population for hand on design work. 
one of the main obstacle the student face be the lack of fabrication experience. 
this typically lead student to begin work too late. 
this have be refer to as time scallop as deadline be approach effort level rise rapidly and fall back to low level repeatedly. 
a problem motivate this paper be that student seem hesitant to use machine tool despite previous introductory training include mill lathe saw sheet metal cutting and bend. 
in this course each student be expect to conceive design build and operate a robot to carry out a specify set of task. 
this paper describe an activity that allow student to quickly build and test a robot within a three hour time frame. 
this robot call mini i serve most student as a starting point to build a more complex machine later on. 
survey indicate the activity build student confidence in their fabrication skill and that the gain be large for female student. 
this work show the benefit of give student small subtask to reduce anxiety about not have adequate skill to design and build a robot. 
this activity have enable student to extract key concept and the student feel more confident that they could complete a more complex robot. 
overall student s self report knowledge of servos motors and use manufacturing equipment increase base on survey result. 
the activity describe in this paper have have a large impact on overall manufacturing confidence and course outcome for student. 
teach manufacturing with group cell practice. 
in traditional manufacturing lab exercise student lean to operate one type of machine tool at a time. 
after learn each machine type they then move to another type and learn all operation on new machine tool. 
there be little connection and interaction among student since each person will produce his her own individual part. 
at the end of training lesson some instructor may verbally describe the link of different process and how a product would flow among those process. 
a manufacturing department typically have to purchase many identical machine tool and different tooling set for variety of possible operation on each machine type. 
the operate cost of such manufacturing laboratory be high and some student might not comprehend the link among different process. 
this model be popular among community college or vocational school but may not be good for engineering student since the latter only need to understand the manufacturing process rather than acquire hand on manufacturing skill. 
we propose a new manufacturing teaching practice at our university by introduce group cell and simulate production line. 
a group of student be responsible to produce product for the whole group. 
after learn and practice basic machine tool operation in a cell lathe mill saw machine and specific manual operation each subgroup of two student operate a machine tool and produce identical component for the whole group. 
student will have option to rotate to other machine or stay with a specific machine to gain more experience. 
a student keep time record of select operation for time study. 
when all component be produce to draw dimension and tolerance student then assemble component to form the final product that be carefully design for process integration while have meaningful value and ecstatic appearance for student to keep. 
in the concluding session a teaching assistant lead the discussion and highlight the capability of each machine flow of part from one machine to the next identify the bottle neck station and let student suggest corrective action at the conclusion of the lab exercise. 
component dimension and part shape be modify for different group to illustrate how a family of part be produce in group cell and the advantage of flexible manufacturing concept. 
the implementation of group cell practice will start in the fall semester of 2013. 
datum from student feedback and quiz grade distribution will be collect to gage the impact of group cell on student subject comprehension. 
development of laboratory modules for use in measurement and instrumentation and applied quality control courses. 
equip engineering student with the skill and knowledge require to be successful global engineer in the 21st century be one of the primary objective of undergraduate educator. 
ideally a properly train workforce of engineer and technician should have expert skill in quality control measurement and instrumentation to maintain high productivity and to improve safety standard in the industry. 
an expert can detect and/or predict deteriorate cut condition through the use of his her sense so that appropriate corrective action can be take before part quality be lose. 
however this level of expertise require many year of experience. 
furthermore machine tool should be bring to a thermally stable state by run at idle mode for several hour so that positional error can be minimize. 
this requirement increase machine down time and production cost. 
machine tool have inherent geometric error cause by mechanical imperfection in their structure and misalignment of machine tool element. 
geometric error be also affect by the thermal state of the machine tool structure. 
hence process and structural factor affect part accuracy in machining process be quite complicated. 
cnc machine tool only minimize a small portion of these error since cnc often do not utilize sensor datum to compensate for geometric thermal error and error generate by the cutting process. 
therefore we must provide our student through our curriculum with an adequate level of expertise through new program course and support laboratory. 
this paper be focus on description of new laboratory module teaching material practical experiment and project develop as an integrated educational environment similar to one use in the present day industry. 
the project and practical activity be develop and implement around renishaw magnetic double ballbar dbb haas om1a three axis cnc vertical machining center and coordinate measuring machine cmm. 
course material and laboratory manual be also develop upgrade and restructure during this project. 
the educational material be implement as course improvement in undergraduate and graduate course such as measurement and instrumentation applied quality control engineering quality methods graduate and sensors and measurements graduate. 
the experimental activity be focus on several aspect applicable in manufacture industry concern measurement instrumentation and quality control. 
one area where we concentrate our effort be the calibration technology of a cnc use machine part and a cmm. 
this approach yield valuable information on non repeatable error due to cut force heat generate by cutting tool setup wear and deflection. 
cmm be use also as a post process confirmation of the machine test component and other discrete part machine in the haasom1 vertical machining center. 
then the deviation between the real part and the theoretical part be measure. 
another area of focus be relate to characterization of the factor and error component that contribute to machine tool error use a dbb. 
a study of process variability of the injection molding of plastics parts use statistical process control spc. 
process variability in the manufacturing of product be a serious concern which if leave unchecked could lead to product waste low productivity and poor quality product one. 
to prevent these unwanted effect from happen statistical process control spc a statistical tool be use to monitor and control process variability. 
spc assume that manufacture product have measureable attribute such as mass dimension of the product mechanical property and visual appearance to name a few. 
these attribute be affect by natural and assignable cause. 
natural cause be inherent to the process and may include variable such as ambient temperature machine vibration and relative humidity variable that be often very difficult to control. 
unlike natural cause assignable cause be controllable and may include item such as bad or wear out machine component that should be replace. 
by monitor a process an assignable cause be detect when process variability exceed the expect range cause by natural cause. 
the primary advantage of spc be that it detect a faulty process which if correct prevent the manufacturing of defective product. 
this be unlike traditional quality control practice that identify defective product after they have be produce. 
the traditional method of quality control lead to a costly manufacturing process. 
in a manufacturing engineering technology program spc be use to monitor and control the injection molding of plastic part since the word plastic mean deformable it have be the tradition in the plastic industry to use the word plastic to avoid any confusion. 
hence the phrase plastic resin or plastic raw material. 
student monitor several injection molding process variable use spc x bar and range control chart while produce 300 plastic part. 
the mass of the product be use as an attribute represent part quality. 
after analyze the process datum student be able to determine whether the process be stable that is in control. 
an assessment of student learn outcome show a 25 improvement in their understanding of spc when apply to a manufacturing process such as the injection mold plastic part. 
match pursuit in eeg analysis development of a diagnostic tool. 
an electroencephalogram eeg signal be the recording of the electrical activity voltage fluctuation along the scalp due to the current that flow during synaptic excitation of the dendrite of many pyramidal neuron in the cerebral cortex. 
when neuron be activate the synaptic current be produce within the dendrite. 
this current produce the magnetic field give rise to mapping of cortical activity measurable by magneto encephalography meg machine and a secondary electrical field over the scalp measurable by eeg system. 
mastery and expertise in clinical eeg interpretation be one of the most desirable diagnostic clinical skill in interpret seizure epilepsy sleep disorder and other neurocognitive study. 
in most case eeg activity be describe in term of frequency amplitude distribution or location symmetry synchrony reactivity morphology rhythmicity and regulation. 
the dynamic nature of epileptic phenomenon cause eeg signal to exhibit stochastic and non stationary behavior. 
the time frequency distribution be potentially very useful for detect and analyze non stationary epileptic eeg. 
although visual analysis of raw eeg trace be still the major clinical tool and the point of reference for other method we can relate visual analysis to mathematic with a time frequency description. 
the eeg signal analysis be often complement with meg and functional magnetic resonance imaging fmri to correlate specific eeg finding with pathology of the brain and selectively demonstrate the diagnosis of certain neuronal disease process and assessment parameter. 
this diagnostic tool be in no way to be take as a final word to replace physician s clinical consultation and opinion rather it be intend to be an early monitoring and warning tool which will aid in diagnosis of certain aspect of critical care and emergency medicine. 
this interactive teaching module will be highly beneficial since it will facilitate progressive learning of student by enhance their understanding of clinical eeg parameter and their relationship with differential diagnosis of the patient. 
discovery learn experiment in a new machine design laboratory. 
a new machine design laboratory at marquette university have be create to foster student exploration with hardware and real world system. 
the laboratory incorporate area for teaching and training and have be design to promote hand on and mind on learn. 
it reflect the spirit of transformational learning that be a theme in the college of engineering. 
the goal be to create discovery learn orient experiment for a require junior level design of machine elements course in mechanical engineering that would give student practical experience and expose they to physical hardware actual tool and real world design challenge. 
in the experiment student face a range of real world task identify and select component measure parameter dimension speed force distinguish between normal and use worn component and between proper and abnormal behavior reverse engineer system and justify design choice. 
the experiment serve to motivate the theory and spark interest in the subject of machine design. 
this paper present detail of the experiment and summarize student reaction and our experience in the machine design laboratory. 
in addition the paper provide some insight for other who may wish to develop similar type of experiment. 
course relate undergraduate projects for dynamic. 
the engineering technology et program at middle tennessee state university mtsu have approximately 450 student. 
our mechanical engineering technology met concentration be start in 2004 fall and currently it have 220 major. 
the author teach dynamic every spring and all met student be require to take this course. 
dynamic be a lecture course and we cover kinematic and kinetic of particle and rigid body in this calculus base course. 
we feel it be necessary to have some hand on project that will help student well understand the principle and application. 
the author develop the egg drop project in which the student work in team and follow the guideline build two structure use balsa wood stick place an egg inside and drop the unit from a certain height so as to land on the target place on the ground. 
they build two such unit with and without a parachute. 
they be require to write a report that include the construction method calculation and graphical presentation of the unit s height as a function of time. 
they also compare the calculate time of fall with the measure value and explain any discrepancy. 
the author derive the equation of motion and the height time relationship for the case with a parachute as these be not readily available in our dynamics textbook. 
the egg drop project of each team be judge base on the compliance to the guideline structure s weight condition of the egg structure after landing distance from the target to the egg structure and aesthetic of the structure. 
this project be a great success and student have fun work together and compete with other team. 
the author briefly discuss in the class a hand on project that would help student well understand the motion of a projectile in a two dimensional space. 
three student show a great interest in the project and that very weekend they purchase a paintball gun and conduct some experiment at a barn. 
their paintball have the capability of give the velocity of the paintball at the barrel exit which be the initial velocity of the projectile. 
they build some fixture to allow the tilting of the gun so that they can measure the angle make by the initial velocity of the projectile. 
they be able compare the calculated range and height of the target with the corresponding measure value and compute the accuracy of their device. 
they be also able to make a video of their experiment. 
the trio make a presentation of their experiment in the class and in collaboration with the author they also participate at the mtsu s annual undergraduate symposium. 
three of our dynamics student be inspire by the paintball gun project and decide to build a golf ball shooter for their capstone project. 
these student apply their knowledge of cadd fluid power machine tool technology and dynamics and successfully complete the project. 
there be numerous application orient publication in the area of engineering mechanics and we have cite two of they in this paper. 
one two we hope our course related hand on project will inspire the et faculty community far and many more interesting project will be present at the future asee conference. 
use simulation to improve the efficiency of cam and cnc instruction. 
the use of industry type cnc machine as oppose to trainer for learn nc operation in engineering technology program present several challenge. 
key amongst these be the potential for damage to the machine tooling work piece and injury to user from improper operation. 
to prevent these occurrence significant effort must be expend on the part of instructor and lab personnel in vetting programming assignment complete by student and in supervise set up and operation of a machine. 
face with few resource and increase class size simulation technique be become increasingly useful to help department well manage their resource and not just for the educational benefit of the student. 
this paper describe effort to utilize simulation in several course in a manufacturing engineering technology program that heavily utilize cnc technology. 
to do this accurate digital model of cnc machine have be create use a cad system and convert into simulation model within an industry standard nc verification application. 
for each of the class that utilize a cnc machine the simulation model along with tool and fixture library be available for student to use in verify the program they create for assignment and project work. 
student be introduce to the simulation software at the start of an introductory course to cnc operation through a single homework assignment. 
the effort in use model be minimal select tool from a library add and position stock geometry and final part when a machining accuracy comparison be require in a fixture often a kurt machinist s vice set up the work coordinate system g54 location and load the nc program. 
these step mirror those that will be perform by the student on the actual cnc and so be reinforce the student s experience. 
evidence of how the use of simulation be help to increase the preparedness of student reduce the occurrence of programming error and machine crash and improve the efficiency of time spend in the lab will be present. 
a distribute multiagent decision process for the control of building systems. 
while ensure safety health and comfort be indispensable today s challenge in build control frequently hinge around system integration and reduce predict and flattening site energy consumption. 
to achieve these goal it be likely necessary that we utilize new perspective approach and technique make possible by the rapidly grow digital world. 
this paper highlight a process that incorporate a handful of these tool provide basic background to their implementation. 
within the multiagent system mas paradigm the structure incorporate probabilistic graphical modeling technique and conditional satisficing game in a way that be intend to facilitate more autonomous control capability. 
the apply theory will be use to give individual equipment controller a framework to explicitly consider uncertainty in control action to simultaneously seek high performance individually and as a system of equipment and permit autonomous adaptability. 
the structure may eventually allow for the improvement of ad hoc heuristic strategy with statistical machine learning technique all while build a system that fundamentally incorporate a system wide perspective of operation. 
risk stratification for arrhythmic sudden cardiac death in heart failure patients use machine learning techniques. 
arrhythmic sudden cardiac death scd be still a major clinical challenge even though much research have be do in the field. 
machine learning technique give a powerful tool for stratify arrhythmic risk. 
we analyze 40 holter recording from heart failure patient 20 of which be characterize as high arrhythmia risk after 16 month follow up. 
the two group high and low risk be not statistically different in basic clinical characteristic. 
we perform windowed analysis and compute 25 heart rate variability hrv index. 
we feed these index as input to two classifier support vector machines svm and random forests rf. 
the classification result show that the automatic classification of the two group of subject be possible. 
frequent pattern base user behavior anomaly detection for cloud system. 
cloud computing be a hot topic in the global it industry which be consider as the main part of the network and computing service provider in recent year. 
some security issue will be more threatening in cloud computing such as account theft and insider threat. 
we propose a framework to utilize anomaly detection and random re sample technique for profile a user s behavior via the frequent pattern of activate system process. 
by utilize the user profile learn from normal datum our method can detect malicious activity and discriminate suspicious activity from different user. 
we use virtual machine vm to collect process log of normal user and malicious tool. 
the collected datum be use on verify if our method can detect the malicious activity on the system. 
the result show that all the malicious activity be detect with less than 4.6 false positive rate. 
we also collect real world datum for test the ability of discriminate activity collect from different user. 
the result show that the user profile can detect on average 86 suspicious behavior from different user with less than one false positive rate. 
use feature selection and association rule mining to evaluate digital courseware. 
effective digital courseware should be easy to implement and integrate into instructional plan save teacher time and help they support their student learn need. 
it should also not only enable student to achieve explicit learning objective but also accelerate the pace at which they do so. 
this paper highlight the advantage of use feature selection technique and associative rule mining to get insightful knowledge from the log datum from the learning management system moodle. 
the machine learning approach can be objectively deploy to obtain a predictive relationship and behavioral aspect that permit map the interaction behaviour of student with their course outcome. 
the knowledge discover could immensely assist in evaluate and validate the various learning tool and activity within the course thus lay the groundwork for a more effective learning process. 
it be hope that such knowledge would result in more effective courseware that provide for a rich compelling and interactive experience that will encourage repeat prolong and self motivate use. 
cardiac disorder detection approach base on local transfer function classifier. 
truly heart be successor to the brain in be the most significant vital organ in the body of a human. 
heart be a magnificent pump have his performance orchestrate via a group of valve and highly sophisticated neural control. 
while the kinetic of the heart be accompany by sound production sound wave produce by the heart be reliable diagnostic tool to check heart activity. 
chronologically several datum set have be put forward to sneak on the heart performance and lead to medical intervention whenever necessary. 
the heart sound datum set utilize in this paper provide researcher with abundance of sound signal that be classify use different classification algorithm decision tree rotation forest random forest be few to mention. 
this paper propose an approach base on local transfer function classifier as a new model of neural network for heart valve disease detection. 
in order to achieve this objective and to increase the efficiency of the predication model boolean reasoning discretization algorithm be introduce to discretion the heart signal datum set then the rough set reduction technique be apply to find all reduct of the datum which contain the minimal subset of attribute that be associate with a class label for classification. 
then the rough set dependency rule be generate directly from all generate reduct. 
rough confusion matrix be use to evaluate the performance of the predict reduct and class. 
finally a local transfer function classifier be employ to evaluate the ability of the select descriptor for discrimination whether they represent healthy or unhealthy. 
the experimental result obtain show that the overall accuracy offer by the employ local transfer function classifier be high compare with other technique include decision table rotation forest random forest and nbtree. 
an application of one vs one method in automated taxa identification of macroinvertebrates. 
freshwater ecosystem face numerous anthropogenic stressor. 
for solve long term effect in aquatic ecosystem due to the human induce action we need to use benthic macroinvertebrate instead of a chemical analysis. 
the use of benthic macroinvertebrate require their identification which be a laborius and cost intensive task. 
by mean of automate taxa identification of macroinvertebrate the cost can be reduce and the identification process can be speed up. 
however the identification demand reliable tool. 
in this research we extend the use of one vs one method from support vector machines into several other classification method and we examine the tie situation problem which be encounter in one vs one method. 
overall we use 15 different classification method in this paper. 
by thorough experimental test we achieve 96.8 accuracy by use support vector machines with the quadratic kernel. 
tie situation analysis reveal that tie be more frequent when use support vector machines together with one vs one classification framework and majority voting method than other classification method. 
a comparision of multiclass svm and hmm classifier for wavelet front end robust automatic speech recognition. 
classifier in automatic speech recognition asr aim to improve the generalization ability of the machine learning and improve the recognition accuracy in noisy environment. 
this paper discuss the classification performance of hidden markov models hmm and support vector machines svm apply to a wavelet front end base asr. 
the experiment be perform on speaker independent timit database which be train in a clean environment and later test in the presence of additive white gaussian noise awgn for various snr level use the htk toolkit and svm light software tool. 
experiment indicate that for large vocabulary the wavelet front end and the multiclass svm classifier with rbf kernel perform well than the conventional hmm classifier. 
use virtualization and guacamole vnc to provide adaptive user interface to disabled people in cloud computing. 
assistive technology at provide essential computer accessibility for people with disability. 
in this paper we examine how cloud computing can provide adaptive user interface to people with disability in order to enable they access at tool in form of software as a service saas. 
the propose solution consist in create adaptive user interface deploy at tool in virtual machines vms which user can manage through the internet. 
by use an html5 base web interface computer user with disability be able to interact with personalized virtual desktop from any networked computer by mean of a web browser without have to setup additional software on the physical machine. 
nevertheless use at software in web access vm be not so easy as well as in physical desktop because several issue have to be overcome. 
in order to address such issue we discuss an architecture integrate guacamole an html5 remote desktop gateway virtual network computing vnc a technology to control a remote desktop virtual box a virtual machine monitor or hypervisor and clever a virtual infrastructure manager vim middleware. 
short term vs. 
long term analysis of diabetes data application of machine learning and data mining techniques. 
chronic care of diabetes come with large amount of datum concern the self  and clinical management of the disease. 
in this paper we propose to treat that information from two different perspective. 
firstly a predictive model of short term glucose homeostasis rely on machine learning be present with the aim of prevent hypoglycemic event and prolong hyperglycemia on a daily basis. 
second datum mining approach be propose as a tool for explain and predict the long term glucose control and the incidence of diabetic complication. 
opinion mining on social media data. 
microblogge twitter or facebook have become a very popular communication tool among internet user in recent year. 
information be generate and manage through either computer or mobile device by one person and be consume by many other person with most of this user generate content be textual information. 
as there be a lot of raw datum of people post real time message about their opinion on a variety of topic in daily life it be a worthwhile research endeavor to collect and analyze these datum which may be useful for user or manager to make informed decision for example. 
however this problem be challenge because a micro blog post be usually very short and colloquial and traditional opinion mining algorithm do not work well in such type of text. 
therefore in this paper we propose a new system architecture that can automatically analyze the sentiment of these message. 
we combine this system with manually annotate datum from twitter one of the most popular microblogging platform for the task of sentiment analysis. 
in this system machine can learn how to automatically extract the set of message which contain opinion filter out non opinion message and determine their sentiment direction i.e. 
positive negative. 
experimental result verify the effectiveness of our system on sentiment analysis in real microblogging application. 
probabilistic modeling of failure dependencies use markov logic network. 
we present a methodology for the probabilistic modeling of failure dependency in large complex system use markov logic networks mlns a state of the art probabilistic relational modeling technique in machine learning. 
we illustrate this modeling methodology on example system architecture and show how the the probabilistic consistency engine pce tool can create and analyze failure dependency model. 
we compare mln base analysis with analytical symbolic analysis to validate our approach. 
the latter method yield bound on the expect system behavior for different component failure probability but it require closed form representation and be therefore often an impractical approach for complex system analysis. 
the mln base method facilitate technique of early design analysis for reliability e.g. probabilistic sensitivity analysis. 
we analyze two example a portion of the time trigger ethernet ttethernet communication platform use in space and an architecture base on honeywell s cabin air compressor cac that highlight the value of the mln base approach for analyze failure dependency in complex cyber physical system. 
exploit spatial locality to improve disk efficiency in virtualized environments. 
virtualization have become a prominent tool in datum center and be extensively leveraged in cloud environment it enable multiple virtual machine vms with multiple operating system and application to run within a physical server. 
however virtualization introduce the challenging issue of preserve the high disk utilization i.e. reduce the seek delay and rotation overhead when allocate disk resource to vm. 
exploit spatial locality a key technique for improve disk utilization and performance face additional challenge in the virtualized cloud because of the transparency feature of virtualization hypervisor do not have the information about the access pattern of application run within each vm. 
to this end this paper contribute a novel disk i o scheduling framework name pregather to improve disk i o efficiency through exposure and exploitation of the special spatial locality in the virtualized environment regional and sub regional spatial locality correspond to the virtual disk space and application access pattern respectively thereby improve the performance of disk intensive application without harm the transparency feature of virtualization without a priori knowledge of the application access pattern. 
the key idea behind pregather be to implement an intelligent model to predict the access regularity of sub regional spatial locality for each vm. 
we implement the pregather disk scheduling framework and perform extensive experiment that involve multiple simultaneous application of both synthetic benchmark and amapreduce application on xen base platform. 
our experiment demonstrate the accuracy of our prediction model and indicate that pregather result in the high disk spatial locality and a significant improvement in disk throughput and application performance. 
design pattern recognition by use adaptive neuro fuzzy inference system. 
software design pattern describe recur design problem and provide the essence of good practice solution. 
it be useful and important for various software engineering task to know which design pattern be implement where in a software design. 
however this information be often lose due to poor or absent documentation and so accurate recognition tool be require. 
the problem be that design pattern give their abstract and vague nature have a level of resistance to be automatically and accurately recognize. 
although this vagueness or fuzziness can be capture and model by the fuzzy inference system it have not yet be apply to solve this problem. 
this paper fill this gap by propose an approach for design pattern recognition base on adaptive neuro fuzzy inference system. 
our approach consist of two phase space reduction phase and design pattern recognition phase. 
both phase be implement by anfis. 
we evaluate the approach by an experiment conduct to recognize six design pattern in an open source application. 
the result show that the approach be viable and promising. 
a natural language processing and semantic base system for contract analysis. 
the contract search tool be a semantic search platform that enable effective analysis of complex long term contractual service agreement for machine such as gas turbine. 
the approach we develop can effectively identify paragraph of text for specific legal concept. 
then the key content can be decompose and organize by the semantic model that capture key element of the concept and link to specific paragraph. 
this be achieve by perform semantic text analysis to capture implicitly state provision and the definition of provision and relevant information be return in an organized manner. 
the tool can be apply to increase productivity of legal review share legal knowledge with service manager and reduce legal risk in contract review process. 
tikhonov or lasso regularization which be well and when. 
it be well know that supervise learning problem with l(1)(lasso and l(2 tikhonov or ridge regularizer will result in very different solution. 
for example the l(1 solution vector will be sparser and can potentially be use both for prediction and feature selection. 
however give a data set it be often hard to determine which form of regularization be more applicable in a give context. 
in this paper we use mathematical property of the two regularization method follow by detailed experimentation to understand their impact base on four characteristic non stationarity of the datum generating process level of noise in the datum sense mechanism degree of correlation between dependent and independent variable and the shape of the datum set. 
the practical outcome of our research be that it can serve as a guide for practitioner of large scale datum mining and machine learning tool in their day to day practice. 
modeling natural language sentences into spn graphs. 
natural language processing and understanding be an attractive field and many technique and tool for document processing have be develop. 
most of the technique use either statistical model or graph base approach. 
here we present the modeling of a methodology base on stochastic petri net spn to explain the transformation of a natural language nl sentence into a state machine representation as state in. 
in particular we initially convert nl sentence into graph use the agent action patient kernel and then we convert the graph into spn graph description in order to efficiently offer a model of semantically represent and understand natural language event of a document. 
the selection of the spn graph model be due to its capability for efficiently represent structural and functional knowledge. 
cognitive visualization for the design of complex system. 
in this paper we introduce a set of new visual representation for complex system. 
these visual representation allow for the efficient description of system that encapsulate a variety of component that can be merge together to form ensemble. 
these ensemble method can outperform individual approach. 
the whole operation of such system can be well interpret use visual tool. 
thus we introduce 3d graphical solution to visualize the component e.g. 
database energy function algorithm and voting model of the system together with their attribute and also their possible relationship. 
for a case study we consider a clinical screening system. 
as a sufficiently flexible and rich 3d visualization framework we select the virca virtual collaboration arena. 
the create virtual space support the manual design of application from the component with test they on different database for the select energy function. 
moreover the user can get familiar with the application generate automatically by machine learning and stochastic search algorithm. 
toward the next generation of recruitment tools an online social network base job recommender system. 
this paper present a content base recommender system which propose job to facebook and linkedin user. 
a variant of this recommender system be currently use by work4 a san francisco base software company that offer facebook recruitment solution. 
work4 be the world leader in social recruitment technology to use its application facebook or linkedin user explicitly grant access to some part of their datum and they be present with the job whose description be match their profile the most. 
the profile of a user contain two type of datum interaction datum user s own datum and social connection datum user s friend datum. 
furthermore the user profile and the description of job be divide into several part call field. 
our experiment suggest that to predict the user interest for job use basic similarity measure together with their interaction datum collect by work4 can be improve upon. 
the second part of this study present a method to estimate the importance of each field of user and job in the task of job recommendation. 
finally the third part be devoted to the use of a machine learn algorithm in order to improve the result obtain with similarity measure we train a linear svm support vector machines. 
our result show that use this supervised learning procedure increase the performance of our content base recommender system. 
combine information extraction and text mining for cancer biomarker detection. 
information technology be advance fast than anticipate. 
the amount of datum capture and store in electronic form by far exceed the capability available for comprehensive analysis and effective knowledge discovery. 
there be always a need for new sophisticated technique that could extract more of the knowledge hide in the raw datum collect continuously in huge repository. 
biomedicine and computational biology be one of the domain overwhelm with huge amount of datum that should be carefully analyze for valuable knowledge that may help uncover many of the still unknown information relate to various disease threaten the human body. 
biomarker detection be one of the area which have receive considerable attention in the research community. 
there be two source of datum that could be analyze for biomarker detection namely gene expression datum and the rich literature relate to the domain. 
our research group have report achievement analyze both domain. 
in this paper we concentrate on the latter domain by describe a powerful tool which be capable of extract from the content of a repository like pubmed the part relate to a give specific domain like cancer analyze the retrieve text to extract the key term with high frequency present the extract term to domain expert for select those most relevant to the investigated domain retrieve from the analyze text molecule relate to the domain by consider the relevant term derive the network which will be analyze to identify potential biomarker. 
for the work describe in this paper we consider pubmed and extract abstract relate to prostate and breast cancer. 
the reported result be promise they demonstrate the effectiveness and applicability of the propose approach. 
simultaneous active learning of classifiers attributes via relative feedback. 
active learning provide useful tool to reduce annotation cost without compromise classifier performance. 
however it traditionally view the supervisor simply as a labeling machine. 
recently a new interactive learning paradigm be introduce that allow the supervisor to additionally convey useful domain knowledge use attribute. 
the learner first convey its belief about an actively choose image e. 
g. 
i think this be a forest what do you think. 
if the learner be wrong the supervisor provide an explanation e. 
g. 
no this be too open to be a forest. 
with access to a pre train set of relative attribute predictor the learner fetch all unlabeled image more open than the query image and use they as negative example of forest to update its classifier this rich human machine communication lead to well classification performance. 
in this work we propose three improvement over this set up. 
first we incorporate a weighting scheme that instead of make a hard decision reason about the likelihood of an image be a negative example. 
second we do away with pre train attribute and instead learn the attribute model on the fly alleviate overhead and restriction of a pre determined attribute vocabulary. 
finally we propose an active learning framework that account for not just the label but also the attribute base feedback while select the next query image. 
we demonstrate significant improvement in classification accuracy on face and shoe. 
we also collect and make available the large relative attribute dataset contain 29 attribute of face from 60 category. 
near optimal and computationally efficient detector for weak and sparse graph structure pattern. 
in this paper we review our recent work on detect weak pattern that be sparse and localize on a graph. 
this problem be relevant to many application include detect anomaly in sensor and computer network brain activity co expression in gene network disease outbreak etc. 
we characterize such a class of weak and sparse graph structure pattern by small subset of weakly activate node with a low cut in an underlie known graph. 
on one hand the combinatorial nature of this class render traditional detector such as glrt aka scan statistic computationally intractable for general graph. 
on the other hand attempt to develop feasible detector such as fast subset scan or average thresholding sacrifice statistical efficiency. 
we describe and compare three detector for weak graph structure pattern that be develop use tool from graph theory optimization and machine learning. 
these detector be computationally efficient applicable to graph and pattern with general structure and come with precise theoretical guarantee often achieve near optimal statistical performance. 
power system online stability assessment use active learning and synchrophasor data. 
analysis of synchrophasor measurement use datum mining tool in pursuit of precise stability assessment require a sufficiently large training datum set. 
traditionally the process of learn the underlie power system behavioral pattern introduce a significant computational burden such that exhaustive simulation of all possible system operating condition be necessary. 
advancement in machine learning make it possible in some case to reduce the amount of operating condition that need to be analyze without impact the accuracy of stability assessment. 
by use a probabilistic learn tool in the describe active learning scheme to interactively query operating condition base on their importance we show that significantly few datum need to be process for accurate voltage stability and oscillatory stability estimation. 
result show that the advantage of active learning be great on more complicated power network where large training datum set be involve. 
ucms user side cloud management system. 
iaas cloud provider as amazon or rackspace provide their user with the ability to create an own virtual environment populate it with their application and manage a wide range of critical issue e.g. 
scale up down load balancing fault by mean of ad hoc service. 
one of the limit of these cloud system be the lack of tool that enable the user to have a direct knowledge of the physical resource support his application. 
some provider supply a set of tool for the monitoring of the user application e.g. 
cloudwatch but these present several limit the monitoring time be constrain by the provider the mechanism to get the value of the state be not always clear the observation procedure introduce an overhead unquantifiable and in some case not always negligible. 
to overcome such a limitation this paper introduce ucms an autonomic user side management system to monitor and control the behaviour of user application on a cloud environment. 
the main advantage offer by ucms be its ability to modify at run time the components virtual machines physical machines mapping previously establish by both the user component virtual machine and cloud provider virtual machine physical machine in order to improve the exploitation of the assign resource. 
experiment lead on real scenario amazon ec2 demonstrate the ability of ucms to reduce the execution time of consider cloud application pipeline and mapreduce by about 50. 
pattern classification for finding facial growth abnormality. 
cephalometric analysis of lateral radiograph of the head be an important diagnosis tool in orthodontic. 
base on actually locate precise landmark it be a tedious long last and error prone mission. 
the objective of this work be to calculate the sna angle snb angle and anb angle between the landmark to identify the input and output parameter pertain to skeletal abnormality. 
by do so the patient data for training and test the back propagation neural network bpnn generalize regression neural network grnn support vector machine svm and extreme learning machine elm classifier by nine fold cross substantiation. 
the presentation of skeletal be originate out use the bpnn grnn svm and elm model. 
this will be useful to identify whether the patient be normal or abnormal need for treatment. 
this will categorize situation of the diverse patient with severity of abnormality in skeletal. 
automatic concept clustering for ontological structure through data mining techniques. 
ontology be a technique for express formal specification. 
it be a conceptualization of domain and its term and relationship. 
the technique of ontology find its application in almost every area some of which include medicine e commerce chemistry education etc. 
concept clustering be the foremost step in construction of ontology. 
concept clustering be usually a manual process involve labor and time intensive task. 
hence there be a need for automatic grouping of concept for ontology construction. 
in this paper automatic concept clustering be attempt through datum mining clustering technique. 
the training set for the concept formation of ontology structure be obtain from zoo dataset in uci machine learning repository. 
the cluster technique be implement through weka 3.7.6 an open source datum mining tool. 
performance of cluster technique viz em farthest first and k means be analyze. 
it be find that farthest first clustering technique yield the good performance with an accuracy of 93.0693. 
the methodology propose in this paper can be adopt for any other case study also. 
on one shot similarity kernels explicit feature map and property. 
kernel have be a common tool of machine learning and computer vision application for modeling nonlinearitie and/ or the design of robust1 similarity measure between object. 
arguably the class of positive semidefinite psd kernel widely know as mercer s kernels constitute one of the most well study case. 
for every psd kernel there exist an associated feature map to an arbitrary dimensional hilbert space h the so call feature space. 
the main reason behind psd kernel popularity be the fact that classification regression technique such as support vector machines svms and component analysis algorithm such as kernel principal component analysis kpca can be devise in h without an explicit definition of the feature map only by use the kernel the so call kernel trick. 
recently due to the development of very efficient solution for large scale linear svm and for incremental linear component analysis the research towards find feature map approximation for class of kernel have attract significant interest. 
in this paper we attempt the derivation of explicit feature map of a recently propose class of kernel the so call one shot similarity kernel. 
we show that for this class of kernel either there exist an explicit representation in feature space or the kernel can be express in such a form that allow for exact incremental learning. 
we theoretically explore the property of these kernel and show how these kernel can be use for the development of robust visual tracking recognition and deformable fitting algorithm. 
learn hash codes with listwise supervision. 
hash technique have be intensively investigate in the design of highly efficient search engine for large scale computer vision application. 
compare with prior approximate near neighbor search approach like tree base indexing hashing base search scheme have prominent advantage in term of both storage and computational efficiency. 
moreover the procedure of devise hash function can be easily incorporate into sophisticated machine learning tool lead to data dependent and task specific compact hash code. 
therefore a number of learn paradigm range from unsupervised to supervised have be apply to compose appropriate hash function. 
however most of the exist hash function learn method either treat hash function design as a classification problem or generate binary code to satisfy pairwise supervision and have not yet directly optimize the search accuracy. 
in this paper we propose to leverage listwise supervision into a principle hash function learn framework. 
in particular the rank information be represent by a set of rank triplet that can be use to assess the quality of rank. 
simple linear projection base hash function be solve efficiently through maximize the rank quality over the training datum. 
we carry out experiment on large image dataset with size up to one million and compare with the state of the art hashing technique. 
the extensive result corroborate that our learn hash code via listwise supervision can provide superior search accuracy without incur heavy computational overhead. 
a new classification scheme use artificial immune systems learning for fuzzy cognitive mapping. 
in this paper an intelligent approach base on artificial immune system ais be propose to perform the task of classification use fuzzy cognitive map learn. 
fuzzy cognitive map be an approach to knowledge representation and inference include learning capability it emphasize the connection of concept as basic unit for store knowledge and the structure that represent the significance of system. 
one of the most useful aspect of the fcm be its prediction capability as a classification tool. 
little research have be do on pattern classification use fcm approach. 
the propose artificial immune algorithm inspire by theoretical immunology and observed immune function principle and model be consider to learn fcm network provide a category after classification. 
consequently the propose method provide an fcm learning methodology for pattern recognition. 
the proposed algorithm be implement in a previous autism classification problem as well as in some benchmark machine learn dataset to show its functionality. 
prediction of energy consumption indices in the automotive industry. 
since the automotive industry be one of the most competitive market key player should be capable of evolve their management strategy from a reactive to proactive approach. 
this way it be critical for this type of company to explore a new performance management approach where an effective interaction between the strategic and operational layer should be achieve. 
in line with this vision a framework be present that help stakeholder make decision base on the ability to anticipate future performance behaviour. 
use lead indicator as reference the key idea be to structure and model the exist knowledge within a mathematical tool in order to project the manufacturing system s behaviour into the future. 
in order to show the reliability and importance of this framework this paper present a research perform at an automotive plant. 
the aim be to model the factor affect energy consumption and thus estimate the future behaviour in term of sustainability issue. 
a study on adaptive nurbs interpolation points calculation with jerk limit acceleration. 
feedrate adaptive interpolation algorithm for nurbs curve effectively reduce the chord error. 
in order to improve the machining quality and reduce the impact to the machining tool cause by the change of feedrate it need to control the fluctuation of the acceleration and jerk. 
in order to efficient and accurate calculate the interpolation point during the process of interpolation through the analysis of the computation structure for b spline an algorithm and its calculation complexity be give for nurbs interpolation base on the sharing of the value of basis function. 
simulation result show that the algorithm effectively control the fluctuation of the acceleration and jerk improve the efficiency of interpolation calculation and shorten the interpolation time. 
multi sensor fusion for sport genre classification of user generated mobile video. 
we present a robust multimodal approach for classify the sport genre in video record by mobile phone user at a sport event. 
in addition to traditional audio visual content analysis tool we propose to analyze auxiliary sensor datum electronic compass datum and accelerometer data capture simultaneously with the video recording. 
by mean of machine learning technique we build model of visual appearance camera motion from auxiliary sensor datum and audio scene which be use for classify the datum from each modality. 
the sport genre be obtain by fuse the information provide by the model. 
we propose to use the quality of each modality as an indication of its reliability. 
extensive experiment be perform on real test datum collect at public sport event. 
we provide comparison on the use of different modality set and fusion method. 
finally we show how the propose method achieve robust classification even in the considered unconstrained scenario. 
autonomous robot teaching use a smart robot in production line. 
in industrial robot application to adapt the environmental change the robot teaching process have to be perform frequently by operator. 
this process increase the operational cost and reduce the manufacture efficiency. 
this paper propose to use a smart robot(named adult robot with advanced sensing and decision make capability to teach child robot in the production line. 
a markov decision process(mdp be formulate and solve use q learning to correct the child robot s tool position. 
the proposed algorithm be implement to teach an industrial robot child to perform a high accuracy peg in hole assembly process. 
the correspond adult robot be a mobile robot platform with an in hand camera. 
the experimental result verify the effectiveness of the propose method. 
since there be no calibration between the vision system the adult robot and the child robot the flexibility of the propose method be greatly increase. 
hence it can be easily apply in industrial application where robot teaching be need. 
use of high resolution multispectral imagery from an unmanned aerial vehicle in precision agriculture. 
precision agriculture require high spatial management of the input to agricultural production. 
this require that actionable information about crop and field status be acquire at the same high spatial resolution and at a temporal frequency appropriate for timely response. 
this paper present some result from an on go project to explore the use of imagery collect from the use of a small unmanned aerial vehicle call aggieair to estimate plant nitrogen and chlorophyll at approximately 13 cm resolution for a field of oat serve by a center pivot sprinkler system. 
when combine with appropriate analytic tool the aggieair imagery can be successfully use to estimate plant nitrogen and chlorophyll level at much fine than one m resolution. 
ensemble of classifier for remote sensed hyperspectral land cover analysis an approach based on linear programming and weighted linear combination. 
hyperspectral image have be consider as one of the most important tool for remote sensed land cover analysis. 
such image have information about material on earth s surface express in many wavelength that allow we to identify and classify those material with more accuracy. 
in this work we use a combination of several classification method in order to produce an accurate thematic map base on the remote sensed hyperspectral image classification. 
to perform the combination three type of feature representation and two learn algorithm support vector machines svm and backpropagation multilayer perceptron neural network mlp be use yield six classification method. 
our approach proposal be base on weighted linear combination wlc in which weight be find use linear programming lp wlc lp. 
experiment be carry out use two well know database indian pines acquire by aviris sensor and pavia university acquire by rosis sensor. 
result show the efficiency of our propose approach which significantly reduce the time require to find optimal weight for the combiner compare to a previous approach base on genetic algorithm. 
learning incoherent subspaces for classification via supervised iterative projections and rotation. 
in this paper we present the supervised iterative projection and rotation s ipr algorithm a method to optimise a set of discriminative subspace for supervised classification. 
we show how the propose technique be base on our previous unsupervised iterative projection and rotation ipr algorithm for incoherent dictionary learning and how project the feature onto the learn sub space can be employ as a feature transform algorithm in the context of classification. 
numerical experiment on the fisheriris and on the usps dataset and a comparison with the pca and lda method for feature transform demonstrate the value of the propose technique and its potential as a tool for machine learning. 
a comparative study of signal and image processing systems for condition monitoring of milling process use artificial intelligence. 
a comparative study between two type of tool wear monitoring system for mill process be introduce in this paper. 
the suggested sensory fusion approach include the implementation of an infrared camera in addition to force vibration sound and acoustic emission sensor. 
the majority of the research work available in literature and industry focus on use one dimensional signal such as force vibration. 
two dimensional datum such as infrared and visual image be limit in literature in relation to machine operation. 
this work compare between one dimensional and two dimensional datum for the development of a tool condition monitor system for mill process. 
the paper present a comparative study between the performance of signal and image processing algorithm use neural network. 
fourier transformation and wavelets analysis be use to process one dimensional and two dimensional datum respectively. 
the result indicate that two dimensional datum obtain from infrared image have significant capability in comparison to one dimensional datum for the detection of tool wear for the select image and signal processing algorithm. 
rapid permissions base detection and analysis of mobile malware use random decision forest. 
the explosion in mobile malware have lead to the need for early rapid detection mechanism that can detect malware and identify risky application prior to their deployment on end user device without the high cost of manual static and dynamic analysis. 
previous work have show that specific combination of android permission intent broadcast receiver native code and embed application can be effectively use to identify potentially malicious application. 
we extend this work by use frequent combination of such attribute as training feature for random decision forest classification of malicious and benign application. 
we demonstrate that use combination of frequently occur permission in this manner significantly improve previous result and provide true positive rate in excess of 90 while maintain tractable false positive rate. 
this be true even with novel malware that be not reliably detect at the time of release by conventional anti malware tool. 
in addition the auxiliary information generate by the random decision forest algorithm provide useful insight into the key indicator of malicious activity and the functionality of the associated malware. 
keeper a tool for management and automated deployment of cms web service. 
the cms experiment at the cern lhc run many web service for different need. 
developer of such service need to learn how to securely configure many other system like apache and shibboleth and to maintain several machine. 
the keeper be a tool that be able to automatically fully deploy project from scratch in node by write flexible configuration python script in a declarative look way by leverage python s object orient capability remove the complexity for developer. 
the keeper also automate log monitoring cronjob and other asset and allow to apply action to they. 
the class be reusable for most of cms project therefore remove the duplication of effort. 
finally it allow to create hierarchy of project from different group to be deploy eliminate the need for developer to maintain their own machine. 
while the keeper be develop for the specific use case inside the cms experiment its implementation be deliberately agnostic with respect to the environment and can be easily adapt to other use outside. 
automatic classification of power quality disturbances a review. 
the development of intelligent power quality pq disturbances classification and analysis tool exploit various digital signal process technique to extract important feature from the pq signal. 
the purpose of this paper be to present a comprehensive review and discussion of the advanced tool for the automatic classification of pq disturbance. 
the digital signal processing tool apply for feature extraction include fourier transform wavelet transform stockwell transform etc. 
for the classification of pq disturbance the artificial intelligence technique such as artificial neural network fuzzy logic and support vector machine be review here. 
a large number of feature use as input to the classifier may affect the accuracy rate and require a large memory space. 
the optimization technique have be use in literature for optimal feature selection which include genetic algorithm simulated annealing particle swarm optimization and ant colony optimization. 
an extensive review provide to the researcher a clear perspective on various technique of pq disturbance classification. 
semi supervised algorithm for concept ontology based word set expansion. 
word list that contain closely relate set of word be a critical requirement in machine understanding and processing of natural language. 
create and maintain such closely related word list be a critical and complex process that require human input and carry out manually in the absence of tool. 
we describe a supervised learning mechanism which employ a word ontology to expand word list contain closely relate set of word. 
the approach describe in this paper use two novel supervised learning technique that complement each other for the purpose of expand exist list of relate word. 
expand concept variable list of relex2frame component of opencog artificial general intelligence framework use wordnet be use as a proof of concept. 
intervention of this project would enable opencog application to attempt to understand word that they be not able to understand before due to the limited size of exist list of relate word. 
machine learning tools for content base search in large multimedia databases. 
z language based an algorithm for event detection analysis and classification in machine vision. 
a common task in various machine learning ml application area involve observe regularly gather datum for interesting event. 
this mission be predominant in reconnaissance but also in responsibility fluctuate from the investigation of scientific datum to the observing of unsurprisingly happen event and from control engineering procedure to notice human behavior. 
we will refer to this observe procedure with the determination of classify remarkable manifestation as event detection analysis and classification. 
with the appearance of personal computer pc a lot of effort have be make to substitute manual investigation by a computerized manner. 
datum nevertheless have become gradually difficult and the size of gather datum have become enormously bulky in late year. 
text document jpeg image mp3 video and even relational datum be now regularly gather. 
in this paper we propose an algorithm for event detection analysis and classification in machine vision. 
till propose algorithm be deliberate a significant facility require degree of event detection can not be achieve. 
finally we use k mean algorithm for classification of incoming event and propose algorithm have be validate by z formal specification language in general. 
the propose algorithm have be implement in matlab and result have be gather through a data mining tool. 
use the propose algorithm the event be easily detect analyze and classify in machine vision. 
an approach towards automatic generation of evidence base decision support systems for clinical diagnosis base on an extensive clinical guideline schema. 
machine executable clinical guideline be of great importance to the implementation of clinical decision support system cdss. 
any change to they in traditional cdss would lead to redesign and redevelopment of system which make the system hard to maintain and not adaptive to different environment. 
we propose in this paper an approach towards automatic generation of evidence base decision support system for clinical diagnosis base on an extensive clinical guideline schema. 
flowchart be use for the representation of good clinical guideline in the graphical knowledge definition tool. 
through mapping rule flowchart can be change into structural knowledge that store in knowledge repository. 
knowledge interpretation engine be design to parse the knowledge and provide necessary information for web base assist diagnosis. 
the mutual transformation of flowchart and structural knowledge base on mapping rule make the knowledge repository adaptive to different situation and easy to be maintain. 
the cooperation of mapping rule and the engine make the propose system as automatic as possible when system capture new clinical knowledge. 
analysis of feature selection techniques for network traffic dataset. 
time take by intrusion detection system ids in order to detect malware be very crucial factor. 
network traffic dataset have many feature and all may not contribute in detection of threat. 
reject irrelevant feature may increase performance of ids by reduce computational time. 
in this paper feature selection technique base on gain ratio attribute correlation feature selection chi squared attribute consistency subset filter attribute filter subset information gain attribute one ra attribute and symmetrical uncert attribute evaluation be test on three classifier naive bayes j48 and part by use weka datum mining and machine learn tool on uci kdd cup 1999 network traffic dataset. 
the feature selection method be analyze on parameter like accuracy number of feature select out of total feature time take tp rate and fp rate. 
the result show that almost same level of accuracy can be achieve by reduce number of feature considerably which also take less computational time to detect threat. 
filter subset evaluation come out to be good technique which suggest only 17.07 of total feature. 
hence it be propose that reduce number of feature should be use in ids for the quick detection of threat. 
protein secondary structure prediction use support vector machines svm. 
bioinformatics or computational biology be field of science in which biology computer science and information technology merge into a single discipline. 
in modern computation biology protein secondary structure prediction be a major problem. 
secondary structure prediction be depend on its amino acid sequence. 
current study prefer machine learning technique for classification and regression task. 
recently many researcher use various datum mining and machine learn tool for protein structure prediction. 
our intention be to use model base i.e. supervised learning approach for protein secondary structure prediction and our objective be to enhance the prediction of 2d protein structure problem use advance machine learning technique like linear and non linear support vector machine with different kernel function. 
the dataset use for this problem be protein data bank pdb set which be base on structural classification of protein scop rs126 and cb513. 
a collaborative tagging system with formal concept analysis. 
tag can be use to annotate resource on the web. 
this enable user to share or browse the resource or retrieve they in future. 
collaborative tagging system or folksonomie have the potential to become an integral part of web 2.0. 
formal concept analysis fca be a powerful tool commonly use in artificial intelligence data mining and with the semantic web. 
fca have be use in online document and resource management system. 
in this case the resource be treat as object and tag as attribute. 
fca group these resource hierarchically in a lattice structure thereby provide multiple dimension to information retrieval. 
object be group with a set of attribute common to all of they. 
these group be call concept and be the building block of fca lattice. 
a system be discuss that model object and their tag with formal concept analysis. 
a user s query for object with certain attribute can be map to a particular concept. 
the object of this concept can be return as result. 
far related and relevant result can be provide by find the concept most similar to the result concept and return their object to the user as well. 
thus an information retrieval system can be implement. 
further automation can be investigate with machine learning or artificial intelligence technique. 
design of asynchronous systems on fpga use direct mapping and synchronous specification. 
complex synchronous digital system can be implement on fpga field programmable gate arrays but due to the global clock might have problem with clock skew performance degradation and increase of power consume. 
an alternative to these design be the asynchronous paradigm that solve the problem relate to the clock. 
however it be difficult to design asynchronous circuit especially in the fpga platform. 
this work present in the style of asynchronous fsm finite state machine data path a method that implement asynchronous digital system on fpga. 
the propose method use the tool of paradigm synchronous thus synthesize without the knowledge of asynchronous logic. 
our method synthesize the asynchronous fsm by direct mapping from the conventional state transition graph. 
through a case study it be show the simplicity of the propose methodology. 
impact of variability in data on accuracy and diversity of neural network based ensemble classifier. 
ensemble classifier be very useful tool which can be apply for classification and prediction task in many real world application. 
there be many popular ensemble classifier generation technique include neural network base technique. 
however there be many problem with ensemble classifier when we apply they to real world datum of different size. 
this paper present and investigate an approach for find the impact of various parameter such as attribute instance class on cluster accuracy and diversity. 
the primary aim of this research be to see whether there be any link between these parameter and accuracy and diversity. 
the secondary aim be to see whether we can find any relationship between number of cluster in ensemble classifier and datum variable. 
a series of experiment have be conduct by use different size of uci machine learn benchmark dataset and neural network ensemble classifier. 
traffic sign detection with vg ram weightless neural network. 
we present a biologically inspire approach to traffic sign detection base on virtual generalizing random access memory weightless neural networks vg ram wnn. 
vg ram wnn be effective machine learning tool that offer simple implementation and fast training and test. 
our vg ram wnn architecture model the saccadic eye movement system and the transformation suffer by the image capture by the eye from the retina to the superior colliculus in the mammalian brain. 
we evaluate the performance of our vg ram wnn system on traffic sign detection use the german traffic sign detection benchmark gtsdb. 
use only 12 traffic sign image for training our system be rank between the first 16 method for the prohibitory category in the german traffic sign detection competition part of the ijcnn 2013. 
our experimental result show that our approach be capable of reliably and efficiently detect a large variety of traffic sign category use a few training sample. 
machine learn to predict extubation outcome in premature infant. 
though treatment of the ventilated premature infant have experience many advance over the past decade determine the good time point for extubation of these infant remain challenge and the incidence of extubation failure largely unchanged. 
the objective be to provide clinician with a decision support tool to determine whether to extubate a mechanically ventilated premature infant by use a set of machine learning algorithm on a dataset assemble from 486 premature infant receive mechanical ventilation. 
algorithms include artificial neural network ann support vector machine svm naive bayesian classifier nbc boost decision tree bdt and multivariable logistic regression mlr. 
result for ann mlr and nbc be satisfactory area under the curve auc]:0.63 0.76 however svm and bdt consistently show poor performance auc similar to 0.5. 
complex medical datum such as the data set use for this study require far preprocesse step before prediction model can be develop that achieve similar or well performance than clinician. 
preprocessing unbalanced data use weighted support vector machines for prediction of heart disease in children. 
machine learning technique be an important tool for diagnose a number of disease as have be show by the recent literature. 
hospital and medical clinic have a huge amount of datum about the treatment of their patient however rarely analysis of these datum be perform in order to extract intrinsic information aim at model a specific problem. 
this work present an analysis of medical datum aim at determine whether child patient be cardiac or not. 
to this end raw datum be collect at a brazilian local hospital to be preprocesse in order to build the classification model. 
only non invasive information be use such as height weight gender and birthday date to create another set of derive variable such as bmi body mass index to support the classification phase. 
however the collected datum be show to be very imbalanced. 
aim at treat this problem many tecnique be employ and one new approach be propose. 
the result show that the propose approach outperform the other method in three out of four evaluation metric. 
intelligent classroom system for qualitative analysis of students conceptual understanding. 
with the increase of ubiquitous datum all over the internet intelligent classroom system that integrate traditional learning technique with modern e learn tool have become quite popular and necessary today. 
although a substantial amount of work have be do in the field of e learn specifically in automation of objective question and answer evaluation personalized learning adaptive evaluation system the field of qualitative analysis of a student s subjective paragraph answer remain unexplored to a large extent. 
the traditional board chalk talk base classroom scenario involve a teacher set question paper base on the concept teach check the answer write by student manually and thus evaluate the student performance. 
however set question paper remain a time consuming process with the teacher have to bother about question quality level of difficulty and redundancy. 
in addition the process of manually correct student answer be a cumbersome and tedious task. 
in this paper we put forth the design analysis and implementation detail along with some preliminary result to build a system that integrate all the above mention task with minimal teacher involvement that not only automate the traditional classroom scenario but also overcome its inherent shortcoming and fallacy. 
intelligent gesture recognition to design more efficient intelligent multimodal systemd. 
technology use in multimodal interface include conventional direct manipulation device like the keyboard mouse and pen and touch screen as well as progressively more advanced recognition technology such as speech recognition 2d and 3d gesture recognition and lip movement and gaze tracking. 
usability study explore and evaluate the human factor involve in multimodal input provide useful insight and guidance toward the design and implementation of multimodal interface. 
the primary goal in the design of any user interface be to facilitate the interaction between user and machine. 
this user center goal be the guide force behind choice make in the design process. 
there be of course many system engineering issue that influence interface design decision such as schedule proper functionality reliability etc. 
however address these issue ideally serve the purpose of create a well user experience with the system. 
one purpose of research multimodal interface from an hci perspective be to evaluate how to take advantage of the benefit they provide over unimodal recognition base interface and conventional keyboard and mouse interface. 
such advantage include flexibility availability adaptability efficiency low error rate and a more intuitive and natural interaction. 
technology be one way to remove the hindrance and benefit the people. 
it be find that all the recent technique for multimodal system be base on computer tool technique and technology like artificial intelligence expert system graph matching soft computing natural language processing nlp multi modal and hci several researcher have explore their possibility and have achieve result to certain extent but progress in speech recognition language understanding use gesture optimization as a whole have be limit which give we future scope to go ahead in this domain. 
greenhouse temperature control system base on fuzzy theory. 
the purpose of this paper be to present an adaptive method base on fuzzy control for temperature control in the greenhouse. 
first of all a mathematic model be construct for the air temperature in the greenhouse. 
then the correspond fuzzy control system be implement by use the simulink tool of matlab. 
at last fuzzy controller be realize use visual basic vb in the upper machine in order to verify the system correct or not. 
the result show the validity and reasonability of the fuzzy control strategy for the temperature control in the greenhouse. 
identification of image fragment for file carving. 
recover image intact be an important process in digital forensic as they may represent primary evidence in crime case such as child pornography. 
due to filesyetem fragmentation mechanism image may be split into several fragment on a physical storage. 
as such recover image fragment and reconstruct the original image embody challenge for file carving tool particularly when the filesystem metadata be not available. 
in this paper we propose a method for image fragment identification use a machine learning approach. 
our method exploit feature in unknown image fragment and apply various machine learn algorithm to reconstruct the original image by identify to which particular image a fragment belong. 
we provide the detail of our method as well as a validation of its effectiveness. 
information integration for emergency management recent csiro case study. 
the csiro ict centre s information engineering laboratory have be involve in a number of emergency management relate project over the last four year. 
in these project we have apply our software engineering expertise in the area of web technology user interface and database along with research capability in machine learning distribute system text processing and datum stream management. 
this process have increase our understanding of the various role and responsibility of different government department at the federal and state level and of the wide emergency service community. 
the research agenda of the csiro be broad and its application to the area of disaster management be no different. 
in this field of research one of the csiro s aim be to improve the process and service delivery of disaster management in australia and to provide high impact solution to strengthen the disaster resilience of the nation in the future. 
as well as the project review in this paper there be other research activity underway or complete within the csiro that address the issue of disaster management see hawkins et al. 
2012 for an overview. 
the focus of this paper be to present three recent csiro project relate to emergency management highlight their difference and similarity with a focus on the challenge encounter and a categorisation of the target datum item utilise. 
the pilot impacts portal http://www.fend.org.au/ be a web accessible user interface to a collection of national datum item describe historical fire emergency and natural disaster event and their associate impact. 
the project be a collaboration with fire rescue nsw that aim to well understand the economic social and environmental impact on community due to disaster event. 
the emergency response intelligence capability project http://eric.csiro.au/ be a collaboration with the australian government department of human services emergency management team who be responsible for intelligence gathering and situation report during emergency event. 
the csiro have develop a tool that support the department s operational task by automatically gather datum from a range of source present the datum on a map base website and generate customise situation report. 
the emergency situation awareness system https://esa.csiro.au/ analyse twitter message to provide early detection of emergency event. 
it extract situation awareness information as the disaster unfold effectively crowd source relevant detail and provide time critical information that allow emergency service to respond rapidly and appropriately. 
a short overview of each project be present. 
each system make use of different type of information historical archive community detail near real time authoritative event information and social medium content. 
combine all of this information will provide emergency management organisation with well quality information for decision making result in improved community outcome. 
social medium be a new channel of information that can provide further intelligence about emergency event. 
authoritative information be be publish on twitter by the emergency service community which can be augment with non authoritative crowd source social medium content to provide a well understanding of emergency event. 
forerunner efficient and smart solution for sg inspection. 
steam generator sg be a critical component in the nuclear power plant npp with the large surface area in the primary reactor coolant system and its integrity be essential for avoid possible radioactivity release to the environment. 
sg tube wall be susceptible to age various degradation mechanism take place in its structural material such as volumetric material loss due to fret wear stress corrosion crack scc pit corrosion flaw accelerate corrosion intergranular attack iga etc. 
new more strict regulatory requirement request plant management to assure the safety of the public and the environment as well as well sg life management strategy. 
therefore those requirement force specialized inspection company to develop advanced probe technology more reliable instrument and robotic and improve training and knowledge of personnel involve in inspection process. 
thank to intensive evolution of electronic and computer in the last decade inspection system have evolve to a much high level of automation efficiency and reliability. 
tool base on the eddy current examination technique be subject to continuous development from a simple detection tool to advanced diagnostic tool that provide input for decision making base on the integrity assessment. 
forerunner be a part of the inetec s inspection system for pwr plant primarily use for quick and accurate positioning of the tube guide on the sg tube sheet and efficient performance sg tube wall inspection. 
it be a light mobile robot adjustible for different tube sheet configuration and inner tube diameter. 
integrated electronic base on the ethercat technology increase the speed of operation and simplify the cable managment. 
use the strong gripper currently available at the market the forerunner be a realible and robust system highly automate with a machine vision and build in smart algorithm for optimal movement. 
forerunner be control by pc base software which be synchronize with inetec eddyone software package. 
the complete scope of inspection activity the planning examination datum analysis and final report become a highly automate process which make the inspection much easy and more reliable. 
accurate 3d textured model of vessels for the improvement of the educational tools of a museum. 
besides the demonstration of the finding modern museum organize educational program which aim to experience and knowledge sharing combine with entertainment rather than to pure learning. 
toward that effort 2d and 3d digital representation be gradually replace the traditional recording of the finding through photo or drawing. 
the present paper refer to a project that aim to create 3d textured model of two lekythoi that be exhibit in the national archaeological museum of athens in greece on the surface of these lekythoi scene of the adventure of odysseus be depict. 
the project be expect to support the production of an educational movie and some other relevant interactive educational program for the museum. 
the creation of accurate development of the painting and of accurate 3d model be the basis for the visualization of the adventure of the mythical hero. 
the datum collection be make by use a structure light scanner consist of two machine vision camera that be use for the determination of geometry of the object a high resolution camera for the recording of the texture and a dlp projector. 
the creation of the final accurate 3d textured model be a complicated and tiring procedure which include the collection of geometric datum the creation of the surface the noise filtering the merging of individual surface the creation of a c mesh the creation of the uv map the provision of the texture and finally the general processing of the 3d textured object. 
for a well result a combination of commercial and in house software make for the automation of various step of the procedure be use. 
the result derive from the above procedure be especially satisfactory in term of accuracy and quality of the model. 
however the procedure be prove to be time consume while the use of various software package presume the service of a specialist. 
a constructivist approach for implement and evaluate algorithm in a machine vision course at the undergraduate level. 
the growth of area such as automation and robotic demand autonomous system endow with sophisticated perception system like machine vision. 
however undergraduate level education be not provide good result in this sense because student do not participate in the creation of their own knowledge they be only passive observer. 
on the other hand fpga technology have great potential in area such as machine vision where many hypothesis be evaluate concurrently high computation rate be require and the current system be far from equal human performance. 
our research note that by use fpga and constructivist learning as the methodology assessment of learn in electronic science be not a separate process after learn have occur but rather learn and assessment be coterminous. 
thus this paper present a constructivist tool focus on a machine vision course that allow student to implement and evaluate algorithm of this area on an fpga. 
c 2013 the authors. 
publish by elsevier ltd.. 
a textbook based serious game for practising spoken language. 
we describe a web enable serious game intend to help german speak beginner student of english improve their generative and auditory competence. 
the tool be build on top of the exist call slt platform the architecture of which be briefly describe. 
it offer a short course of eight interactive lesson use a combined vocabulary of about 450 word and be develop in collaboration with a secondary school teacher with the content take from a commonly use textbook. 
lesson be structure as a short dialogue between the student and the machine where the student be encourage to use simple language in practical context like book a hotel room buy clothe or order a meal in a restaurant. 
a lesson connect together group of component example. 
at each turn the system start by play a short video file in english and simultaneously display a piece of text in german indicate to the student how they should reply. 
the student give a spoken response in english if they be uncertain how to respond they can first ask for a help example. 
after the student answer the system perform speech recognition machine translation and matching and either accept or reject. 
there be multiple path through the dialogue control by a lesson structure define in an xml file supply by the course designer. 
the overall system be gamifie to increase student motivation use common game element such as badge. 
we conclude with a brief description of an informal pre study carry out on several child age between nine and 13. 
the old child like the system and find it easy to use while the young one struggle. 
predict student performance in foreign language with a serious game. 
in this digital age many statement have be make regard the use of technology for teaching purpose. 
in this sense serious games be gain ground consider that besides their technological advantage they provide fun which allegedly engage student in their training. 
much research have be carry out to show how serious games improve teaching methodology and student learn outcome in various subject. 
this research focus on the field of digital game base learning from a different perspective namely the work carry out do not focus on the use of serious games for teaching and learning but on the use of such tool for the prediction of learn outcome. 
accurately predict future student performance let teacher give customize advice to they. 
the approach be undertake by mean of machine learning and datum mining technique and educational datum mining technique in particular. 
these technique be apply to datum collect from game play by student. 
for such purpose the conference interpreter coin a serious game which simulate a context of simultaneous interpreting have be develop and use as a data mining tool. 
follow this the experiment carry out be describe and machine learning datum mining result be present and discuss. 
acquire gear knowledge by a company with sound background in machining technology. 
the high performance manufacturing group of the faculty of engineering of bilbao be always look for new and spread way to improve the knowledge in order to teach accord to the late innovation. 
one of the main field of engineering take care of analyze the different element integrate in machine tool such as gear. 
nowadays there be a lot of company whose production be base on the wide range of gear manufacture straight helical spiral bevel gear. 
manufacture gear without previous knowledge present a new challenge for the company. 
in these case the company must find outside knowledge. 
from this idea the enngrana project have be develop join together university and company. 
this paper show how theoretical concept of gear must be transmit to a company and what documentation be need consider the new technology that be use for make gear. 
besides consider the exist difference between people in formation process qualified people engineer or workshop employee the practical lesson must be adapt to their different need. 
be productivity the main objective of the project. 
on machine tool training for mechanical engineer. 
the high performance manufacturing group of the university of the basque country upv ehu have a fully equip workshop. 
the department of mechanical engineering have more than 20 machine commonly use to improve some aspect of teaching and also for research on innovation project. 
it also have various offimatic desktop equipment that allow to use software support tool as development help. 
student learn in the workshop can use available system as a first approach to real industry and theoretical studied operation. 
besides this fact provide student a much well training orient to a successful career. 
innovation in machine tool be one of the most important key of this educational issue. 
take into account this target it have be develop a software application define as subsystem to help both researcher and student to get the good in simulation performance. 
it include mechanical operation such as turning mill or drill in a simulated environment. 
the result show fully performance in every realistic exercise carry on. 
moreover the development of these simulation tool can almost completely avoid the possibility of error when machine and therefore get close to the optimal result in an easy way. 
thus combine real experimental test and simulation allow student to identify real process and learn practically easily and with a much great efficiency. 
interdisciplinary coordination between subject of materials engineering degree through problem based learning. 
this work describe the innovative educational project relate to three subject of the degree on materials engineering. 
this involve the coordination among lecturer of the subject for the production of new educational material that imply the active participation of the student to favour their autonomous learning and the development of the generic and specific skill associate to the subject. 
the methodology consist in learning base on real industrial problem. 
they be divide into two part that be analyze and solve under diverse point of view in each subject i physical problem be solve in the subject of electronic and thermal behavior of the materials and optical and magnetic behavior of the materials and ii the second part be treat in the subject ceramic materials. 
for example a real industrial application about optical fiber can be associate to problem of material with specific optical property and another important aspect be the selection of the ceramic material the choice of design or manufacturing process etc. 
new procedure for the evaluation of acquire knowledge and develop skill be establish. 
to evaluate the success of the activity the opinion of the student be take into account through voluntary and anonymous survey. 
simulator for lean manufacturing application quick change case. 
we report a case of education in implement improvement in the industry with result that significantly reduce training time and significantly increase knowledge retention as a result of an improvement to shorten the learn cycle deployment to user of lean manufacturing tool. 
this research address the impact of the transmission of knowledge through the practice of lean manufacturing technique use physical machine for simulation. 
it point out that this be a physical simulation to differentiate the concept from that of a virtual simulator. 
the development of a simulator for lean manufacturing application have two main component that need to be define. 
the first one be simulate we use it in the sense to try and learn in an environment where condition have double appearance and characteristic of real system without compromise business productivity. 
with simulation it have be achieve great success in teach concept and process. 
the business benefit achieve by company use simulator for implement improvement allow they to compete with their local national and international counterpart. 
for company a short implementation time mean the benefit will be enjoy soon. 
the second refer to the concept lean a word introduce as a new paradigm a couple of decade ago in the book the machine that change the world and be synonymous with the toyota production system. 
the essence of it be the search of perfection through decision base on a long term philosophy even at the expense of short term financial goal. 
it consist in design manufacturing in a way that constantly eliminate waste. 
it be about people their development their aspiration and their work environment. 
it be the solution of manufacturing problem through continuous improvement and training. 
it be base on knowledge that be learn from practice. 
the appearance of lean technique to solve problem have increase profit in over 50 compare to those obtain in mass manufacturing. 
the knowledge of these procedure help operator to improve process in the production floor quickly and accurately. 
experimentation in toyota s way allow people to test their hypothesis and learn from their success and failure. 
in fact it encourage experimentation promote the exchange of the comfort zone to uncharted territory. 
this work present a model base on the cdio model in which the four letter mean conceive design implement and operate the model present in this research also include a renew analysis of the unmet need of the market and the strength that have the company. 
it be very helpful to rethink the educational offer in the light of new technology. 
any focus on improve engineering education must be direct toward these central question what be the knowledge skill and attitude that the engineering student must have complete his study as what skill level be require how can we ensure that student get these skill the development of a simulator for lean manufacturing application to represent real situation that happen in the industry and once build improve learn these technique through experimentation. 
cooperative scheduling system with emergent swarm based behavior. 
this paper present a swarm base cooperation mechanism for scheduling optimization. 
we intend to conceptualize real manufacturing system as interact autonomous entity in order to support decision making in agile manufacturing environment. 
agent coordinate their action automatically without human supervision consider a common objective global scheduling solution take advantage from collective behavior of specie through implicit and explicit cooperation. 
the performance of the cooperation mechanism will be evaluate consider implicit cooperation at first stage through acs pso and abc algorithm and explicit through cooperation mechanism application. 
energy efficient machining via energy data integration. 
energy efficient machining strategy be require to be implement in daily practice to advance the competitiveness of the enterprise on global scale. 
energy information which currently not consider as an integral part of production datum be study. 
a need be identify to integrate energy information into production program and solidify the knowledge for extensive reference. 
to effectively represent and share the data standardized format be regard as one promise approach thus step nc be adopt. 
the propose data model be group into four automate energy monitoring and recording energy estimation and labeling energy optimization and machine tool energy performance. 
the developed schema be compliant and harmonize with other part in step nc standard. 
a case study be present to add energy information to step nc file. 
it can be conclude that standardized datum format enable the integration of energy information into the production process and enhance its sustainable performance. 
design of fundamental ontology for manufacturing product lifecycle application. 
in today s world of fast manufacturing high quality demand and highly competitive market it have become vital for company to be able to extract knowledge from their operate datum to manage and to reuse this knowledge in efficient and automated manner. 
ontology have prove to be one of the most successful method in fulfil this demand and to this day it have be apply in number of scenario within company of all scale. 
the most appealing feature of the ontology be well define structure of the knowledge organization be machine understandable enable automatic reasoning and inference and finally well defined semantic enable easy interoperability and design of the plug in module. 
still one key downfall of ontology be that it usually have to be manually design from the beginning for each new use case. 
this require highly specialized knowledge expert work closely with the domain expert for sometimes significant period of time. 
in this paper we propose linkeddesign solution for describe issue as an example of design of fundamental ontology which can be easily adjust and adopt for different production system thus eliminate the need for repetition of entire design process for every individual company. 
we also discuss and point to a new and challenging field of research emerge from application of ontology into manufacture company mainly concern rapidly grow amount of knowledge which be begin to exceed human ability to process it. 
analysis of manufacturing process sequences use machine learning on intermediate product states as process proxy data. 
quality and efficiency increase in importance over the last year within the manufacturing industry. 
to stay competitive company be force to constantly improve their product and process. 
today s information technology and datum analysis tool be promise to far enhance the performance of modern manufacturing. 
in this paper at first the concept of the product state base view in a distributive manufacturing chain be present follow by a brief introduction of relation between product state along the chain. 
after show that a in detail description base on cause effect model be not economical viable today the possibility of use machine learning on intermediate product state to analyze the process sequence be introduce and discuss. 
provide a chance to analyze large amount of datum with high dimensionality and complexity machine learning tool combine with cluster analysis be perfectly suit for the task at hand within the product state base concept. 
productivity measurement and improvements a theoretical model and applications from the manufacturing industry. 
at many company worker associate productivity or efficiency increase with something negative it be interpret as an increase in speed and the sweat factor. 
productivity be not only make up of the speed factor but these misconception and lack of knowledge tend to put a wet blanket on all attempt to increase productivity. 
it be therefore important to clarify what productivity be and especially how it can be improve. 
in general the productivity at shop floor level can be improve through improve the method increase the performance and increase the utilization. 
the design of the product and the amount of scrape product also affect the productivity in both manual task as well as work perform by machine. 
these aspect of productivity will be elaborate in the theoretical model and the industrial application present in this article. 
the sumo toolbox a tool for automatic regression modeling and active learning. 
many complex real world phenomenon be difficult to study directly use control experiment. 
instead the use of computer simulation have become commonplace as a feasible alternative. 
due to the computational cost of these high fidelity simulation surrogate model be often employ as a drop in replacement for the original simulator in order to reduce evaluation time. 
in this context neural network kernel method and other modeling technique have become indispensable. 
surrogate model have prove to be very useful for task such as optimization design space exploration visualization prototype and sensitivity analysis. 
we present a fully automate machine learn tool for generate accurate surrogate model use active learning technique to minimize the number of simulation and to maximize efficiency. 
ai tool for use in assembly automation and some example of recent application. 
purpose this paper aim to review seven artificial intelligence tool that be useful in assembly automation knowledge base system fuzzy logic automatic knowledge acquisition neural network genetic algorithm case base reasoning and ambient intelligence. 
design methodology approach each artificial intelligence tool be outline together with some example of their use in assembly automation. 
findings artificial intelligence have produce a number of useful and powerful tool. 
this paper review some of those tool. 
application of these tool in assembly automation have become more widespread due to the power and affordability of present day computer. 
research limitation implication many new assembly automation application may emerge and great use may be make of hybrid tool that combine the strength of two or more of the tool review in the paper. 
the tool and method review in this paper have minimal computation complexity and can be implement on small assembly line single robot or system with low capability microcontroller. 
practical implication it may take another decade for engineer to recognize the benefit give the current lack of familiarity and the technical barrier associate with use these tool and it may take a long time for direct digital manufacturing to be consider commonplace. 
but it be expand. 
the appropriate deployment of the new ai tool will contribute to the creation of more competitive assembly automation system. 
social implication other technological development in ai that will impact on assembly automation include datum mining multi agent system and distribute self organise system. 
originality value the novel approach propose use ambient intelligence and the mixing of different ai tool in an effort to use the good of each technology. 
the concept be generically applicable across all industrial assembly process and this research be intend to prove that the concept work in manufacturing. 
predictive model to assess risk of type two diabetes hypertension and comorbidity machine learn algorithm and validation use national health datum from kuwait a cohort study. 
objective we build classification model and risk assessment tool for diabetes hypertension and comorbidity use machine learn algorithm on datum from kuwait. 
we model the increase proneness in diabetic patient to develop hypertension and vice versa. 
we ascertain the importance of ethnicity and native vs expatriate migrant and of use regional datum in risk assessment. 
design retrospective cohort study. 
four machine learn technique be use logistic regression k near neighbour k nn multifactor dimensionality reduction and support vector machine. 
the study use fivefold cross validation to obtain generalisation accuracy and error. 
set kuwait health network khn that integrate datum from primary health centre and hospital in kuwait. 
participant 270 172 hospital visitor of which 89 858 be diabetic 58 745 hypertensive and 30 522 comorbid comprise kuwaiti native asian and arab expatriate. 
outcome measure incident type two diabetes hypertension and comorbidity. 
result classification accuracy of 85 for diabetes and 90 for hypertension be achieve use only simple non laboratory base parameter. 
risk assessment tool base on k nn classification model be able to assign high risk to 75 of diabetic patient and to 94 of hypertensive patient. 
only five of diabetic patient be see assign low risk. 
asian specific model and assessment perform even well. 
pathological condition of diabetes in the general population or in hypertensive population and those of hypertension be model. 
two stage aggregate classification model and risk assessment tool build combine both the component model on diabetes or on hypertension perform well than individual model. 
conclusion datum on diabetes hypertension and comorbidity from the cosmopolitan state of kuwait be available for the first time. 
this enable we to apply four different case control model to assess risk. 
these tool aid in the preliminary non intrusive assessment of the population. 
ethnicity be see significant to the predictive model. 
risk assessment need to be develop use regional datum as we demonstrate the applicability of the american diabetes association online calculator on datum from kuwait. 
automated delineation of radiotherapy volume be we go in the right direction. 
rapid and accurate delineation of target volume and multiple organ at risk within the endure international commission on radiation units and measurement framework be now hugely important in radiotherapy owe to the rapid proliferation of intensity modulate radiotherapy and the advent of four dimensional image guide adaption. 
nevertheless delineation be still generally clinically perform with little if any machine assistance even though it be both time consume and prone to interobserver variation. 
currently available segmentation tool include those base on image greyscale interrogation statistical shape modelling and body atlas base method. 
however all too often these be not able to match the accuracy of the expert clinician which remain the universally acknowledge gold standard. 
in this article we suggest that current method be fundamentally limit by their lack of ability to incorporate essential human clinical decision making into the underlie model. 
hybrid technique that utilise prior knowledge make sophisticated use of greyscale information and allow clinical expertise to be integrate be need. 
this may require a change in focus from automate segmentation to machine assist delineation. 
similarly new metric of image quality reflect fitness for purpose would be extremely valuable. 
we conclude that method need to be develop to take account of the clinician s expertise and hone visual processing capability as much as the underlying clinically meaningful information content of the image datum be interrogate. 
we illustrate our observation and suggestion through our own experience with two software tool develop as part of research council fund project. 
industrial application of advanced adaptive concepts for automatic panel bender. 
recently the requirement on sheet metal production process have increase significantly. 
high precision and flexibility with efficient energy consumption and short cycle time can be achieve by advanced concept only. 
this require a deep insight into the non linear bending process. 
for this sake efficient simulation model have be implement to model the bending process two and three dimensional finite element model combine with multibody simulation tool contact mechanic algorithm and substructure technique. 
the simulation tool have be successfully calibrate by measurement result. 
with the obtain detailed process knowledge new adaptive concept have be introduce a smart crowning system in order to achieve straight profile. 
the industrial application have show the advantage of utilize the above mention technique. 
the straightness of the bend have be significantly increase while energy consumption and cycle time have be reduce. 
secondly the development time of new machine concept have be drastically reduce such that the first prototype can be transfer to series production within short time. 
moreover the apply strategy show a large potential for future development. 
a comprehensive review and evaluation of permutation flowshop heuristic to minimize flowtime. 
in recent year a large number of heuristic have be propose for the minimization of the total or mean flowtime completion time of the well know permutation flowshop scheduling problem. 
although some literature review and comparison have be make they do not include the late available heuristic and result be hard to compare as no common benchmark and computing platform have be employ. 
furthermore exist partial comparison lack the application of powerful statistical tool. 
the result be that it be not clear which heuristic especially among the recent one be the good. 
this paper present a comprehensive review and computational evaluation as well as a statistical assessment of 22 exist heuristic. 
from the knowledge obtain after such a detailed comparison five new heuristic be present. 
careful design of experiment and analysis of variance anova technique be apply to guarantee sound conclusion. 
the comparison result identify the good exist method and show that the five newly present heuristic be competitive or well than the good perform one in the literature for the permutation flowshop problem with the total completion time criterion. 
c 2012 elsevier ltd. 
all right reserve. 
utilizing multiple objectives for the optimization of the pultrusion process based on a thermo chemical simulation. 
pultrusion be one of the most cost effective manufacturing technique for produce fiber reinforce composite with constant cross sectional profile. 
this obviously make it more attractive for both researcher and practitioner to investigate the optimum process parameter pull speed power and dimension of the heating platen length and width of the heating die design of the resin injection chamber etc to provide well understanding of the process consequently to improve the efficiency of the process as well as the product quality. 
use validated computer simulation be a cheap therefore attractive and efficient tool for autonomous numerical optimization. 
optimization problem in engineering in general comprise multiple objective often have conflict with each other. 
evolutionary multi objective optimization emo algorithm provide an ideal way of solve this type of problem without any biased treatment of objective such as weight constant serve as pre assumed user preference. 
in this paper first a thermochemical simulation of the pultrusion process have be present consider the steady state condition. 
follow that it be integrate with a well know emo algorithm non dominated sort genetic algorithm nsga ii to simultaneously maximize the pull speed and minimize a so call criterion of total energy consumption toc which be define as a measure of total heating area(s and associate temperature(s. 
as a result a set of optimal solution be obtain for different trade off between these conflicting objective. 
have this set of trade off solution obviously make the decision make much easy at the end. 
finally a pair of solution be select consider their process parameter and heating die configuration. 
svr noc a performance analysis tool for network on chip use learning base support vector regression model. 
in this work we propose svr noc a learning base support vector regression svr model for evaluate network on chip noc latency performance. 
different from the state of the art noc analytical model which use classical queuing theory to directly compute the average channel wait time the propose svr noc model perform noc latency analysis base on learn the typical training datum. 
more specifically we develop a systematic machine learn framework that use the kernel base support vector regression method to predict the channel average wait time and the traffic flow latency. 
experimental result show that svr noc can predict the average packet latency accurately while achieve about 120x speed up over simulation base evaluation method. 
a web base semantic tagging and activity recognition system for specie accelerometry datum. 
increasingly animal biologist be take advantage of low cost micro sensor technology by deploy accelerometer to monitor the behavior and movement of a broad range of specie. 
the result be an avalanche of complex tri axial accelerometer data stream that capture observation and measurement of a wide range of animal body motion and posture parameter. 
analysis of these parameter enable the identification of specific animal behavior however the analysis process be immature with much of the activity identification step undertake manually and subjectively. 
consequently there be an urgent need for the development of new tool to streamline the management analysis indexing querying and visualization of such datum. 
in this paper we present a semantic annotation and activity recognition saar system which support store visualize annotating and automatic recognition of tri axial accelerometer data stream by integrate semantic annotation and visualization service with support vector machine svm technique. 
the interactive web interface enable biologist to visualize and correlate 3d accelerometer data stream with associate video stream. 
it also enable domain expert to accurately annotate or tag segment of tri axial accelerometer datum stream with standardized term from an activity ontology. 
these annotate datum stream can then be use to dynamically train a hierarchical svm activity classification model which can be apply to new accelerometer data stream to automatically recognize specific activity. 
this paper describe the design implementation and functional detail of the saar system and the result of the evaluation experiment that assess the performance usability and efficiency of the system. 
the evaluation result indicate that the saar system enable ecologist with little knowledge of machine learn technique to collaboratively build classification model with high level of accuracy sensitivity precision and specificity. 
c 2012 elsevier b.v. 
all right reserve. 
transfer deep knowledge on machine vibration to daily manufacturing production. 
in the department of mechanical engineering of the university of the basque country there be a permanent task of research project between university training center and company. 
the high performance manufacturing group hpmg pretend to carry out quality research in the field of manufacturing process the result be both use to improve academic activity and to be transfer to industry. 
thus while the company seek for manufacturing process optimization and productivity improvement the hpmg afford a breakthrough in research and educational growth of the student. 
in this paper the aim of the author be to give a perspective of the different element involve in a project and how this temporary junction can lead to mutual benefit of the work partner. 
as an example we show the fundamental of a recent software that have be create to help a machine builder company in machine tool design. 
learning design versus learning experience design be the experience api make the difference. 
learning design ld emerge from the development of educational modeling language use for the description of learn scenario. 
as a formal specification ims ld of their interoperable representation it can operationalize a wide variety of instructional model in term of role and activity and other standardized concept in a machine readable way. 
unfortunately with the notable exception of the open university of the netherlands ounl ims global learning consortium ims and some devoted center of instructional design its use could not become widespread community practice and ims ld apparently face the destiny of top down educational standard as html5 base mobile learning trend call into question its usability. 
the usability problem that lead to simplified but expressive tool for designing managing and deliver online learning activity such as j. 
dalziel s learning activity management system lams converge towards issue of learning experience design lxd that transplanted principle of usability engineering from the user experience designers uxd community into the field of technology support e didactic. 
meanwhile the new training and learning architecture tla of advanced distributed learning be transform the landscape of activity management with the introduction of the new experience api xapi tincan specification. 
both ims ld and xapi exceed the simple sequencing methodology of scorm and focus on the organization of learn activity but their approach be relate to different knowledge management conception. 
ld be more education orient while xapi be close to the learner center knowledge management conception of lxd. 
reconsider the original goal of ld force the conclusion that it be worthwhile to maintain its modeling advantage separate issue of interoperability machine interpretability of course management and transparency of modeling learning scenario. 
don t make i think unnecessarily be a rule of the second medium age that do not tolerate non domain specific complexity. 
if the need of user friendly visual tool suitable for digital content creation conceptualization and activity orient knowledge organization be not acknowledge as oppose to the requirement of write xml line it be hard to expect in the era of social learning that pedagogic knowledge transfer will comply with powerful e learn standard. 
claim to transparent nodal knowledge representation and orientation in the whole spectrum of mobile multimedia base e content be rightful expectation on behalf of learner anticipate positive learning experience. 
analysis of the possible use case of the tincan api specification point to the recognition that it extricate web base learn from the closed content package course conception of lcms base e learn 1.0. 
its extension include potential refinement of activity tracking may pave the way for effective performance testing. 
the advantage of the modeling capability of the original ld approach and of the promising capability of tla together with the xapi specification circumscribe a more provident web 3.0 conception of lxd. 
such a conception adapt to new self organize and knowledge explorative role of the learner to the orienting orchestrate activity of the coach and to the free use of web base tool and user generate content. 
the emergence and the exposition of the uxd conception confirm that in the open collaborative three. 
zero world of digital content creation lxd be become an activity that shape the space of learn opportunity problem motivation and interest recover the ancient meaning of learn to follow and/or find the track. 
embodied learning a glimpse into the future of skill development in emerging market. 
india be in the midst of an unprecedented phase of demographic change. 
nearly 63.38 about 760 million of india s 1.2 billion population be in the work age group 15 59 year of age. 
in 2010,90 437.4 million of india s total labour force be employ in the unorganized sector. 
however only five 10 of this workforce have receive any kind of skill training. 
therefore we have an urgent need to exponentially increase the seating capacity of skill training institute to reach government s target of 500 million skilled worker by 2022. 
to understand the problem face by current skill training institute in india we conduct a survey and various face to face interview with student instructor and administrator at government industrial training institute sanathnagar hyderabad. 
from the datum we observe that among other reason huge set up cost cost of tool machine raw material etc of training workshop be the major reason which restrict the growth of such skill training institute. 
this paper look towards embody learn as a solution. 
embody learn in most simple term be define as use body for learn. 
it be a relatively new field which merge learn science and human computer interaction. 
it can be most effective form of learn in vocational training as the skill that be learnt be physical and involve body motion. 
we have combine research from multiple area such as learn science human computer interaction simulation and virtual reality to conceptualize our system. 
in recent past there have be significant innovation in the field of body motion sensor which can help we build such embody learning environment with very low cost. 
we be use microsoft kinect for body motion sense. 
in our system we have create a virtual workshop environment which be similar to an actual skill training workshop. 
in the virtual environment the user can move around pick up tool and control a process just as he would do in real life. 
first the user have to follow a tutorial in which the avatar show the user sequence of step involve in do the particular task after this the user have to correctly replicate what the avatar be do by use his own body. 
application of such system range from learn wood working machine operation to high end skill training like aviation medical and combat. 
the system will be able to reduce the cost of skill training by 60 80 as the user will not require raw material tool and machine for basic initial training. 
experimental approach on torsor dynamic analysis for mill process monitoring and diagnosis. 
in the manufacturing process the interaction tool chip machine tool generate cut force and also moment a complete torsor on the tool in three direction. 
these moment represent a significant proportion of energy consume in cut process. 
the aim of this paper be a dynamic analysis apply to the mechanical action the complete torsor and the mechanical vibration to develop a monitoring and diagnosis approach in three dimensional case. 
the method use in our research refer to an advanced analysis of mechanical action to obtain the response of the mill tool during the cutting process and also to identify various defect. 
an important approach in monitoring process be base on the synchronous envelope sea apply on cut vibration continue with the dynamic analysis of the moment. 
fo understand the dynamic phenomenon due to the milling process a complex experimental protocol and analysis be design and realize. 
c 2013 the authors. 
publish by elsevi b.v. 
open access under cc by nc nd. 
simulation based parameterization for process monitoring of machining operations. 
process monitoring can prevent machine and tool failure in metal cutting. 
a successful process monitoring of cut process depend on reliable monitoring limit for the process. 
in industrial application these limit have to be generate in a learning phase during a ramp up process. 
in order to enable process monitoring for single batch production without a leaming phase this paper describe a simulation base approach for generate reference datum to set process limit. 
as a foundation for calculation of monitor limit a position base process simulation have to be establish. 
in a first step an approach of model material removal be evaluate to check whether it fit the application for parameterize the process monitoring. 
in this context the potential of a process simulation for calculate process limit be clarify. 
additionally the quality of datum generate by this kind of simulation be discuss. 
in a second step a method be describe to implement machine property by a virtual machine tool within a simulation of material removal. 
for that purpose a method to use actual datum of axis position and tool within the simulation of material removal be necessary. 
with these datum a way base simulation of material removal can generate reference parameter for monitor limit instead of use datum from a learning phase during the ramp up process. 
by use position datum of a virtual machine tool a reliable source for the actual position of all axis enable the position base simulation to perform material removal in a more accurate way. 
c 2013 the authors. 
publish by elsevi b.v. 
open access under cc by nc nd license. 
performance analysis of unreliable manufacturing system with uncertain parameter estimate. 
traditional system engineering method for the performance evaluation of manufacturing system assume that machine reliability parameter mean time to failure and mean time to repair be precisely know. 
however in practical situation these parameter be either estimate from real life datum or base on expert knowledge. 
in both case they be subject to uncertainty. 
this paper propose for the first time an approach for the performance evaluation of unreliable manufacturing system that consider uncertain machine parameter estimate. 
the propose method be base on the combined use of bayesian estimation probability density function discretization and exist decomposition base technique for analyze manufacturing line compose of unreliable machine and capacitate buffer. 
numerical result show that neglecting uncertainty in the input parameter estimate generate consistent error in the output performance measure estimate thus make the consequent system design and operation decision sub perform. 
an industrial case be propose to show the benefit of this method in real production setting. 
c 2013 the authors. 
publish by elsevier b.v.. 
concept map and internet aid manufacturing. 
manufacturing be a knowledge intensive activity and the internet have become a useful tool for store sharing and reuse knowledge. 
this study describe some issue of internet aid manufacturing knowledge representation from the context of concept map a visual mean for represent knowledge. 
manufacture knowledge be categorize into three category namely general exploratory and emergent knowledge. 
general and exploratory knowledge be exist knowledge whereas emergent knowledge be new knowledge create for perform manufacturing activity designing monitoring optimizing etc. 
all these three category of knowledge have cross referential relationship. 
some of the logical process for create emergent knowledge be also describe. 
use a tool call cmaptools develop by ihmc internet embed concept map be construct. 
further study will be carry out for enhance the machine comprehensibility of the concept map of manufacture knowledge. 
c 2013 the authors. 
publish by elsevier b.v.. 
stock market related pricing mechanism for the tool and mould manufacture industry. 
tool and mould manufacturer typically prepare their quot provide an accurate price of for example a die cast mould be a key competitive factor for such company. 
however particularly in the customise production area calculate the quotation and tender have be prove as extremely challenging and subjective matter. 
one main cause be that time dynamic cost be rarely take into consideration sufficiently even though they have a major impact on the final quotation due to the large time frame between the moment of the initial quotation and the actual production start. 
they neglect can lead to a significant discrepancy of up to 40 percent between pre and post calculation and thus to a loss of the corporate add value. 
a novel method develop at the institute of production engineering and machine tools ifw leibniz universitat hannover aim to provide a framework which allow tool and mould manufacturer to prepare a more precise and reliable quotation by take time dependent dynamic cost into consideration. 
the prediction of the time dynamic cost take place by use stock market pricing mechanism. 
subsequently base on enterprise relate knowledge aggregation this method also account for the probability of occurrence of each quotation thereby minimise the discrepancy between the pre and post calculation c 2013 the authors. 
publish by elsevier b.v.. 
production data handling use a manufacturing indicators knowledge model. 
this paper demonstrate the add value of use knowledge modeling for the structure of manufacture indicator. 
there be a methodology describe the generation of relevant indicator value base on knowledge modeling. 
the model have three different layer start from a generic one down to an instance layer. 
this model can be use for reasoning purpose where the user can identify pertinent information regard the production performance indicators ppi s attribute relation to resource an their connection to other indicator. 
furthermore it can also be use for the generation of query for the handling of datum stream from the shop floor and their translation into useful information for the high level. 
both type of functionality be demonstrate through a specific automotive use case where energy relate datum stream generate from machine be handle by query create through this model. 
c 2013 the authors. 
publish by elsevier b.v.. 
virk an active learning base system for bootstrappe knowledge base development in the neuroscience. 
the frequency and volume of newly publish scientific literature be quickly make manual maintenance of publicly available database of primary datum unrealistic and costly. 
although machine learning ml can be useful for develop automate approach to identify scientific publication contain relevant information for a database develop such tool necessitate manually annotate an unrealistic number of document. 
one approach to this problem active learning al build classification model by iteratively identify document that provide the most information to a classifier. 
although this approach have be show to be effective for related problem in the context of scientific database curation it fall short. 
we present virk an al system that while be train simultaneously learn a classification model and identify document have information of interest for a knowledge base. 
our approach use a support vector machine svm classifier with input feature derive from neuroscience relate publication from the primary literature. 
use our approach we be able to increase the size of the neuron registry a knowledge base of neuron relate information by a factor of 90 a knowledge base of neuron relate information in three month. 
use standard biocuration method it would have take between one and two year to make the same number of contribution to the neuron registry. 
here we describe the system pipeline in detail and evaluate its performance against other approach to sample in al. 
pyspace a signal processing and classification environment in python. 
in neuroscience large amount of datum be record to provide insight into cerebral information processing and function. 
the successful extraction of the relevant signal become more and more challenging due to increase complexity in acquisition technique and question address. 
here automate signal processing and machine learning tool can help to process the datum to separate signal and noise. 
with the present software pyspace http://pyspace.github.io/pyspace signal processing algorithm can be compare and apply automatically on time series datum either with the aim of find a suitable preprocessing or of train supervised algorithm to classify the datum. 
pyspace originally have be build to process multi sensor windowed time series datum like event relate potential from the electroencephalogram eeg. 
the software provide automate datum handling distribute processing modular build up of signal processing chain and tool for visualization and performance evaluation. 
include in the software be various algorithm like temporal and spatial filter feature generation and selection classification algorithm and evaluation scheme. 
far interface to other signal processing tool be provide and since pyspace be a modular framework it can be extend with new algorithm accord to individual need. 
in the present work the structural hierarchy be describe. 
it be illustrate how user and developer can interface the software and execute offline and online mode. 
configuration of pyspace be realize with the yaml format so that programming skill be not mandatory for usage. 
the concept of pyspace be to have one comprehensive tool that can be use to perform complete signal processing and classification task. 
it far allow to define own algorithm or to integrate and use already exist library. 
a knowledge base approach to match human neurodegenerative disease and animal model. 
neurodegenerative disease present a wide and complex range of biological and clinical feature. 
animal model be key to translational research yet typically only exhibit a subset of disease feature rather than be precise replica of the disease. 
consequently connect animal to human condition use direct data mining strategy have prove challenging particularly for disease of the nervous system with its complicated anatomy and physiology. 
to address this challenge we have explore the use of ontology to create formal description of structural phenotype across scale that be machine processable and amenable to logical inference. 
as proof of concept we build a neurodegenerative disease phenotype ontology ndpo and an associated phenotype knowledge base pkb use an entity quality model that incorporate description for both human disease phenotype and those of animal model. 
entity be draw from community ontology make available through the neuroscience information framework nif and quality be draw from the phenotype and trait ontology pato. 
we generate similar to 1200 structure phenotype statement describe structural alteration at the subcellular cellular and gross anatomical level observe in 11 human neurodegenerative condition and associated animal model. 
phenosim an open source tool for compare phenotype be use to issue a series of competency question to compare individual phenotype among organism and to determine which animal model recapitulate phenotypic aspect of the human disease in aggregate. 
overall the system be able to use relationship within the ontology to bridge phenotype across scale return non trivial match base on common subsumer that be meaningful to a neuroscientist with an advanced knowledge of neuroanatomy. 
the system can be use both to compare individual phenotype and also phenotype in aggregate. 
this proof of concept suggest that express complex phenotype use formal ontology provide considerable benefit for compare phenotype across scale and specie. 
computer aid diagnosis and localization of lateralize temporal lobe epilepsy use interictal fdg pet. 
interictal fdg pet pet be a core tool for localize the epileptogenic focus potentially before structural mri that do not require rare and transient epileptiform discharge or seizure on eeg. 
the visual interpretation of ipet be challenge and require year of epilepsy specific expertise. 
we have develop an automate computer aid diagnostic cad tool that have the potential to work both independent of and synergistically with expert analysis. 
our tool operate on distribute metabolic change across the whole brain measure by ipet to both diagnose and lateralize temporal lobe epilepsy tle. 
when diagnose leave tle ltle or right tle rtle vs. 
non epileptic seizure nes our accuracy in reproduce the result of the gold standard long term video eeg monitoring be 82 or 88 95 ci 76 94 respectively. 
the classifier that both diagnose and lateralize the disease have overall accuracy of 76 95 ci 66 84 where 89 95 ci 77 96 of patient correctly identify with epilepsy be correctly lateralize. 
when identify ltle our cad tool utilize metabolic change across the entire brain. 
by contrast only temporal region and the right frontal lobe cortex be need to identify rtle accurately a finding consistent with clinical observation and indicative of a potential pathophysiological difference between rtle and ltle. 
the goal of cads be to complement not replace expert analysis. 
in our dataset the accuracy of manual analysis ma of ipet similar to 80 be similar to cad. 
the square correlation between our cad tool and ma however be only 30 indicate that our cad tool do not recreate ma. 
the addition of clinical information to our cad however do not substantively change performance. 
these result suggest that automate analysis might provide clinically valuable information to focus treatment more effectively. 
varibench a benchmark database for variation. 
several computational method have be develop for predict the effect of rapidly expand variation datum. 
comparison of the performance of tool have be very difficult as the method have be train and test with different dataset. 
until now unbiased and representative benchmark dataset have be miss. 
we have develop a benchmark database suite varibench to overcome this problem. 
varibench contain dataset of experimentally verify high quality variation datum carefully choose from literature and relevant database. 
it provide the mapping of variation position to different level protein rna and dna sequence protein three dimensional structure along with identifier mapping to relevant database. 
varibench contain the first benchmark dataset for variation effect analysis a field which be of high importance and where many development be currently go on. 
varibench dataset can be use for example to test performance of prediction tool as well as to train novel machine learning base tool. 
new dataset will be include and the community be encourage to submit high quality dataset to the service. 
varibench be freely available at http://structure.bmc.lu.se/varibench. 
hum mutat 34:42 49 2013. 
c 2012 wiley periodicals inc.. 
a framework for multimodal data collection visualization annotation and learning. 
the development and iterative refinement of inference model for multimodal system can be challenge and time intensive. 
we present a framework for multimodal datum collection visualization annotation and learn that enable system developer to build model use various machine learning technique and quickly iterate through cycle of development deployment and refinement. 
adaptive timeline interface to personal history data. 
as the growth of store personal digital information such as photograph and email be continuously increase new tool for browse and searching be need. 
we introduce an intelligent mobile information access tool for personal datum. 
the datum be present in an adaptive timeline where the display item function as search cue. 
the novelty be that the visualization be dynamically change to emphasize relevant item which make they easy to recognize and select. 
the relevance be infer during usage of the system from user feedback. 
in a user study the dynamic timeline base interface on a mobile device be show to require less effort than conventional textual search. 
icmi 2013 grand challenge workshop on multimodal learning analytics. 
advance in learn analytic be contribute new empirical finding theory method and metric for understand how student learn. 
it also contribute to improve pedagogical support for student learn through assessment of new digital tool teaching strategy and curricula. 
multimodal learning analytic mmla be an extension of learn analytic and emphasize the analysis of natural rich modality of communication across a variety of learn context. 
this mmla grand challenge combine expertise from the learn sciences and machine learning in order to highlight the rich opportunity that exist at the intersection of these discipline. 
as part of the grand challenge researcher be ask to predict one which student in a group be the dominant domain expert and two which problem that the group work on would be solve correctly or not. 
analysis be base on a combination of speech digital pen and video datum. 
this paper describe the motivation for the grand challenge the publicly available datum resource and result report by the challenge participant. 
the result demonstrate that multimodal prediction of the challenge goal one be surprisingly reliable use rich multimodal datum source two can be accomplish use any of the three modality explore and three need not be base on content analysis. 
automatic detection of atrial fibrillation in cardiac vibration signals. 
we present a study on the feasibility of the automatic detection of atrial fibrillation af from cardiac vibration signal ballistocardiogram bcg record by unobtrusive bed mount sensor. 
the propose system be intend as a screening and monitor tool in home healthcare application and not as a replacement for ecg base method use in clinical environment. 
base on the bcg datum record in a study with ten af patient we evaluate and rank seven popular machine learning algorithm naive bayes linear and quadratic discriminant analysis support vector machine random forest as well as bag and boost tree for their performance in separate 30 s long bcg epoch into one of three class sinus rhythm af and artifact. 
for each algorithm feature subset of a set of statistical time frequency domain and time domain feature be select base on the mutual information between feature and class label as well as the first and second order interaction among feature. 
the classifier be evaluate on a set of 856 epoch by mean of tenfold cross validation. 
the good algorithm random forest achieve a matthews correlation coefficient mean sensitivity and mean specificity of 0.921 0.938 and 0.982 respectively. 
a behaviour centric approach for build semantic service discovery for the knowledge advantage machine. 
purpose our main purpose be to build an on demand service discovery model to find useful knowledge object dub jan whose service behaviour be consistent with the requestor s expectation. 
it go beyond the keyword approach by incorporate behaviour centricity into the discovery process. 
design methodology approach we propose an approach of behaviour centric service discovery bcsd which be a new way to discover and construct useful jan for build knowledge advantage machine kam. 
we bring the idea of jan as a service to provide an abstract layer above web resource to achieve the uniqueness for different user share the same resource. 
originality value this methodology put in evidence about the definition of service behaviour the conceptual modelling of bcsd and the architecture model of kam discovery agent. 
combine with ontology semantic web service and multi agent technique we build a semantic service discovery model. 
we also propose a method for quality evaluation with conformance checking of service behaviour which we consider be an innovative and relevant contribution to the state of the art. 
the propose bcsd model promote an effective mechanism for knowledge management and share. 
the kam discovery agent be a very useful tool as it provide a model for dynamically create self describe knowledge object for knowledge acquisition management and sharing. 
practical implication the outcome of the application be a prototype of the discovery agent for one type of kam user such as an academic. 
we present a jan discovery implementation that involve user interaction at some point in an end to end process of find relevant research paper. 
we develop a prototype of kam discovery agent base on the jade project and integrate into owl s.. 
visual analytic of movement an overview of method tool and procedure. 
analysis of movement be currently a hot research topic in visual analytic. 
a wide variety of method and tool for analysis of movement datum have be develop in recent year. 
they allow analyst to look at the datum from different perspective and fulfil diverse analytical task. 
visual display and interactive technique be often combine with computational processing which in particular enable analysis of a large number of datum than would be possible with purely visual method. 
visual analytic leverage method and tool develop in other area relate to datum analytic particularly statistic machine learning and geographic information science. 
we present an illustrate structured survey of the state of the art in visual analytic concern the analysis of movement datum. 
besides review the exist work we demonstrate use example how different visual analytic technique can support our understanding of various aspect of movement. 
roc analysis of classifier in machine learning a survey. 
the use of roc receiver operating characteristic analysis as a tool for evaluate the performance of classification model in machine learning have be increase in the last decade. 
among the most notable advance in this area be the extension of two class roc analysis to the multi class case as well as the employment of roc analysis in cost sensitive learning. 
method now exist which take instance vary cost into account. 
the purpose of our paper be to present a survey of this field with the aim of gather important achievement in one place. 
in the paper we present application area of the roc analysis in machine learning describe its problem and challenge and provide a summarize list of alternative approach to roc analysis. 
in addition to present theory we also provide a couple of example intend to illustrate the describe approach. 
adaptive lqr control to attenuate chatters in milling process. 
chatter be induce by rigidity flexibility coupling between tool and workpiece which cause cut disturbance over cut and quick tool wear and hence greatly limit the workpiece machining efficiency and quality. 
to attenuate the chatter dynamic traditional passive control method usually decrease the spin speed or cut depth at the cost of reduce machining efficiency. 
in this work we investigate deeply on the structure of the cut force variation matrix and then design an online system identification method base on the fourier series. 
in this way a linear quadratic regulator adaptive control method be develop to greatly enlarge the chatter stability region in the lobe diagram. 
moreover the recede horizon and output rectification mechanism be apply to overcome the external disturbance as well. 
the feasibility and superiority of the method be verify by the benchmark example where close loop stable operation point be remarkably increase and a high productivity rate be thus achieve. 
effect of alternate metal for use in natural fibre reinforce fibre metal laminate under bend impact and axial loading. 
fibre metal laminate fml be largely use in the manufacture of aircraft. 
the commercially available fml glare carall carbon reinforced aluminium laminate and arall make use of aluminium metal. 
other fml that be under study by researcher make use of metal such as titanium and magnesium base alloy. 
owe to the high cost of carbon fibre and the necessity for environment friendly alternative in the present work a portion of carbon be replace by natural fibre jute in carall and carmal carbon reinforced magnesium laminate. 
to the knowledge of the author this attempt have not be make before in the field of fml. 
the result carbon jute reinforced aluminium laminate and carbon jute reinforced magnesium laminate be name as cajrall and cajrmal. 
both these laminate be make by hand layup technique and then compress in a compression moulding machine. 
the cajrall and the cajrmal specimen be subject to axial flexure and impact test accord to astm standard. 
the effect of the orientation of fibre and influence of the stack sequence of the fibre and metal combination and the use of alternate metal on the mechanical performance be experimentally investigate. 
the experimental and theoretical result as well as the result obtain through finite element analysis be find to be in close agreement. 
also the failure of the fml be predict by conduct micro level structure analysis. 
c 2013 the authors. 
publish by elsevier ltd.. 
predict human microrna disease association base on support vector machine. 
the identification of disease relate micrornas be vital for understand the pathogenesis of disease at the molecular level and may lead to the design of specific molecular tool for diagnosis treatment and prevention. 
experimental identification of disease relate micrornas pose difficulty. 
computational prediction of microrna disease association be one of the complementary mean. 
however one major issue in microrna study be the lack of bioinformatics program to accurately predict microrna disease association. 
herein we present a machine learn base approach for distinguish positive microrna disease association from negative microrna disease association. 
a set of feature be extract for each positive and negative microrna disease association and a support vector machine svm classifier be train which achieve the area under the roc curve of up to 0.8884 in 10 fold cross validation procedure indicate that the svm base approach describe here can be use to predict potential microrna disease association and formulate testable hypothesis to guide future biological experiment. 
hands on assessment during computer aided engineering education. 
this contribution discuss aspect and benefit from involve physical representation when teach engineering design and computer aided engineering at linkoping university sweden. 
the paper present a syllabus for a comprehensive introductory cad course. 
the course be populate by some 300 student on the mechanical engineering master s and bachelor s program as well as the design and product development master s program. 
assessment be make via a project where the student be assign to model and optimize a small catapult. 
the catapult be then produce use cheap material by the hand of the student who model it. 
finally the catapult be validate by enter a contest where it be judge in respect of accuracy weight and cost. 
the catapult assignment be construct in such a way that the student be force to seek individual way of apply their newly acquire knowledge of the cad tool. 
some 100 catapult be produce but the material cost for each catapult be only about sic)4. 
the low cost nature of the catapult originate from research conduct at the division of machine design at linkoping university where the concept of low cost demonstrator for enhancement of the conceptual design phase have be develop over the past decade. 
the result from this research point towards several benefit from use physical representation alongside the common digital tool during the early stage of the product development process. 
furthermore evaluation of parameter such as the student performance and their own opinion of the course show notable enhancement compare to previous course. 
effectiveness of problem solving software in engineering conceptual design. 
the process of generate the most attractive product concept in engineering design be still one of the great challenge of the 21st century. 
there be several tool for support this extremely uncontrollable phase of engineering design. 
except for the method the problem solve software be the very important tool. 
one of the most useful method in teaching and learning brief theory of inventive problem solving btips be discuss in other paper and. 
this paper be devoted to the software support the problem solving process. 
there be still no software suitable for a completely satisfactory automation of the conceptual design process. 
however there be some software package that could be the most helpful in support the process and would greatly influence the quality of the final product especially in case of contradict constraint. 
in this paper some result of the research on the use and effectiveness of invention machine im tm software product be describe. 
four package be discuss and compare the im v. 
two for windows techoptimizer v. 
3.5 techoptimizer v. 
4.0 and goldfire v. 
6.5. 
goldfire v. 
6.5 evaluation be still in the process and be not completely finish yet. 
the first three package be use in teach several junior senior and graduate course at the university of connecticut uconn for many year. 
the experience with goldfire v. 
6.5 be comparatively limited. 
in the research describe in this paper the content and the teaching effectiveness of the software package in teaching be study. 
datum from student feedback be evaluate conclusion be derive. 
on the basis of this recommendation for the future use of the software be offer. 
this paper concentrate on some instrumental software quality that could be use in teaching of solve problem of industrial product conceptual design. 
the user s experience and its connection with the effectiveness of the package use be discuss in the paper. 
conclusion be derive at the end. 
engineering problem solving learning and practice. 
the engineering problem solving process have two aspect. 
it rely on the talent of the designer on the one hand and the efficiency of the problem solve tool on the other. 
talent be an attribute of a person. 
it be very difficult to formalize the talent of an individual and no satisfactory formalization have be achieve successfully. 
for this reason only the original designer s talent and his her knowledge and experience be available for use during the problem solving process. 
however there be several choice and decision that can be make concern method algorithm and software package. 
after those choice be make the next step in the problem solving process can be outline. 
the problem solve method describe in this paper be call a brief theory of inventive problem solving btips and be develop on the basis of triz and tips theory of inventive problem solving and teach at the university of connecticut uconn. 
the application of this method start with the accurate definition of the problem. 
the problem have to be properly separate from the environment. 
further problem solve choice depend on the knowledge of the designer and include the right sequence of step definition of contradiction choice of solution module algorithm definition of design system and subsystem and choice of element and object. 
there be several further path to be select and result decision to be make. 
those decision and the process follow they be describe in this paper. 
the recommendation for the proper path be give and the procedure be discuss. 
the derivation of the ideal solution be describe and test of the solution s effectiveness and economy be give. 
the experience gain from teach one mechanical engineering course three mem management engineering for manufacturing course at ucorm one graduate course at uconn one graduate course at the university of fairfield and several special non academic course for practice engineer be summarize. 
some student opinion be analyze and recommendation for further education and the practice of engineering problem solve be derive. 
the reference to the exist teaching research practice and development study be quote. 
this paper be devoted to the characteristic of btips method. 
the companion paper be devoted to the characteristic of the software that could be use with the method. 
tips the theory of inventive problem solving be a further development of altshuller s theory do by invention machine under the leadership of valery tsourikov. 
btips brief theory of inventive problem solving be a simplified version of tips develop at the university of connecticut uconn especially for teaching purpose though it be also powerful when apply to engineering practice problem. 
data mining for knowledge discovery from object based segmentation of vhr remotely sensed imagery. 
the success of the object base image analysis obia paradigm can be attribute to the fact that region obtain by mean of segmentation process be depict with a variety of spectral shape texture and context characteristic. 
these representative object attribute can be assign to different land cover land use type by mean of two option. 
the first be to use supervised classifier such as k near neighbor knn and support vector machine svm the second be to create classification rule. 
supervised classifier perform very well and have generally high accuracy. 
however one of their drawback be that they provide no explicit knowledge in understandable and interpretable form. 
the building of the rule set be generally base on the domain expert knowledge when deal with a small number of class and a small number of attribute but have a dozen of continuously value attribute attach to each image object make it a tedious task and expert quickly get overwhelmed and become totally helpless. 
this be where data mining technique for knowledge discover help to understand the hide relationship between class and their attached attribute. 
the aim of this paper be to highlight the benefit of use knowledge discovery and data mining tool especially rule induction algorithm for useful and accurate information extraction from high spatial resolution remotely sensed imagery. 
automatic extraction of core learning goals and generation of pedagogical sequences through a collection of digital library resources. 
a key challenge face educational technology researcher be how to provide structure and guidance when learner use unstructured and open tool such as digital library for their own learning. 
this work attempt to use computational method to identify that structure in a domain independent way and support learner as they navigate and interpret the information they find. 
this article highlight a computational methodology for generate a pedagogical sequence through core learning goal extract from a collection of resource which in this case be resource from the digital library for earth system education dlese. 
this article describe how we use the technique of multi document summarization to extract the core learn goal from the digital library resource and how we create a supervised classifier that perform a pair wise classification of the core learning goal the judgment from these classification be use to automatically generate pedagogical sequence. 
result show that we can extract good core learning goal and make pair wise classification that be up to 76 similar to the pair wise classification generate from pedagogical sequence create by two science education expert. 
thus we can dynamically generate pedagogically meaningful learning path through digital library resource. 
chart the digital library evaluation domain with a semantically enhanced mining methodology. 
the digital library evaluation field have an evolve nature and it be characterize by a noteworthy proclivity to enfold various methodological orientation. 
give the fact that the scientific literature in the specific domain be vast researcher require tool that will exhibit either commonly acceptable practice or area for further investigation. 
in this paper a datum mining methodology be propose to identify prominent pattern in the evaluation of digital library. 
use machine learning technique all paper present in the ecdl and jcdl conference between the year 2001 and 2011 be categorize as relevant or non relevant to the dl evaluation domain. 
then the relevant paper be semantically annotate accord to the digital library evaluation ontology dileo vocabulary. 
the produce set of annotation be cluster to evaluation pattern for the most frequently use tool method and goal of the domain. 
our finding highlight the expressive nature of dileo place emphasis on semantic annotation as a necessary step in handle domain centric corpus and underline the potential of the propose methodology in the profiling of evaluation activity. 
high throughput classification of clinical population from natural view eye movement. 
many high prevalence neurological disorder involve dysfunction of oculomotor control and attention include attention deficit hyperactivity disorder adhd fetal alcohol spectrum disorder fasd and parkinson s disease pd. 
previous study have examine these deficit with clinical neurological evaluation structure behavioral task and neuroimage. 
yet time and monetary cost prevent deploy these evaluation to large at risk population which be critically important for early detection and well treatment. 
we devise a high throughput low cost method where participant simply watch television while we record their eye movement. 
we combine eye track datum from patient and control with a computational model of visual attention to extract 224 quantitative feature. 
use machine learning in a workflow inspire by microarray analysis we identify critical feature that differentiate patient from control subject. 
with eye movement trace record from only 15 min of video we classify pd versus age match control with 89.6 accuracy chance 63.2 and adhd versus fasd versus control child with 77.3 accuracy chance 40.4. 
our technique provide new quantitative insight into which aspect of attention and gaze control be affect by specific disorder. 
there be considerable promise in use this approach as a potential screening tool that be easily deploy low cost and high throughput for clinical disorder especially in young child and elderly population who may be less compliant to traditional evaluation test. 
discriminant diffusion map analysis a robust manifold learner for dimensionality reduction and its application in machine condition monitoring and fault diagnosis. 
various feature extract from raw signal usually contain a large amount of redundant information which may impede the practical application of machine condition monitoring and fault diagnosis. 
hence as a solution dimensionality reduction be vital for machine condition monitoring. 
this paper present a new technique for dimensionality reduction call the discriminant diffusion map analysis ddma which be implement by integrate a discriminant kernel scheme into the framework of the diffusion map. 
the effectiveness and robustness of ddma be verify in three different experiment include a pneumatic pressure regulator experiment a roll element bearing test and an artificial noisy nonlinear test system with empirical comparison with both the linear and nonlinear method of dimensionality reduction such as principle component analysis pca independent component analysis ica linear discriminant analysis lda kernel pca self organize map som isomap diffusion map dm laplacian eigenmap le locally linear embed lle analysis hessian base lle analysis and local tangent space alignment analysis ltsa. 
result show that ddma be capable of effectively represent the high dimensional datum in a low dimensional space while retain most useful information. 
in addition the low dimensional feature generate by ddma be much well than those generate by most of other state of the art technique in different situation. 
c 2012 elsevier ltd. 
all right reserve. 
e labs and the stock of health method for simulating health policies. 
regional outcome of national health policy be difficult to forecast. 
this be partly due to a lack of realistically complex model that can be use to appraise policy option and partly a lack of accessible and adaptable tool that can be use to simulate the consequence of policy decision. 
these barrier might be overcome by exploit the commoditization of massively parallel computing architecture advance in machine learning and the increase availability of large scale link healthcare datum. 
this paper present a novel modelling methodology the stock of health for harness emerge datum and computational resource to simulate health policy with application initially to coronary heart disease. 
we detail the use of multi core graphical processing architecture to facilitate a micro simulation approach. 
the simulation tool have be deploy through the impact framework. 
we explore how this framework can be extend to support the sharing and reuse of policy model and simulation base on the digital publishing concept of e lab. 
shell and solid modeling for structural body in white part. 
finite element analysis fea be a numerical method that facilitate designer to produce a part with the high degree of reliability. 
these advantage allow manufacturing engineer to produce a virtual tool prototype. 
this approach have eliminate the requirement to manufacture the prototype model from soft tool part and soft tool press die. 
this research focus on the numerical experiment for an advanced high strength steel part in body in white. 
the patchwork blank sheet of a structural body in white be model with three condition shell element without spot weld nugget shell element with spot weld nugget and solid element. 
shell element be usually the obvious choice in the blank in sheet metal form simulation primarily due to the rapid and fairly accurate result generate. 
solid element of the other hand require extremely high computation time. 
the main objective of this study be to critically compare plastic deformation result obtain from three approach on a b pillar part with 1.75 mm thickness. 
the finite element model be develop from the cad datum of production tool and blank material. 
the blank material be mesh with quad element for optimize compute time and result. 
the input parameter for the simulation model be obtain from the current setup at press machine and production tool. 
the analysis of plastic deformation for all three blank material model be compare to the actual part thickness. 
percentage of deviation from the actual part geometry will indicate the good approach in produce finite element model for hot forming process. 
selection of business process alternatives base on operational similarity for multi subsidiary organization. 
this work suggest a method for machine assist support for multi subsidiary organization in select business process alternative base on operational similarity. 
operational similarity between process can be derive from process repository use a linguistic analysis of process descriptor. 
the suggested method aim to assist operation manager in multi subsidiary organization in identify similar process that can substitute process that can not be carry out within a certain subsidiary. 
this decision making be base on knowledge that be encapsulate within exist business process repository. 
the method be demonstrate use a real life process repository from the paper manufacturing industry. 
fabrication of high precision metallic freeform mirror with magnetorheological finishing mrf. 
the fabrication of complex shaped metal mirror for optical imaging be a classical application area of diamond machining technique. 
aspherical and freeform shape optical component up to several 100 mm in diameter can be manufacture with high precision in an acceptable amount of time. 
however application be naturally limit to the infrared spectral region due to scatter loss for short wavelength as a result of the remain periodic diamond turning structure. 
achieve diffraction limited performance in the visible spectrum demand for the application of additional polishing step. 
magnetorheological finishing mrf be a powerful tool to improve figure and finish of complex shape optic at the same time in a single processing step. 
the application of mrf as a figure tool for precise metal mirror be a nontrivial task since the technology be primarily develop for figure and finish a variety of other optical material such as glass or glass ceramic. 
in the present work mrf be use as a figure tool for diamond turn aluminum lightweight mirror with electroless nickel plating. 
it be apply as a direct follow up process after diamond machining of the mirror. 
a high precision measurement setup compose of an interferometer and an advanced computer generated hologram with additional alignment feature allow for precise metrology of the freeform shape optic in short measuring cycle. 
shape deviation less than 150 nm p v 20 nm rm be achieve reliably for freeform mirror with aperture of more than 300 mm. 
characterization of removable and induce spatial frequency be carry out by investigate the power spectral density. 
product process machine system modeling approach and industrial case studies. 
global trend in the worldwide economy lead to new challenge for manufacture enterprise and to new requirement regard model industrial organization like integration of real time information from operation and information about neighboring enterprise in the value network. 
consequently there be a need to design new knowledge base workflow and support software system to increase efficiency of design and maintain new product range production planning and manufacturing. 
the paper present an approach to a specific aspect of enterprise modeling product process machine modeling derive from two real life case study. 
it assume ontology base integration of various information source and software system and distinguish four level. 
the upper two level level of product manager and product engineer concentrate on customer requirement and product modeling. 
the low two level level of production engineer and production manager focus on production process and production equipment modeling. 
three loop positioning servo system of ultraprecision machine tool use adaptive reference modelling. 
the development of many advanced technology product depend entirely on its component which tolerance or dimension need to meet the micro or even nanotechnology range requirement. 
it be generally accept that position servo controller of machine tool be the main concern in achieve the high machining precision. 
nanometric level positioning accuracy of the ultra precision machine tool be difficult to obtain particularly with parameter uncertainty external nonlinear disturbance. 
in order to compensate above disadvantage a model reference adaptive control method be propose to adjust the important and main position loop of the three closed loop control system which be design mainly for regulate mechanical transmission module and counterbalance internal and external disturbance. 
in addition the other two close loop be build in adjust the acceleration and velocity of the electric drive system respectively that aim to achieve the fast and precise response and increase dynamic stiffness. 
the result illustrate satisfactory performance in steady state error load capability high rapidity and so on. 
evolve pcb visual inspection programs use genetic programming. 
automated optical inspection aoi be desirable in print circuit board pcb manufacturing as inspect manually be time consume and error prone. 
this paper present a study on evolve an aoi program with genenetic programming gp an evolution inspire technique. 
use a gp base approach domain knowledge such as board design and lighting condition be not require. 
conventional feature extraction process can also be avoid. 
the result demonstrate the evolved program capability to detect flaw under varied scenario. 
furthermore it can be readily apply on different type of image without calibration or re training. 
bangla text processing and recognition based on fuzzy unsupervised feature extraction and svm. 
optical character recognition ocr be a widely use technology to convert text image to editable text. 
researcher already propose many machine learn algorithm to address this problem. 
however bangia text recognition be highly challenging job for its complicated writing style compound character and highly diversified font. 
to address the segmentation problem we have propose an algorithm namely blob label character segmentation blcs that initiate with an extensive preprocessing to extract the character from text. 
our novel character segmentation procedure extract character maintain 97.5 accuracy. 
unsupervised feature learning become a powerful tool in machine learning nowadays. 
to increase the recognition rate of the character we have introduce a fuzzy unsupervised feature learn algorithm to learn feature of individual character. 
we then use artificial neural network ann and support vector machine svm to classify the character. 
the svm provide 99.4 accuracy which outperform all other approach. 
behavior base malware analysis use profile hidden markov models. 
in the area of malware analysis static binary analysis technique be become increasingly difficult with the code obfuscation method and code packing employ when write the malware. 
the behavior base analysis technique be be use in large malware analysis system because of this reason. 
in these dynamic analysis system the malware sample be execute and monitor in a control environment use tool such as cwsandbox(willems et al 2007. 
in previous work a number of clustering and classification technique from machine learning and datum mining have be use to classify the malware into family and to identify even new malware family from the behavior report. 
in our work we propose to use the profile hidden markov model to classify the malware file into family or group base on their behavior on the host system. 
phmm have be use extensively in the area of bioinformatics to search for similar protein and dna sequence in a large database. 
we see that use this particular model will help we overcome the hurdle pose by polymorphism that be common in malware today. 
we show that the classification accuracy be high and comparable with the state of art method even when use very few training sample for building model. 
the experiment be on a dataset with 24 family initially and later use a large dataset with close to 400 different family of malware. 
a fast clustering method to group malware with similar behaviour follow the scoring on the phmm profile database be use for the large dataset. 
we have present the challenge in the evaluation method and metric of cluster on large number of malware file and show the effectiveness of use profile hidden model model for known malware family. 
an improvement of dbscan algorithm to analyze cluster for large dataset. 
clustering be an important tool which have see an explosive growth in machine learning algorithms. 
dbscan density  based spatial clustering of applications with noise cluster algorithm be one of the most primary method for cluster in data mining. 
dbscan have ability to find the cluster of variable size and shape and it will also detect the noise. 
the two important parameter epsilon eps and minimum point minpts be require to be inputte manually in dbscan algorithm and on the basis these parameter the algorithm be calculate such as number of cluster un  cluster instance as well as incorrectly cluster instance and also evaluate the performance on the basic of parameter selection and calculate the time take by the dataset. 
experimental evaluation on the basis of different dataset in arff format with help of weka tool which show that quality of cluster of our propose algorithm be efficient in cluster result and more accurate. 
this improved work on dbscan have use in a large scope. 
development of efficient image quarrying technique for mammographic image classification to detect breast cancer with supervised learning algorithm. 
this breast cancer be one of the most prevalent lump in woman increase day by day around in worldwide. 
the scheme for the detection of breast cancer be mammographic technique that be use at the very early stage. 
in this paper two kind of classification support vector machine svm and linear discriminant analysis lda be use to analyze the mammographic image. 
the two classification method be use the image pre processing in wavelet decomposition and image enhancement. 
the result be verify with 322 mammogram image which be size for 1024x1024 with pgm format. 
the result show that the propose algorithm can able to classify the image with a good performance rate of 98. 
it can be conclude that supervised learn algorithm give fast and accurate classification and it work as efficient tool for classification of breast cancer cell. 
verification and validation of parallel support vector machine algorithm base on mapreduce program model on hadoop cluster. 
from the recent year the large volume of datum be grow big and big. 
it be difficult to measure the total volume of structured and unstructured datum that require machine base system and technology in order to be fully analyze. 
efficient implementation technique be the key to meet the scalability and performance requirement entail in such scientific datum analysis. 
so for the same in this paper the sequential support vector machine in weka and various mapreduce programs include parallel support vector machine on hadoop cluster be analyze and thus in this way algorithms be verify and validate on hadoop cluster use the concept of mapreduce. 
in this paper the performance of above application have be show with respect to execution time training time and number of node. 
experimental results show that as the number of node increase the execution time decrease. 
this experiment be basically a research study of above mapreduce application. 
a brief survey on corpus uses. 
corpus open up many new area of research in the domain of linguistic which would never be possible without it. 
recently corpus linguistic become a hot topic in the research community. 
however enter this area for new computer researcher may take lot of effort and time. 
in this paper we provide new researcher in this domain with the basic term measure and tool use in this area. 
software construction of experimental environment for computer network course. 
at present shortage of network laboratory equipment and fund be the problem of construction in network lab. 
the sniffer tool virtual machine and network simulation software be adopt to build a network experimental environment thus save the investment in network laboratory equipment reduce the network lab manager burden and improve the learn effect. 
preliminary design of estimation heart disease by use machine learn ann within one year. 
in this paper discuss the development of heart disease prediction use machine learning in this case the artificial neural network or ann. 
there be 13 variable that can determine heart disease accord to miss chaitrali paper. 
prediction of a person s heart disease one year ahead be perform by study the model heart rate datum. 
datum be take by use tool such as smart mirror smart mouse smart phone and smart chair. 
heart rate datum be collect through the internet and collect in a server. 
learn in this system be perform for a period of one year to get enough datum to make prediction. 
predictive of future heart disease in one year can increase a person s awareness of heart disease itself. 
the system be also expect to reduce the number of patient and the number of death from heart disease. 
data mining and support vector regression machine learning in semiconductor manufacturing to improve virtual metrology. 
advanced process control be an important research area in semiconductor manufacturing to improve process stability crucial for product quality. 
especially in low volume high mixture fabrication plant knowledge discovery in database be extremely challenging due to complex technology mixture and reduce availability of datum for comparable process step. 
thus actual research focus on data mining use machine learning method to model unknown functional interrelation. 
high density plasma chemical vapor deposition appear to be a process area in semiconductor manufacturing predestinate for application of data mining. 
promising result have be achieve by implement statistical model to predict the thickness of dielectric layer deposit onto a metallization layer of the manufactured wafer. 
this paper describe the approach to predict the layer thickness use a state of the art machine learning regression algorithm support vector regression. 
the recent extension of support vector machines overcome pure classification and deal with multivariate nonlinear input datum for regression. 
investigation on performance of various ceramic tooling while milling nickel based superalloy. 
one of the most cost effective dimensionally accurate process use in manufacturing today that be capable of produce a superior surface finish be machine. 
as tooling wear however the advantage of machine greatly diminish. 
in addition the time lose change out the tooling significantly affect the overall process efficiency. 
therefore method that decrease the wear rate of tooling and thereby increase tool longevity be essential to improve the efficiency of machine. 
optimize the machining feed and speed be one method that have be demonstrate to significantly increase the wear resistance of traditional tooling material such as hss tungsten carbide and advanced ceramic tooling. 
however the effect of machine feed and speed be not well establish for gamma strengthen nickel base superalloy. 
in addition round geometry insert be study due to the rise popularity in industry since there be an increase number of cut edge. 
to help establish these effect in this work commercial grade sialon silicon aluminium oxynitride and si wra silicon carbide whiskers reinforced alumina cut insert be compare. 
mill test be conduct on a gamma  strengthened nickel base superalloy. 
more specifically tool life machine force and power be analyze to evaluate the performance improvement of ceramic tooling. 
this study find that the abrasive adhesion flank wear be the main failure mechanism of the ceramic insert. 
adaptive robust control of circular machining contour error use global task coordinate frame. 
the contour error of machine process be define as the difference between the desire and actual produce shape. 
two major factor contribute to contour error be axis position error and tool deflection. 
a large amount of research work formulate the contour error in convenient locally define task coordinate frame that be subject to significant approximation error. 
the more accurate global task coordinate frame gtcf can be use but transform the control problem to the gtcf lead to a highly nonlinear control problem. 
an adaptive robust control arc approach be design to control machine position in the gtcf while directly account for tool deflection to minimize the contour error. 
the combined gtcf arc approach be experimentally validate by apply the control to circular contour on a three axis mill machine. 
the result show that the propose approach reduce contour error in all case test. 
correlating acoustic emission to calibration phenomena for possible measurement standard. 
when use acoustic emission ae technology tensile and compressive test can provide a detector for material deformation. 
in this paper improvement be make to standardise calibration technique. 
ae signature be evaluate from various calibration source base on the energy from the first harmonic dominant energy band. 
the work present here provide far valuable knowledge to both the manufacturing and structural health monitoring research community. 
the effect of ae against its calibration identity be investigate where signal be correlate to the average energy and distance of the detect phenomenon. 
five source of calibration would be require in order to calculate an average amount. 
ae evaluate by a neural network nn regression classification technique identify how far the malformation have progress in term of energy force during material transformation. 
a genetic fuzzy c cluster classifier be use as the 2nd classification technique to verify the classification of the nn. 
this calibration method can be use for legislation purpose when either machining or operating. 
in summary this paper present a new method of ae calibration through the correlation of ae and force distance measurement. 
model learning in a multistage machining process online identification of force coefficients and model use in the manufacturing enterprise. 
this work present a system approach in machine process control. 
traditional force base machining process control have be focus on single machine single operation. 
the force or power sensor be use to measure the instantaneous force power and control action be take by change the feedrate in real time to follow a give force setpoint. 
the application of such control have successfully be implement to prevent chatter and to elongate tool life by minimize tool wear. 
this research seek to extend the application of control algorithm to learn about the machining system comprise in this context of a workpiece be operate on in progressive machining and how knowledge generate by the process can be pass on to the next process for optimization. 
to demonstrate this turn of a partially harden bar be explore. 
a nonlinear mechanistic force model base control framework attempt to control the cut force at a designate setpoint with material property change over the cut. 
the force coefficient for the material be calculate offline use experimental datum and bayesian inference method. 
since the harden part of the bar will shift the force coefficient value an online estimation strategy bayesian recursive least square estimator be use to learn the new coefficient as well as satisfy the control objective. 
with the newly learn coefficient pass downstream the subsequent operation experience no compromise of control objective as well reduce the maximum value of force encounter. 
numerical analysis present show the adaptation and control scheme performance. 
automation in manufacturing operation of crankshaft. 
this paper deal with multistage flow type manufacturing of crankshaft. 
the advanced methodology in manufacturing system re configurability and high speed manufacturing adopt in the paper will help reduce cost and improve productivity. 
the optimization of the multistage manufacturing be base on mathematical programming formulation and decomposition approach. 
the optimum process parameter such as speed feed and depth of cut for individual operation be calculate use this technique. 
the effect of change in design datum on manufacture parameter and eventually the cost of the crankshaft at each operation be visualize. 
this be likely to help the manufacturing engineer to attempt to reduce cost at appropriate stage. 
the manufacturing automation of crankshaft be attempt on the methodology present in the paper. 
the final configuration of the automate production system show the specification of machine tool in the production system. 
highest efficient film cooling by improved nekomimi film cool holes part two hot gas flow condition. 
in modern gas turbine the film cool technology be essential for the protection of the hot part in particular of the first stage vane and blade of the turbine against the hot gas from the combustion process in order to reach an acceptable life span of the component. 
as the cool air be usually extract from the compressor the reduction of the cool effort would directly result to an increase thermal efficiency of the gas turbine. 
understanding of the fundamental physics of film cooling be necessary for the improvement of the state of the art. 
thus huge research effort by industry as well as research organization have be undertake to establish high efficient film cool technology. 
it be common knowledge today that film cool effectiveness degradation be cause by secondary flow inside the cool jet the counter rotate vortices crv or sometimes also mention as kidney vortex which induce a lift off of the jet. 
further understanding of the secondary flow development inside the jet and how this could be influence have lead to hole configuration which can induce anti counter rotate vortex acrv in the cool jet. 
as a result the cool air remain close to the wall and be additionally distribute flatly along the surface. 
beside different other technology the nekomimi cool technology be a promising approach to establish the desire acrv. 
it consist of a combination of two hole in just one configuration so that the air be distribute mainly on two cool air streak follow the special shape of the generate geometry. 
the original configuration be find to be difficult for fabrication by advanced machining process. 
thus the improvement of this configuration have be reach by a set of geometry parameter which lead to configuration easy to be manufacture but preserve the principle of the nekomimi technology. 
within a numerical parametric study several advanced configuration have be obtain and investigate under hot gas flow condition. 
by systematic variation of the parameter a further optimization with respect to high film cool effectiveness have be perform. 
the good configuration outperform the basic configuration by more than 20 regard the overall average adiabatic film cool effectiveness. 
e learning software for improving student s music performance use comparison. 
in the last decade there have be several attempt to use computer in music education. 
new pedagogical trend encourage incorporate technology tool in the process of learn music. 
between they those system base on artificial intelligence be the most promising one as they can derive new information from the input and visualize they in several meaningful way. 
this paper present an application of machine learn to music performance which be able to discover the similarity and difference between a give performance and those from other musician. 
such a system would help student to well learn how to perform a certain piece of music allow they to compare with other student or master performer. 
smote for regression. 
several real world prediction problem involve forecast rare value of a target variable. 
when this variable be nominal we have a problem of class imbalance that be already study thoroughly within machine learning. 
for regression task where the target variable be continuous few work exist address this type of problem. 
still important application area involve forecast rare extreme value of a continuous target variable. 
this paper describe a contribution to this type of task. 
namely we propose to address such task by sample approach. 
these approach change the distribution of the give training datum set to decrease the problem of imbalance between the rare target case and the most frequent one. 
we present a modification of the well know smote algorithm that allow its use on these regression task. 
in an extensive set of experiment we provide empirical evidence for the superiority of our proposal for these particular regression task. 
the propose smoter method can be use with any exist regression algorithm turn it into a general tool for address problem of forecast rare extreme value of a continuous target variable. 
research methodology of cuting procese of aspen wood. 
machining of wood of soft deciduous tree be currently base on the knowledge about cutting of wood of hard deciduous and coniferous tree and have not develop a comprehensive research methodology of cut process. 
therefore the objective of the study be a development of methodology for longitudinal sawing with circular saw and straight milling that would be utilize with a purpose of acquire further knowledge on wood cutting and the improvement of cut tool design. 
sub objective of the study be determination of duration of cutter s wear period when use develop methodology. 
for the purpose of solve problem regard cut process of soft deciduous wood the optimization of cut tool and cut mode be carry out in condition that comply with the tendency of the practise. 
the cutting process be carry out by a computer numerical control machine and the data acquisition by electronic measure instrument. 
aspen populus tremula l. wood be use for wood sample. 
the methodology be develop for sawing which complement the author previously describe methodology of the milling process investigation. 
initially only the result of period of cutter wear and cut velocity effect on these period when mill process be use be obtain. 
it be conclude that the methodology can be use for further investigation and the critical wear period begin two time later when cut velocity increase twice. 
key word saw milling aspen methodology of cut process optimization of wood cutting. 
an offline programming method for the robotic deburring of aerospace components. 
deburring of aerospace component be a complex task in case of large single piece design and optimize to deliver many mechanical function. 
a constant high quality require accurate 3d surface contouring operation with engineer tool compliance and cut power. 
moreover aeronautic cast part production be characterize by small lot size with high variability of geometry and defect. 
despite robot be conceive to provide the necessary flexibility reconfigurability and efficiency most robotic workcell be very limited by too long programming and setup time especially at changeover. 
the paper report a design method deal with the integrate development of process and production system and analyze and compare a cad base and a digitizer base offline programming strategy. 
the deburring of gear transmission housing for aerospace application serve as a severe test field. 
the strategy be compare by the involved cost and time learn easiness production downtime and machine accuracy. 
the result show how the reconfigurability of the system together with the exploitation of offline programming tool improve the robotic deburring process. 
a decision tree base model for evaluate the thermal comfort of horse. 
thermal comfort be of great importance in preserve body temperature homeostasis during thermal stress condition. 
although the thermal comfort of horse have be widely study there be no report of its relationship with surface temperature t s. 
this study aim to assess the potential of datum mining technique as a tool to associate surface temperature with thermal comfort of horse. 
t s be obtain use infrared thermography image processing. 
physiological and environmental variable be use to define the predict class which classify thermal comfort as comfort and discomfort. 
the variable of armpit croup breast and groin t s of horse and the predict class be then subject to a machine learning process. 
all variable in the dataset be consider relevant for the classification problem and the decision tree model yield an accuracy rate of 74. 
the feature selection method use to reduce computational cost and simplify predictive learning decrease model accuracy to 70 however the model become simple with easily interpretable rule. 
for both these selection method and for the classification use all attribute armpit and breast t s have a high power rating for predict thermal comfort. 
data mining technique show promise in the discovery of new variable associate with the thermal comfort of horse. 
ontology and language for represent mathematical knowledge on the semantic web. 
mathematics be a ubiquitous foundation of science technology and engineering. 
specific area of mathematic such as numeric and symbolic computation or logic enjoy considerable software support. 
working mathematician have recently start to adopt web 2.0 environment such as blog and wiki but these system lack machine support for knowledge organization and reuse and they be disconnect from tool such as computer algebra system or interactive proof assistant. 
we argue that such scenario will benefit from semantic web technology. 
conversely mathematic be still underrepresented on the web of link datum. 
there be mathematic relate linked data for example statistical government datum or scientific publication database but their mathematical semantic have not yet be model. 
we argue that the service for the web of data will benefit from a deep representation of mathematical knowledge. 
mathematical knowledge comprise structure give in a logical language formulae statement e.g. 
axiom and theory a mixture of rigorous natural language and symbolic notation in document application specific metadata and discussion about conceptualization formalization proof and counter example. 
our review of vocabulary for represent these structure cover ontology for mathematical problem proof interlinked scientific publication scientific discourse as well as mathematical metadata vocabulary and domain knowledge from pure and apply mathematic. 
many field of mathematic have not yet be implement as proper semantic web ontology however we show that mathml and openmath the standard xml base exchange language for mathematical knowledge can be fully integrate with rdf representation in order to contribute exist mathematical knowledge to the web of data. 
we conclude with a roadmap for get the mathematical web of data start what dataset to publish how to interlink they and how to take advantage of these new connection. 
paraconsistent owl and related logic. 
the web ontology language owl be currently the most prominent formalism for represent ontology in semantic web application. 
owl be base on description logic and automate reasoner be use to infer knowledge implicitly present in owl ontology. 
however because typical description logic obey the classical principle of explosion reason over inconsistent ontology be impossible in owl. 
this be so despite the fact that inconsistency be bind to occur in many realistic case when multiple ontology be merge or when ontology be create by machine learning or datum mining tool. 
in this paper we present four value paraconsistent description logic which can reason over inconsistency. 
we focus on logic correspond to owl dl and its profile. 
we present the logic sroiq4 show that it be both sound relative to classical sroiq and that its embed into sroiq be consequence preserve. 
we also examine paraconsistent variety of el++ dl lite and horn dls. 
the general framework describe here have the distinct advantage of allow classical reasoner to draw sound but nontrivial conclusion from even inconsistent knowledge basis. 
truth value gap and glut can also be selectively eliminate from model by insert additional axiom into knowledge basis. 
if gap but not glut be eliminate additional classical conclusion can be draw without affect paraconsistency. 
weibull multiplicative model and machine learning model for full automatic dark spot detection from sar images. 
as a major aspect of marine pollution oil release into the sea have serious biological and environmental impact. 
among remote sense system which be a tool that offer a non destructive investigation method synthetic aperture radar sar can provide valuable synoptic information about the position and size of the oil spill due to its wide area coverage and day night and all weather capability. 
in this paper we present a new automate method for oil spill monitoring. 
a new approach be base on the combination of weibull multiplicative model and machine learn technique to differentiate between dark spot and the background. 
first the filter create base on weibull multiplicative model be apply to each sub image. 
second the sub image be segment by two different neural network technique pulse coupled neural networks and multilayer perceptron neural networks. 
as the last step a very simple filter process be use to eliminate the false target. 
the propose approach be test on 20 envisat and ers2 image which contain dark spot. 
the same parameter be use in all test. 
for the overall dataset the average accuracy of 94.05 and 95.20 be obtain for pcnn and mlp method respectively. 
the average computational time for dark spot detection with a 256x256 image in about four s for pcnn segmentation use idl software which be the fast one in this field at present. 
our experimental result demonstrate that the propose approach be very fast robust and effective. 
the propose approach can be apply to the future spaceborne sar image. 
prediction of lung tumor type base on protein attribute by machine learning algorithm. 
early diagnosis of lung cancer and distinction between the tumor type small cell lung cancer sclc and non small cell lung cancer nsclc be very important to increase the survival rate of patient. 
herein we propose a diagnostic system base on sequence derive structural and physicochemical attribute of protein that involve in both type of tumor via feature extraction feature selection and prediction model. 
1497 protein attribute computed and important feature select by 12 attribute weighting model and finally machine learning model consist of seven svm model three ann model and two nb model apply on original database and newly create one from attribute weight model model accuracy calculate through 10 fold cross and wrapper validation just for svm algorithm. 
in line with our previous finding dipeptide composition autocorrelation and distribution descriptor be the most important protein feature select by bioinformatics tool. 
the algorithm performance in lung cancer tumor type prediction increase when they apply on dataset create by attribute weighting model rather than original dataset. 
wrapper validation perform well than x validation the good cancer type prediction result from svm and svm linear model 82. 
the good accuracy of ann gain when neural net model apply on svm dataset 88. 
this be the first report suggest that the combination of protein feature and attribute weighting model with machine learning algorithm can be effectively use to predict the type of lung cancer tumor sclc and nsclc. 
embody information in structural timber. 
the formal and material variety of timber element in pre industrial building reflect the bio diversity of available forest and of the craft knowledge to exploit it. 
industrialization diminish the formal richness of wood building woodland and woodwork. 
how this essay characterize formal elaboration and variety as physically embody information. 
historically as machine make it cheap to impart energy to material their speed and their geometric limitation make it hard to impart information. 
the essay sketch out basic category of embody information and describe the impact of industrialization upon each. 
today s information tool enable we to engage once again in certain formal elaboration but in way that cost energy and that strip further information out of our cultivation and our culture of wood. 
the final section of the paper explore what truly post industrial wood building might look like and the pragmatic challenge it would face. 
towards self optimization in hpc i o. 
performance analysis and optimization of high performance i o system be a daunting task. 
mainly this be due to the overwhelmingly complex interplay of internal process while execute application program. 
unfortunately there be a lack of monitor tool to reduce this complexity to a bearable level. 
for these reason the project scalable i o for extreme performance siox aim to provide a versatile environment for record system activity and learn from this information. 
while still under development siox will ultimately assist in locate and diagnose performance problem and automatically suggest and apply performance optimization. 
the siox knowledge path be concern with the analysis and utilization of datum describe the cause and effect chain record via the monitoring path. 
in this paper we present our refined modular design of the knowledge path. 
this include a description of logical component and their interface detail about extract store and retrieve abstract activity pattern a concept for tie knowledge to these pattern and the integration of machine learning. 
each of these task be illustrate through example. 
the feasibility of our design be far demonstrate with an internal component for anomaly detection permit intelligent monitoring to limit the siox system s impact on system resource. 
extreme learning machine approach for on line voltage stability assessment. 
in recent year voltage instability have become a major threat for the operation of many power system. 
this paper propose a scheme for on line assessment of voltage stability of a power system for multiple contingency use an extreme learning machine elm technique. 
extreme learning machine be single hide layer feed forward neural network where the training be restrict to the output weight in order to achieve fast learning with good performance. 
elm be compete with neural networks as tool for solve pattern recognition and regression problem. 
a single elm model be develop for credible contingency for accurate and fast estimation of the voltage stability level at different loading condition. 
loading margin be take as the indicator of voltage instability. 
precontingency voltage magnitude and phase angle at the load bus be take as the input variable. 
the training datum be obtain by run continuation power flow cpf routine. 
the effectiveness of the method have be demonstrate through voltage stability assessment in ieee 30 bus system. 
to verify the effectiveness of the propose elm method its performance be compare with the multi layer perceptron neural network mlpnn. 
simulation result show that the elm give fast and more accurate result for on line voltage stability assessment compare with the mlpnn. 
multiscale and multilevel wavelet analysis of mammogram use complex neural network. 
mammography be an effective tool for early detection of breast cancer. 
the various abnormality such as microcalcification clusters masses spiculated lesion asymmetry and architectural distortion be strong marker of breast cancer. 
efficient diagnosis of these abnormality from mammograms rely heavily on the kind of feature extract and the selection of classifier. 
in this paper a novel methodology for microcalcification detection use multilevel wavelet analysis and phase encoded complex extreme learning machine be propose. 
generally complex neural network operate only on complex feature for classification. 
however pecelm enable transform the real value feature to the complex domain to exploit the orthogonal decision boundary of complex value classifier for solve real value classification problem. 
this proposed methodology base on multiscale and multilevel wavelet analysis on complex domain achieve an average efficiency of 95.41 and a maximum efficiency of 100. 
identify dynamic data structures by learn evolving patterns in memory. 
we investigate whether dynamic datum structure in pointer program can be identify by analyse program execution only. 
this paper describe a first step towards solve this problem by apply machine learning and pattern recognition technique to analyse execution of c program. 
by search for repeat temporal pattern in memory cause by multiple invocation of data structure operation we be able to first locate and then identify these operation. 
apply a prototypic tool implement our approach to pointer program that employ list queue and stack we show that the identify operation can accurately determine the data structure use. 
improve the contribution of climate model information to decision make the value and demand of robust decision framework. 
in this paper we review the need for use of and demand on climate modeling to support so call robust decision framework in the context of improve the contribution of climate information to effective decision making. 
such framework seek to identify policy vulnerability under deep uncertainty about the future and propose strategy for minimize regret in the event of break assumption. 
we argue that currently there be a severe underutilization of climate model as tool for support decision making and that this be slow progress in develop informed adaptation and mitigation response to climate change. 
this underutilization stem from two root cause about which there be a grow body of literature one a widespread but limiting conception that the usefulness of climate model in planning begin and end with regional scale prediction of multidecadal climate change two the general failure so far to incorporate learn from the decision and social science into climate relate decision support in key sector. 
we far argue that address these root cause will require expand the conception of climate model not simply as prediction machine within predict then act decision framework but as scenario generator source of insight into complex system behavior and aid to critical thinking within robust decision framework. 
such a shift however would have implication for how user perceive and use information from climate model and ultimately the type of information they will demand from these modelsand thus for the type of simulation and numerical experiment that will have the most value for inform decision making. 
wires clim change 2013 4:3960. 
doi 10.1002 wcc.202 for further resource relate to this article please visit the wires website. 
this article be a u.s. 
government work and as such be in the public domain in the united states of america. 
from scientific literacy to lifelong research a social innovation approach. 
scientific literacy do not equal teaching and learn science in public education. 
it be a complex set of knowledge of method approach attitude and skill. 
on the other side multiply the number of scientifically literate citizen help to overcome the control crisis of contemporary science which need a real copernican turnabout to turn new brain into problem solve research mega machine. 
between the age of 12 and 18 everybody can think and work as a scientist of course it do not mean that everybody will be a scientist. 
but everybody can learn to deal with scientific issue as a part of research community even after their school life. 
we call this paradigm lifelong research our online workflow platform palaestria support define planning organize perform and disseminate hybrid research project. 
its feature stock exchange of subject scientific application store publication module reward engine and implementation plan of this future orient online tool will be present. 
on line svm learning via an incremental primal dual technique. 
support vector machine svm be very powerful tool for datum classification and pattern recognition problem. 
they have be prove to have very good generalization performance in practice. 
in many real life situation the datum to be train be available on line and batch training method be not suitable. 
here we propose a new algorithm to efficiently train svm in such situation. 
the training problem be express as a general nonlinear optimization problem with special decomposition property. 
the idea of incremental gradient technique be use and apply to interior point method and more precisely to a primal dual technique. 
computational result be give for various training datum set and the result be compare with those of the other state of the art on line training algorithm as well as of the batch training method. 
it be show that the propose algorithm achieve good result in term of prediction accuracy as well as cpu time performance. 
a single machine carryover sequence dependent group scheduling in pcb manufacturing. 
this paper consider the problem of minimize the makespan on a single machine with carryover sequence dependent setup time. 
a similar problem with multi machine flow shop usually arise in the assembly of print circuit board pcb. 
this research investigate the possibility of process all component of pcb use just one machine. 
by do so the operational cost of have multi machine can be reduce and as a result find an optimal solution might be more plausible. 
the objective be to minimize the maximum completion time of all board group commonly know as makespan. 
the operational constraint be such that all board type within a board group must be completely kitte as it be traditionally perform by kitte staff before that board group begin its assembly operation. 
we introduce the external setup kitting time and require that it be perform solely by the machine operator during the run time of the current board group and thereby completely eliminate the need for kitte staff. 
the carryover sequence dependent setup time namely the internal machine setup time be realize when a new board group be ready for assembly operation and be dependent on all of the previously schedule board group and their sequence. 
to the good of our knowledge this be the first time the external and internal setup time be integrate in pcb group scheduling research. 
we develop a branch and bind algorithm and a lower bound structure. 
the lower bind consist of two approach which enable the algorithm to simultaneously reduce perform unnecessary exploration. 
in order to test the efficiency of the algorithm several problem instance with different board group have be use. 
the algorithm develop require a significantly large computation time to optimally solve very large problem. 
thus to speak for the efficiency in term of solve comparable large industry size problem we evaluate the deviation of the algorithm from the low bind which turn out to be very small with an average of only six in all of the problem instance consider. 
c 2012 elsevier ltd. 
all right reserve. 
genensemble a new model for the combination of classifier and integration of biological knowledge apply to genomic datum. 
in the last year microarray technology have become widely use in relevant biomedical area such as drug target identification pharmacogenomic or clinical research. 
however the necessary prerequisite for the development of valuable translational microarray base diagnostic tool be i a solid understanding of the relative strength and weakness of underlie classification method and ii a biologically plausible and understandable behaviour of such model from a biological point of view. 
in this paper we propose a novel classifier able to combine the advantage of ensemble approach with the benefit obtain from the true integration of biological knowledge in the classification process of different microarray sample. 
the aim of the current work be to guarantee the robustness of the propose classification model when apply to several microarray datum in an inter dataset scenario. 
the comparative experimental result demonstrate that our proposal work with biological knowledge outperform other well know simple classifier and ensemble alternative in binary and multiclass cancer prediction problem use publicly available datum. 
c 2012 elsevier ltd. 
all right reserve. 
the transformation of surgery patient care with a clinical research information system. 
implement a computerized clinical research information system cris can make clinical research easy and more efficient while improve patient care by provide surgeon with performance feedback. 
to transform the original manual patient information management system so it deliver patient care this study develop a cris for cardiovascular disease to facilitate surgery treatment tracking. 
the cris track hundred of piece of datum through surgical stage and convert these datum into computerized registry provide surveillance mechanism and generate clinical interpretive report in a timely manner. 
surgeon can use the cris to identify surgical relate datum and interventional cardiovascular procedure risk base on specific patient characteristic and it have increase the quality and efficiency of patient care. 
an intelligent datum analysis ida tool base on the weka library that seamlessly integrate with the cris have help provide model for clinical research. 
c 2012 elsevier ltd. 
all right reserve. 
electronic detection of lameness in dairy cow through measure pedometric activity and lie behavior. 
the objective of this research be to evaluate the efficiency of electronic measurement of activity and lie behavior by alt pedometer to recognize different behavior pattern between non lame and lame cow. 
the sensor be use to measure the activity and lie behavior include the total time spend lie down the number of lie bout the duration of each bout for individual cow and maximal minimal bout duration. 
a total of 30 lactate holstein dairy cow be select base on their locomotion score nrs two. 
these cow be gait score accord to a five point numerical rating system nrs and categorize during the experiment as nrs two nrs three nrs 3.5. 
this result in a dataset of 549 label day from eleven cow in total with approximately the same amount of lame and non lame day. 
huge difference in daily behavior between individual cow be observe. 
those difference be significantly large than the change in daily behavior cause by lameness for each cow. 
therefore it be conclude that threshold and usage of the absolute value be not feasible to predict lameness for all cow. 
hence instead of use absolute measurement for prediction the deviation from normal behavior be use for classification. 
as this deviation be in some feature equally likely to differ in positive and negative direction non linear prediction model have to be use. 
in addition single feature be not informative enough to reveal lameness and thus a model combine all feature for prediction be necessary. 
for classification support vector machines with an rbf kernel be use. 
in contrast to a prediction accuracy of 65 from the model derive for absolute value we be able to predict lameness with an accuracy of 76 use the deviation from normal behavior as feature. 
our result demonstrate that alt pedometer measurement in combination with machine learning tool have the potential to detect lameness accurately on farm. 
c 2012 elsevier b.v. 
all right reserve. 
a computational model for compressed sense rnai cellular screening. 
background rna interference rnai become an increasingly important and effective genetic tool to study the function of target gene by suppress specific gene of interest. 
this system approach helps identify signal pathway and cellular phase type by track intensity and/or morphological change of cell. 
the traditional rnai screen scheme in which one sirna be design to knockdown one specific mrna target need a large library of sirnas and turn out to be time consume and expensive. 
result in this paper we propose a conceptual model call compressed sense rnai csrnai which employ a unique combination of group of small interfere rnas sirnas to knockdown a much large size of gene. 
this strategy be base on the fact that one gene can be partially bind with several small interfere rnas sirnas and conversely one sirna can bind to a few gene with distinct bind affinity. 
this model construct a multi to multi correspondence between sirnas and their target with sirnas much few than mrna target compare with the conventional scheme. 
mathematically this problem involve an underdetermined system of equation linear or nonlinear which be ill pose in general. 
however the recently develop compressed sensing cs theory can solve this problem. 
we present a mathematical model to describe the csrnai system base on both cs theory and biological concern. 
to build this model we first search nucleotide motif in a target gene set. 
then we propose a machine learn base method to find the effective sirnas with novel feature such as image feature and speech feature to describe an sirna sequence. 
numerical simulation show that we can reduce the sirna library to one third of that in the conventional scheme. 
in addition the feature to describe sirnas outperform the exist one substantially. 
conclusion this csrnai system be very promising in save both time and cost for large scale rnai screen experiment which may benefit the biological research with respect to cellular process and pathway. 
identify the status of genetic lesion in cancer clinical trial document use machine learning. 
background many cancer clinical trial now specify the particular status of a genetic lesion in a patient s tumor in the inclusion or exclusion criterion for trial enrollment. 
to facilitate search and identification of gene associate clinical trial by potential participant and clinician it be important to develop automate method to identify genetic information from narrative trial document. 
method we develop a two stage classification method to identify gene and genetic lesion status in clinical trial document extract from the national cancer institute s nci s physician data query pdq cancer clinical trial database. 
the method consist of two step one to distinguish gene entity from non gene entity such as english word and two to determine whether and which genetic lesion status be associate with an identify gene entity. 
we develop and evaluate the performance of the method use a manually annotate datum set contain 1,143 instance of the eight most frequently mention gene in cancer clinical trial. 
in addition we apply the classifier to a real world task of cancer trial annotation and evaluate its performance use a large sample size 4,013 instance from 249 distinct human gene symbol detect from 250 trial. 
result our evaluation use a manually annotate datum set show that the two stage classifier outperform the single stage classifier and achieve the good average accuracy of 83.7 for the eight most frequently mention gene when optimize feature set be use. 
it also show well generalizability when we apply the two stage classifier train on one set of gene to another independent gene. 
when a gene neutral two stage classifier be apply to the real world task of cancer trial annotation it achieve a high accuracy of 89.8 demonstrate the feasibility of develop a gene neutral classifier for this task. 
conclusion we present a machine learning base approach to detect gene entity and the genetic lesion statuse from clinical trial document and demonstrate its use in cancer trial annotation. 
such method would be valuable for build information retrieval tool target gene associate clinical trial. 
implementation of computerized prescriber order entry in four academic medical center. 
purpose. 
lesson learn through the transition to computerized prescriber order entry cpoe at four academic medical center be review. 
summary. 
cpoe be an important strategy in effort to improve medication and patient safety and achieve compliance with federal health care information technology objective. 
pharmacy lead cpoe implementation team at brigham and women s hospital georgia health sciences health system uc health university hospital and university of utah hospitals and clinics be challenge to overcome different type of resource staffing and hardware software constraint. 
their collective experience point to a number of factor that be essential to successful cpoe implementation include one involvement you all ancillary personnel in system planning development implementation and refinement two selection of cpoe equipment that offer a high level of interoperability with exist information system and automate dispense machine three development of electronic order set and clinical decision support cds tool that be design for ease of use and tailor to the hospital s clinical workflow and four dedication of adequate resource and time for staff training technical support and system troubleshoot and maintenance. 
in particular facility transition to cpoe must secure initial and ongoing physician input and feedback to ensure patient safety and reduce cds relate problem and other barrier to broad system acceptance. 
conclusion. 
before implement cpoe address institutional consideration pertain to system selection preimplementation preparation staff training necessary equipment program rollout and postimplementation maintenance can increase the likelihood of a smooth transition to cpoe and optimal system performance. 
be j health syst pharm. 
2012 69:2166 73. 
effect of meteorological forcing on coastal eutrophication model with model tree. 
the exploration of process lead to coastal eutrophication be a major challenge in ecological research particularly in light of important new policy such as the european water framework directive. 
in the present study primary production in term of chlorophyll alpha chl alpha be model base on a number of abiotic parameter use model tree mts a machine learning ml approach whereby linear regression be induce within homogeneous subset of sample tree leave. 
standardized regression be apply to determine the relative weight of abiotic parameter in the mt tree leave whereas the efficiency of the mt method in chl alpha prediction be test against neural network nns which be the most frequently use ml approach and the classical multiple linear regression mlr. 
to assess the efficiency of model to describe eutrophication relate response under different environmental condition the method be apply on a coastal ecosystem affect by terrestrial runoff for two meteorologically contrast annual cycle a typical dry 04  05 and a typical wet 09  10. 
mts show increase predictive power in chl alpha prediction attribute to the discrimination of input data space into tree leave instead of use a uniform space as in nn and mlr. 
by group sample of each test annual cycle wet and dry on a seasonal basis into discrete group leave mt offer a much more explanatory description of ecosystem status than nns and mlr. 
the discriminate variable form tree leave and the weigh coefficient of linear models lms in each leaf provide a useful scaling of abiotic parameter drive chl alpha dynamic. 
the mt method be thus propose as an efficient tool for obtain insight into ecosystem process lead to eutrophication event in coastal ecosystem and a useful component in integrate coastal zone management. 
c 2012 elsevier ltd. 
all right reserve. 
hierarchical virtual screening for the discovery of new molecular scaffold in antibacterial hit identification. 
one of the initial step of modern drug discovery be the identification of small organic molecule able to inhibit a target macromolecule of therapeutic interest. 
a small proportion of these hit be far develop into lead compound which in turn may ultimately lead to a market drug. 
a commonly use screening protocol use for this task be high throughput screening hts. 
however the performance of hts against antibacterial target have generally be unsatisfactory with high cost and low rate of hit identification. 
here we present a novel computational methodology that be able to identify a high proportion of structurally diverse inhibitor by search unusually large molecular database in a time cost  and resource efficient manner. 
this virtual screening methodology be test prospectively on two version of an antibacterial target type ii dehydroquinase from mycobacterium tuberculosis and streptomyce coelicolor for which hts have not provide satisfactory result and consequently you all know inhibitor be derivative of the same core scaffold. 
overall our protocol identify 100 new inhibitor with calculate k i range from four to 250 mu m confirm hit rate be 60 and 62 against each version of the target. 
most importantly over 50 new active molecular scaffold be discover that underscore the benefit that a wide application of prospectively validate in silico screening tool be likely to bring to antibacterial hit identification. 
dynamic analysis and design guideline of mechanical oscillator for cut soil through vibrate tool. 
the reduction of the soil cut force through vibrate tool be the object of many study during the second half of the last century. 
these study initially focus on soil movement by bulldozer and then on soil tillage in agriculture. 
over the past year the field of tree nursery mechanization have be employ this knowledge due to the use of equipment with oscillate tool for root ball plant. 
transportation and planting must be perform with the root contain in a hemispherical ball of the original soil. 
this hemispherical root ball be obtain by use a vibrate semicircular blade that cut the soil underneath the plant. 
the blade oscillator be complex because the blade must oscillate and advance in the frame to cut the root ball. 
for this reason we correlate the oscillation and cut movement with the oscillator feature through a dynamic analysis use the hong s formulae for coulomb friction with a harmonic force torque. 
the result periodic motion have a substantial phase lag with respect to the force torque generate by the rotation of eccentric masse instead the amplitude predict with the coulomb friction be 15 low than the amplitude calculate without friction. 
experiment be also conduct to verify the value of these amplitude and to determine the correlation between the cut torque of the blade in typical tree nursery soil and the blade diameter. 
all the correlation propose in this article together with the perform literature survey be useful for draft new design guideline for mechanical oscillator. 
pac bayes bounds with data dependent priors. 
this paper present the prior pac bayes bind and explore its capability as a tool to provide tight prediction of svm generalization. 
the computation of the bind involve estimate a prior of the distribution of classifier from the available datum and then manipulate this prior in the usual pac bayes generalization bind. 
we explore two alternative to learn the prior from a separate data set or to consider an expectation prior that do not need this separate datum set. 
the prior pac bayes bind motivate two svm like classification algorithm prior svm and eta prior svm whose regularization term push towards the minimization of the prior pac bayes bind. 
the experimental work illustrate that the new bound can be significantly tight than the original pac bayes bind when apply to svm and among they the combination of the prior pac bayes bind and the prior svm algorithm give the tight bind. 
flow shop scheduling problem use fuzzy approach. 
in this paper we present fuzzy scheduling approach to the modern engineering and industrial manufacturing unit. 
these unit be face lot of problem in many aspect such as processing time of job setup time of machine raw material man power electricity and customer s constraint. 
in a real production scheduling environment there exist various internal or external uncertainty due to incomplete knowledge or uncertain production environment it be often difficult to model all parameter in the scheduling system with crisp value. 
when a new job start processing such a complex problem of vagueness and uncertainty can be handle by the theory of fuzzy logic. 
here we propose fuzzy model with flexible constraint impose on the processing capacity. 
the task be to find a schedule which achieve maximum level of satisfaction as well as minimal setup and hold cost. 
fuzzy flow shop scheduling problem fssp be solve by use fuzzy triangular membership function ftmf. 
rough set base feature weighted kernels for support vector machine. 
support vector machine svm be a popular classification paradigm in machine learning and have achieve great success in real application. 
the standard svm neglect the relative significance of each feature with respect to the classification task. 
rough set be a valid mathematic tool to handle imprecision uncertainty and vagueness. 
conventionally the rough set base feature significance be adopt as heuristic information for feature selection. 
in this paper the problem of improve svm by use feature weigh kernel with rough set base feature significance be consider. 
in more detail the propose method first estimate the relative significance of each feature by rough set theory and then utilize the significance as feature weight to adjust the kernel function in svm. 
in this way the svm can avoid be dominate by trivial relevant or irrelevant feature and lead to an improvement of the generalization performance. 
the propose method be demonstrate with some uci machine learn benchmark example. 
optimal assembly of support vector regressors with application to system monitoring. 
power plant be high complexity system run risk of low frequency but high consequence. 
the field of machine learning appear to offer the necessary tool for develop automate instrument surveillance system support decision making in critical system such as power station. 
a novel prediction method be present with the aim to enhance system safety and performance by make an ahead of time prediction of the status of fundamental system component and subsequent detection of abnormality. 
the utilization of a linear assembly of support vector regressor employ unique kernel be propose in a hybrid computational scheme that encompass the formulation of a multi objective optimization problem address with an evolutionary algorithm that employ pareto theory to identify an optimal solution. 
the approach be test on the ahead of time prediction of the crack length in power plant turbine blade utilize historical datum. 
the result obtain highlight the efficiency of the propose methodology since well performance over the standalone support vector regressor be observe. 
boost three d geometric feature for efficient face recognition and gender classification. 
we utilize idea from two grow but disparate idea in computer vision shape analysis use tool from differential geometry and feature selection use machine learning to select and highlight salient geometrical facial feature that contribute most in three d face recognition and gender classification. 
first a large set of geometry curve feature be extract use level set circular curve and streamline radial curve of the euclidean distance function of the facial surface together they approximate facial surface with arbitrarily high accuracy. 
then we use the well know adaboost algorithm for feature selection from this large set and derive a composite classifier that achieve high performance with a minimal set of feature. 
this greatly reduce set consist of some level curve on the nose and some radial curve in the forehead and cheek region provide a very compact signature of a three d face and a fast classification algorithm for face recognition and gender selection. 
it be also efficient in term of datum storage and transmission cost. 
experimental result carry out use the frgcv2 dataset yield a rank one face recognition rate of 98 and a gender classification rate of 86 rate. 
nonparametric statistical analysis for multiple comparison of machine learning regression algorithms. 
in the paper we present some guideline for the application of nonparametric statistical test and post hoc procedure devise to perform multiple comparison of machine learning algorithm. 
we emphasize that it be necessary to distinguish between pairwise and multiple comparison test. 
we show that the pairwise wilcoxon test when employ to multiple comparison will lead to overoptimistic conclusion. 
we carry out intensive normality examination employ ten different test show that the output of machine learning algorithm for regression problem do not satisfy normality requirement. 
we conduct experiment on nonparametric statistical test and post hoc procedure design for multiple one x n and n x n comparison with six different neural regression algorithm over 29 benchmark regression data set. 
our investigation prove the usefulness and strength of multiple comparison statistical procedure to analyse and select machine learning algorithm. 
model for identification of erroneous atom to atom mapping of reactions perform by automated algorithms. 
machine learning svm and jrip rule learner method have be use in conjunction with the condensed graph of reaction cgr approach to identify error in the atom to atom mapping of chemical reaction produce by an automate mapping tool by chem axon. 
the modeling have be perform on the three first enzymatic class of metabolic reaction from the kegg database. 
each reaction have be convert into a cgr represent a pseudomolecule with conventional single double aromatic etc bond and dynamic bond characterize chemical transformation. 
the chem axon tool be use to automatically detect the match atom pair in reagent and product. 
these automate mapping be analyze by the human expert and classify as correct or wrong. 
isida fragment descriptor generate for cgr for both correct and wrong mapping be use as attribute in machine learning. 
the learned model have be validate in n fold cross validation on the training set follow by a challenge to detect correct and wrong mapping within an external test set of reaction never use for learn. 
result show that both svm and jrip model detect most of the wrongly map reaction. 
we believe that this approach could be use to identify erroneous atom to atom mapping perform by any automated algorithm. 
predict the distribution of out of reach biotope with decision tree in a swedish marine protect area. 
through spatially explicit predictive model knowledge of spatial pattern of biota can be generate for out of reach environment where there be a paucity of survey datum. 
this knowledge be invaluable for conservation decision. 
we use distribution modeling to predict the occurrence of benthic biotope or megafaunal community of the seabed to support the spatial planning of a marine national park. 
nine biotope class be obtain prior to modeling from multivariate specie datum derive from point source underwater imagery. 
five map layer relate to depth and terrain be use as predictor variable. 
biotope type be predict on a pixel by pixel basis where pixel size be 15315 m and total model area be 455 km(2. 
to choose a suitable modeling technique we compare the performance of five common model base on recursive partitioning two type of classification and regression tree prune by 10 fold cross validation and prune by minimize complexity random forest conditional inference ci tree and ci forest. 
the select model be a ci forest an ensemble of ci tree a machine learn technique whose discriminatory power class byclass area under the curve auc range from 0.75 to 0.86 and classification accuracy 72 surpass those of the other method test. 
conditional inference tree be virtually new to the field of ecology. 
the final model s overall prediction error be 28. 
model prediction be also check against a custom build measure of dubiousness calculate at the polygon level. 
key factor other than the choice of modeling technique include the use of a multinomial response account for the heterogeneity of observation and spatial autocorrelation. 
to illustrate how the model result can be implement in spatial planning representation of biodiversity in the national park be describe and quantify. 
give a goal of maximize classification accuracy we conclude that conditional inference tree be a promise tool to map biota. 
species distribution modeling be present as an ecological tool that can handle a wide variety of system e.g. the benthic system. 
pit corrosion behaviour of austenitic stainless steel use artificial intelligence technique. 
different artificial intelligent tool have be use to model pit corrosion behaviour of en 1.4404 austenitic stainless steel. 
sample from this material have be subject to polarization test in different chloride solution use different precursor salt nacl and mgcl2. 
the aim of this work be to compare the result obtain from the different classification model use both solution study the influence of they. 
furthermore in order to determine pit potential value e pit different environmental condition have be test vary chloride ion concentration ph value and temperature. 
the technique use try to find the relation between the environmental parameter study and the status pit corrosion of this alloy. 
several classification technique have be use classification trees ct discriminant analysis da k nearest neighbours k nn back propagation neural networks bpnn and support vector machine svm. 
the result obtain show the good correlation between experimental and predict datum for all the case study demonstrate the utility of artificial intelligence for model pitting corrosion problem. 
c 2012 elsevier b.v. 
all right reserve. 
landscape analysis of wetland plant functional type the effect of image segmentation scale vegetation class and classification method. 
remote sense base analysis of vegetation function such as photosynthesis and productivity be challenge in wetland with complex cover and difficult field access. 
recent advance in object base image analysis obia and machine learn algorithm offer new image classification tool however few comparison of different approach have be discuss to date. 
we apply obia to delineate wetland plant functional type pfts for poyang lake the large freshwater lake in china and ramsar wetland conservation site from a spring 2008 landsat tm image. 
we target major pft that represent dominant vegetation group along wetland inundation gradient and affect ecosystem biogeochemical cycle and ecological habitat. 
classification result be compare among a several small object segmentation scale with average object size 1350 9000 m(2 b algorithm from six family of statistical machine learn classifier bayesian logistic neural network decision trees k nearest neighbors and support vector machines and c two hierarchical level of vegetation classification a generalize three class set and a more specific six class set. 
we also examine the response of classification accuracy to four basic object level texture metric. 
the high accuracy 85 90 and good agreement among algorithm occur at coarser object scale rather than close to pixel scale. 
no single machine learn algorithm be consistently superior at all scale although support vector machine k near neighbor and artificial neural network most frequently provide the high overall and pft specific accuracy. 
include texture metric have both positive and negative low magnitude effect on classification accuracy that be not consistent among scale value algorithm or pft class. 
individual pft differ in scale at which they be well discriminate from other reflect their unique landscape position ecology of dominant specie and disturbance agent. 
there be a 29 35 disagreement between map area of generalized pft and their respective subclass suggest potential mismatch between the ecological classification scheme and pft landscape patch structure and raise concern on error propagation in multi scale classification. 
we conclude that obia with machine learn classifier be useful for landscape vegetation analysis however consideration of spatial scale and image segmentation outcome be critical in map pft and should be more thoroughly investigate in future work. 
c 2012 elsevier inc. 
all right reserve. 
a collaborative video annotation system base on semantic web technologies. 
in recent year video have become more and more a familiar multimedia format for common user. 
in particular the advent of web 2.0 and the spreading of video sharing service over the web have lead to an explosion of online video content. 
the capability to provide broad support in access and explore video content and in general other kind of multimedia format as image and document be become more and more important. 
in this context the value of semantically structure datum and metadata be recognize as a key factor both to improve search efficiency and to guarantee datum interoperability. 
this latter aspect be critical to connect different heterogeneous content come from a variety of datum source. 
on the other hand the annotation of video resource have be increasingly understand as a medium factor to enable deep analysis of content and collaborative study of online digital object. 
however as exist annotation tool provide poor support for semantically structure content or in some case express the semantic in proprietary and non interoperable format such knowledge that user build by carefully annotate content hardly cross the boundary of a single system and often can not be reuse by different community e.g. to classify content or to discover new relation among resource. 
in this paper a novel semantic web base annotation system be present that enable user annotation to form semantically structure knowledge at different level of granularity and complexity. 
annotation can be reuse by external application and mix with web of data source to enable serendipity the reuse of datum produce for a specific task annotation by different people and in different context from the one datum originate from. 
the main idea behind the approach be to build on ontology and support linking at data level to precise thesauri and vocabulary as well as to the linked open data cloud. 
by describe the software model develop in the context of semlib eu project and by provide an implementation of an online video annotation tool the main aim of this paper be to demonstrate how such technology can enable a scenario where user annotation be create while browse the web naturally share among user store in machine readable format and then possibly recombine with external datum and ontology to enhance end user experience. 
wimp web server tool for miss datum imputation. 
the imputation of unknown or missing datum be a crucial task on the analysis of biomedical dataset. 
there be several situation where it be necessary to classify or identify instance give incomplete vector and the existence of miss value can much degrade the performance of the algorithm use for the classification recognition. 
the task of learn accurately from incomplete datum raise a number of issue some of which have not be completely solve in machine learning application. 
in this sense effective missing value estimation method be require. 
different method for miss datum imputation exist but most of the time the selection of the appropriate technique involve test several method compare they and choose the right one. 
furthermore apply these method in most case be not straightforward as they involve several technical detail and in particular in case such as when deal with microarray dataset the application of the method require huge computational resource. 
as far as we know there be not a public software application that can provide the computing capability require for carry the task of datum imputation. 
this paper present a new public tool for miss datum imputation that be attach to a computer cluster in order to execute high computational task. 
the software wimp web imputation be a public available web site where register user can create execute analyze and store their simulation relate to miss datum imputation. 
c 2012 elsevier ireland ltd. 
all right reserve. 
a systematic approach for an accuracy level use rapid prototyping technology. 
nowadays there have emerge a series of rapid prototype process with great potential and designer and engineer need to know the accuracy performance of these process to compare and select the good solution. 
there be a significant lack of publish datum relate to rapid prototype process and feature accuracy. 
this research be conduct to minimize this gap and provide much need accuracy in term of dimensional and geometric information. 
the methodology include the summarization of previous study and definition of a benchmarke part that be compose of elementary shape representative of different feature most likely to be find in a final product. 
the benchmarke part be control in term of dimensional accuracy geometric precision and freeform deviation. 
the source of error control by the final user be analyse like standard tessellation language stl file format resolution and build direction. 
four custom rapid prototype process have be use and compare stereolithography selective laser sinter fuse deposition modelling and three dimensional printer. 
computer numerically control machining have be use as an alternative prototyping process in this study as a standard to compare cost and accuracy. 
this work assess measure that can be use to quantify the accuracy performance for a give part so that the choice for prototype can be make base on scientific knowledge and good work practice. 
these result be very useful for design product to be prototype or manufacture through direct method. 
the result can be use to improve the functionality of prototype and the decision process through the good systematic approach. 
adaptive execution of an nc program with feed rate optimization. 
the use of adaptive feed rate shorten machining time and increase the potential of efficient machining. 
currently feed rate in an numerically control nc program be pre set constant value that be often determine base on the job shop experience gain over the year by skilled operator. 
there be no such way to adapt feed rate to on go cut condition since the feed rate be set before the nc code be execute. 
in this study an optimizer for canonical machining command opticmc have be develop. 
fuzzy adaptive control be use to keep a constant cutting load by adjust feed rate automatically to the cut condition. 
the result show that optimum feed rate can be achieve and control during the machining process consider the machine tool s capability and limitation. 
the develop opticmc help achieve machine optimization shorten machining time and increase product quality. 
towards a global control strategy for induction motor speed regulation flux optimization and power factor correction. 
a great deal of interest have be pay to induction machine control over the last year. 
however most previous work have focus on the speed flux torque regulation suppose the machine magnetic circuit to be linear and ignore the machine power conversion equipment. 
the point be that speed regulation can not be ensure in optimal efficiency condition for a wide range of speed set point and load torque unless the magnetic circuit nonlinearity be explicitly account for in the motor model. 
on the other hand the negligence of the power conversion equipment make it impossible to deal properly with the harmonic pollution issue due to motor power supply grid interaction. 
this paper present a theoretical framework for a global control strategy of the induction machine and related power equipment. 
the propose strategy involve a multi loop nonlinear adaptive controller design to meet the three main control objective tight speed regulation for a wide range speed reference variation flux optimization for energy consumption and power factor correction pfc. 
tool from the averaging theory be resort to formally describe the control performance. 
crown copyright c 2012 publish by elsevier ltd. 
all right reserve. 
mlp neural network base decision for power transformer fault diagnosis use an improved combination of rogers and doernenburg ratio dga. 
dissolve gas analysis dga be a widely use method to detect the power transformer fault because of its high sensitivity to small amount of electrical fault. 
the dga be exploit for fault classification tool implementation use the artificial intelligence technique. 
in this study we use the rogers ratio the doernenburg ratio method and our propose combination of rogers and doernenburg ratio dga method as gas signature. 
the multi layer perceptron neural network mlpnn be apply for decision making. 
the paper present a comparative study on one hand for the choice the most appropriate dga method and to resolve the problem of conflict between the rogers and doernenburg ratio method. 
on the other hand it compare the various mlp architecture by compare two output datum type and three hide layer type with the aim to establish the most appropriate mlp model. 
before testing the propose structure be train and test by the experimental datum from tunisian company of electricity and gas steg. 
the test result suggest that mlpnn ratio combination can generalize well than other mlpnn model. 
the approach have the advantage of high accuracy. 
the other advantage be that the model be practically applicable and may be utilize for an automate power transformer diagnosis. 
the classification accuracy of the mlpnn classifier be compare with fuzzy logic fl radial basis function rbf k near neighbor knn and probabilistic neural network pnn classifier. 
the test result indicate that the develop preprocessing approach can significantly improve the diagnosis accuracy for power transformer fault classification. 
c 2012 elsevier ltd. 
all right reserve. 
metalocgramn a meta predictor of protein subcellular localization for gram negative bacteria. 
subcellular localization be a key functional characteristic of protein. 
it be determine by signal encode in the protein sequence. 
the experimental determination of subcellular localization be laborious. 
thus a number of computational method have be develop to predict the protein location from sequence. 
however prediction make by different method often disagree with each other and it be not always clear which algorithm perform good for the give cellular compartment we benchmarke primary subcellular localization predictor for protein from gram negative bacteria psortb3. 
pslpred cello and sosui gramn on a common dataset that include 1056 protein. 
we find that psortb3 perform well on the average but be outperform by other method in prediction of extracellular protein. 
this motivate we to develop a meta predictor which combine the primary method by use the logistic regression model to take advantage of their combine strength and to eliminate their individual weakness. 
metalocgramn run the primary method and base on their output classifie protein sequence into one of five major localization of the gram negative bacterial cell cytoplasm plasma membrane periplasrn outer membrane and extracellular space. 
metalocgramn achieve the average matthews correlation coefficient of 0.806 12 well than the good individual primary method. 
metalocgramn be a meta predictor specialize in predict subcellular localization for protein from gram negative bacteria. 
accord to our benchmark it perform well than all other tool run independently. 
metalocgramn be a web and soap server available for free use you all academic user at the url http://iimcb.genesilico.pl/metalocgramn. 
this article be part of a special issue entitle computational methods for protein interaction and structural prediction. 
c 2012 elsevier b.v. 
all right reserve. 
an affordance base framework for human computation and human computer collaboration. 
visual analytics be the science of analytical reasoning facilitate by visual interactive interface. 
the goal of this field be to develop tool and methodology for approach problem whose size and complexity render they intractable without the close coupling of both human and machine analysis. 
researcher have explore this coupling in many venue vast vis infovis chi kdd iui and more. 
while there have be myriad promise example of human computer collaboration there exist no common language for compare system or describe the benefit afford by design for such collaboration. 
we argue that this area would benefit significantly from consensus about the design attribute that define and distinguish exist technique. 
in this work we have review 1,271 paper from many of the top rank conference in visual analytic human computer interaction and visualization. 
from these we have identify 49 paper that be representative of the study of human computer collaborative problem solve and provide a thorough overview of the current state of the art. 
our analysis have uncover key pattern of design hinge on human  and machine intelligence affordance and also indicate unexplored avenue in the study of this area. 
the result of this analysis provide a common framework for understand these seemingly disparate branch of inquiry which we hope will motivate future work in the field. 
determination of trace element in bovine semen sample by inductively couple plasma mass spectrometry and datum mining technique for identification of bovine class. 
the reproductive performance of cattle may be influence by several factor but mineral imbalance be crucial in term of direct effect on reproduction. 
several study have show that element such as calcium copper iron magnesium selenium and zinc be essential for reproduction and can prevent oxidative stress. 
however toxic element such as lead nickel and arsenic can have adverse effect on reproduction. 
in this paper we apply a simple and fast method of multi element analysis to bovine semen sample from zebu and european class use in reproduction program and artificial insemination. 
sample be analyze by inductively couple plasma spectrometry icp ms use aqueous medium calibration and the sample be dilute in a proportion of 1:50 in a solution contain 0.01 vol vol triton x 100 and 0.5 vol vol nitric acid. 
rhodium iridium and yttrium be use as the internal standard for icp ms analysis. 
to develop a reliable method of trace the class of bovine seman we use datum mining technique that make it possible to classify unknown sample after check the differentiation of know class sample. 
base on the determination of 15 element in 41 sample of bovine seman three machine learn tool for classification be apply to determine cattle class. 
our result demonstrate the potential of support vector machine svm multilayer perceptron mlp and random forest rf chemometric tool to identify cattle class. 
moreover the selection tool make it possible to reduce the number of chemical element need from 15 to just eight. 
discovery of factor influence citation impact base on a soft fuzzy rough set model. 
in this paper the machine learning tool be use to identify key feature influence citation impact. 
both the paper external and quality information be consider in construct paper feature space. 
base on the feature space the soft fuzzy rough set be use to generate a series of associate feature subset. 
then the knn classifier be use to find the feature subset with the good classification performance. 
the result show that citation impact could be predict by objectively assess factor. 
both the paper quality and external feature mainly represent as the reputation of the first author be contribute to future citation impact. 
evolutionary response surface for classification an interpretable model. 
response surface be powerful tool for both classification and regression because they be able to model many different phenomenon and construct complex boundary between class. 
with very simple expression response surface be able to accurately solve difficult problem. 
thus the interpretability of the result be very interesting from the point of view of the expert which be provide by a classification model from which useful information may be infer. 
however response surface suffer from a major problem that limit their applicability. 
even with a low degree and a moderate number of feature the number of term in the surface be extremely large. 
thus standard learning algorithm find many problem to efficiently obtain the coefficient of the term and the risk of overfitting be high. 
to overcome this problem we present evolutionary response surface for the classification of two class problem. 
the use of a fitness function that combine accuracy and interpretability obtain accurate classifier that be simple and interpretable by the expert. 
the result obtain for 20 problem from the uci machine learning repository be comparable with well know classification algorithm with a more interpretable polynomial function. 
survey on data drive industrial process monitoring and diagnosis. 
this paper provide a state of the art review of the method and application of data drive fault detection and diagnosis that have be develop over the last two decade. 
the scope of the problem be describe with reference to the scale and complexity of industrial process operation where multi level hierarchical optimization and control be necessary for efficient operation but be also prone to hard failure and soft operational fault that lead to economic loss. 
commonly use multivariate statistical tool be introduce to characterize normal variation and detect abnormal change. 
far diagnosis method be survey and analyze with fault detectability and fault identifiability for rigorous analysis. 
challenge opportunity and extension be summarize with the intent to draw attention from the system and control community and the process control community. 
c 2012 elsevier ltd. 
all right reserve. 
empirical methods for the study of denotation in nominalizations in spanish. 
this article deal with deverbal nominalization in spanish concretely we focus on the denotative distinction between event and result nominalization. 
the goal of this work be twofold first to detect the most relevant feature for this denotative distinction and second to build an automatic classification system of deverbal nominalization accord to their denotation. 
we have base our study on theoretical hypothesis deal with this semantic distinction and we have analyze they empirically by mean of machine learning technique which be the basis of the adn classifier. 
this be the first tool that aim to automatically classify deverbal nominalization in event result or underspecified denotation type in spanish. 
the adn classifier have help we to quantitatively evaluate the validity of our claim regard deverbal nominalization. 
we set up a series of experiment in order to test the adn classifier with different model and in different realistic scenario depend on the knowledge resource and natural language processor available. 
the adn classifier achieve good result 87.20 accuracy. 
review of microwave assisted manufacturing technologies. 
this paper review recent advancement of microwave mw assist manufacturing technology. 
because mw energy interact with material in unique way mw assist manufacturing technology have the potential to develop entirely new or enhanced manufacture product and material as well as new approach for produce such material. 
there have be various field mw technology have be apply material processing of ceramic polymer metal carbon nanotube and composite machining synthesis of organic and inorganic compound waste remediation and environmental application solvent extraction from food and bioproduct. 
this review introduce some fundamental knowledge of mw and current status of mw application focus on manufacture technology. 
also some suggestion for future research be address. 
analyse syntactic regularities and irregularities in snomed ct. 
motivation in this paper we demonstrate the usage of rio a framework for detect syntactic regularity use cluster analysis of the entity in the signature of an ontology. 
quality assurance in ontology be vital for their use in real application as well as a complex and difficult task. 
it be also important to have such method and tool when the ontology lack documentation and the user can not consult the ontology developer to understand its construction. 
one aspect of quality assurance be check how well an ontology complie with establish code standard be the ontology regular in how description of different type of entity be axiomatise be there a similar way to describe they and be there any corner case that be not cover by a pattern detection of regularity and irregularity in axiom pattern should provide ontology author and quality inspector with a level of abstraction such that compliance to code standard can be automate. 
however there be a lack of such reverse ontology engineering method and tool. 
result rio framework allow regularity to be detect in an owl ontology repetitive structure in the axiom of an ontology. 
we describe the use of standard machine learning approach to make cluster of similar entity and generalise over their axiom to find regularity. 
this abstraction allow match to and deviation from an ontology s pattern to be show. 
we demonstrate its usage with the inspection of three module from snomed ct a large medical terminology that cover present and absent finding as well as chronic and acute finding. 
the module size be five 065 20 688 and 19 812 asserted axiom. 
they be analyse in term of their type and number of regularity and irregularity in the asserted axiom of the ontology. 
the analysis show that some module of the terminology which be expect to instantiate a pattern describe in the snomed ct technical guide be find to have a high number of regularity deviation. 
a subset of these be categorise as design defect by verify they with past work on the quality assurance of snomed ct. 
these be mainly incomplete description. 
in the bad case the expect pattern describe in the technical guide be follow by only five of the axiom in the module. 
conclusion it be possible to automatically detect regularity and then inspect irregularity in an ontology. 
we argue that rio be a tool to find and report such match and mismatch for evaluation by the domain expert. 
we have demonstrate that standard clustering technique from machine learning can offer a tool in the drive for quality assurance in ontology. 
logic base event recognition. 
today s organization require technique for automate transformation of their large datum volume into operational knowledge. 
this requirement may be address by use event recognition system that detect event activity of special significance within an organization give stream of low level information that be very difficult to be utilize by human. 
consider for example the recognition of attack on node of a computer network give the transmission control protocol internet protocol message the recognition of suspicious trader behaviour give the transaction in a financial market and the recognition of whale song give a symbolic representation of whale sound. 
various event recognition system have be propose in the literature. 
recognition system with a logic base representation of event structure in particular have be attract considerable attention because among other they exhibit a formal declarative semantic they have prove to be efficient and scalable and they be support by machine learning tool automate the construction and refinement of event structure. 
in this paper we review representative approach of logic base event recognition and discuss open research issue of this field. 
we illustrate the review approach with the use of a real world case study event recognition for city transport management. 
train in coordinate measurement use 3d virtual instrument. 
coordinate metrology be a subject that have evolve drive by two important vector hardware and software development. 
at present most 3d measure software offer feature for offline programming of the coordinate measuring machines cmm. 
a few software solution enable the simulation of both the cmm and other element involve in the measuring process such as the human operator or an automate system for loading and unload the measure part. 
the paper present the feature and advantage offer by delmia v5 for simulate a complete measuring environment encompass the cmm the human operator a robot or automate system for manipulate the part. 
the simulation develop represent a powerful learning tool that can complement exist model for cmm training. 
c 2011 elsevier ltd. 
all right reserve. 
high performance concrete compressive strength prediction use time weighted evolutionary fuzzy support vector machines inference model. 
the major different between high performance concrete hpc and conventional concrete be essentially the use of mineral and chemical admixture. 
these two admixture make hpc mechanical behavior act differently compare to conventional concrete at microstructure level. 
certain property of hpc be not fully understand since the relationship between ingredient and concrete property be highly nonlinear. 
therefore predict hpc behavior be relatively difficult compare to predict conventional concrete behavior. 
this paper propose an artificial intelligence hybrid system to predict hpc compressive strength that fuse fuzzy logic fl weight support vector machines wsvm and fast messy genetic algorithm fmga into an evolutionary fuzzy support vector machine inference model for time series data efsimt. 
validation result show that the efsimt achieve high performance in comparison with support vector machines svm and obtain result comparable with back propagation neural network bpn. 
hence efsimt offer strong potential as a valuable predictive tool for hpc compressive strength. 
c 2012 elsevier b.v. 
all right reserve. 
ontology learning reviste. 
the term ontology come from the field of philosophy that be concern with the study of be or existence. 
in general computer science define ontology as an explicit specification of a conceptualization which be the object concept and other entity that be presume to exist in some area of interest and the relationship that hold among they. 
ontology hold a great importance to modern knowledge base system. 
they enable shared knowledge and reuse where information resource can be communicate between human or software agentsand should be machine readable. 
manual construction of ontology be an expensive and time consume task. 
an answer to this problem be to provide an automatic or semi  automatic tool for ontology construction. 
over the past year this field of research have not yet reach the goal of fully automate the ontology development process. 
in this paper we will review the ontology creation process with the help of ontology learning ol and extend our previous ol framework. 
we will examine ol application with respect to the extension of our framework. 
and last we will define a roadmap for future work. 
on the differential benchmarking of promotional efficiency with machine learning modeling i principle and statistical comparison. 
sale promotion have become in recent year a paramount issue in the marketing strategy of many company and they have even more relevance in the present economic situation. 
currently the empirical model aim at assess consumer behavior in response to certain sale promotion activity such as temporary price reduction be receive grow attention in this relevant research field due to two reason mainly one the complexity of the interaction among the different element incorporate inside promotion campaign attract grow attention and two the increase availability of electronic record on sale history. 
hence it will become important that the performance description and comparison among all available machine learning promotion model as well as their design parameter selection will be perform use a robust and statistically rigorous procedure while keep functionality and usefulness. 
in this paper we first propose a simple nonparametric statistical tool base on the pair bootstrap resampling to allow an operative result comparison among different learning from sample promotional model. 
secondly we use the bootstrap statistical description to evaluate the model in term of average and scatter measurement for a more complete efficiency characterization of the promotional sale model. 
these statistical characterization allow we to readily work with the distribution of the actual risk in order to avoid overoptimistic performance evaluation in the machine learn base model. 
we also present the analysis perform to determinate whether the figure of merit have a significant impact on final result together with an in depth design parameter selection to optimize final result during the promotion evaluation use statistical learning technique. 
no significant difference be obtain in term of figure of merit choice and mean absolute error be select for performance measurement. 
as a summary the apply technique allow clarify the design of the promotional sale model for a real database milk category accord to the influence of the figure of merit use for design parameter selection show the robustness of the machine learn technique in this setting. 
result obtain in this paper will be subsequently apply and present in the companion paper devote to a more detailed quality analysis to evaluate four well know machine learning algorithm in real database for two category with different promotional behavior. 
c 2012 elsevier ltd. 
all right reserve. 
intelligent decision making for liver fibrosis stadialization base on tandem feature selection and evolutionary drive neural network. 
hepatic fibrosis represent the principal pointer to the development of liver disease. 
the correct evaluation of its degree base on both recent non invasive procedure and machine learning model be of current major concern. 
one of the late medical imaging methodology for assess it be the fibroscan support by biochemical and clinical examination. 
since the complex interaction between the fibroscan stiffness indicator and the biochemical and clinical result be hard to be manually manage towards the liver fibrosis stadialization well perform machine learning algorithm have be propose to support an automatic diagnosis. 
we propose in this paper a tandem feature selection mechanism and evolutionary drive neural network as a computer base support for liver fibrosis stadialization in chronic hepatitis c. 
a synergetic system base on both specific statistical tool and the sensitivity analysis provide by neural network be use for reduce the dimension of the database from twenty five to just six attribute. 
an evolutionary train neural network be develop afterwards for the classification of the liver fibrosis stage. 
the tandem approach be direct and simple result from embed the feature selection system into the method structure in order to dynamically concentrate the search only on the most relevant attribute. 
experimental result and a thorough statistical analysis clearly demonstrate the efficiency of the propose intelligent system in comparison with other machine learning technique report in literature. 
c 2012 elsevier ltd. 
all right reserve. 
model base clustering and typologies in the social sciences. 
social scientist spend considerable energy construct typology and discuss their role in measurement. 
less discuss be the role of typology in evaluate and revise theoretical argument. 
we argue that unsupervised machine learning tool can be profitably apply to the development and testing of theory base typology. 
we review recent advance in mixture model as apply to cluster analysis and argue that these tool be particularly important in the social science where it be common to claim that high dimensional object group together in meaningful cluster. 
model base clustering mbc ground analysis in probability theory permit the evaluation of uncertainty and application of information base model selection tool. 
we show that the mbc approach force analyst to consider dimensionality problem that more traditional cluster tool obscure. 
we apply mbc to the variety of capitalism a typology receive significant attention in political science and economic sociology. 
we find weak and conflicting evidence for the theory s expect grouping. 
we therefore caution against the current practice of include typology derive dummy variable in regression and case comparison research design. 
increase splicing site prediction by train gene set base on species. 
biological datum have be increase exponentially in recent year and analyze these datum use datum mining tool have become one of the major issue in the bioinformatics research community. 
this paper focus on the protein construction process in high organism where the deoxyribonucleic acid or dna sequence be filter. 
in the process unmeaningful dna sub sequence call intron be remove and their meaningful counterpart call exon be retain. 
accurate recognition of the boundary between these two class of sub sequence however be know to be a difficult problem. 
conventional approach for recognize these boundary have seek for solely enhance machine learning technique while inherent nature of the datum themselves have be overlook. 
in this paper we present an approach which make use of the datum attribute inherent to specie in order to increase the accuracy of the boundary recognition. 
for experimentation we have take the data set for four different specie from the university of california santa cruz ucsc datum repository divide the datum set base on the species type then train a preprocesse version of the data set on neural network(nn) based and support vector machine(svm) base classifier. 
as a result we have observe that each specie have its own specific feature relate to the splice site and that it imply there be relate distance among specie. 
to conclude divide the training datum set base on specie would increase the accuracy of predict splice junction and propose new insight to the biological research. 
prosper an integrated feature base tool for predicting protease substrate cleavage sites. 
the ability to catalytically cleave protein substrate after synthesis be fundamental for all form of life. 
accordingly site specific proteolysis be one of the most important post translational modification. 
the key to understand the physiological role of a protease be to identify its natural substrate(s. 
knowledge of the substrate specificity of a protease can dramatically improve our ability to predict its target protein substrate but this information must be utilize in an effective manner in order to efficiently identify protein substrate by in silico approach. 
to address this problem we present prosper an integrated feature base server for in silico identification of protease substrate and their cleavage site for twenty four different protease. 
prosper utilize establish specificity information for these protease derive from the merops database with a machine learn approach to predict protease cleavage site by use different but complementary sequence and structure characteristic. 
feature use by prosper include local amino acid sequence profile predict secondary structure solvent accessibility and predict native disorder. 
thus for protease with know amino acid specificity prosper provide a convenient pre prepared tool for use in identify protein substrate for the enzyme. 
systematic prediction analysis for the twenty four protease thus far include in the database reveal that the feature we have include in the tool strongly improve performance in term of cleavage site prediction as evidence by their contribution to performance improvement in term of identify known cleavage site in substrate for these enzyme. 
in comparison with two state of the art prediction tool pops and siteprediction prosper achieve great accuracy and coverage. 
to our knowledge prosper be the first comprehensive server capable of predict cleavage site of multiple protease within a single substrate sequence use machine learning technique. 
it be freely available at http://lightning.med.monash.edu.au/prosper/.. 
get the word out neural correlate of enthusiastic message propagation. 
what happen in the mind of a person who first hear a potentially exciting idea we examine the neural precursor of sprreade idea with enthusiasm and dissect enthusiasm into component process that can be identify through automate linguistic analysis gestalt human rating of combined linguistic and non verbal cue and point of convergence divergence between the two. 
we combine tool from natural language processing nlp with datum gather use fmri to link the neurocognitive mechanism that be set in motion during initial exposure to idea and subsequent behaviour of these message communicator outside of the scanner. 
participant language from video tape interview collect post scan be transcribe and give to an automate linguistic sentiment analysis sa classifier which return rating for evaluative language evaluative vs. 
descriptive and valence positive vs. 
negative. 
separately human coder rate the enthusiasm with which participant transmit each idea. 
more positive sentiment rating by the automate classifier be associate with activation in neural region include medial prefrontal cortex mpfc precuneus posterior cingulate cortex pc pcc and medial temporal lobe mtl. 
more evaluative positive description be associate exclusively with neural activity in temporal parietal junction tpj. 
finally human rating indicative of more enthusiastic sentiment be associate with activation across these region mpfc pc pcc dmpfc tpj and mtl as well as in ventral striatum vs inferior parietal lobule and premotor cortex. 
take together these datum demonstrate novel link between neural activity during initial idea encoding and the enthusiasm with which the idea be subsequently deliver. 
this research lay the groundwork to use machine learning and neuroimaging datum to study word of mouth communication and the spread of idea in both traditional and new medium environment. 
development and experimental test of support vector machine virtual screening method for search src inhibitor from large compound library. 
background src play various role in tumour progression invasion metastasis angiogenesis and survival. 
it be one of the multiple target of multi target kinase inhibitor in clinical use and trial for the treatment of leukemia and other cancer. 
these success and appearance of drug resistance in some patient have raise significant interest and effort in discover new src inhibitor. 
various in silico method have be use in some of these effort. 
it be desirable to explore additional in silico method particularly those capable of search large compound library at high yield and reduce false hit rate. 
result we evaluate support vector machine svm as virtual screening tool for search src inhibitor from large compound library. 
svm train and test by 1,703 inhibitor and 63,318 putative non inhibitor correctly identify 93.53%similar to 95.01 inhibitor and 99.81%similar to 99.90 non inhibitor in five fold cross validation study. 
svm train by 1,703 inhibitor report before 2011 and 63,318 putative non inhibitor correctly identify 70.45 of the 44 inhibitor report since 2011 and predict as inhibitor 44,843 0.33 of 13.56 m pubchem 1,496 0.89 of 168 k mddr and 719 7.73 of 9,305 mddr compound similar to the know inhibitor. 
conclusion svm show comparable yield and reduce false hit rate in search large compound library compare to the similarity base and other machine learn vs method develop from the same set of training compound and molecular descriptor. 
we test three virtual hit of the same novel scaffold from in house chemical library not report as src inhibitor one of which show moderate activity. 
svm may be potentially explore for search src inhibitor from large compound library at low false hit rate. 
rapid measurement of total acid content tac in vinegar use near infrared spectroscopy base on efficient variable selection algorithm and nonlinear regression tool. 
total acid content tac be an important index in assess vinegar quality. 
this work attempt to determine tac in vinegar use near infrared spectroscopy. 
we systematically study variable selection and nonlinear regression in calibrate regression model. 
first the efficient spectra interval be select by synergy interval pls si pls then two nonlinear regression tool which be extreme learning machine elm and back propagation artificial neural network bp ann be attempt. 
experiment show that the model base on elm and si pls si elm be superior to other and the optimum result be achieve as follow the root mean square error of prediction rmsep be 0.2486 g/100 ml and the correlation coefficient r p be 0.9712 in the prediction set. 
this work demonstrate that the tac in vinegar could be rapidly measure by nir spectroscopy and si elm algorithm show its superiority in model calibration. 
c 2012 elsevier ltd. 
all right reserve. 
predict seminal quality with artificial intelligence method. 
fertility rate have dramatically decrease in the last two decade especially in man. 
it have be describe that environmental factor as well as life habit may affect semen quality. 
artificial intelligence technique be now an emerge methodology as decision support system in medicine. 
in this paper we compare three artificial intelligence technique decision tree multilayer perceptron and support vector machines in order to evaluate their performance in the prediction of the seminal quality from the datum of the environmental factor and lifestyle. 
to do that we collect datum by a normalize questionnaire from young healthy volunteer and then we use the result of a semen analysis to asse the accuracy in the prediction of the three classification method mention above. 
the result show that multilayer perceptron and support vector machines show the high accuracy with prediction accuracy value of 86 for some of the seminal parameter. 
